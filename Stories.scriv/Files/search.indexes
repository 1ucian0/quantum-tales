<?xml version="1.0" encoding="UTF-8"?>
<SearchIndexes Version="1.0">
    <Documents>
        <Document ID="86C8B548-3645-44E6-AA2B-0D5156B02DE8">
            <Title>quantum algorithm implementations for beginners</Title>
            <Text>Quantum Algorithm Implementations for Beginners
ABHIJITH J., ADETOKUNBO ADEDOYIN, JOHN AMBROSIANO, PETR ANISIMOV, AN- DREAS BÄRTSCHI, WILLIAM CASPER, GOPINATH CHENNUPATI, CARLETON COF- FRIN, HRISTO DJIDJEV, DAVID GUNTER, SATISH KARRA, NATHAN LEMONS, SHIZENG LIN, ALEXANDER MALYZHENKOV, DAVID MASCARENAS, SUSAN MNISZEWSKI, BALU NADIGA, DANIEL O’MALLEY, DIANE OYEN, SCOTT PAKIN, LAKSHMAN PRASAD, RANDY ROBERTS, PHILLIP ROMERO, NANDAKISHORE SANTHI, NIKOLAI SINITSYN, PIETER J. SWART, JAMES G. WENDELBERGER, BORAM YOON, RICHARD ZAMORA, WEI ZHU, STEPHAN EIDENBENZ∗, PATRICK J. COLES∗, MARC VUFFRAY∗, and ANDREY Y. LOKHOV∗,
Los Alamos National Laboratory, Los Alamos, New Mexico 87545, USA
As quantum computers become available to the general public, the need has arisen to train a cohort of quantum programmers, many of whom have been developing classical computer programs for most of their careers. While currently available quantum computers have less than 100 qubits, quantum computing hardware is widely expected to grow in terms of qubit count, quality, and connectivity. This review aims to explain the principles of quantum programming, which are quite different from classical programming, with straightforward algebra that makes understanding of the underlying fascinating quantum mechanical principles optional. We give an introduction to quantum computing algorithms and their implementation on real quantum hardware. We survey 20 different quantum algorithms, attempting to describe each in a succinct and self-contained fashion. We show how these algorithms can be implemented on IBM’s quantum computer, and in each case, we discuss the results of the implementation with respect to differences between the simulator and the actual hardware runs. This article introduces computer scientists, physicists, and engineers to quantum algorithms and provides a blueprint for their implementations.
Contents
Abstract 1 Contents 1 1 Introduction 3 1.1 The quantum computing programming model 4
1.1.1 The qubit 4
1.1.2 System of qubits 5
1.1.3 Superposition and entanglement 5
1.1.4 Inner and outer products 6
1.1.5 Measurements 7
1.1.6 Unitary transformations and gates 7
1.1.7 Observables and expectation values 9
1.1.8 Quantum circuits 11
1.1.9 Quantum algorithms 12
1.2 Implementations on a real quantum computer 12
1.2.1 The IBM quantum computer 12
1.2.2 Programming the IBM quantum computer: Qiskit library 14
1.3 Classes of quantum algorithms 16 2 Grover’s Algorithm 17 2.1 Problem definition and background 17
 ∗eidenben@lanl.gov; pcoles@lanl.gov; vuffray@lanl.gov; lokhov@lanl.gov. LA-UR-20-22353
arXiv:1804.03719v2 [cs.ET] 18 Mar 2020

2
Abhijith J., et al.
2.2 2.3 3 3.1 3.2 3.3 4 4.1 4.2 4.3 4.4 5 5.1 5.2 5.3 6 6.1 6.2 6.3 7 7.1 7.2 8 8.1 8.2 8.3 9 9.1 9.2 10 10.1 10.2 10.3 11 11.1 11.2 12 12.1 12.2 13 13.1 13.2 13.3 13.4 14 14.1 14.2 14.3
Algorithm description
Algorithm implemented on IBM’s 5-qubit computer Bernstein-Vazirani Algorithm
Problem definition and background
Algorithm description
Algorithm implemented on IBM’s 5-qubit and 16-qubit computers
Linear Systems
Problem definition and background
Algorithm description
Phase estimation
Algorithm implemented on IBM’s 5 qubit computer
Shor’s Algorithm for Integer Factorization
Problem definition and background
Algorithm description
Algorithm implemented on IBM’s 5-qubit computer
Matrix Elements of Group Representations
Problem definition and background
Algorithm description
Algorithm implemented on IBM’s 5-qubit computer
Quantum Verification of Matrix Products Problem definition and background Algorithm description
Group Isomorphism
Problem definition and background Algorithm description
Algorithm implemented using Qiskit
Quantum Persistent Homology Problem definition and background Quantum algorithm description
Quantum Random Walks
Problem definition and background
Example of a quantum random walk
Algorithm implementation using Qiskit on IBM Q
Quantum Minimal Spanning Tree Problem definition and background Algorithm description
Quantum Maximum Flow Analysis Problem definition and background Algorithm description
Quantum Approximate Optimization Algorithm Problem definition and background Algorithm description
QAOA MaxCut on ibmqx2
A proof-of-concept experiment Quantum Principal Component Analysis
Problem definition and background
Algorithm description
Algorithm implemented on IBM’s 5-qubit computer
18
19
19
19
20
21
23
23
23
24
26
28
28
29
31
32
32
36
37
38
38
38
40
40
40
42
43
43
45
47
47
48
49
50
50
51
54
54
56
57
57
58
59
61
62
62
63
65

Quantum Algorithm Implementations for Beginners 3
15
16
16.1
16.2
16.3
17
17.1
17.2
18
18.1
18.2
18.3
18.4
19
19.1
19.2
19.3
19.4
19.5
20
20.1
20.2
20.3
20.3.1
20.3.2
21
21.1
21.2
21.3
21.4
Acknowledgments 90 References 90
Quantum Support Vector Machine 66 Quantum Simulation of the Schrödinger Equation 67 Problem definition and background 67 Algorithm description 68 Algorithm implemented on IBM’s 5-qubit computer 69 Ground State of the Transverse Ising Model 70 Variational quantum eigenvalue solver 70 Simulation and results 72 Quantum Partition Function 74 Background on the partition function 74 A simple example 76 Calculating the quantum partition function 77 Implementation of a quantum algorithm on the IBM Quantum Experience 77 Quantum State Preparation 78 Single qubit state preparation 78 Schmidt decomposition 79 Two-qubit state preparation 81 Two-qubit gate preparation 81 Four qubit state preparation 82 Quantum Tomography 82 Problem definition and background 82 Short survey of existing methods 84 Implementation of the Maximum Likelihood method on 5-qubit IBM QX 85 Warm-up: Hadamard gate 85 Maximally entangled state for two qubits 86 Tests of Quantum Error Correction in IBM Q 87 Problem definition and background 87 Test 1: errors in single qubit control 88 Test 2: errors in entangled 3 qubits control 89 Discussion 89
1 INTRODUCTION
Quantum computing exploits quantum-mechanical effects—in particular superposition, entangle- ment, and quantum tunneling—to more efficiently execute a computation. Compared to traditional, digital computing, quantum computing offers the potential to dramatically reduce both execution time and energy consumption. These potential advantages, steady advances in nano-manufacturing, and the slow-down of traditional hardware scaling laws (such as Moore’s Law) have led to a substan- tial commercial and national-security interest and investment in quantum computing technology in the 2010s. Recently, Google announced that it has reached a major milestone known as quan- tum supremacy–the demonstration that a quantum computer can perform a calculation that is intractable on a classical supercomputer [8]. The problem tackled here by the quantum computer is not one with any direct real-world application. Nonetheless, this is a watershed moment for quantum computing and is widely seen as an important step on the road towards building quantum

4 Abhijith J., et al.
computers that will offer practical speedups when solving real-world problems [82]. (See [2] for a precise technical definition of quantum supremacy.)
While the mathematical basis of quantum computing, the programming model, and most quantum algorithms have been published decades ago (starting in the 1990s), they have been of interest only to a small dedicated community. We believe the time has come to make quantum algorithms and their implementations accessible to a broad swath of researchers and developers across computer science, software engineering, and other fields. The quantum programming model is fundamentally different from traditional computer programming. It is also dominated by physics and algebraic notations that at times present unnecessary entry barriers for mainstream computer scientists and other more mathematically trained scientists.
In this review, we provide a self-contained, succinct description of quantum computing and of the basic quantum algorithms with a focus on implementation. Since real quantum computers, such as IBM Q [55], are now available as a cloud service, we present results from simulator and actual hardware experiments for smaller input data sets. Other surveys of quantum algorithms with a different target audience and also without actual implementations include [10, 26, 58, 75, 76, 88]. Other cloud service based quantum computers are also available from Rigetti and IonQ, but in this review we will focus solely on IBM’s quantum computing ecosystem. The code and implementations accompanying the paper can be found at https://github.com/lanl/quantum_algorithms.
1.1 The quantum computing programming model
Here we provide a self-contained description of the quantum computing programming model. We will define the common terms and concepts used in quantum algorithms literature. We will not discuss how the constructs explained here are related to the foundations of quantum mechanics. Interested readers are encouraged to take a look at Ref. [77] for a more detailed account along those lines. Readers with a computer science background are referred to Refs. [67, 85, 110], for a more comprehensive introduction to quantum computing from a computer science perspective.
Quantum computing basically deals with the manipulation of quantum systems. The physical details of this is dependent on the quantum computer’s hardware design. Here we will only talk about the higher level abstractions used in quantum computing: a typical programmer will only be exposed to these abstractions. The state of any quantum system is always represented by a vector in a complex vector space (usually called a Hilbert space). Quantum algorithms are always expressible as transformations acting on this vector space. These basic facts follow from the axioms of quantum mechanics. Now we will explain some of the basic concepts and terminology used in quantum computing.
1.1.1 The qubit. The qubit (short for ’quantum bit’) is the fundamental information carrying unit used in quantum computers. It can be seen as the quantum mechanical generalization of a bit used in classical computers. More precisely, a qubit is a two dimensional quantum system. The state of a qubit can be expressed as,
|φ⟩ = α |0⟩ + β |1⟩ . (1) Here α and β are complex numbers such that, |α|2 + |β|2 = 1. In the ket-notation or the Dirac
􏰐1􏰑 􏰐0􏰑
notation, |0⟩ = 0 and |1⟩ = 1 are shorthands for the vectors encoding the two basis states of a
two dimensional vector space. So according to this notation, Eq. (1) expresses the fact that the state
􏰐α􏰑
of the qubit is the two dimensional complex vector β . Unlike a classical bit the state of a qubit
cannot be measured without changing it. Measuring a qubit, whose state given by Eq. (1), will yield

Quantum Algorithm Implementations for Beginners 5
the classical value of either zero (|0⟩) with probability |α|2 or one (|1⟩) with probability |β|2. Qubit implementations and technologies are a very active area of research that is not the focus of our review, an interested reader is referred to [65] for a survey.
1.1.2 System of qubits. The mathematical structure of a qubit generalizes to higher dimensional quantum systems as well. The state of any quantum system is a normalized vector (a vector of norm one) in a complex vector space. The normalization is necessary to ensure that the total probability of all the outcomes of a measurement sum to one.
A quantum computer contains many number of qubits. So it is necessary to know how to
construct the combined state of a system of qubits given the states of the individual qubits. The
joint state of a system of qubits is described using an operation known as the tensor product, ⊗.
Mathematically, taking the tensor product of two states is the same as taking the Kronecker product
􏰐α􏰑 of their corresponding vectors. Say we have two single qubit states |φ⟩ = β
the full state of a system composed of two independent qubits is given by,
αα′ 􏰐􏰑􏰐′􏰑 ′
′ and |φ ⟩ =
􏰐α′􏰑 β′
. Then
(2)
′ α α 􏰤􏰨αβ􏰥􏰩
|φ⟩ ⊗ |φ ⟩ = ⊗
β β 􏰨βα􏰩
Sometimes the ⊗ symbol is dropped all together while denoting the tensor product to reduce clutter. Instead the states are written inside a single ket. For example, |φ⟩ ⊗ |φ′⟩ is shortened to |φφ′⟩, and |0⟩ ⊗ |0⟩ ⊗ |0⟩ is shortened to |000⟩ . For larger systems the Dirac notation gives a more succinct way to compute the tensor product using the distributive property of the Kronecker product. For a system of, say, three qubits with each qubit in the state 􏰍􏰍γj 􏰌 = αj |0⟩ + βj |1⟩, for j = 1, 2, 3, the joint state is,
|γ1γ2γ3⟩ = |γ1⟩ ⊗ |γ2⟩ ⊗ |γ3⟩ (3) = α1α2α3 |000⟩ + α1α2β3 |001⟩ + α1β2α3 |010⟩ + α1β2β3 |011⟩
+ β1α2α3 |100⟩ + β1α2β3 |101⟩ + β1β2α3 |110⟩ + β1β2β3 |111⟩ (4)
A measurement of all three qubits could result in any of the eight (23) possible bit-strings associated with the eight basis vectors. One can see from these examples that the dimension of the state space grows exponentially in the number of qubits n and that the number of basis vectors is 2n .
1.1.3 Superposition and entanglement. Superposition refers to the fact that any linear combination of two quantum states, once normalized, will also be a valid quantum state. The upshot to this is that any quantum state can be expressed as a linear combination of a few basis states. For example, we saw in Eq. (1) that any state of a qubit can be expressed as a linear combination of |0⟩ and |1⟩. Similarly, the state of any n qubit system can be written as a normalized linear combination of the 2n bit-string states (states formed by the tensor products of |0⟩’s and |1⟩’s). The orthonormal basis formed by the 2n bit-string states is called the computational basis.
Notice that Eq. (3) described a system of three qubits whose complete state was the tensor product of three different single qubit states. But it is possible for three qubits to be in a state that cannot be written as the tensor product of three single qubit states. An example of such a state is,
|ψ⟩ = √1 (|000⟩ + |111⟩). (5) 2
States of a system of which cannot be expressed as a tensor product of states of its individual subsystems are called entangled states. For a system of n qubits, this means that an entalged state
′ = 􏰨 ′􏰩 ββ′
􏰦􏰧

6 Abhijith J., et al.
cannot be written a tensor product of n single qubit states. The existence of entangled states is a physical fact that has important consequences for quantum computing, and quantum information processing in general. In fact, without the existence of such states quantum computers would be no more powerful than their classical counterparts [108]. Entanglement makes it possible to create a complete 2n dimensional complex vector space to do our computations in, using just n physical qubits.
1.1.4 Inner and outer products. We will now discuss some linear algebraic notions necessary for understanding quantum algorithms. First of these is the inner product or overlap between two quantum states. As we have seen before, quantum states are vectors in complex vectors spaces. The overlap between two states is just the inner product between these complex vectors. For example, take two single qubit states, |φ⟩ = α |0⟩ + β |1⟩ and |ψ ⟩ = γ |0⟩ + δ |1⟩ . The overlap between these states is denoted in the ket notation as ⟨ψ |φ⟩. And this is given by,
⟨ψ|φ⟩ =γ∗α +δ∗β, (6)
where ∗ denotes the complex conjugate. Notice that,⟨ψ|φ⟩ = ⟨φ|ψ⟩∗. The overlap of two states is in general a complex number. The overlap of a state with a bit-string state will produce the corresponding coefficient. For instance from Eq. (1), ⟨0|φ⟩ = α and ⟨1|φ⟩ = β. And from Eq. (3), ⟨001|γ1γ2γ3⟩ = α1α2β3. Another way to look at overlaps between quantum states is by defining what is called a bra state. The states we have seen so far are ket states, like |φ⟩, which represented column vectors. A bra state corresponding to this ket state, written as ⟨φ|, represents a row vector
􏰐α􏰑 􏰇∗ ∗􏰈
with complex conjugated entries. For instance |φ⟩ = β implies that ⟨φ| = α β . The overlap
of two states is then the matrix product of a row vector with a column vector, yielding a single number. The reader must have already noticed the wordplay here. The overlap, with its closing angled parenthesis, form a ‘bra-ket’!
The outer product of two states is an important operation that outputs a matrix given two states. The outer product of the two states we defined above will be denoted by, |ψ⟩⟨φ|. Mathematically the outer product of two states is a matrix obtained by multiplying the column vector of the first state with the complex conjugated row vector of the second state (notice how the ket is written before the bra to signify this). For example,
􏰐α􏰑􏰇 ∗ ∗􏰈 􏰐αγ∗ αδ∗􏰑
|ψ⟩⟨φ|= β γ δ = βγ∗ βδ∗ (7)
In this notation any matrix can be written as a linear combination of outer products between bit-string states. For a 2 × 2 matrix,
􏰐A00 A01 􏰑
A= A10 A11 =A00 |0⟩⟨0|+ A01 |0⟩⟨1|+ A10 |1⟩⟨0|+ A11 |1⟩⟨1|. (8)
Acting on a state with a matrix then becomes just an exercise in computing overlaps between states. Let us demonstrate this process:
A|φ⟩=A00|0⟩⟨0|φ⟩+ A01|0⟩⟨1|φ⟩+ A10|1⟩⟨0|φ⟩+ A11|1⟩⟨1|φ⟩, 􏰐A00α +A01β􏰑
=(A00α+A01β)|0⟩+(A10α + A11β)|1⟩ = A10α+A11β . (9)
This notation might look tedious at first glance but it makes algebraic manipulations of quantum states easily understandable. This is especially true when we are dealing with large number of qubits as otherwise we would have to explicitly write down exponentially large matrices.

Quantum Algorithm Implementations for Beginners 7
The outer product notation for matrices also gives an intuitive input-output relation for them. For instance, the matrix |0⟩ ⟨1| + |1⟩ ⟨0| can be read as "output 0 when given a 1 and output 1 when given a 0". Likewise,the matrix, |00⟩ ⟨00| + |01⟩ ⟨01| + |10⟩ ⟨11| + |11⟩ ⟨10| can be interpreted as the mapping {"00" –&gt; "00", "01" –&gt; "01", "11" –&gt; "10", "10" –&gt; "11" }. But notice that this picture becomes a bit tedious when the input is in a superposition. In that case the correct output can be computed like in Eq. (9).
1.1.5 Measurements. Measurement corresponds to transforming the quantum information (stored in a quantum system) into classical information. For example, measuring a qubit typically corre- sponds to reading out a classical bit, i.e., whether the qubit is 0 or 1. A central principle of quantum mechanics is that measurement outcomes are probabilistic.
Using the aforementioned notation for inner products, for the single qubit state in Eq. (1), the probability of obtaining |0⟩ after measurement is | ⟨0|φ⟩ |2 and the probability of obtaining |1⟩ after measurement is | ⟨1|φ⟩ |2. So measurement probabilities can be represented as the squared absolute values of overlaps. Generalizing this, the probability of getting the bit string |x1 . . . xn ⟩ after measuring an n qubit state, |φ⟩, is then | ⟨x1 . . . xn |φ⟩ |2.
Now consider a slightly more complex case of measurement. Suppose we have a three qubit state, |ψ ⟩ but we only measure the first qubit and leave the other two qubits undisturbed. What is the probability of observing a |0⟩ in the first qubit? This probability will be given by,
􏰭
| ⟨0x2x3|φ⟩ |2. (10) (x2x3)∈{0,1}2
The state of the system after this measurement will be obtained by normalizing the state,
􏰭
⟨0x2x3|φ⟩ |0x2x3⟩ . (11) (x2x3)∈{0,1}2
Applying this paradigm to the state in Eq. (5) we see that the probability of getting |0⟩ in the first qubit will be 0.5, and if this result is obtained, the final state of the system would change to |000⟩ . On the other hand, if we were to measure |1⟩ in the first qubit we would end up with a state |111⟩ . Similarly we can compute the effect of subsystem measurements on any n qubit state.
In some cases we will need to do measurements on a basis different from the computational basis. This can be achieved by doing an appropriate transformation on the qubit register before measurement. Details of how to do this is given in a subsequent section discussing observables and expectation values.
The formalism discussed so far is sufficient to understand all measurement scenarios in this paper. We refer the reader to Ref. [77] for a more detailed and more general treatment of measurement.
1.1.6 Unitary transformations and gates. A qubit or a system of qubits changes its state by going through a series of unitary transformations. A unitary transformation is described by a matrix U with complex entries. The matrix U is called unitary if
UU† =U†U =I, (12)
where U † is the transposed, complex conjugate of U (called its Hermitian conjugate) and I is the identity matrix. A qubit state |φ⟩ = α |0⟩ + β |1⟩ evolves under the action of the 2 × 2 matrix U according to
􏰐U00 U01􏰑 􏰐α􏰑 􏰐U00α +U01β􏰑
|φ⟩→U|φ⟩= U10 U11 β = U10α+U11β . (13)

8 Abhijith J., et al.
Operators acting on different qubits can be combined using the Kronecker product. For example, if U1 and U2 are operators acting on two different qubits then the full operator acting on the combined two qubit system will be given by U1 ⊗ U2.
For an n qubit system the set of physically allowed transformations, excluding measurements, consists of all 2n × 2n unitary matrices. Notice that the size of a general transformation increases exponentially with the number of qubits. In practice a transformation on n qubits is effected by using a combination of unitary transformations that act only on one or two qubits at a time. By analogy to classical logic gates like NOT and AND, such basic unitary transformations, which are used to build up more complicated n qubit transformations, are called gates. Gates are unitary transformations themselves and from Eq. (12) it is clear that unitarity can only be satisfied if the number of input qubits is equal to the number of output qubits. Also, for every gate U it is always possible to have another gate U † that undoes the transformation. So unlike classical gates quantum gates have to be reversible. Reversible means that the gate’s inputs can always be reconstructed from the gate’s outputs. For instance, a classical NOT gate, which maps 0 to 1 and 1 to 0 is reversible because an output of 1 implies the input was 0 and vice versa. However, a classical AND gate, which returns 1 if and only if both of its inputs are 1, is not reversible. An output of 1 implies that both inputs were 1, but an output of 0 provides insufficient information to determine if the inputs were 00, 01, or 10.
But this extra restriction of reversibility does not mean that quantum gates are ‘less powerful’ than classical gates. Even classical gates can be made reversible with minimal overhead. Reversibility does not restrict their expressive power [87]. Quantum gates can then be seen as a generalization of classical reversible gates.
The most common gates are described in Table 1. The X gate is the quantum version of the NOT gate. The CNOT or “controlled NOT” negates a target bit if and only if the control bit is 1. We will use the notation CNOTij for a CNOT gate controlled by qubit i acting on qubit j. The CNOT gate can be expressed using the outer product notation as,
CNOT=|0⟩⟨0|⊗I+|1⟩⟨1|⊗X =|00⟩⟨00|+|01⟩⟨01|+|10⟩⟨11|+|11⟩⟨10|. (14)
The Toffoli gate or “controlled-controlled NOT” or CCNOT, is a three qubit gate that is essentially the quantum (reversible) version of the AND gate. It negates a target bit if and only if both control bits are 1. In the outer product notation,
CCNOT = |11⟩ ⟨11| ⊗ X + (I − |11⟩ ⟨11|) ⊗ I. (15) Another way to look at the CCNOT gate is as a CNOT gate with an additional control qubit,
CCNOT = |0⟩ ⟨0| ⊗ I + |1⟩ ⟨1| ⊗ CNOT. (16) In general, one can define controlled versions of any unitary gate U as,
CU =|0⟩⟨0|⊗I+|1⟩⟨1|⊗U. (17)
CU applies U to a set of qubits only if the first qubit (called the control qubit) is |1⟩.
A set of gates that together can execute all possible quantum computations is called a universal gate set. Taken together, the set of all unary (i.e., acting on one qubit) gates and the binary (i.e., acting on two qubits) CNOT gate form a universal gate set. More economically, the set {H,T,CNOT} (Refer Table 1 for definitions of these gates) forms a universal set. Also, the Toffoli gate by itself is
universal [77].

Quantum Algorithm Implementations for Beginners
9
 One-qubit gates
􏰐􏰑
1 1 1 Hadamard=H=√2 1 −1
􏰐􏰑􏰐􏰑
1 0 1 0 I = 0 1 , S = 0 i
Multi-qubit gates
    1000
􏰤􏰨 0 1 0 0 􏰥􏰩
CNOT=CX=􏰨􏰨 0 0 0 1 􏰩􏰩 0010
        T =
􏰐􏰑
1 0
􏰦􏰧
1000
􏰤􏰨 0 1 0 0 􏰥􏰩 C Z = 􏰨􏰨 0 0 1 0 􏰩􏰩
0 0 0 −1 􏰦􏰧
1000
􏰤􏰨 0 1 0 0 􏰥􏰩 Controlled-U =CU =􏰨 􏰩 􏰨 0 0 U00 U01 􏰩
0 0 U10 U11 􏰦􏰧
0 e
iπ/4
    􏰐􏰑
1000
􏰤􏰨 0 0 1 0 􏰥􏰩
0 1 NOT=X= 1 0
􏰐􏰑􏰐􏰑
SWAP=􏰨􏰨0 1 0 0􏰩􏰩 0001
    Y =
i
, Z =
0 0 −1
Toffoli = 􏰨
(CCNOT)
􏰩 00001000 􏰩
0−i 10
􏰦􏰧
10000000 􏰤01000000􏰥
􏰨􏰩
􏰨􏰨 0 0 1 0 0 0 0 0 􏰩􏰩
􏰨􏰨 00010000 􏰩􏰩
􏰐10􏰑 R(θ)=P(θ)= 0 eiθ
􏰨
􏰨􏰨 0 0 0 0 0 1 0 0 􏰩􏰩
􏰨􏰨 0 0 0 0 0 0 0 1 􏰩􏰩 􏰦00000010􏰧
  Table 1. Commonly used quantum gates.
1.1.7 Observables and expectation values. We have seen that experiments in quantum mechanics are probabilistic. Often in experiments we will need to associate a real number with a measurement outcome. And quantities that we measure in quantum mechanics will always be statistical averages of these numbers. For instance, suppose we do the following experiment on many copies of the single qubit state in Eq. (1): We measure a copy of the state and if we get |0⟩ we record 1 in our lab notebook , otherwise we record −1. While doing this experiment we can never predict the outcome of a specific measurement. But we can ask statistical questions like: “What will be the average value of the numbers in the notebook?” From our earlier discussion on measurement we know that the probability of measuring |0⟩ is |α|2 and the probability of measuring |1⟩ is |β|2. So the average value of the numbers in the notebook will be,
|α|2 − |β|2 (18)

10 Abhijith J., et al.
In quantum formalism, there is neat way to express such experiments and their average outcomes, without all the verbiage, using certain operators. For the experiment described above the associated operator would be the Z gate,
􏰐10􏰑
Z =|0⟩⟨0|−|1⟩⟨1|= 0 −1 (19)
By associating this operator with the experiment we can write the average outcome of the experi- ment, on |φ⟩, as the overlap between |φ⟩ and Z |φ⟩,
⟨φ|Z|φ⟩ = ⟨φ|0⟩ ⟨0|φ⟩ − ⟨φ|1⟩ ⟨1|φ⟩ = |α|2 − |β|2. (20)
The operator Z is called the observable associated with this experiment. And the quantity ⟨φ|Z|φ⟩ is called its expectation value. The expectation value is sometimes denoted by ⟨Z⟩, when there is no ambiguity about the state on which the experiment is performed.
Here we saw an experiment done in the computational basis. But this need not always be the case. Experiments can be designed by associating real numbers to measurement outcomes in any basis. What would be the observable for such an experiment? For an experiment that associates the real numbers {ai } to a measurement onto a basis set {|Φi ⟩}, the observable will be,
O ≡ 􏰭 ai |Φi ⟩ ⟨Φi | . (21) i
This observable will reproduce the correct expectation value for this experiment done on any state |ψ⟩,
⟨ψ|O|ψ⟩=􏰭ai ⟨ψ|Φi⟩⟨Φi|ψ⟩=􏰭ai|⟨Φi|ψ⟩|2. (22) ii
Because the states {|Φi ⟩} are orthonormal, we can see that O obeys the following eigenvalue equation,
O 􏰍􏰍Φj 􏰌 = 􏰭 ai |Φi ⟩ 􏰋Φi |Φj 􏰌 = aj 􏰍􏰍Φj 􏰌 . (23) i
So O is an operator that has complete set of orthogonal eigenvectors and real eigenvalues. Such operators are called Hermitian operators. Equivalently, these operators are equal to their Hermitian conjugates (O = O†). In quantum mechanics, any Hermitian operator is a valid observable. The eigenvectors of the operator give the possible outcomes of the experiment and the corresponding eigenvalues are the real numbers associated with that outcome.
But can all valid observables be measured in practice? The answer to this depends on the quantum system under consideration. In this tutorial, the system under consideration is an IBM quantum processor. And in these processors only measurements onto the computational basis are supported natively. Measurements to other basis states can be performed by applying an appropriate unitary transformation before measurement. Suppose that the hardware only lets us do measurements onto the computational basis {|i⟩} but we want to perform a measurement onto the basis set {|Φi ⟩}. This problem can be solved if we can implement the following unitary transformation,
U =􏰭|i⟩⟨Φi|. (24) i
Now measuring U |ψ ⟩ in the computational basis is the same as measuring |ψ ⟩ in the {|Φi ⟩} basis. This can be seen by computing the outcome probabilities on U |ψ ⟩,
|⟨j|U|ψ⟩|2 = |􏰭⟨j|i⟩⟨Φi|ψ⟩|2 = |􏰋Φj|ψ􏰌|2. (25) i

Quantum Algorithm Implementations for Beginners 11
So once U is applied, the outcome |j⟩ becomes equivalent to the outcome 􏰍􏰍Φj 􏰌 in the original measurement scenario. Now, not all such unitary transformations are easy to implement. So if a quantum algorithm requires us to perform a measurement onto some complicated set of basis states, then the cost of implementing the corresponding U has be taken into account.
1.1.8 Quantum circuits. Quantum algorithms are often diagrammatically represented as circuits in literature. Here we will describe how to construct and read quantum circuits. In the circuit representation, qubits are represented by horizontal lines. Gates are then drawn on the qubits they act on. This is done in sequence from left to right. The initial state of the qubit is denoted at the beginning of each of the qubit lines. Notice that when we write down a mathematical expression for the circuit, the gates are written down from right to left in the order of their application.
These principles are best illustrated by an example. Given in Fig. 1 is a circuit to preparing an entangled two qubit state called a Bell state from |00⟩.
|0⟩ H • |0⟩
Fig. 1. Quantum circuit for preparing a Bell state
The circuit encodes the equation,
CNOT12 (H ⊗ I) |00⟩ = √1 (|00⟩ + |11⟩). 2
Let us now carefully go over how the circuit produces the Bell state. We read the circuit from left to right. The qubits are numerically labelled starting from the top. First the H gate acts on the top most qubit changing the state of the system to,
 H⊗I|00⟩=(H|0⟩)⊗(I|0⟩)= √
⊗|0⟩=√ (|00⟩+|10⟩). 22
􏰐 |0⟩ + |1⟩ 􏰑 1
 Then CNOT12 acts on both of these qubits. The blackened dot on the first qubit implies that this qubit is the control qubit for the CNOT. The ⊕ symbol on the second qubit implies that this qubit is the target of the NOT gate (controlled by the state of the first qubit). The action of the CNOT then gives,
􏰐1􏰑11
CNOT12 √ (|00⟩ + |10⟩) = √ (CNOT12 |00⟩ + CNOT12 |10⟩) = √ (|00⟩ + |11⟩).
222
The measurement of a qubit is also denoted by a special gate with a meter symbol on it, given in Fig 2. The presence of this gate on a qubit means that the qubit must be measured in the computational basis.
Fig. 2. The measurement gate

12 Abhijith J., et al.
1.1.9 Quantum algorithms. We have now introduced all the basic elements needed for the discus- sion of practical quantum algorithms. A quantum algorithm consists of three basic steps:
• Encoding of the data, which could be classical or quantum, into the state of a set of input qubits.
• A sequence of quantum gates applied to this set of input qubits.
• Measurements of one or more of the qubits at the end to obtain a classically interpretable
result.
In this review, we will describe the implementation of these three steps for a variety of quantum algorithms.
1.2 Implementations on a real quantum computer
1.2.1 The IBM quantum computer. In this article, we consider IBM’s publicly available quantum computers. In most cases, we specifically consider the ibmqx4, which is a 5-qubit computer, although in some cases we also consider other quantum processors freely accessible through the IBM Quantum Experience platform. These processors can be accessed by visiting the IBM Quantum Experience website (https://quantum-computing.ibm.com/)
There are several issues to consider when implementing an algorithm on real quantum computers, for example:
(1) What is the available gate set with which the user can state their algorithm?
(2) What physical gates are actually implemented?
(3) What is the qubit connectivity (i.e., which pairs of qubits can two-qubit gates be applied to)? (4) What are the sources of noise (i.e., errors)?
We first discuss the available gate set. In IBM’s graphical interface to the ibmqx4, the available gates include:
{I,X,Y,Z,H,S,S†,T,T†,U1(λ),U2(λ,φ),U3(λ,φ,θ),CNOT}. (26)
The Graphical User Interface (GUI) also provides other controlled gates and operations like measure- ment and reset. Most of these gates appear in our Table 1. The gatesU1(λ),U2(λ,φ), andU3(λ,φ,θ) are continuously parameterized gates, defined as follows:
􏰐1 0􏰑 1 􏰐1 −eiλ 􏰑 􏰐 cos(θ/2) −eiλsin(θ/2)􏰑 U1(λ) = 0 eiλ , U2(λ,φ) = √2 eiφ ei(λ+φ) , U3(λ,φ,θ) = eiφ sin(θ/2) ei(λ+φ) cos(θ/2) .
(27)
Note that U3(λ,φ,θ) is essentially an arbitrary one-qubit gate.
The gates listed in Eq. (26) are provided by IBM for the user’s convenience. However these are
not the gates that are physically implemented by their quantum computer. IBM has a compiler that translates the gates in (26) into products of gates from a physical gate set. The physical gate set employed by IBM is essentially composed of three gates [1]:
{U1(λ),RX(π/2),CNOT}. (28) Here, RX (π /2) is a rotation by angle π /2 of the qubit about it’s X -axis, corresponding to a matrix
similar to the Hadamard:
1􏰐1 −i􏰑
RX(π/2)=√2 −i 1 . (29)
The reason why it could be important to know the physical gate set is that some user-programmed gates may need to be decomposed into multiple physical gates, and hence could lead to a longer

Quantum Algorithm Implementations for Beginners
13
1
023
4
Fig. 3. The connectivity diagram of ibmqx4. The circles represent qubits and the arrows represent the ability to apply a physical CNOT gate between the qubits.
physical algorithm. For example, the X gate gets decomposed into three gates: two RX (π /2) gates sandwiching one U1(λ) gate.
The connectivity of the computer is another important issue. Textbook algorithms are typically written for a fully-connected hardware, which means that one can apply a two-qubit gate to any two qubits. In practice, real quantum computers may not have full connectivity. In the ibmqx4, which has 5 qubits, there are 6 connections, i.e., there are only 6 pairs of qubits to which a CNOT gate can be applied (Fig.3). In contrast a fully connected 5-qubit system would allow a CNOT to be applied to 20 different qubit pairs. In this sense, there are 14 “missing connections”. Fortunately, there are ways to effectively generate connections through clever gate sequences. For example, a CNOT gate with qubit j as the control and qubit k as the target can be reversed (such that j is the target and k is the control) by applying Hadamard gates on each qubit both before and after the CNOT, i.e.,
CNOTkj =(H⊗H)CNOTjk(H⊗H). (30) Similarly, there exists a gate sequence to make a CNOT between qubits j and l if one has connections
between j and k, and k and l, as follows:
CNOTjl = CNOTkl CNOTjk CNOTkl CNOTjk . (31)
Hence, using (30) and (31), one can make up for lack of connectivity at the expense of using extra gates.
Finally, when implementing a quantum algorithm it is important to consider the sources of noise in the computer. The two main sources of noise are typically gate infidelity and decoherence. Gate infidelity refers to the fact that the user-specified gates do not precisely correspond to the physically implemented gates. Gate infidelity is usually worse for multi-qubit gates than for one-qubit gates, so typically one wants to minimize the number of multi-qubit gates in one’s algorithm. Decoherence refers to the fact that gradually over time the quantum computer loses its “quantumness” and behaves more like a classical object. After decoherence has fully occurred, the computer can no longer take advantage of quantum effects. This introduces progressively more noise as the quantum algorithm proceeds in time. Ultimately this limits the depth of quantum algorithms that can be implemented on quantum computers. It is worth noting that different qubits decohere at different rates, and one can use this information to better design one’s algorithm. The error rates for individual qubits in the IBM processors are listed in the IBM Quantum Experience website. In this tutorial, we will show in many cases how infidelity and decoherence affect the algorithm performance in practice.

14 Abhijith J., et al.
  Fig. 4. The quantum circuit to prepare a Bell state and measure it in the IBM quantum experience GUI
A simple example of programming the IBM quantum computer is given in Fig. 4, which shows the Bell state preparation circuit Fig.1 compiled using the IBM quantum experience GUI. Extra measurement operations at the end serve to verify the fidelity of the implementation.
1.2.2 Programming the IBM quantum computer: Qiskit library. Qiskit [3] is an open-source quantum computing library developed under the aegis of IBM. Qiskit allows users to write and run programs on either IBM’s quantum processors or on a local simulator, without the use of the graphical interface. This is an important feature because the graphical interface becomes impractical as the number qubits become large. At the time of writing, users can use Qiskit to access quantum processors with up to 16 qubits. Smaller processors are also accessible. Qiskit is a very powerful software development kit (SDK) which has multiple elements in it that tackle a variety of problems associated with practical quantum computing. Qiskit is further split into four modules called: Terra, Aer, Aqua, and Ignis. Each of these modules deal with a specific part of quantum software development. In this section we will only give a brief overview of programming simple quantum circuits with Qiskit. For a comprehensive overview of Qiskit and its various capabilities, the reader is encouraged to visit the official website ( www.qiskit.org ) [3].
For our purposes, Qiskit can be viewed as a Python library for quantum circuit execution. A basic Qiskit code has two parts, designing the circuit and running it. In the circuit design phase, we create an instance of QuantumCircuit with the required number of qubits and classical bits. Then gates and measurements are added to this blank circuit. Gates and measurements are implemented in Qiskit as methods of the QuantumCircuit class. After the circuit has been designed we need to choose a backend to run the circuit. This can be either be a simulator called the qasm_simulator or it can be one of IBM’s quantum processors. To use a quantum processor, you will need to load your IBM Q account information into Qiskit. Given in Fig. 5 is a simple code to construct the Bell state. This is the Qiskit version of the circuit in Fig. 1 with measurement added at the end to verify our results.

Quantum Algorithm Implementations for Beginners 15
### Quantum circuit for preparing the Bell state ####
import numpy as np
from qiskit import QuantumCircuit, execute, Aer
# Create a Quantum Circuit with two qbits and 2 classical bits
circuit = QuantumCircuit(2,2)
# Add a H gate on qubit 0
circuit.h(0)
# Add a CX (CNOT) gate on control qubit 0 and target qubit 1
circuit.cx(0,1)
# Map the quantum measurement to the classical bits
circuit.measure([0,1],[0,1])
# Use Aer's qasm_simulator
simulator = Aer.get_backend('qasm_simulator')
# Execute the circuit on the qasm simulator
job = execute(circuit, simulator, shots=1000)
# Grab results from the job
result = job.result()
# Returns counts
counts = result.get_counts(circuit) print("\nTotal count for 00 and 11 are:",counts)
Fig. 5. Qiskit code to create and measure a Bell state. Source: www.qiskit.org
In Fig.5 we are running the circuit on the simulator for 1000 independent runs. The final output |00⟩+|11⟩
was {'11': 493, '00': 507}. This is what we expect from measuring the Bell state ( √2 ), up
 to statistical fluctuations. While running the same code on the 14 qubit ibmq_16_melbourne processor for 1024 runs gave |11⟩ with probability 0.358 and |00⟩ with probability 0.54. The remaining probability was distributed over 01 and 10, which should not be a part of the Bell state. As we discussed before, this phenomenon is due to errors inherent to the quantum processor. As the backend technology improves we expect to get better results from these trials. Often, we will also present a circuit using OpenQASM (Open Quantum Assembly Language). OpenQASM provides an intermediate representation of a program in the form of a quantum circuit, that is neither the actual program written by the programmer nor the machine instructions seen by the processor. OpenQASM ‘scores’ we show in this paper will be simple sequence of gates and measurements, with the corresponding registers that they act on. The syntax of these scores will be self explanatory.

16
Abhijith J., et al.
 Class
Inverse Function Computation
Number-theoretic Applications Algebraic Applications
Graph Applications
Learning Applications
Quantum Simulation Quantum Utilities
Problem/Algorithm
Grover’s Algorithm Bernstein-Vazirani
Shor’s Factoring Algorithm
Linear Systems
Matrix Element Group Representations Matrix Product Verification
Subgroup Isomorphism
Persistent Homology
Quantum Random Walk
Minimum Spanning Tree Maximum Flow
Approximate Quantum Algorithms
Quantum Principal Component Analysis (PCA) Quantum Support Vector Machines (SVM) Partition Function
Schrödinger Equation Simulation Transverse Ising Model Simulation
State Preparation Quantum Tomography Quantum Error Correction
Paradigms used
GO n.a.
QFT
HHL QFT
GO
QFT GO, QFT
n.a. GO GO SIM
QFT QFT QFT
SIM VQE
n.a. n.a. n.a.
Hardware
QX4 QX4, QX5
QX4
QX4 ESSEX n.a. none QX4
VIGO QX4 QX4 QX4
QX4 none QX4
QX4 none
QX4 QX4 QX4
Simulation Match
med high
med
low
low
n.a.
n.a. med-low
med-low med-low med-low high
med
n.a. med-low
low n.a.
med med med
        Table 2. Overview of studied quantum algorithms. Paradigms include Grover Operator (GO), Quantum Fourier Transform (QFT), Harrow-Hassidim-Lloyd (HHL), Variational Quantum Eigenvalue solver (VQE), and direct Hamiltonian simulation (SIM). The simulation match column indicates how well the hardware quantum results matched the simulator results
1.3 Classes of quantum algorithms
In this review, we broadly classify quantum algorithms according to their area of application. We will discuss quantum algorithms for graph theory, number theory, machine learning and so on. The complete list of algorithms discussed in this paper, classified according to their application areas, can be found in Table 2. The reader is also encouraged to take a look at the excellent Quantum Algorithm Zoo website [58] for a concise and comprehensive list of quantum algorithms.
In classical computing, algorithms are often designed by making use of one or more algorithmic paradigms like dynamic programming or local search, to name a few. Most known quantum algorithms also use a combination of algorithmic paradigms specific to quantum computing. These paradigms are the Quantum Fourier Transform (QFT), the Grover Operator (GO), the Harrow- Hassidim-Lloyd (HHL) method for linear systems, variational quantum eigenvalue solver (VQE), and direct Hamiltonian simulation (SIM). The number of known quantum algorithmic paradigms is much smaller compared to the number of known classical paradigms. The constraint of unitarity on quantum operations and the impossibility of non-intrusive measurement make it difficult to design quantum paradigms from existing classical paradigms. But researchers are constantly in search for new paradigms and we can expect this list to get longer in the future. Table 2 also contains information about the paradigms used by the algorithms in this article.
The rest of the paper presents each of the algorithms shown in Table 2, one after the other. In each case, we first discuss the goal of the algorithm (the problem it attempts to solve). Then we describe the gate sequence required to implement this algorithm. Finally, we show the results from implementing this algorithm on IBM’s quantum computer1.
 1The code and implementations for most of the algorithms can be found at https://github.com/lanl/quantum_algorithms.

Quantum Algorithm Implementations for Beginners 17
2 GROVER’S ALGORITHM
2.1 Problem definition and background
Grover’s algorithm as initially described [52] enables one to find (with probability &gt; 1/2) a specific √
item within a randomly ordered database of N items using O( N) operations. By contrast, a
classical computer would require O (N ) operations to achieve this. Therefore, Grover’s algorithm
provides a quadratic speedup over an optimal classical algorithm. It has also been shown [14] that
Grover’s algorithm is optimal in the sense that no quantum Turing machine can do this in less than
√
O( N) operations.
While Grover’s algorithm is commonly thought of as being useful for searching a database, the basic ideas that comprise this algorithm are applicable in a much broader context. This approach can be used to accelerate search algorithms where one could construct a “quantum oracle” that distinguishes the needle from the haystack. The needle and hay need not be part of a database. For example, it could be used to search for two integers 1 &lt; a &lt; b such that ab = n for some number n, resulting in a factoring algorithm. Grover’s search in this case would have worse performance than Shor’s algorithm [93, 94] described below, which is a specialised algorithm to solve the factoring problem. Implementing the quantum oracle can be reduced to constructing a quantum circuit that flips an ancillary qubit, q, if a function, f (x), evaluates to 1 for an input x. We use the term ancilla or ancillary qubit to refer to some extra qubits that are used by the algorithm.
The function f (x) is defined by
􏰘1 ifx=x∗
f(x)= 0 ifx􏰯x∗ (32)
where x = x1x2 . . . xn are binary strings and x∗ is the specific string that is being sought. It may seem paradoxical at first that an algorithm for finding x∗ is needed if such a function can be constructed. The key here is that f (x) need only recognize x∗ – it is similar to the difference between writing down an equation and solving an equation. For example, it is easy to check if the product of a and b is equal to n, but harder to factor n. In essence, Grover’s algorithm can invert an arbitrary function with binary outputs, provided we have a quantum oracle that implements the function. Grover’s algorithm has been used, with appropriate oracles, to solve problems like finding triangles in a graph [72], finding cycles [28], and finding maximal cliques [109]. For the analysis of Grover’s algorithm, the internals of the oracle is typically considered a black-box. Often, the oracle operator for the problem at hand has to be constructed as a quantum circuit. But, keep in mind that an inefficient oracle construction can nullify any practical advantages gained by using Grover’s search.
Here we implement a simple instance of Grover’s algorithm. That is, the quantum oracle we utilizeisaverysimpleone.Letx=x1x2 andwewishtofindx∗ suchthatx1∗ =1andx2∗ =1.While finding such an x ∗ is trivial, we don a veil of ignorance and proceed as if it were not. This essentially means that our function f (x) is an AND gate. But AND gate is not reversible and cannot be a quantum gate. However the Toffoli gate, that was introduced in the previous section, is a reversible version of the classical AND gate. The Toffoli gate takes three bits as input and outputs three bits. The first two bits are unmodified. The third bit is flipped if the first two bits are 1. The unitary matrix corresponding to the Toffoli gate can be found in Table 1. In other words, the Toffoli gate implements our desired quantum oracle where the first two inputs are x1 and x2 and the third bit is the ancillary bit, q. The behavior of the oracle in general is |x⟩ |q⟩ → |x⟩ 􏰍􏰍f (x) 􏰪q􏰌, where 􏰪 is the XOR operation . Here we will only discuss the case where x∗ is unique. Grover’s algorithm can also be used to search for multiple items in a database.

18 Abhijith J., et al.
 Fig. 6. A schematic diagram of Grover’s algorithm is shown. Note that in this case, one application of the Grover operator is performed. This is all that is necessary when there are only two bits in x, but the Grover operator should be applied repeatedly for larger problems.
2.2 Algorithm description
Here we present a brief introduction to Grover’s algorithm. A more detailed account can be found in Nielsen and Chuang [77]. Let N be the number of items (represented as bit strings) amongst which we are performing the search. This number will also be equal to the dimension of the vector space we are working with. An operator, called the Grover operator or the diffusion operator, is the key piece of machinery in Grover’s algorithm. This operator is defined by
G = (2 |ψ ⟩ ⟨ψ | − I )O (33) where |ψ⟩ = √1 􏰫i |i⟩ is the uniform superposition over all the basis states and O is the oracle
N
operator (see Fig. 6 for a representation of this operator in the case where x consists of 2 bits). The actionof(2|ψ⟩⟨ψ|−I)onanarbitrarystate,givenby􏰫i ai |i⟩,whendecomposedoverthebasis
states is,
(2|ψ⟩⟨ψ|−I)􏰭ai |i⟩=􏰭(2⟨a⟩−ai)|i⟩ (34) ii
where ⟨a⟩ = 􏰫i ai is the average amplitude in the basis states. From Eq. (34) one can see that the N
amplitude of each |i⟩-state (ai ) is flipped about the mean amplitude.
In order to use the Grover operator to successfully perform a search, the qubit register must
be appropriately initialized. The initialization is carried out by applying a Hadamard transform
to each of the the main qubits (H ⊗n ) and applying a Pauli X transform followed by a Hadamard
transform (HX) to the ancilla. This leaves the main register in the uniform superposition of all |0⟩−|1⟩
states, |ψ ⟩, and the ancilla in the state √2 . After performing these operations, the system is in |0⟩−|1⟩
the state |ψ ⟩ √2 . Using Eq. (34), we can now understand how the Grover operator works. The ∗ |0⟩−|1⟩
action of the oracle operator on |x ⟩ √2 reverses the amplitude of that state
| 0 ⟩ − | 1 ⟩ 􏰍􏰍 f ( x ∗ ) 􏰪 0 􏰌 − 􏰍􏰍 f ( x ∗ ) 􏰪 1 􏰌 ) | 1 ⟩ − | 0 ⟩ | 0 ⟩ − | 1 ⟩ O |x∗⟩ √ → |x∗⟩ √ = |x∗⟩ √ = − |x∗⟩ √
(35)
    2222
A similar argument shows that all other states are unmodified by the oracle operator. Combining this with Eq. (34) reveals why the Grover operator is able to successfully perform a search. Consider what happens on the first iteration: The oracle operator makes it so that the amplitude of |x∗⟩ is below ⟨a⟩ (using the notation of Eq. (34)) while all the other states have an amplitude that is slightly above ⟨a⟩. The effect of applying 2 |ψ ⟩ ⟨ψ | − I is then to make |x∗⟩ have an amplitude above the mean while all other states have an amplitude below the mean. The desired behavior of the Grover

Quantum Algorithm Implementations for Beginners 19
operator is to increase the amplitude of |x∗⟩ while decreasing the amplitude of the other states. If the Grover operator is applied too many times, this will eventually stop happening. The Grover
operator should be applied exactly 􏰞 π √N 􏰟 times after which a measurement will reveal x∗ with 4
probability close to 1. In the case where x has two bits, a single application of Grover’s operator is sufficient to find x∗ with certainty (in theory). Below is a high level pseudocode for the algorithm.
Algorithm 1 Grover’s algorithm
Input:
• An Oracle operator effecting the transformation |x⟩ |q⟩ → |x⟩ |q ⊕ f (x)⟩. Output:
  • The unique bit string x∗ satisfying Eq. (32) Procedure:
Step 1. Perform state initialization |0 . . . 0⟩ → |ψ ⟩ ( Step 2. Apply Grover operator 􏰞 π √N 􏰟 times
|0⟩−|1⟩ √2 )
4
Step 3. Perform measurement on all qubit except the ancillary qubit.
 2.3 Algorithm implemented on IBM’s 5-qubit computer
Fig. 7 shows the circuit that was designed to fit the ibmqx4 quantum computer. The Toffoli gate is not available directly in ibmqx4 so it has to be constructed from the available set of gates given in Eq. 26.
The circuit consists of state preparation (first two time slots), a Toffoli gate (the next 13 time slots), followed by the 2 |ψ ⟩ ⟨ψ | − I operator (7 time slots), and measurement (the final 2 time slots). We use q[0] (in the register notation from Fig. 7) as the ancillary qubit, and q[1] and q[2] as x1 and x2 respectively. Note that the quantum computer imposes constraints on the possible source and target of CNOT gates.
Using the simulator, this circuit produces the correct answer x = (1, 1) every time. We executed 1,024 shots using the ibmqx4 and x = (1, 1) was obtained 662 times with (0, 0), (0, 1), and (1, 0) occurring 119, 101, and 142 times respectively. This indicates that the probability of obtaining the correct answer is approximately 65%. The deviation between the simulator and the quantum computer is due to the inherent errors in ibmqx4. This deviation will get worse for circuits of larger size.
We also ran another test using CNOT gates that did not respect the underlying connectivity of the computer. This resulted in a significantly deeper circuit and the results were inferior to the results with the circuit in Fig. 7.
This implementation used a Toffoli gate with a depth of 23 (compared to a depth of 13 here) and obtained the correct answer 48% of the time.
3 BERNSTEIN-VAZIRANI ALGORITHM
3.1 Problem definition and background
Suppose we are given a classical Boolean function, f : {0, 1}n 􏰅→ {0, 1}. It is guaranteed that this function can always be represented in the form, fs(x) = 􏰪i sixi ≡ ⟨s,x⟩. Here, s is an unknown bit string, which we shall call a hidden string. Just like in Grover’s algorithm we assume that we have a quantum oracle that can compute this function.
The Bernstein-Vazirani (BV) algorithm then finds the hidden string with just a single application of the oracle. The number of times the oracle is applied during an algorithm algorithm is known as

20 Abhijith J., et al.
            Fig.7. ThecircuitthatwasexecutedonIBM’s5-qubitquantumcomputer.Thefirsttwotimeslotscorrespond to the state preparation. The next 13 time slots implement a Toffoli gate. The next 7 time slots implement the 2 |ψ ⟩ ⟨ψ | − I operator, and the final two time slots are used for observing x1 and x2.
its query complexity. The BV algorithm has a query complexity of one. From our earlier discussions √
we saw that Grover’s algorithm has a query complexity of O ( N ).
In the classical case each call to fs(x) produces just 1 bit of information, and since an arbitrary
hidden string s has n-bits of information, the classical query complexity is seen to be n. Even with bounded error, there is no way that this classical complexity can be brought down, as can be seen using slightly more rigorous information-theoretic arguments.
The quantum algorithm to solve this problem was developed by Bernstein and Vazirani [15] building upon the earlier work of Deutsch and Jozsa [36]. Their contribution was a quantum algorithm for the hidden string problem, which has a non-recursive quantum query complexity of just 1. This constitutes a polynomial O(n) query-complexity separation between classical and quantum computation. They also discovered a less widely known recursive hidden-string query algorithm, which shows a O(nlog n ) separation between classical and quantum query-complexities. These developments preceded the more famous results of Shor and Grover, and kindled a lot of early academic interest in the inherent computational power of quantum computers.
One thing to note about the BV algorithm is that the black-box function fs(·) can be very complex to implement using reversible quantum gates. For an n-bit hidden string, the number of simple gates needed to implement fs(·) scales typically as O(4n)[77]. Since the black box is a step in the algorithm, its serial execution time could in the worst-case even scale exponentially. The real breakthrough of this quantum algorithm lies in speeding up the query complexity and not the execution time per se.
3.2 Algorithm description
Let us explore the BV algorithm in more detail. Let Us be the oracle for the function fs(x). It acts in the usual way and computes the value of the function onto an ancilla qubit,
Us |x⟩ |q⟩ = |x⟩ |q ⊕ ⟨s,x⟩⟩ (36) √
Denoting |−⟩ = (|0⟩ − |1⟩)/ 2, we can easily verify from Eq. (35) that,
Us |x⟩ |−⟩ = (−1)⟨s,x⟩ |x⟩ |−⟩ . (37)
Also, note that the n-qubit Hadamard operator, which is just n single qubit H operators applied in parallel, can be expanded as,
H⊗n = √1 􏰭 (−1)⟨x,y⟩ |y⟩⟨x| (38) 2n x,y∈{0,1}n
The reader may verify this identity by applying H ⊗n to the computational basis states.

Quantum Algorithm Implementations for Beginners 21
 Fig. 8. Bernstein-Vazirani hidden string discovery quantum algorithm. The hidden string s is discovered with just a single query. The measurement result 􏰛s gives the hidden string.
Us and H ⊗n are the only two operators needed for the BV algorithm. The pseudocode for the algorithm is given in Algorithm 2. Notice that the initialization part is identical to that of Grover’s algorithm. This kind of initialization is a very common strategy in quantum algorithms.
Algorithm 2 Bernstein-Vazirani algorithm
Input:
• An oracle operator, Us , effecting the transformation |x⟩ |q⟩ → |x⟩ |q ⊕ ⟨s, x⟩⟩. Output:
• The hidden string s. Procedure:
Step 1. Perform state initialization on n + 1 qubits, |0 . . . 0⟩ → |ψ ⟩ |−⟩ Step 2. Apply Us .
Step 3. Apply H ⊗n to the first n qubits.
Step 4. Measure all qubits except the ancillary qubit.
The final measurement will reveal the hidden string, s, with probability 1. Let us now delve into the algorithm to see how this result is achieved. The entire circuit for the BV algorithm is represented in Figure 8. This circuit can be analyzed as follows,
   |0⟩
|1⟩
√
2n x=0 1 2n−1
􏰭
−→ √ (−1) 2n x=0
n
⊗(n) 􏰭
􏰭
⟨s,x⟩⊕⟨x,y⟩
⟨s,x⟩
H⊗H12n−1 Us12n−1
−−−−−−→
|x⟩ ⊗ |−⟩
|x⟩ ⊗ |−⟩
|y⟩ ⊗ |−⟩ ≡ |s⟩ ⊗ |−⟩ . (39)
⊗n −−→
H
(−1)
Here we have crucially used the identity for H ⊗n given in Eq.(38).
√
2n x,y=0
3.3 Algorithm implemented on IBM’s 5-qubit and 16-qubit computers
From the BV algorithm description in the previous section, we see that in any practical implementa- tion of this algorithm, the main ingredient is the construction of the oracle Us given a binary hidden

22 Abhijith J., et al.
string s. Let us see how this is done using an example binary hidden string “01”. Equation (40) below shows how the 3-qubit operator maps the 23 = 8 basis vectors onto themselves. The first line is the input binary vector (in the order x1, x0, q), and the second line is the output binary vector.
􏰐000 010 100 110 001 011 101 111􏰑
U01 = 000 011 100 111 001 010 101 110 (40)
This mapping, U01 : |x⟩ |q⟩ 􏰅→ |x⟩ |⟨01, x⟩ ⊕ q⟩, is unitary. The next task in implementation is to lower the unitary matrix operator U01 to primitive gates available in the quantum computer’s architecture given in Eq (26). The time cost of applying these gates can be accessed from IBM’s published calibration models [103] for the primitive hardware gates.
In order to decompose arbitrary unitary matrices to the primitive gates, we need to first perform a unitary diagonalization of the 2(n+1) × 2(n+1) matrix using multi-qubit-controlled single-qubit unitary Given’s rotation operations. Such multi-qubit-controlled single-qubit operations can be decomposed further to primitive gates using standard techniques [77] to the hardware primitive gates. Even after this step we will be left with arbitrary CNOT gates that do not respect the topology of the underlying quantum processor. Since both ibmqx4, ibmqx5 computers have restricted CNOT connectivity between qubits, we will need to decompose the CNOT gates further into available CNOT gates using the method discussed in the introductory section. As we saw in the Grover’s algorithm section, such decompositions will further degrade the quality of our results. As the overall primitive gate counts scale as O(4n ) for arbitrary n-qubit unitary operators, these decompositions quickly becomes hard to do by hand. To address this we wrote a piece of software called Quantum Netlist Compiler (QNC) [89] for performing these transformations automatically. QNC can do much more than convert arbitrary unitary operators to OpenQASM-2.0 circuits—it has specialized routines implemented to generate circuits to do state-preparations, permutation operators, Gray coding to reduce gate counts, mapping to physical machine-topologies, as wells as gate-merging optimizations. Applying QNC tool to the unitary matrix Us gives us a corresponding quantum gate circuit Gs as shown in Figure 8 for a specific bit-string s.
QNC generated black-box circuits with following gate-counts for the non-trivial 2-bit hidden- strings: “01”: 36, “11”: 38, “10”: 37, with estimated execution time2 for critical path ∼17μs on an ideal machine with all-to-all connection topology. For the 5-qubit ibmqx4 machine the corresponding gate-counts where: “01”: 42, “11”: 43, “10”: 41, with estimated execution time for critical path ∼15μs, and for the 16-qubit ibmqx5, they were: “01”: 66, “11”: 67, “10”: 67, with estimated execution time for critical path ∼28μs. In all these cases, QNC used a specialized decomposition of U01, considering its permutation matrix nature, and therefore was able to reduce gate-counts by 5× over the case when this special structure was ignored. Considering that the machines’ observed coherence times are of the order of ∼60μs, these QNC optimizations were crucial to the feasibility of the resulting score. The quantum score (circuit) generated by QNC for U01 for ibmqx4 is shown in Figure 9. A similarly prepared score for 3-bit hidden-string “111” had a gate-count of 428 in the ibmqx4 architecture with an estimated execution time of 153μs which was well above the machines’ coherence times.
We tested the QNC generated quantum scores for all non-trivial 1-qubit, 2-bit and 3-bit strings using the IBM-Qiskit based local simulator. In all cases, the simulator produced the exact hidden- string as the measurement result, 100% of the trials. We then tested all 1-bit and 2-bit strings on both the 5-qubit ibmqx4 and the 16-qubit ibmqx5 machines. The results are shown in Figure 10. For 2-bit strings, the worst case noise was observed for the string “01” on ibmqx4 when the qubits q0,q1,q2 where used for x0,x1,y respectively. Since the estimated critical path times exceeded the machines’ coherence times for 3-bit strings, we did not run those scores on the physical machines.
2 These times are estimated using the data available from IBM at the time of writing. These values will change as the hardware improves.
 
Quantum Algorithm Implementations for Beginners 23
Even for 2-bit strings, the scores were quite long, and the results were quite noisy even with 8192 machine-shots.
Fig. 10. Results from running the BV algorithm for 8192 shots on 2-bit hidden-strings “01”, “10” and “11” respectively (left to right) on ibmqx4. The y-axis here is the probability of obtaining the hidden string, which theoretically should be 1.
4 LINEAR SYSTEMS
4.1 Problem definition and background
Solving linear systems is central to a majority of science, engineering, finance and economics applications. For example, one comes across such systems while solving differential or partial differential equations or while performing regression. The problem of solving a system of linear equations is the following: Given a system Ax􏰆 = b􏰆, find x􏰆 for a given matrix A􏰆 and vector b􏰆. Here we assume that A is a Hermitian matrix, in that it is self-adjoint. To represent x􏰆, b􏰆 as quantum states |x⟩, |b⟩, respectively, one has to rescale them as unit vectors, such that ||x􏰆|| = ||b􏰆|| = 1. Thus, one can pose the problem as finding |x⟩ such that
   with the solution |x⟩ being
4.2 Algorithm description
A|x⟩ = |b⟩, (41)
|x⟩= A−1|b⟩ . (42) ||A−1 |b⟩ ||
 The quantum algorithm for the linear system was first proposed by Harrow, Hassidim, and Lloyd (HHL) [53]. The HHL algorithm has been implemented on various quantum computers in [11, 24, 111]. The problem of solving for x􏰆 in the system Ax􏰆 = b􏰆 is posed as obtaining expectation value of some operator M with x􏰆, x􏰆†Mx􏰆, instead of directly obtaining the value of x􏰆. This is particularly useful when solving on a quantum computer, since one usually obtains probabilities with respect to some measurement, typically, these operators are Pauli’s operators X , Y , Z . These probabilities can then be translated to expectation values with respect to these operators.
Fig. 9. Quantum circuit for BV algorithm with hidden string “01” targeting the ibmqx4 architecture.
        
24 Abhijith J., et al.
The main idea of the algorithm is as follows. Let {􏰍􏰍uj􏰌} and {λj} be the eigenvectors and
eigenvaluesofA,respectively,withtheeigenvaluesrescaledsuchthat0&lt;λj &lt;1.Thenthestate
|b⟩, can be written as a linear combination of the eigenvectors {􏰍􏰍uj 􏰌}, |b⟩ = 􏰫Nj=1 βj 􏰍􏰍uj 􏰌. The goal
oftheHHLalgorithmistoobtain|x⟩intheform|x⟩=􏰫Nj=1βjλ1 􏰍􏰍uj􏰌.BydecomposingA=R†ΛR, j
the HHL algorithms in a nutshell involves performing a set of operations that essentially performs the three steps:
† Step1 Step2 −1 Step3 † −1
R ΛR|x⟩=|b⟩ =⇒ ΛR|x⟩=R|b⟩ =⇒ R|x⟩=Λ R|b⟩ =⇒ |x⟩=R Λ R|b⟩ (43)
This procedure requires us to find the eigenvalues of A. This can be done using a quantum subroutine called phase estimation. We will discuss this subroutine in some detail as it is a common ingredient in many quantum algorithms.
4.3 Phase estimation
Phase estimation is a quantum subroutine that lets us find the eigenvalues of a unitary matrix U given the ability to apply it to a quantum register as a controlled gate. Let |u⟩ be an eigenvector of U such that, U |u⟩ = e2πiλu |u⟩. Then the phase estimation subroutine effects the following transformation,
􏰍 ̃􏰙
|0⟩|u⟩→− 􏰍􏰍λu |u⟩. (44)
Here λ ̃u is an estimate for λu . This subroutine makes use of an important transformation called the Quantum Fourier Transform (QFT)
Quantum Fourier Transform. The Discrete Fourier Transform (DFT) takes as an input a vector X of size N and outputs vector Y = W X where the Fourier matrix W is defined by
1 1 1 ... 1 
1 ω ω2 ... ωN−1  1 1 ω2 ω4 ... ω2(N−1) 
W=√ , N . . . ... . 

1 ωN−1 ω2(N−1) ... ω(N−1)(N−1)  
wheretheij-thelementofthematrixisWij =ωij andωisaprimitiveN-throotofone(ωN =1).A straightforward implementation of the matrix-vector multiplication takes O (N 2 ) operations, but, by using the special structure of the matrix, the Fast Fourier Transform (FFT) does the multiplication in only O (N log N ) time. The algorithm is recursive and is illustrated on Figure 11. The Quantum Fourier Transform (QFT) is defined as a transformation between two quantum states that are determined using the values of DFT (FFT). If W is a Fourier matrix and X = {xi } and Y = {yi } are vectors such that Y = W X , then the QFT is defined as the transformation
􏰔N−1 􏰕 N−1
QFT 􏰭xk|k⟩ =􏰭yk|k⟩. (45)
k=0 k=0
The implementation of the QFT mimics the stages (recursive calls) of the FFT, but implements each stage using only n + 1 additional gates per stage. A single Hadamard gate on the last (least significant) bit implements the additions/subtractions of the outputs from the recursive call and the multiplications by ωj are done using n controlled phase gates. The circuit for n = 5 is shown on Figure 12.

.3 The quantum Fourier transform circuit
we have reproduced the diagram (from Section 2.6.4) showing how the classical FFT cir- for M-vectors is composed of two FFT circuits for (M/2)-vectors followed by some simple
s.
Quantum Algorithm Implementations for Beginners 25
FFTM (input: α0,...,αM−1, output: β0,...,βM−1) yj
  .2 x.
+ -
N−2
x1 x3 .
xN−1
ωj
x0 x
FFTN/2
  FFTN/2
yj+N/2 seehowFitgo.1s1.imFaustlaFotuerietrhTirsanosfnormacqirucuaitn,wtuhemrejsdyesntoetmes.aroTwhferomintpheutopishanlfowfthencicrcouditeadndinωtdheneot2es
jm that the corresponding value is multiplied by ω j . The plus and minus symbols indicate that the corresponding
litudes of m = log M qubits. Thus the decomposition of the inputs into evens and odds, values have to be added or subtracted, respectively.
own in the preceding figure, is clearly determined by one of the qubits—the least sig- ant qubit. How do we separate the even and odd inputs and apply the recursive circuits
    H
P(π ) P(π ) P(π ) P(π )
mpute F F T
totherema•iningHm−1quPb(it)s.TheeffectP(of)thisistoapplyQFPT( ) tothesuperpo-
on each half? The answer is remarkable: just apply the quantum circuit
  2 4 8 16
M/2
M/2 2 4 8M/2
         πππ
  n of all the m-bit strings of the form x0 (of which there are M/2), and separately to the
      ••H P(π) P(π) 24
rpositionofallthem-bitstringsoftheformx1.Thusthetworveclassicalcircuits
     beemulatedbyasinglequantumcircuit—•ane•xpone•ntialHspeehenweunPw(in)dthe
     rsion!
π
2
••••H Fig. 12. A Quantum Fourier Transform circuit for five qubits (n = 5).
      m − 1 qubits
The phase estimation procedure cleverly uses the QFT operator to estimate the eigenphases of
least significant bit
QFTM/2 QFTM/2
the operator U . The circuit for performing phase estimation given in Fig. 13. Notice that the QFT is
H
et us now consider the gates in the classical FFT circuit after the recursive calls to
thejthandthe(M/2+j)thoutputs,respectively.Howdntumcircuitachieve esultoftheseMclassicalgates?Simple:justperformHardgateonthefirst
|0⟩H •··· t!Recallfromtheprecedingdiscussion(Section10.5.1)thatfypossibleconfigura-
applied in reverse.
|0⟩ H ··· • :thewirespairupjwithM/2+j,andignoringfwhasethatisapplied
or no btrac woul the
 the p these t a qua
 adam
QFT†
or ever and 1
esult of
 ngs 0 r the
   M/2 econtentsofthe(M/2+j)thwire,wemustaddandsutwoquantitiestoob-
 ...
     of the remaining m − 1 qubits x, this pairs up the stri x x. Translating from ry, this means we are pairing up x and M/2+x. Moreove r the Hadamard gate
|0⟩ H • ···
at for each such pair, the amplitudes are replaced by the sum and difference (normalized
ecursi dup w
     √2) , respectively. So far the QFT requires almost no gates at all! |u⟩ / U 2 ··· 2
he phase that must be applied to the U(M/2 + j)th wiUret for each j requires a little more . Notice that the phase of ωj must be applied only if the first qubit is 1. Now if j is
   Fig. 13. Quantum circuit for phase estimation.
The pseudocode for phase estimation is given in Algorithm 3. Notice that the algorithm also works if the input state is not an eigenstate. The output in this case can be determined by expanding the input state in terms of the eigenstates and then applying the linearity of quantum operations.
           5
e
s h
o
T
e
L
T
h r
/
T k

26 Abhijith J., et al.
In the code, we have numbered the ancillary qubits from the top and CiU denotes the unitary controlled by the ith ancilla qubit acting on the main n qubit register.
Algorithm 3 Phase estimation subroutine
Input:
• Controlled unitaries CiU
•Annqubitinputstate|ψ⟩=􏰫uψu|u⟩,whereU|u⟩=e2πiλu |u⟩. Output:
􏰫􏰍 ̃􏰙
• uψu􏰍􏰍λu |u⟩
Procedure:
Step 1. Take t ancillary qubits initialized to zero and perform H ⊗t on them to produce the
uniform superposition state over them. for 0 ≤ i &lt; t do
Step 2. Apply Ct −i −1U 2i end for
Step 3. Apply QFT† .
Optional Measure the ancillary qubits to get 􏰍􏰍λu |u⟩ with probability |ψu |
The number of ancillary qubits used in the phase estimation algorithm will determine both its run-time and its accuracy. On the accuracy front, the number of ancillary qubits used is equal to the bit precision of λ ̃u as the answer is stored in this register. The exact complexity of this subroutine is discussed in Ref. [77].
Now we can discuss the HHL algorithm which makes use of the phase estimation procedure to perform a matrix inversion. The HHL algorithm requires three sets of qubits: a single ancilla qubit, a register of n qubits used to store the eigenvalues of A in binary format with precision up to n bits, and a memory of O(log(N )) that initially stores |b⟩ and eventually stores |x⟩. Start with a state |0⟩a |0⟩r |b⟩m, where the subscripts a, r, m, denote the sets of ancilla, register and memory qubits, respectively. This subscript notation was used in [111], and we found it to be most useful in keeping things clear. The HHL algorithm requires us to run the phase estimation procedure on the unitary operator eiA. The phases estimated would be approximations to the eigenvalues of A. The problem of applying the unitary operation eiA given the matrix A is called quantum simulation. There are many algorithms in literature that tackle the problem of quantum simulation [16] [47] and that will not be our focus in this section. We will explain the steps of the HHL algorithm below assuming that the quantum simulation part is taken care of. We will also include some mathematical details in the pseudocode given in Algorithm 4 .
These three steps are equivalent to the three steps shown in Eq. (43). The algorithm is probabilistic, we get |x⟩ only if the final measurement gives |1⟩. But this probability can be boosted using a technique called amplitude amplification [21]. This technique is explained in detail in Section VII.
4.4 Algorithm implemented on IBM’s 5 qubit computer
􏰐1.5 0.5􏰑 Now we implement the HHL algorithm on a 2 × 2 system. For this, we chose A = 0.5 1.5 . We
use four qubits for solving the system – one ancilla, one memory and two register qubits. For this
1 􏰐1􏰑
case, the eigenvalues of A are λ1 = 1 and λ2 = 2 with the eigenvectors being √2 −1 ≡ |−⟩ and
  􏰍 ̃􏰙 2
 
    q FF
q
g d
g
g
p p
ee21=Trr((⌃))⇤⇤((11+ 1122((11 ee =Tr(r(⌃(⌃))⇤ (1(11+ 11 22(1(11 PP))/)//22. As depicted in Fig. ??, this simple(7(a66)l)g)1orithm is schematically divid
g
p
quantifying the purity, and classical post-processing. e = Tr(⌃) ⇤ (1  1  2(1 
ig. ??, this simple algorithm is schematically divided up into four steps: classical pre-processing, q
o
f
l
o
f l1
o of
tr mo
ol
t = u
h= tp u
ti =p uq 0
=
p q0
p uq x0p
s s
0
x
p
i
g
q q
g
q
-q
nd
g
d
r d
r nd
211 ⇤⇤ p 
uantifying the purity, and classical post-processing. ee =Trr((⌃))⇤⇤((11 1122((11
Classical Pre-processing quuaannttifiyfyininggtthheeppuurritityy, ,aannddcclalassSsicitcaatlelpporosestpt-ap-rprarotoicocenesssiningg. .
Classical Pre-processing State preparation
ssttaatteepprreeppaarraattioionn,,qquuaannttifiyfyininggtthheeppuurritityy,,aannddcclalasssicicaallppoosstt-p-prroocceesssinin
Classical Pre-processing
state preparation, quantifying the purity, and classical post-processin A A s s d d e e p p i c i c t t e e d d i n i n F F i g i g . . ? ? ? ? , , t t h h i s i s s s i mi m p p l e l e a a l g l g o o r r i t i t h h m m i s i s s s c c h h e e m m a a t t i c i c a a l l l y l y d d i v i v i d i
Classical Pre-processing
uantifying the purity, and classical post-processing. igig..???,,tthhisisssimimppleleaalglgoorritithhmisissscchheemaatticicaallylyddivividideedduuppininttoofofouurrsstteeppss:: cclalasssicicaallpprree-p-prroocceesssiningg,,
Quantum Algorithm Implementations for Beginners
Classical Pre-processing State preparation Quuaanntitfiyfyi2ni7nggththeeppuurritiyty
A A A
⌃!⇢! onnIIBM’s’s55--
Quantifying the purity CClalasssicicaal lPPrere-p-prorocceesssiningg
CClalasssicicaal lPPrere-p-prorocceesssiningg State preparation
State preparation Quantifying the purity
Quantifying the purity CClalasssicicaal lPPoosst-tp-prorocceesssining
Classical Post-processing
Classical Post-processing
Conclusions AlglgoorritithhmimimpplelemeenntteeddoonnIIBM’s’s55--qquubbititccoomppuutteerr Classical Post-processing
Coonncclulussioionnss
state preparation, quantifying the purity, and classical post-processin
ee2=Trr((⌃))⇤⇤((11 1122((11PP)))//22.. As depicted in Fig. ??, this simple((a77l)g)orithm is schematically divid
2
ig. ??, this simple algorithm is schematically divided up into four steps: classical pre-processing, 22
CClalasssicicaal lPPrere-p-prorocceesssiningg
Fig. 14. Schematic of the circuit for the quantum algorithm for solving a 2 × 2 linear system. ThCelafsirssictasltePpost-processing
Conclusions
Conclusions
involves phase estimation, which maps the eigenTvhaheleuaeadsdvvλaanntotaafggAeeoionfftRoRBthiteittrthehgaatistittietrisiisninintshseennsbsitintiviavereyttofoossrtmtaat.teeT-p-hprereeppaarraattioionnaan
f RB it that it is insensitive to state-preparation and measurement errjors (SPAM), and that it can
CClalasssicicaal lPPoosst-tp-prorocceesssining
CClalasssicicaal lPPoosst-tp-prorocceesssiningg 1 bbeeimimpplelemeenntteeddmoorreeeefficcieiennttlylyoonnlologgicicaal lqquubbititsstthhaCanonnpprcroloucceseisossntstoomooggr
re efficientlyseocnonlodgsitceapl qinuvboiltvsesthcCaononntprcorlolulcesedisosrnotstoamtiongroafpthhye. ancilla qubit, so that the inverse of the eigenvalues
show
RB it that it is insensitive to state-preparation and measurement errors (SPAM), and that it can
goes as follows.
ThheeRBpprroottooccool lggooeessaassfofollolowss. .
AlglgoorritithhmimimpplelemeenntteeddoonnIIBM’s’s55-
λj
The advantage of RB it that it is insensitive to state-preparation an
up in the state. The third step is the inverse phase estimation to disentangle the system, and restorCeCsootnhnceclulussioionnss
re efficiently on logical qubits thaCnoonpncrcolulcusesisoisonntsosmography. be implemented more efficiently on logical qubits than process tomog The advantage of RB it that it is insensitive to state-preparation an
RB it that ritegisistinerssentosit|0iv⟩e. Tthoesmtaetme-opryepqaurbaitionnowansdtomresea|xsu⟩r, ewmheicnht iesrrthoresn(pSoPsAt-pMro),ceasnsdedthtoatgeit cthaen expectation values
T11h..eRaanBnddopomrmoltyloyccohhloogososesaaseetftoololfofmwms.eelelemeennttssfrfroomG,,ddeennootteeddG= G ogoosesaaseftoollfowms.elements from G, denoted G = G , ..., G . 1
1m
be implemented more efficiently on logical qubits than process tomog
re efficientlywoitnhlroegsipceacltqtuobtihtsetPhaaunliporpoecreastsortsoXm,oYgranpdhyZ.. ThheeaaddvvaannttaaggeeooffRBitittthhaattititisisininsseennssititiviveettoossttaattee-p-prreeppaarraattioionnaan f R RB B i ti t t th ha at t i ti t i si s i ni ns se en ns si ti ti vi ve e t to o s st ta at te e- p- pr re ep pa ar ra at ti oi on n a an nd d m me ea as su ur re em me en nt t e er r r ro or rs s ( (S SPPA AM M) ), , a an nd d t th ha at t i ti t c ca an n
The RB protocol goes as follows.
ogoionsesatastsefto0ollifo.wms.elements from G, denoted G = G , ..., G .212..PRPrarenepdpaaorrmeeqlyquudcdhitiotionisnesstataatsteet 0o0ifi..m elements from G, denoted G = G1
or re e e effi ffic ci ei en nt tl yl y o on n l ol og gi ci ca al l q qu ub bi ti ts s t th ha an n p pr ro oc ce es s s s t to om mo og gr ra ap ph hy y. .
1 mb b e e i mi m p p l e l e m m e e n n t t e e d d m m o o r r e e e e ffi ffi c c i e i e n n t t l y l y o o n n l o l o g g i c i c a a l l q q u u b b i t i t s s t t h h a a n n p p r r o o c c e e s s s s t t o o m m o o g g
p
SStatatetepprereppaararatitoionn
Classical Post-processing
SStatateteppr Quantifyin PosCt-plarossciecsaslinPgo
 i vector register 0iData vectors ! ⌃ ! ⇢ ! Xi vector
!(#/&amp;)
ancilla
Phase
Controlled rotation
SStatatetepprereppaararatitoionn
Inverse phase estimation
Quantifying the purity
estimation
Classical Post-processing
Quuaanntitfiyfyini Classical Po
  Quuaanntitfiyfyininggththeeppuurritiyty Classical Post-processing
0iData vectors ! ⌃ ! ⇢ ! CClalasssicicaal lPPoosst-tp-prorocceesssiningg
lgorithm implemented on IBM’s 5-qubit computer
QST on the
  !(#)
010iiDaattaavveeccttoorrss! meCmCloalarsyssiqciucaablliPtPo
 register 0iData vectors ! ⌃ ! ⇢ ! Xi vector lgorithm implemented on IBM’s 5-qubit computer
Algorithm implemented o
memory 0b0iiDaattaavveecHcttoorrss!⌃!⇢⇢! iivveeccttoorr Classical Post-processing
00iiDaattavaavlvueeccsttoworristsh! H x CClalasssicicaal lPPo
X
X
0iData vectors ! Expectation
X X
0iData vectors !
 lgorithm implemented on IBM’s 5-qubit computer
Alglgoorritithhmimimpplelemeenntteeddo
  Algorithm implemented o
Pauli X, Y, Z
ereppaararatitoionn
g the purity
st-processing
nggththeeppuurritiyty st-processing
⌃!⇢⇢! osst-tp-prorocceesssining
⌃!⇢!
n IBM’s 5-
⌃!⇢⇢! osst-tp-prorocceesssining
n IBM’s 5-
 ThheeRBpprroottooccoollggooeessaassfofollolowss.. ††
lggooeessaassfofollolowss.. † 12. RPraenpdaorme lqyucdhitooinsestaastet 0oif.m elements from G, denoted G = G1
Algorithm 4 HHL algorithm
ooinsestaastet 0oif.m elements from G, denoted G = G , ..., G .33..AccttoonntthheeqquuddititwitithhuunnititaarryyG G foforrjj=00,,..,.,m,,witithhG
1m jj++11j 00 ditwithunitaryG G forj=0,..,m,withG =G =1. j
Input:
j+1j 0 m+1
 11..Raannddoomlylycchhooosseeaasseettooffmeelelemeennttss†frfroomG,,ddeennootteeddG= G † 􏰫 􏰍 􏰌 2. Prepare qudit in state 0i. 1 ooinossesetaatseseett0oiof.fmeelelemeennttssfrfroomG,,ddeennootteeddG= G1,,...,.,Gm.3.4..AMcteaosnurtehethqeuqduitdiwtiwthituhnPitOarVyMGQ=G Qfor,1j1=Q0,..,,mw,hweriethwGety
1 m 4.MeasurethequditwithPOVMQj+=1 Q0,1Q0,wherewet0y qduidtiwtiwthithunPitOaVryMGQj+=1GQfo,r1j=Q0,..,mwh,ewrieth􏰍weGt0y=picGamlly+1ta=ke1Q. =0ih0. j 0 0
•Thestate|b⟩= β u
j00jjj0
22..PPrreeppaarreeqquuddititininssttaattee 00ii..
tininssttaattee 00ii.. 34. AMcetasounrethtehequqduidtitwwithithunPitOaVryMGQj+=1G Qfo,r1j=Q0, .., mwh, ewreithweGt0y
† † iAt
duidtiwtiwthithunPitOaVryMGQ•=TGhQefoa,rb1ijli=tyQ0t,o..,p,mewrh,feowriemthwceGotnyt=priocGlallelydtoap=k5e51.r1.aQ.RtRieoep=pneesaa0twtihsi0stteh.eppsusn22-i4-t4amrmiaeansnyoyfttitmihmeessfionirntmtoooeorrddejerr0ttooeessttimim0aatteeppGG:=:=PPrr((Q
2-4 many times intjo+o1rdjer0to estim0ate pG := Pr(0Q0), tmh+e1probab0ility of obtaining outcome Q0.
††
Output:†† 3. Act on the qudit with unitary G G for j = 0,..,m, with G 3. Act on the qudit with unitary G j+1G for j = 0,..,m, with G 0 4. Measure the qudit with POVM Qj+=1 jQj , 1  Q , where we t0y
uddititwitithhuunnititaarryyG G foforrjj=00,,..,.,m,,witithhG =G =656.1.1.1.R.Reepeeaattsstteepss121-5-45maanyyttimimeessininttoooorrdeerr0ttooeessttimim0aatteehphpp :i=i,,tPthhere(eQex 21u-d45itmwanityhtPimOeVsMintQojoj++o=o1r1rdjeQjr0t,o1estiQm0at,ewphhper:i=e, wtPhere(t0Qey0xppi)c,eactlmthlmaye+t+1itpo1arnkoebvaQlbu0iel=itoyf0opifh0ob(.atvaeinrainggedouotvceormaell QG). GGG
GG0􏰆G 0 • The quantum state |x⟩ such that Ax􏰆 = b.
44..MeeaassuurreetthheeqquuddititwitithhPPOVMQ= Q0,,1Q0 ,,whheerreeweettyy
5.Repeatsteps2-4manytimesintoorder0toestim0atep :=Pr(Q quuddititwitithhPPOVMQ= Q,,1Q ,,whheerreeweettyyppicicaallylyttaakk6ee.QRQep=ea0t0ihsih0t0e.p.s 1-5 many times into order to estimate hpG i, the ex
21-45 many times into order 0t0o estim0a0te php :i=, tPhre(Qexp),ectthaetipornobvalbu0i0elitoyf opf o(batvaeinrainggedouovtceormalel QG). G Procedure: GG 0 G 0
Step 1. Perform quantum phase estima65t5i.o.RnReueppseieanatgtststhteepepsus12n2-i54-t4amrmyaantnryyatntismimfoeesrsminianttoionorrdedeerrt.toToheesiststimimatptesehppGG:i=:,=tPhPrer((QeQx 1 2 2 - - 5 4 - 4 m m m a a a n n n y y y t t i t i m mi m e e e s s s i i n n i n t t o t o o o o o r r d r d d e e e r r r t t o t o o e e e s s t s t i t i m mi m a a a t t e t e e h p p p G G : i =: , = t P h P e r r ( ( e Q Qx 0 p 0 ) e ) , , c t t t h a h e t e i p o p n r r o o v b b a a a l b u b i e l i i l t i o t y f y o p o f f o o ( b a b t v t a e a i r n i n a i n g i n e g g d o o o u u v t t c e c o r o m a m l e l e QG Q 0 ) 0 . . . i A G
GG
the eigenvalues λj into the register in the binary form to transform the system,
6 6 . . R R e e p p e e a a t t s s t t e e p p s s 1 1 - 5 - 5 m m a a n n y y t t i mi m e e s s i n i n t t o o o o r r d d e e r r t t o o e e s s t t i mi m a a t t e e h h p p G i i , , t t h h e e e e x
1 1 - 5 - 5 m m a a n n y y t t i mi m e e s s i n i n t t o o o o r r d d e e r r t t o o e e s s t t i mi m a a t t e e h h p p G i i , , t t h h e e e e x x p p e e c c t t a a t t i o i o n n v v a a l u l u e e o o f f p p G ( ( a a v v e e r r a a g g e e d d o o v v e e r r a a l l l l G G ) ) . . GNG
G
|0⟩a|0⟩r|b⟩m→􏰭βj|0⟩a􏰍􏰍λj􏰌􏰍􏰍uj􏰌 . (46) rm
j=1
Step 2. Rotate the ancilla qubit |0⟩ to 􏰢1 − C2 |0⟩ + C |1⟩ for each λ . This is performed
 a λ2jaλja j
through controlled rotation on the |0⟩a ancilla qubit. The system will evolve to
j=1
Step 3. Perform the reverse of Step 1. This will lead the system to
N
βj 1− 2 |0⟩a+ |1⟩a 􏰍λj r􏰍uj m. (47)
􏰔􏰣 􏰕
􏰭 C2 C 􏰍􏰌􏰍􏰌
 λj λj
N
βj 1− 2 |0⟩a+ |1⟩a |0⟩r􏰍uj m. (48)
􏰔􏰣 􏰕
􏰭 C2 C 􏰍􏰌
 λj λj Step 4. Measuring the ancilla qubit will give ,
if the measurement outcome is |1⟩
j=1
􏰭N 􏰐βj􏰑􏰍􏰌
|x⟩≈ Cλj􏰍uj, (49)
j=1
 
28 Abhijith J., et al.
       Fig. 15. Circuit implemented on IBM’s 5-qubit ibmqx4 quantum computer for the case with |b⟩ set to |0⟩ and with ⟨Z ⟩ measurement. After implementing the circuit in Fig. 14 and setting the coupling map of the ibmqx4 architecture, Qiskit-sdk-py re-arranges the qubits to fit the mapping. This circuit represents the outcome of the re-arrangement which was implemented on the ibmqx4 quantum computer.
Table 3. Comparison between theoretical and simulator values for the expectation values ⟨X ⟩, ⟨Y ⟩, ⟨Z ⟩. T stands for theoretical and S stands for simulator.
     1 􏰐1􏰑 √2 1
|b⟩ T⟨X⟩ S⟨X⟩ T⟨Y⟩ S⟨Y⟩ T⟨Z⟩ S⟨Z⟩ |0⟩ -0.60 -0.60 0.00 -0.027 0.80 0.81 |+⟩ 1.00 1.00 0.00 -0.06 0.00 0.02 |−⟩ -1.00 -1.00 0.0060 0.000 -0.02 0.00
≡ |+⟩, respectively. For this system, the three steps of the HHL algorithm, can be performed
by the operations shown in Fig. 14. For the controlled rotation, we use a controlled U rotation
withθ =π forλ1 andθ =π/3forλ2.ThisisdonebysettingC =1intheEq.(47).Bothλandφ
are set to zero in these controlled U rotations. Although the composer on Quantum Experience
does not have this gate, in IBM Qiskit-sdk-py, we use cu3 function for this purpose. Three cases 􏰐1􏰑 1 􏰐1􏰑 1 􏰐1􏰑
are used for b: 0 , √2 −1 and √2 1 . We post selected the states with |1⟩ in the ancilla qubit.
The probabilities of these states are normalized such that their sum is one. Measurements with respect to ⟨X ⟩, ⟨Y ⟩, ⟨Z ⟩ can then be performed to obtain the expectation values. QASM code is output from Qiskit-sdk-py and then uploaded on to IBM Quantum Experience. Figure 15 shows the equivalent composer circuit generated from QASM for the measurement in the computational basis (Z measurement).
To first test our implementation of the algorithm, we ran nine cases on the local simulator provided by Qiskit-sdk-py – three b cases and three measurements with respect to the operators X , Y , Z , for each b case. The comparison between the theoretical expectation values ⟨X ⟩, ⟨Y ⟩, ⟨Z ⟩ and the simulator values are shown in Table 3. The simulator expectation values and the theoretical values match well. This shows that the implementation of the algorithm gives expected results. Similar expectation values were also seen using the simulator on IBM Quantum Experience instead of the local simulator. We then ran the circuit on the quantum computer ibmqx4. Fig. 16 shows a comparison between the simulator results and the results from the ibmqx4 with Z measurement on the circuit. As can be seen from Fig. 16, the results from the actual run do not give the expected answer as seen in the simulator results. We remark that recent modifications to the algorithm [22, 101] can in some cases allow for larger scale and more accurate implementations on noisy quantum computers.
5 SHOR’S ALGORITHM FOR INTEGER FACTORIZATION
5.1 Problem definition and background
The integer factorization problem asks, given an integer N as an input, to find integers 1 &lt; N1, N2 &lt; N such that N = N1N2. This problem is hardest when N1 and N2 are primes with roughly the

Quantum Algorithm Implementations for Beginners 29
 àà àà8 àà6 àà4 àà2 ààà
IBM QX Simulator
      àà àà8 àà6 àà4 àà2 ààà
ibmqx4 Run
 Fig. 16. Results of the circuit with Z measurement (computational basis measurement) from the actual run and the simulator on a ibmqx4. 4096 shots were used for both the cases.
same number of bits. If n denotes the number of bits of N , no algorithm with polynomial in n time
complexity is known. The straightforward algorithm that tries all factors from 2 to
polynomial in N , but exponential in n. The most efficient known classical algorithm has running
N takes time time O exp 9 n(log n) [81]. In practice, integers with 1000 or more bits are impossible to
􏰐􏰐􏰡364 2􏰑􏰑
√
 factor using known algorithms and classical hardware. The difficulty of factoring big numbers is the basis for the security of the RSA cryptosystem [86], one of the most widely used public-key cryptosystems.
One of the most celebrated results in quantum computing is the development of a quantum algorithm for factorization that works in time polynomial in n. This algorithm, due to Peter Shor and known as Shor’s algorithm [93], runs in O (n3 log n) time and uses O (n2 log n log log n) gates. The first experimental implementation of this algorithm on a quantum computer was reported in 2001, when the number 15 was factored [106]. The largest integer factored by Shor’s algorithm so far is 21 [73].
In this section we describe Shor’s algorithm and its implementation on ibmqx4 5.2 Algorithm description
Reducing factorization to period finding. One way to factor an integer is by using modular exponentiation. Specifically, let an odd integer N = N1N2 be given, where 1 &lt; N1, N2 &lt; N . Pick any integer k &lt; N such that gcd(k , N ) = 1, where gcd denotes the greatest common divisor. One can show that there exists an exponent p &gt; 0 such that kp ≡ 1 (mod N ). Recall that, by definition, x ≡ y (mod m) if and only if m divides x − y. Assume that p is the smallest such number. If we find such p and p is even, then, by the definition of the modulo operation, N divides
kp − 1 = (kp/2 − 1)(kp/2 + 1).
But since the difference between n1 = kp/2 + 1 and n2 = kp/2 − 1 is 2, n1 and n2 have no common factor greater than 2. Moreover, both numbers are nonzeros by the minimality of p. Since N = N1N2 was assumed to be odd, then N1 is a factor of either n1 or n2. Assume N1 is a factor of n1. Since N1 is also a factor of N , then N1 divides both n1 and N and one can find N1 by computing gcd(n1, N ). Hence, if one can compute such a p, one can find the factors of N efficiently as gcd can be computed in polynomial time.
Inordertofindp,considerthemodularexponentiationsequenceA=a0,a1,...,whereai =ki (mod N).Eachai isanumberfromthefiniteset{0,...,N −1},andhencethereexistsindicesq
Probability
Probability
àààà
ààààà
àààà
ààà
ààààà àààà
àààà ààà
àààà ààà
ààà àà
àààà ààà
ààà àà
ààà àà
àà à

30 Abhijith J., et al.
andrsuchthataq =ar.Ifqandrarethesmallestsuchindices,onecanshowthatq=0andAis periodic with period r . For instance, for N = 15 and k = 7, the modular exponentiation sequence is 1,7,4,13,1,7,4,13,1,... with period 4. Since the period 4 is an even number, we can apply the above idea to find
74 mod15≡1⇒74 −1mod15≡0⇒(72 −1)(72 +1)mod15≡0⇒15divides48·50, which can be used to compute the factors of 15 as gcd(48, 15) = 3 and gcd(50, 15) = 5.
Finding the period of the sequence A is, however, not classically easier than directly searching for
factors of N , since one may need to check as many as
a repetition. However, with quantum computing, the period can be found in polynomial time using the Quantum Fourier Transform (QFT). The QFT operation was introduced earlier during our discussion of phase estimation.
The property of the QFT that is essential for the factorization algorithm is that it can “compute” the period of a periodic input. Specifically, if the input vector X is of length M and period r , where r divides M, and its elements are of the form
􏰘􏰠r/M ifimodr≡s xi = 0 otherwise
forsomeoffsets &lt;r,andQFT 􏰎􏰫M x |i⟩􏰏 =􏰫M y |i⟩,then i=0 i i=0 i
y= i
􏰘1/√r ifimodM/r≡0 0 otherwise
Period-finding algorithm
i.e., the output has nonzero values at multiples of M/r (the values 􏰠r/M and 1/√r are used for
normalization). Then, in order to factor an integer, one can find the period of the corresponding
• Given a coprime 𝑘 of 𝑁, find 𝑝 s.t. 𝑘: ≡ 1mod𝑁 of a quantum state (the input to QFT).
modular exponentiation sequence using QFT, if one is able to encode its period in the amplitudes
√
N different values of A before encountering
S. Dasgupta, C.H. Papadimitriou, and U.V. Vazirani 327 A period-finding circuit for solving the integer factorization problem is shown in Fig 17 [34].
• Period-finding circuit
The first QFT on register A produces an equal superposition of the qubits from A, i.e., the resulting
Figure 10.6 Quantum factoring. 0
0
state is
𝑘"𝑀/𝑝 𝑘&amp;𝑀/𝑝 GC
              QFTM
measure
    ... 𝑘k𝑀/𝑝
        f(i) = xi mod N
QFTM
           Fig. 17. Illustration of the period-finding circuit, where m = 2n and M 􏰌= 2m .
1 M−1 􏰴,0 1 M−1 􏰴
√ 􏰶 􏰴 􏰌 √ 􏰶 􏰴,
1 􏰭M
√ |i,0⟩.
M a=0 M a=0
M i=0
Let n = logN be the number of bits of the input N. The running time of the algorithm
is dominated by the 2 log N = O(n) repetitions of step 3. Since modular exponentiation takes O(n3) steps (as we saw in Section 1.2.2) and the quantum Fourier transform takes O(n2) steps, the total running time for the quantum factoring algorithm is O(n3 log n).
        D
register 𝐵 register 𝐴
𝑛 qubits 00
𝑚 qubits
measure

Quantum Algorithm Implementations for Beginners
31
Next is a modular exponentiation circuit that computes the function f (i) = xi second register. The resulting state is
1 􏰭M
√ |i, f (i)⟩ .
(mod N) on the
M i=0
Before we apply the next QFT transform, we do a measurement of register B. (By the principle of
deferred measurement [77] and due to the fact that register A and B don’t interact from that point on, we don’t have to actually implement the measurement, but it will help to understand the final output.) If the value measured is s, then the resulting state becomes
M
1
M/r i=0
f (i)=s
where r is the period of f (i). In particular, register A is a superposition with equal non-zero amplitudes only of |i⟩ for which f (i) = s, i.e., it is a periodic superposition with period r. Given the property of QFT, the result of the transformation is the state
1 􏰭r
√ |i(M/r),s⟩.
r i=0
Hence, the measurement of register A will output a multiple of M /r . If the simplifying assumption
that r divides M is not made, then the circuit is the same, but the classical postprocessing is a bit more involved [77].
Period finding can also be viewed as a special case of phase estimation. The reader may refer Nielsen and Chuang [77] for this perspective on period finding.
5.3 Algorithm implemented on IBM’s 5-qubit computer
We implemented the algorithm on ibmqx4, a 5-qubit quantum processor from the IBM Quantum Experience, in order to factor number 15 with x = 11. The circuit as described on Figure 17 requires 12 qubits and 196 gates, too large to be implemented on ibmqx4. Hence, we used an optimized/compiled version from [106] that uses 5 qubit and 11 gates (Fig 18).
|0⟩H P(π2) H   • |0⟩H H• •
|0⟩ H • • P(π4) P(π2) |0⟩
|0⟩
Fig. 18. Circuit for Shor’s algorithm for N = 15 and x = 11.
The results from the measurements are shown on Figure 19.
The periods found by the simulator are p = 0, which is ignored as a trivial period, and p = 4, whichisagoodone.SinceM = 8,wecanconcludethatr dividesM/p = 8/4 = 2,hencer = 2. Then 15 divides
(xr −1)=(112 −1)=(11−1)(11+1)=10·12. By computing gcd(15, 10) = 5 and gcd(15, 12) = 3, we find the factors of 15.
􏰭
􏰠 |i,s⟩,
             
32 Abhijith J., et al.
  Fig. 19. Output from the circuit from Figure 18 implemented on the simulator (left) and ibmqx4 (right). The output from ibmqx4 finds the same periods 0 and 4 with the highest probabilities, but
contains much more noise.
6 MATRIX ELEMENTS OF GROUP REPRESENTATIONS
6.1 Problem definition and background
In this section we will discuss another quantum algorithm that makes use of the QFT operation. In this section we will also introduce a subroutine called the Hadamard test, which lets us compute matrix elements of unitary operators. But first, we will require some knowledge of group theory to understand the problem being tackled here. This section follows the work of Jordan in Ref. [59].
A Group (G, ·) or (G) is a mathematical object defined by its elements (д1, д2, . . . ) and an operation between elements (·), such that these four properties are satisfied.
(1) Closure: for any two group elements, the defined group operation produces another element, whichbelongstothegroup(for∀дi,дj ∈G,дi ·дj =дk ∈G).
(2)Associativity:for∀дi,дj,дm ∈G,дi ·􏰇дj ·дm􏰈=􏰇дi ·дj􏰈·дm.
(3) Identity element: e ∈ G, such that e · дi = дi · e = дi .
(4) Inverseelement:for∀дi ∈G,thereexistsдp,suchthatдi ·дp =дp ·дi =e.

Quantum Algorithm Implementations for Beginners 33
A group with a finite amount of elements n is called a finite group with order n, while a group with an infinite amount of elements is an infinite group. In this section, we will discuss quantum algorithms to solve certain problems related to finite groups. As before, we will also implement them on the IBM machines. Some examples of groups are given below.
Example 1A. Abelian group An with n elements: 0, 1, . . . , n − 1, and the group operation addition
modulon:дi ·дj =(i+j)mod(n).Forinstance,forn=3:a0 =0,a1 =1,a2 =2.Then,a2 ·a2 =4
mod(3)=1=a1,a2 ·a1 =3mod(3)=0=a0,etc.Theidentityelementisa0 =0anditsinverse
is itself. For all other elements the inverse element is, a−1 = an−i . This group is called Abelian or i
commutative, because in addition to the four group properties, it has a property of commutativity: ai ·aj =aj ·ai for∀ai,aj ∈An.
Example 1S. Symmetry group Sn with n! group elements, each is a permutation of n objects: [1, 2.., n], [2, 1.., n], . . . , [n, n − 1.., 2, 1]. Consequent application of two permutations is a group operation. For instance, for group S2: (e,p) we have two objects a and b. The identity element e is no permutation: ab → ab, while one permutation p is the second group element: ab → ba. Then, p · p = e, and p−1 = p. Only S1 and S2 are Abelian groups. For n ≥ 3, Sn are not commutative. Let us write elements of group S3 as a permutation of elements 123 in the next order: [123] → [123], [231], [312], [213], [132], [321]. Then s4 · s2 = s6, while s2 · s4 = s5.
While group definition is quite simple, it is not straightforward how to operate with group elements in general, especially when defined operations between them is not trivial and/or the group order, n, is large. In this case, it is helpful to apply the representation theory to the group. The idea is simple: if we can map a group of unknown objects with nontrivial operations to the group of known objects with some trivial operations, we can gain some information about the unknown group. In general, we introduce a function applied to a group element: ρ (дi ), which does this mapping between two groups. Such function defines the group representation of G if for ∀ дi , дj ∈ G, ρ(дi ) ∗ ρ(дi ) = ρ(дi · дj ), where (∗) can be a different operation from (·).
Example2A.RepresentationofAbeliangroupAn:aj →ρ(aj)=ei2πj/N,wheretheoriginal operation (+mod(n)) is substituted by the new operation of multiplication. Note that the group S2 can be represented in the same way as A2.
Example 2S. Representation of group S3: sj → ρ(sj ) = 1, where the original operation is again substituted by the new operation of multiplication. Such representation of the group S3 is trivial, since it does not carry any information about the group, however it satisfies the definition of the group representation. Moreover, [1,1, . . . ] is a trivial representation for any group. Another representation of group S3 is, [1, 1, 1, −1, −1, −1] → [s1, s2, . . . , sn ], where we map odd permutations to −1 and even permutations to 1 . While it carries more information about the initial group than the trivial representation, it does not imply that the group S3 is not Abelian. One cannot construct a one-dimensional representation for group S3 which would retains all its properties. The smallest equivalent representation for S3 is two-dimensional. The multidimensional representations can be easy understood when represented by matrices.
Most useful representations are often ones which map a group to a set of matrices. When ρ(д) is a dρ × dρ matrix, the representation is referenced as a matrix representation of the order dρ , while (∗) is the operation of matrix multiplication. All representations of finite group can be expressed as unitary matrices given an appropriate choice of basis. To prove the last fact, we introduce a particular representation called the regular representation.
The regular representation of a group of N elements is a matrix representation of order N . We will explain the construction of the regular representation using the Dirac notation. First, we associate with each element of the group дi a ket |дi ⟩. This ket could simply be the basis state |i⟩, since the elements of the group are numbered. This ensures that the kets associated with different

34 Abhijith J., et al.
group elements are orthonormal by construction, 􏰋дi |дj 􏰌 = δi j . This also ensures that the identity
operator can be expressed as 􏰫N |д ⟩ ⟨д | . The regular representation of д i=1 i i k
N
R(дk) = 􏰭􏰍􏰍дk ·дj􏰌􏰋дj􏰍􏰍.
j=1
is then given by,
(50)
The matrix elements of this representation are, Ri j (дk ) ≡ 􏰋дi |R(дk )|дj 􏰌 = ⟨дi |дk · дj ⟩. From the defining properties of a group it can be easily seen that multiplying every element in the group by the same element just permutes the elements of the group. This means that R(дk ) matrices are always permutation matrices and are hence unitary. We can prove that the regular representation is a representation using simple algebra,
NN R(дk)·R(дm)=􏰭􏰭|дk ·дi⟩⟨дi|дm ·дj⟩􏰋дj􏰍􏰍,
i=1 j=1 NN
=􏰭􏰭􏰍􏰍дk ·дm ·дj􏰌⟨дi|дm ·дj⟩􏰋дj􏰍􏰍, i=1 j=1
N
=􏰭􏰍􏰍дk ·дm ·дj􏰌􏰋дj􏰍􏰍=R(дk ·дm). (51)
j=1
Here we used orthogonality: ⟨дi |дm · дj ⟩ = 1 only if |дi ⟩ = 􏰍􏰍дm · дj 􏰌 and 0 otherwise, which allowed us to swap these two states. Then, we used the same fact to calculate the sum over i. Below we give some explicit examples of regular representations.
Example 3A. Regular representation of the Abelian group A4, where each matrix element is calculatedusingtheresultderivedaboveRij(ak)=⟨ai|ak ·aj⟩:
1000 0001 0010 0100
􏰤􏰨0 1 0 0􏰥􏰩 􏰤􏰨1 0 0 0􏰥􏰩 􏰤􏰨0 0 0 1􏰥􏰩 􏰤􏰨0 0 1 0􏰥􏰩 R(a0) = 􏰨 􏰩 , R(a1) = 􏰨 􏰩 , R(a2) = 􏰨 􏰩 , R(a3) = 􏰨 􏰩 .
􏰨0 0 1 0􏰩 􏰨0 1 0 0􏰩 􏰨1 0 0 0􏰩 􏰨0 0 0 1􏰩 0001 0010 0100 1000
􏰦􏰧􏰦􏰧􏰦􏰧􏰦􏰧
(52) Example 3S. Regular representation of the group S3, where we use the same order of permutations
Commutative property is conserved: R(ai ) · R(aj ) = R(aj ) · R(ai ). introduced above ([123] → [123], [231], [312], [213], [132], [321])
100000 001000 010000
􏰤􏰨0 1 0 0 0 0􏰥􏰩 􏰤􏰨1 0 0 0 0 0􏰥􏰩 􏰤􏰨0 0 1 0 0 0􏰥􏰩
􏰨􏰨0 0 1 0 0 0􏰩􏰩 􏰨􏰨0 1 0 0 0 0􏰩􏰩 􏰨􏰨1 0 0 0 0 0􏰩􏰩 R(s1)=􏰨 􏰩, R(s2)=􏰨 􏰩, R(s3)=􏰨 􏰩,
􏰨0 0 0 1 0 0􏰩 􏰨0 0 0 0 0 1􏰩 􏰨0 0 0 0 1 0􏰩 􏰨􏰨0 0 0 0 1 0􏰩􏰩 􏰨􏰨0 0 0 1 0 0􏰩􏰩 􏰨􏰨0 0 0 0 0 1􏰩􏰩
000001 000010 000100
􏰦􏰧􏰦􏰧􏰦􏰧
(53)

Quantum Algorithm Implementations for Beginners
35
000100 000010 000001
􏰤􏰨000010􏰥􏰩 􏰨􏰨000100􏰩􏰩
􏰨 􏰩 􏰨001000􏰩
􏰨􏰨010000􏰩􏰩 010000 001000 100000
􏰤􏰨0 0 0 0 0 1􏰥􏰩 􏰨􏰨0 0 0 0 1 0􏰩􏰩
􏰤􏰨0 0 0 1 0 0􏰥􏰩 􏰨􏰨0 0 0 0 0 1􏰩􏰩
.
R(s4) = 􏰨 􏰩 , R(s5) = 􏰨1 0 0 0 0 0􏰩
􏰨 􏰩 , R(s6) = 􏰨0 1 0 0 0 0􏰩
􏰨􏰨1 0 0 0 0 0􏰩􏰩
􏰦 􏰧􏰦 􏰧􏰦 􏰧(54)
􏰨􏰨0 0 1 0 0 0􏰩􏰩
Now we can finally explain the problem of calculating matrix elements of the group representa- tions, which is equivalent to the problem of calculating an expectation value of an operator A in respect to the state |ψ ⟩ in quantum mechanics: ⟨A⟩ = ⟨ψ | A |ψ ⟩.
Example 4A. Calculating matrix elements of the regular representation of the element a2 from the Abelian group A4 with respect to the state ψ13 which is the equal superposition of |a1⟩ and |a3⟩. In operator form we find:
⟨a|+⟨a|􏰔N−1 􏰕|a⟩+|a⟩ ⟨a|a ·a⟩⟨a|a⟩ ⟨a|a ·a⟩⟨a|a⟩ ⟨ψ12|a2|ψ12⟩= 1√ 3 􏰭|a2·ai⟩⟨ai| 1√ 3 = 3 2 1 1 1 + 1 2 3 3 3 =1.
    2i=0 2 2 2
(55)
It is quite obvious that if a quantum computer is capable of finding expectation values of a unitary operator, it will be able to solve the problem of finding the matrix elements of the regular representation of a group element. This will consist of, at least, two stages: the first stage is the state preparation, and the second is applying the unitary operator of the regular representation to that state. The unitary operator of the regular representation of an element of any group Gn can be created using a combination of only two type of operations: qubit flip (|0⟩ → |1⟩) and qubit swap (􏰍􏰍qjqi􏰌 → 􏰍􏰍qiqj􏰌).
Up to this point, we have only talked about the regular representation. The regular representation is quite convenient, it is straightforward to find for any group, it carries all the information about the group, and a corresponding unitary operator is easy to construct using standard quantum circuits. However, for groups with a large number of elements, it requires matrix multiplication between large matrices. So for many applications, instead of regular representations one is interested in what are known as irreducible representations, which are matrix representations that cannot be decomposed into smaller representations. Or in other words, every matrix representation (including the regular representation) can be shown to be equivalent to a direct sum of irreducible representations, up to a change of basis. This lets us reduce the representation theory of finite groups into the study of irreducible representations. The importance of irreducible representations in group theory cannot be overstated. The curious reader may refer these notes by Kaski [60].
A result from group theory ensures that the direct sum of all irreducible representations (each has different dimensions dρ in general) where each irreducible representation appears exactly dρ times is a block diagonal N × N matrix (the group has N elements). The Fourier transform pair over this group representation can be introduced by decomposing each irreducible representation over the group elements and vice versa. Moreover, the above defined direct sum of all irreducible representations can be decomposed as a regular representation conjugated by the direct and inverse Fourier transform operators [59]. This result lets us find the the matrix elements of the irreducible representations given the ability to implement the regular representation.

36 Abhijith J., et al.
               Fig. 20. Schematic diagram for the quantum algorithm
6.2 Algorithm description
In this section we will describe an algorithm to find the matrix elements of irreducible represen- tations of a group given the ability to apply its regular representations to a quantum register in a controlled fashion. The quantum algorithm calculating matrix elements ⟨ψ | U1 |ψ ⟩ of a unitary operator U1 is known as the Hadamard test, which is illustrated on Fig. 20.
Algorithm 5 Hadamard test
Input:
• The controlled unitary CU .
• Input state |0⟩|ψ⟩. Output:
• An estimate for the real part of ⟨ψ |U |ψ ⟩ Procedure:
Step 1. Apply H to the ancilla. This produces the state,
|0⟩ + |1⟩
  |ψ⟩
Step 2. Apply CU controlled on the ancilla. This produces the state,
|0⟩|ψ⟩+|1⟩U |ψ⟩
√
2 Step 3. Apply H to the ancilla again. This gives,
|0⟩(|ψ⟩+U |ψ⟩)+|1⟩(|ψ⟩−U |ψ⟩)
√
2
Step 4. Measure the ancillary qubit. Repeat to estimate the probability of obtaining |0⟩ and
√
2
   |1⟩.
The ancilla qubit should be prepared as √2 to calculate the imaginary parts of the matrix ele-
 |0⟩−i |1⟩
ment. From the pseudocode, we can see that the probability of measuring |0⟩ is P0 = || √2 || =
 |ψ⟩+U|ψ⟩ 2 1+Re ⟨ψ |U |ψ ⟩ . Hence, we find: Re ⟨ψ | U |ψ ⟩ = 2P0 − 1. The reader is encouraged to work out the same
  2
steps for the imaginary part as well.

Quantum Algorithm Implementations for Beginners 37
                           Fig. 21. Actual circuit implemented on IBM’s 5-qubit computer for calculating matrix elements of the regular representation for the second element of the group S2 and A2 in respect to the state |0⟩ on the left and
|0⟩+|1⟩
on the right. The expected probabilities to find a final state in the ground state are (1 + 0)/2 = 0.5 and the bottom) are presented on the right side of each circuit.
√
(1 + 1)/2 = 1 respectively. The results of the 1024 runs on the actual chip (on the top) and the simulator (on
2
With the Hadamard test algorithm, the problem of calculating matrix elements of an arbitrary unitary operator is reduced to the problem of effectively implementing it as a controlled gate. For the regular representation of any group U0, where unitary operator is an N x N square matrix with only one non-zero element equal to 1 in each row, this implementation can be done for any group as a combination of CNOT and Z gates.
At the same time solutions for the direct sum of all irreducible representations U1, which can be decomposed as U1(д) = F1U0(д−1)F−1, exists for any group whose Fourier transform over that
1
group can be effectively implemented using quantum circuits. Quantum circuits for the Fourier
transform are already known for the symmetric group S(n) [12], the alternating group An, and some Lie groups: SU (n), SO(n) [9], while solutions for other groups, hopefully, will be found in the future. For Abelian groups this Fourier transform implementation can be efficiently done using the QFT circuit that was discussed in the earlier sections. For non-Abelian groups the implementation is trickier and efficient implementations are not universally known.
6.3 Algorithm implemented on IBM’s 5-qubit computer
The actual gate sequence that we implemented on IBM’s 5-qubit computer (ibmq_essex) and IBM’s quantum simulator to find matrix elements of the regular representation of the second element of the group S2 is shown in Fig. 21. The matrix for this representation is simply a X gate. Hence, we have to use one CNOT gate and two Hadamard gates, plus some gates to prepare state |ψ ⟩ from the state |00⟩. We mapped the ancilla qubit to the actual machine q1 qubit instead of q0, because of the machine architecture, where the first qubit can control the zero qubit but not vice versa. We could have used the original qubit sequence as in Fig. 20, by realizing the CNOT gate as a swapped CNOT and four Hadamard gates, but this would add more gates to the circuit and potentially more computational errors rather than just a virtual swap of the qubits.
For the irreducible representation of the same element of the group A2 , the element is represented by the Z gate. Hence the Hadamard test requires implementing a controlled-Z gate, which is not available as an actual gate on the IBM Quantum Experience. However, it can be constructed using two Hadamard and one CNOT gates as shown in Fig. 22. Notice that the Hadamard gate is actually the Fourier transform operator over group S2 and A2, while the X gate is a regular representation operator, as we mentioned earlier. Hence, such controlled-Z gate representation

38 Abhijith J., et al.
                          Fig. 22. Actual circuit implemented on IBM’s 5-qubit computer for calculating matrix elements of the direct sum of the irreducible representations for the second element of the group S2 and A2 with respect to the state |0⟩ on the left and |1⟩ on the right. The expected probabilities to find a final state in the ground state are (1 + 1)/2 = 1 and (1 − 1)/2 = 0 respectively. The results of the 1024 runs on the actual chip (on the top) and the simulator (on the bottom) are presented on the right side of each circuit.
is in fact the decomposition of the irreducible representation to the regular representation using Fourier transform over that group.
7 QUANTUM VERIFICATION OF MATRIX PRODUCTS
7.1 Problem definition and background
Matrix multiplication is one of the most important linear algebra subroutines. Most scientific computing algorithms use matrix multiplication in one form or another. Therefore, the compu- tational complexity of matrix multiplication is a subject of intense study. For two n × n matrices the computational complexity of the naive matrix multiplication algorithm is O(n3) A faster algo- rithm for matrix multiplication implies a considerable performance improvement for a variety of computational tasks. Strassen [100] first showed that two n × n matrices can be multiplied in time O(n2+α ) (α &lt; 1). The best known algorithm to date with α ≈ 0.376 was found by Coppersmith and Winnograd [32]. Despite that, it remains an open problem to determine the optimal value of α . The so-called problem of matrix verification is defined as, verifying whether the product of two n × n matrices is equal to a third one. So far the best classical algorithm can do this with high probability in time proportional to n2 [45].
Ref. [4] was the first to study matrix verification for quantum computation. The authors use a quantum algorithm based on Grover’s algorithm to verify whether two n × n matrices equal a third in time O(n7/4), thereby improving the optimal classical bound of Ref. [45]. Ref. [23] presents a quantum algorithm that verifies a product of two n × n matrices over any integral domain with bounded error in worst-case time O(n5/3) and expected time O(n5/3/min(w, √n)1/3), where w is the number of wrong entries. This further improves the time performance O(n7/4) from Ref. [4].
7.2 Algorithm description
We briefly sketch the quantum algorithm from Ref. [4]. The presentation here follows from Ref. [99]. Before we discuss this algorithm we introduce the concept of amplitude amplification.
Many real world algorithms are probabilistic, i.e., independent runs of the algorithm on the same input will not necessarily give the same output. This is because the algorithm uses some source of randomness during its execution. Most quantum algorithms are probabilistic owing to the inherent randomness present in quantum mechanics.

Quantum Algorithm Implementations for Beginners 39
Suppose that the job of our probabilistic classical/quantum algorithm is to return one of a specific set of states. Assume that we also have at our disposal an oracle that can identify the members of this set from other states. An example of this would be polynomial root finding. The set of states in this case would correspond to the roots of the polynomial. Our algorithm should return one of the roots of the polynomial and we can verify if an output is a root by plugging it in to the polynomial.
Obviously the algorithm is good only if it can return a state that is a member of this set with high probability. But how high of a success probability is good enough? For practical reasons we would like the probability of success to be a constant. That is, it should be a value independent of the problem size and other parameters in the problem. Any constant value between 0 and 1 would work here. The value 23 is usually used in literature.
But often algorithms won’t succeed with constant probability and their success provability will diminish with growing input size. In that case, how can we boost the success probability to the desired level? The classical answer to this question is to repeatedly run the algorithm until we succeed, i.e., till the algorithm outputs a state from the specific set of states that we want. If the algorithm initially had a success probability of p, after O(p1 ) repetitions we are guaranteed to find the desired state with constant probability.
For quantum algorithms we can do something better. Let U be a quantum algorithm and suppose
that we want this algorithm to return a state from the subspace spanned by the orthogonal states,
{|ui ⟩}. Let P be the projection operator onto this subspace, P = 􏰫i |ui ⟩ ⟨ui | . The oracle we have is
then, O = I − 2P . This oracle will mark the states in the desired subspace. The success probability of
our algorithm is p = 􏰋0 . . . 0|U †PU |0 . . . 0􏰌. In this scenario we can use amplitude amplification to
boostthesuccessprobabilitytoaconstantwithonlyO(√1 )repetitions.Thisisaquadraticspeedup p
over the classical strategy.
Essentially, amplitude amplification is a generalization of Grover search described in Section II .
In Grover search we repeatedly apply the Grover operator, G = (2 |ψ ⟩ ⟨ψ | − I )O , where |ψ ⟩ is the uniform superposition state. Amplitude amplification uses a more general operator,
GU =U(2|0⟩⟨0|−I)U†O. (56) TogetthedesiredresultweapplythistotheU |0...0⟩stateO(√1 )times.Noticethattheoriginal
p
Grover search is a specific case of amplitude amplification with U = H ⊗ . . . ⊗ H . In that case, the probability of getting the marked state in |ψ ⟩ is N1 so we run the algorithm for O (√N ) steps. The reader is referred to Ref. [21] for more details on amplitude amplification.
The matrix product verification procedure uses amplitude amplification as its outer loop. The algorithm first splits the full matrix verification problem into smaller matrix verification problems. Then it uses amplitude amplification to search if one of these verifications fail. Each of these smaller verification steps also use a Grover search to look for disagreements. So the complete algorithm uses one quantum search routine nested inside another quantum search routine. This is a common strategy used while designing quantum algorithms to improve query complexity. The full algorithm is sketched below.
The number of qubits and the circuit depth required for this algorithm is too large for it to be successfully implemented on the IBM machines. But at the heart of this algorithm is the Grover search procedure, which we have already discussed and implemented in Section II

40 Abhijith J., et al.
 Algorithm 6 Matrix product verification [4] [99]
 Input:
• n × n matrices A, B, C . Output:
• Verifies if AB = C Procedure:
√√
n submatrices of size n × n. Call these Bi and Ci respectively.
Step 1. Partition B and C into
AB =C ifandonlyifABi =Ci foralli.
Step 2. Use amplitude amplification over i on these steps:√
Step 2a. Choose a random vector x of dimension n.
Step 2b. Compute y = Bi x and z = Ci x classically
Step 2c. Verify equation Ay = z by Grover search. Search for a row j such that
(Ay−z)j 􏰯0
8 GROUP ISOMORPHISM
8.1 Problem definition and background
The group isomorphism problem, originally identified by Max Dehn in 1911 [35], is a well-known decision problem in abstract algebra. Simply stated, it asks whether there exists an isomorphism between two finite groups, G and G′. Which, according to the standpoint of group theory, means that they are equivalent (and need not be distinguished). At the end of Section 5 we saw an example of two isomorphic groups, S2 and A2. These two are the same group in terms of how the group operation works on the group elements, but are defined in different ways. More precisely, two groups, (G1, ·) and (G2, ∗) are called isomorphic if there is a bijection, f : G1 → G2, between them such that, f (д1 · д2) = f (д1) ∗ f (д2).
To solve this problem using a quantum algorithm, we assume that each element can be uniquely identified by an arbitrary bit-string label. We also assume that a so-called group oracle can be used to return the product of multiple elements. That is, given an ordered list of group-element labels, the oracle will return the product label. In practice, this means that we must be able to construct a quantum circuit to implement Ua : |y⟩ → |ay⟩, for any a ∈ G.
In this section, we will focus our attention on the abelian group isomorphism problem, because it can be solved using a generalization of Shor’s algorithm [94]. As we saw before, abelian simply means that the operation (·) used to define the group is commutative, such that a · b = b · a, for a,b ∈ G. Although Shor’s approach is specifically intended to leverage a quantum period-finding algorithm to reduce the time-complexity of factoring, the procedure effectively solves the group isomorphism problem over cyclic groups. Using this relationship, Cheung and Mosca [25] have developed a theoretical quantum algorithm to solve the abelian group isomorphism problem by computing the decomposition of a given group into a direct product of cyclic subgroups.
8.2 Algorithm description
The procedure presented in Algorithm 7 assumes the fundamental theorem of finite abelian groups, that they can be decomposed as a direct sum of cyclic subgroups of prime power order. This decomposition can then be used to test if an isomorphism exists between two groups.
Since the procedure in Algorithm 7 is mostly classical, we shall treat the task of finding the generators of the hidden subgroup in Step 1 as the most critical for us to explore. This task is commonly referred to as the hidden subgroup problem (HSP). This means that, given a function д that maps a finite group A onto a finite set X, we are asked to find a generating set for the
 
Quantum Algorithm Implementations for Beginners 41
 Algorithm 7 Decompose(a1, . . . , ak , q), of Cheung and Mosca [25]
Input:
•Ageneratingset{a1, ...,ak}ofG.
• The maximum order, q, of the generating set. Output:
•Thesetofelementsд1, ...,дl fromgroupG,withl ≤k. Procedure:
Step1.Defineд:Zk →Gbymapping(x , ...,x )→д(x)=ax1 ···axk. q1k1k
Find generators for the hidden subgroup K of Zqk as defined by function д. Step 2. Compute a set y1, . . . ,yl ∈ Zqk /K of generators for Zqk /K. Step3.Outputtheset{д(y1), ...,д(yl)}.
subgroup K . For K to be the so-called hidden subgroup of A, we require that д is both constant and distinct on the cosets of K. On a quantum computer, this problem can be solved using a number of operations that is polynomial in log|A|, in addition to one oracle evaluation of the unitary transform U |a⟩ |h⟩ = |a⟩ |h ⊕ д(a)⟩. The general procedure needed to complete Step 1 of algorithm 7 is described in algorithm 8.
Algorithm 8 Solution to the hidden subgroup problem (for finite abelian groups). Based on Ref. [77]
Input:
• Two quantum registers.
• Elements of the finite abelian group A (or the generating set). • A function д, such that д : A → X , with a ∈ A and h ∈ X .
Output:
• The generating set for the hidden subgroup K. Procedure:
Step 1. Create initial state.
Step 2. Create superposition between resisters.
Step 3. Apply unitary operation (U ) for function д(a).
1
    → 􏰠|A|
Step 5. Measure the phase from first register. → l/|A|
Step6.SampleK froml/|A|.
|A| a∈A
|a⟩ |д(a)⟩ (57)
􏰭
→ 􏰠 Step 4. Apply inverse Fourier transform.
1 |A|−1
l=0
(59)
Like the period-finding approach used in quantum factorization in Section V, Algorithm 8 is heavily based on the concept of phase estimation. Note that the Fourier transform in Eq. 58 represents a ∈ A indexed by l. The key concept of the procedure is that |дˆ(l)⟩ has nearly zero amplitude for all values of l , except those which satisfy
􏰭 2πila/|A|
e |дˆ(l)⟩ (58)
 
42 Abhijith J., et al.
 Fig. 23. Basic phase-estimation quantum circuit needed to solve the general hidden subgroup problem in algorithm 8. Here, |u⟩ is an eigenstate of the unitary operator U .
|K| = 􏰭e−2πilh/|A|, (60) h∈K
and that knowledge of l can be used to determine both the elements and generating set of K. As discussed by Nielsen and Chuang [77], the final step in algorithm 8 can be accomplished by expressing the phase as
M
→e2πila/|A| =􏰮e2πiliai/pi. (61)
i=1
for ai ∈ Zpi , where pi are primes, and Zpi is the group containing integers {0, 1, . . . , pi − 1} with the operator being addition modulo pi .
The quantum circuit needed to solve the HSP is schematically illustrated in Fig. 23. This simplified circuit includes steps 1-5 of algorithm 8, and makes it clear that all forms of the HSP (order-finding, period-finding, discrete logarithm, etc.) are extensions of quantum phase estimation.
8.3 Algorithm implemented using Qiskit
Since the generalized group isomorphism problem is somewhat complex, we will focus here on the implementation of the HSP circuit fragment illustrated in Fig. 23. We also chose a specific instance of the HSP: the problem of finding the period of a mod n. In Fig. 24, the basic outline of the code needed for this specific problem is illustrated using the python-based Qiskit interface.
Like most instances of the HSP, one of the most challenging practical tasks of finding the period of a mod n on a quantum computer is the implementation of the oracle. The details of the oracle are not explicitly shown in the Qiskit snippet, but for the required Ca mod 15 operations, one can simply used the circuits developed by Markov and Saeedi [87]. The code in Fig. 24 also assumes thatafunctionqft_inv()willreturnthegatesforaninversequantumFouriertransform,andthata classical continued fractions algorithm can be used to convert the end result (a phase) to the desired integer period.
Although the specific procedure outlined in Fig. 24 can be directly implemented using the IBM Qiskit interface, the resulting QASM code is not expected to lead to accurate results on the IBMX4 (or IBMX5). This is because the generated circuit is long enough for decoherence error and noise to ultimately dominate the measured state. In other words, the physical hardware requires further

Quantum Algorithm Implementations for Beginners 43
#======================================================================# #---------- Finding period (r) of a % N, with N=15 ------------------# #======================================================================# def findperiod(a, N=15, nqubits1, nqubits2):
    # Create QuantumProgram object, and define registers and circuit
    Q_program = QuantumProgram()
    qr1 = Q_program.create_quantum_register("qr1", nqubits1)
    qr2 = Q_program.create_quantum_register("qr2", nqubits2)
    cr1 = Q_program.create_classical_register("cr1", nqubits1)
    cmod15 = Q_program.create_circuit("cmod15", [qr1, qr2], [cr1])
# Apply a hadamard to each qubit in register 1 # and prepare state |1&gt; in regsiter 2
for j in range(nqubits1): cmod15.h(qr1[j]) cmod15.x(qr2[nqubits2-1])
    # Loop over qubits in register 1
for p in range(nqubits1):
        # Calculate next 'b' in the Ub to apply
        # ( Note: b = a^(2^p) % N ).
        # Then apply Ub
        b = pow(a,pow(2,p),N)
        CxModM(cmod15, qr1, qr2, p, b, N, nqubits1, nqubits2)
    # Perform inverse QFT on first register
    qft_inv(cmod15, qr1, nqubits1)
    # Measure each qubit, storing the result in the classical register
for i in range(n_qr1): cmod15.measure(qr1[i], cr1[i])
Fig. 24. Simple implementation of the quantum period-finding algorithm in Qiskit
optimization to reduce the number of gates used between the initial state preparation and the final measurement.
9 QUANTUM PERSISTENT HOMOLOGY
9.1 Problem definition and background
Big data analysis often involves large numbers of multidimensional data points. Understanding their structure can lead to insights into the processes that generated them. Data clustering is closely related to spatially connected components. Other features such as holes and voids and their higher dimensional analogs that characterize the distributions of data points are useful for understanding their structure. Persistent homology connects data points across scales to reveal the most enduring features of datasets. Methods from algebraic topology are employed to build simplicial complexes from data points, and the topological features of these simplicial complexes are extracted by linear algebraic techniques. However, such an investigation on a set of n points

44 Abhijith J., et al.
 Fig.25. Examplesofsimplices,simplicialdecompositionofatopologicalspaceX,relationshipsamonggroups Cp (chains), Zp (cycles), and Bp (boundaries) under the action of boundary homomorphisms ∂p , and the example of the torus.
leads to storage and computational costs of O(2n) as there is a combinatorial explosion in the number of simplices generated by n points. Thus representational and computational efficiency has to be greatly enhanced for viability. Quantum algorithms provide such efficiency by superposing 2n simplex states with only n qubits and implementing quantum parallel computations. The study of such a quantum algorithm, proposed by Lloyd et. al [68] is the focus of this section.
Data points P = {p0, . . . ,pn−1} can be envisaged as vertices of a simplicial decomposition of a subsetX.Anorientedk−simplexσk =[pj0,...,pjk],0≤j0 &lt;j1,...,&lt;jk ≤n−1,istheconvex hull of k + 1 points, and the simplicial complex is comprised of all the simplices. Thus, a 0-simplex is a vertex, a 1-simplex is an edge, a 2-simplex is a triangle, a 3-simplex is a tetrahedron, and so on. Determining which distance scales ε of vertex connectivity capture enduring topological features is the goal of Persistent Homology [68]. The numbers of various topological features at any scale are obtained from algebraic structures involving the simplices.
Define the kth chain group Ck as the set of all formal integer linear combinations of k-simplices:
Ck = {􏰫i aiσki |ai ∈ Z}. Ck is an abelian group generated by the k-simplices. Further, define
boundary operators ∂k : Ck → Ck−1 between chain groups as group homomorphisms whose action
on a k-simplex σk = [pj0,...,pjk ] is given by ∂kσk = 􏰫ki=0(−1)i[pj0,...,pji−1,pji+1,...,pjk ] (i.e.,
the ith vertex is omitted from σk , 0 ≤ i ≤ k, to get the k + 1 oriented ith boundary (k − 1)-simplex
faces). With this, every k-chain ci ∈ Ck gives rise to a (k − 1)-chain ci ∈ Ck−1. A chain c ∈ Ck k k−1
such that ∂kc = 0, where 0 is the null chain, is called a k-cycle. Also, ∂k ∂k+1 ≡ 0. That is to say, the boundary of a boundary is the null chain 0, since the boundary of every k + 1-chain is a k-cycle. Zk = Ker(∂k)isthesubgroupofCk consistingofallk-cycles,andBk = Imaдe(∂k+1)isthesubgroup of Ck consisting of boundaries of all (k + 1)-chains in Ck+1. Clearly, Bk ⫅ Zk . The relationships between chain groups, cycles and boundaries as established by the boundary homomorphisms is illustrated in Fig. 25(c). The kth Betti number βk of a topological space X is defined as the number of linearly independent k-cycles that are not boundaries of (k + 1)-chains, and characterizes the topological features at dimension k. For instance, β0 is the number of connected components of X, β1 is the number of 1-dimensional holes, β2 is the number of voids, and so on. The kth Homoloдy GroupofX isdefinedasthequotientgroupHk(X)=Zk(X)/Bk(X),wherebyβk isthenumberof generators of Hk (X ).
Equivalently, the kth Betti number βk is the dimension of the kernel of the combinatorial Laplacian operator, ∆k = ∂†∂k + ∂k+1∂† , βk = dim(Ker(∆k)). This allows the computation of
k k+1
Betti numbers by finding the null space of a linear transformation. Lloyd’s quantum algorithm [68]
diagonalizes the Laplacian to compute Betti numbers.

Quantum Algorithm Implementations for Beginners 45
  Fig. 26. Grover’s Algorithm circuit implemented on the 5 qubit quantum computer showing 3 qubits being used with the multiple solution version of Grover’s Algorithm. U3 gates are used to input the scaled distances between points.
       Fig.27. QuantumPhaseEstimationAlgorithmcircuitimplementedonthe5qubitquantumcomputershowing how the quantum density matrix implemented on qubits 0, 1, and 2 would be applied to obtain a classical measurement on qubit 3.
9.2 Quantum algorithm description
A quantum algorithm for calculating Betti Numbers is presented in [68]. The algorithm uses Grover’ssearchcombinedwithphaseestimationtofindthedimensionKer(∆k).Grover’salgorithm is used to prepare a suitable initial state for the phase estimation. We will demonstrate how phase estimation can be used to estimate the dimension of the kernel of an eigenspace. Suppose that we haveanN ×N unitaryoperatorU =ei2πH onwhichwewillapplyphaseestimation.Let􏰍􏰍uj􏰌and
ei2π λj be the eigenvectors and eigenvalues of U . Now given a starting state √1 N
that the phase estimation subroutine will effect the following transformation, 1􏰭N 1􏰭N􏰍􏰍􏰙
􏰍􏰍 􏰌 􏰍􏰍 􏰌  ̃ √N uj |0⟩ → √N uj 􏰍λj ,
􏰫Nj=1 􏰍􏰍uj 􏰌 we know (62)
j=1 j=1
where λ ̃j are approximations to the original eigenphases. Now consider a measurement on the
ancillary register that stores these eigenphases. If one of the λj were zero, we can see that the probabilityofmeasuring|0⟩onthesecondregisterisequalto dim(Ker(H)).Moreovertheprobability
 􏰍 ̃􏰙 N
of measuring any 􏰍􏰍λj will similarly be related to the dimension of its eigenspace. So by estimating
these probabilities, we can figure out the dimensions of the eigenspaces. Notice that the performance and correctness of the procedure will depend on the precision of λ ̃ j . This will in turn depend on the number of ancillary qubits used in the procedure. For this procedure to work it was crucial

46 Abhijith J., et al.
that we started with the uniform superposition of all the eigenstates. This is a correct but naive way to go about the problem especially if the dimension of the null space is exponentially small compared to the size of the matrix. But, this technique will work equally well if the input to the procedure was a classical mixture of some of the eigenstates such that the probability of the null states in the said mixture was related to the dimension of the null space. This would let us recover the dimension of the null space from the measurement probabilities. The algorithm to find Betti numbers uses such a generalization of the naive procedure illustrated above.
We will roughly sketch the full algorithm without going into the details. We associate with each simplex σk a computational basis state |σk ⟩ such that the 1s in |σk ⟩ correspond to the points chosen in σk . Then the algorithm roughly goes as follows:
(1) First we construct a uniform superposition over all the simplex states in a set denoted by Skε . The precise definition of the set is not important to us now. The crucial fact is that there exists an easily computable function that determines the membership of a simplex to this set. This requires an additional input of scaled distance between points. This function can then be used as an oracle in Grover search to compute the desired state.
(2) Then this state is modified to produce an equiprobable mixture over all the simplicies in Skε . This mixture is represented as a quantum density matrix ρ. Readers unfamiliar with the concept of density matrices should read the section on quantum tomography.
(3) Now perform phase estimation on ρ to find the probabilities of an eigenvalue to be multiplied with the number of simplices to obtain input for the calculation of a Betti number
Working with only 5 qubits implies that the largest number of points n that could be processed at once is constrained by n(n − 1)/2 ≤ 5. Thus only 3 points at a time could be processed on the 5 qubit quantum computer. In the implementation of Grover’s Algorithm is shown in Fig. 26, only one iteration of Grover’s algorithm is shown. The output of this part of the algorithm is a quantum distribution of simplices.
Calculating the quantum density matrix could not be accomplished by the IBM machine due to the lack of Quantum RAM needed for the algorithm. Options considered to circumvent this problem included implementing a quantum algorithm for computing the outer product to form an 8x8 quantum density matrix. This was abandoned as the sheer size of quantum algorithms to implement four qubit addition [107] was well beyond the 5 qubits available on the quantum computer. The Quantum Experience message boards’ suggestion to perform Grover’s algorithm 64 times and reassemble the output into a density matrix was also not viable due to decoherence. Had a quantum density matrix been produced, phase estimation would have been applied to find the probabilities of eigenvalues of the boundary operator. This would then be multiplied times the number of simplices and used as input to find the Betti Number. The phase estimation quantum circuit for this purpose is shown in Fig. 27. Hence the main bottleneck here is seen to the the coherence time of the computer.
In order to check the coherence of the quantum 5 qubit computer a study was designed. All five qubits were flipped in the first timestep and measurements were then taken place approximately every five timesteps throughout the 74 available timesteps in the quantum composer. The quantum algorithm applied is shown in Fig. 28 showing the use of the Idle gates for 5 timesteps after the qubits are flipped with the X gate.
The data was collected for all the timesteps, processed into a form to evaluate the coherence percentages for all individual qubits and for all qubits combined. The results are depicted in Fig. 29 showing the decoherence rates with quantum composer timesteps. The coherence rates here measure the ‘quantumness’ of the qubits as detailed in Ref. [105]. Note that although the coherence rates are fairly high for individual qubits, the overall qubit coherence percentages are far less. This

Quantum Algorithm Implementations for Beginners 47
          Fig. 28. The quantum algorithm applied to estimate the Decoherence time of the 5 qubit quantum computer as implemented in the Quantum Composer to measure the decoherence after 5 timesteps. Note that this produces an optimistic estimate as the "id" quantum gates utilize minimal time whereas other gates, such as CNOT and U3 gates, could use more time.
          Fig.29. TimestepsavailablewiththeQuantumComposerareshownonthexaxis,rangingupto74.Coherence percentage is calculated for all individual qubits and is plotted on the y axis. Coherence percentages of all 5 qubits combined is also shown on the y axis. Note that the coherence percentage rate falls below 50 percent between the 15th and the 20th timesteps.
is because a single qubit decohering also decoheres the entire 5 qubit quantum computer. This should be considered to determine how many qubits will actually be usable in an actual machine. It is also interesting that qubit 3 seems to decohere at a faster rate than the other qubits past timestep 15.
10 QUANTUM RANDOM WALKS
10.1 Problem definition and background
Quantum algorithms for graph properties using the adjacency matrix (as part of an oracle) have been published for minimum spanning tree, shortest path, deciding if a graph is bipartite, detecting

48 Abhijith J., et al.
cycles, finding subgraphs (such as a triangle), maximal clique, and many more. Each typically involves the use of Grover’s search [52] with an oracle constructed from the adjacency matrix.
But for some problems Grover’s algorithm is insufficient to achieve optimal query complexity. In such cases, a quantum random walk can sometimes be useful in reducing the query complexity of an algorithm further. An example of this is the quantum algorithm for element distinctness by Ambainis [5]. Additionally, quantum walk algorithms can also be used to search and find graph properties [29, 38, 42, 61, 62, 71]. Quantum random walks can be seen as a quantum mechanical generalization of classical random walks. Quantum random walk algorithms come in two forms, discrete time quantum walks and continuous time quantum walks [61]. The discrete form operates in a step-wise fashion, requiring multiple copies of a set of gates per step. The continuous form uses a transition matrix that is expressed as a Hamiltonian, whose time evolution is then simulated. Quantum random walks can be used to walk a graph [38, 62], search for marked vertices [42], and to solve s-t connectivity [62]. An excellent survey of this approach to quantum search can be found in Ref. [88].
Most quantum algorithms that solve graph problems requires an oracle that knows the properties of the underlying graph. A graph properties oracle can be assembled as a circuit based on the adjacency matrix of the graph and linear algebra transformations. For example, a quantum circuit for finding maximal cliques in a graph with n nodes, requires an oracle workspace of n2 data qubits and n2 ancilla qubits (see [109]). Each oracle call requires execution of 6n2 Toffoli gates and 2n CNOT gates. An oracle such as this can be run on a simulator, but requires too many qubits to run on actual qubit hardware. Quantum algorithms for finding a triangle, quadrilateral, longer cycles, and arbitrary subgraphs [28] typically use the adjacency matrix to create the oracles. Here we will not get into using quantum random walks to solve such problems. Instead we will demonstrate how to implement a simple quantum random walk on a quantum computer.
10.2 Example of a quantum random walk
Quantum random walks or simply quantum walks are quantum analogues of classical random walks and Markov chains. Unlike the continuous time quantum walk, the discrete time quantum walk algorithm requires the use of one or more coin qubits representing the number of movement choices from each graph vertex. These extra coin degrees of freedom are necessary to ensure unitarity of the quantum walk. An appropriate unitary transformation on these coin qubits then acts like the quantum version of a random coin toss, to decide the next vertex for the walker.
Intuitively, the quantum walk is very similar to its classical cousin. In a classical walk, the walker observes some random process, say a coin toss, and decides on his next step conditioned on the output of this random process. So for a classical random walk, the walker is given a probability to make a transition. In a quantum walk, on the other hand, the random process is replaced by a quantum process. This quantum process is the application of the coin operator, which is a unitary matrix. So the next step of the walker is controlled by a complex amplitude rather than a probability. This generalization, from positive numbers to complex numbers, makes quantum walks more powerful than classical random walks.
The full Hilbert space for the discrete quantum walk on a cycle with N = 2n nodes can then be constructed as follows. We use an n qubit register to represent the nodes of the graph as bit strings. For the cycle every node has only two neighbours, so the coin space only needs a dimension of 2. Hence, only one extra coin qubit is required. The basis vectors of the coin (|0⟩ and |1⟩) will denote the right and left neighbours. So a basis state in the full Hilbert space will have the form |k,q⟩, where k is represents a node on the cycle and q is a single bit representing the coin state.
The quantum walk is then a product of two operators, the shift operator (S) and the coin operator (C). As we mentioned before the coin operator only acts on the coin qubit. The coin operator can be

Quantum Algorithm Implementations for Beginners 49
in principle any unitary that mixes the coin states, but here we will use the Hadamard coin which is just the H gate on the coin qubit,
|k,0⟩+(−1)q |k,1⟩
C |k,q⟩ = I ⊗ H |k,q⟩ = √ . (63)
2
The shift operator acts on both the registers. It moves the walker to the left or right depending on the coin state and then flips the coin state,
S |k,q⟩ = |k + (−1)q,q ⊕ 1⟩ (64)
The quantum walk then proceeds by applying these two operators in alternation. A p step quantum walk is just the operator (SC)p . This type of a walk was first introduced in Ref. [92] and is sometimes referred to as a ‘flip-flop’ quantum walk.
The definition of these operators can change for different types of quantum walk. The coin operator can be a Hadamard gate or a sub-circuit that results in mixing the coin states. The shift operator can be simple as described above or can be a more complicated circuit that selects the next vertex in the path based on the state of the coin. A simple pseudo-code for implementing the quantum walk is given in Algorithm 9.
Algorithm 9 Discrete time quantum walk
Input:
• Two quantum registers. The coin register and the position register.
• Number of steps, T . Output:
• State of the quantum walk after T steps. Procedure:
Step 1. Create the initial state. The initial state depends on the application. For instance, in quantum search algorithms, the initial state is the uniform superposition state.
for 0 ≤ k &lt; T do
Step 2a. Apply the coin operator, C, to the coin register.
Step 2b. Apply the shift operator, S. This shifts the position of the walker controlled
on the coin state.
end for
Step 3. (Optional) Measure the final state.
10.3 Algorithm implementation using Qiskit on IBM Q
In this section we will implement a simple quantum walk on Qiskit and execute it on both the simulator and ibmq_vigo, which is a 5 qubit machine available on IBM Q. We will test the quantum walk on a simple 4 vertex cycle with the vertices labels as given in Fig. 30.
    
50 Abhijith J., et al.
 Fig. 30. A graph of 4 nodes in the form of a square is used for the random walk algorithm. The starting vertex is labeled 00. The next possible vertex choices vary by 1-bit in their labels, 01 and 10. The quantum walk algorithm will walk around the graph.
The coin operator in Eq. (63) is just the H gate acting on the coin qubit. The shift operator defined in Eq. (64) is more non-trivial. We can implement it by the circuit given in Fig. 31.
••X• • • X•X
Fig. 31. Quantum circuit for the shift operation on the 4 vertex cycle. The top qubit is the coin qubit.
Running the walk for multiple steps requires us to apply the shift operator circuit many times. So it would be tedious to implement the quantum walk on the IBM Q graphical interface. Instead we can use Qiskit to design the shift operator as a user defined gate and then run the walk for multiple steps using a simple for loop. The Qiskit code for this is given in Fig. 32.
We ran this Qiskit code for 4 steps of the quantum walk. We chose 4 steps since, a simple
calculation shows that, starting from |000⟩ and applying (SC)4 will concentrate all the probability
to the state |100⟩ . This is confirmed by running the Qiskit code on the simulator. But running the
same code on ibm_vigo gave |100⟩ with only 21.7% probability. The rest of the probability was
distributed among the other basis states, but |100⟩ was still the state with the largest probability.
This poor performance is due to the circuit having large depth. We can expect to get better results
    by running the quantum walk for a single step. After a single step, starting from |000⟩, the state of |111⟩+|010⟩
the system is √2 . This is again confirmed by the simulator. Running on ibm_vigo, we got |111⟩ with 33.5% probability and |010⟩ with 28.5% probability.
 11 QUANTUM MINIMAL SPANNING TREE
11.1 Problem definition and background
A common problem in network design is to find a minimum spanning tree. Suppose we are responsible for maintaining a simple network of roads. Unfortunately, each segment needs repair and our budget is limited. What combination of repairs will guarantee the network remains connected? Fig 33 shows a model of a simple road network as a graph, together with a minimal spanning tree.
Formally, a graph G = (V , E) consists of a set V (the nodes) and a set E consisting of pairs of nodes. A graph is connected if between any two nodes there exists a path. A spanning tree of aconnectedgraphG=(V,E)isthegraphT=(V,ET)whereET ⊂EandTcontainsnocycles

Quantum Algorithm Implementations for Beginners 51
from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister from qiskit import Aer, execute
n_steps =  4          #Number of steps
#Defining the shift gate
shift_q =  QuantumRegister(3)
shift_circ = QuantumCircuit (shift_q, name='shift_circ')
shift_circ.ccx (shift_q[0],  shift_q[1], shift_q[2])
shift_circ.cx ( shift_q[0], shift_q[1] )
shift_circ.x ( shift_q[0] )
shift_circ.x ( shift_q[1] )
shift_circ.ccx (shift_q[0],  shift_q[1], shift_q[2])
shift_circ.x ( shift_q[1] )
shift_circ.cx ( shift_q[0], shift_q[1] )
#3 qubit register
#Circuit for shift operator
#Toffoli gate
#CNOT gate
shift_gate = shift_circ.to_instruction()
q = QuantumRegister (3, name='q')
c = ClassicalRegister (3, name='c') circ = QuantumCircuit (q,c)
for i in range(n_steps):
    circ.h (q[0])
    circ.append (shift_gate, [q[0],q[1],q[2]])
#Convert the circuit to a gate
#3 qubit register
#3 bit classical register
#Main circuit
#Coin step
#Shift step
circ.measure ([q[0],q[1],q[2]], [c[0],c[1],c[2]])
Fig. 32. Qiskit code to implement the quantum walk on a 4 vertex cycle.
(i.e., there is exactly one path between any two vertices). It is not hard to see that a graph T is a spanning tree if and only if T is connected and has n nodes and n − 1 edges. A weighted graph is a graph G = (V,E,w) where w is a map on the edges w : E → R. A minimal spanning tree of a graph G is then a spanning tree T = (V , ET ) which minimizes
􏰭 w(e). (65) e∈ET
11.2 Algorithm description
Algorithmically, a graph is usually presented in one of two ways: either as a list of edges or as an
adjacency matrix. We consider the case where G is presented as a list of edges. A quantum algorithm
for finding a minimal spanning tree of an input graph is given in [39]. This algorithm requires
√
onlyO( nm)querieswherenisthenumberofnodesandmthenumberofedgesinthegraph.
Classically, the best algorithms run in time O(m logn). In particular, this is the time complexity of Borůvka’s algorithm [19]. The quantum algorithm combines Borůvka’s algorithm together with the quantum search algorithm of Grover [52].

52
Abhijith J., et al.
           (a) The weighted graph model.
           (b) A minimal spanning tree.
Fig. 33. A graph modeling repair costs of a simple transportation network (a) together with (b) its minimal spanning tree (the solid edges). The sum of the weights of the edges in the minimal spanning tree is 21.
           Fig.34. ThefirsttwostepsofBorůvka’salgorithm.Startingwitheachnodeasadistincttree,findtheminimal weighed edge between each tree and the rest of the trees. The direction of the solid edges indicates the edge is the minimal weighted edge for the source node. The components connected by solid edges (disregarding the directions) will form the trees at the start of the second run of step (2) of Borůvka’s algorithm
Borůvka’s algorithm builds a collection of disjoint trees (i.e., a forest) and successively merges by adding minimal weight edges. The first two steps of the algorithm are shown in Fig 34. Formally, we have
(1) Let T be the collection of n disjoint trees, each consisting of exactly one node from the graph G.
10
10
10
3
3
3
1
1
1
8
8
8
1
1
1
2
2
2
1
1
1
6
6
6
2
2
2
2
2
2
5
5
5

Quantum Algorithm Implementations for Beginners 53
(2) Repeat:
(a) For each tree Ti in T find the minimal weighted edge, ei , of G between Ti and the other
trees of T .
(b) Merge the trees {Ti ∪ {ei }} so that they are disjoint: set this new collection to T .
If there are k trees in T at a given iteration of Step (2), then the algorithm performs k searches for the respective minimal weighted edges. As the trees are disjoint, we can perform the k searches in one sweep by inspecting each of the m edges of G once. As there will be at most log n iterations of Step (2), this results in a running time of O(m logn). The quantum algorithm takes advantage of the Grover search algorithm, to speed up the searches in Step (2).
In the previous sections we used Grover search to look for a single item in a list of N elements. But the search algorithm will work even if there are M elements in the list that are marked by the
oracle. One of these marked elements can then be found using O (􏰡 N ) queries to the oracle. M
In the algorithm above, we need to find the minimal element of an appropriate list. Clearly this can not be implemented directly as an oracle without actually inspecting each of the list elements. Luckily, there is a simple work around given by Durr et al [39] which involves multiple calls to the Grover algorithm as described in Algorithm 10.
Algorithm 10 Minima finding algorithm Input:
• A unitary implementation a function F on a list of N elements, UF |x⟩|y⟩=|x⟩|y⊕F(x)⟩.
Output:
• |x∗⟩ such that F(x∗) is the minimum of the function over the list. Procedure:
Step 1. Pick a random j from the list. for 0 ≤ k &lt; T do
  Step 2a. Do Grover search [20] with the oracle for function fj such that, 􏰘1 ifF(i)≤F(j)
fj(i)= 0 ifF(i)&gt;F(j) Step 2b. Update j with the result of Grover search.
end for
AprobabilisticanalysisshowsthatT =22.5√N+1.4log2(N)sufficestofindtheminimalelement with high probability [40] . The inner loop of the algorithm uses a Grover search routine with potentially multiple marked items. But the number of marked items is not known beforehand. This poses problem as Grover search being a unitary algorithm needs to be stopped exactly at the right number of iterations to give the correct answer. Running the procedure for longer deteriorates the quality of the answer. If the number of marked items is unknown the stopping criterion of the algorithm is also unknown. This problem can be rectified using some extra steps by a technique given in Boyer et al [20]. We have to use this modified version of Grover search in the inner loop.
We did not implement the full algorithm due to space constraints on the IBM computer. Even to successfully implement a minima finding algorithm, at least 6 qubits would be necessary to
 
54 Abhijith J., et al.
compare two 3-bit numbers. Therefore we implemented the minima finding algorithm by hard coding the oracle for each of eight possible functions fx : {fx (i) = 1 if F(i) ≤ F(x)}. The results are shown in Figure 35. The QASM code for implementing f2(i) = 1 if F(i) ≤ F(2) required just under 100 lines of code (more than 100 individual gates.) The results, even when using the simulator are not good when k ≥ N /4 elements are marked. A typical way to get around this is to double the length of the list by adding N extra items which will evaluate to 0 under fx , which however requires an extra qubit.
     0.3 0.2 0.1
0.3 0.2 0.1 000
1 2 3 4
x=1
x=5
1 2 3 4 5 6 7 8
x=2
x=6
x=3 x=4
      1 2 3 4 5 6 7 8
Resulting Value
x=7 x=8 5 6 7 8
1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 81
(a) IBM Q Implementation
     0.9
0.5
0.1
x=5
1 2 3 4
    0.9
0.5
0.1
000
x=7 x=8 5 6 7 8
x=1
x=2
x=6
x=3 x=4
 1 2 3 4 5 6 7 8
1 2 3 4 5 6 7 8 1 2 3 4 5 6 7 81
1 2 3 4 5 6 7 8
Resulting Value
(b) Simulator Implementation
Fig. 35. The results of running 1000 trials of the minima finding algorithm on both (a) the ibmqx4 chip and
(b) the IBM simulator to find values less than or equal to the input x.
12 QUANTUM MAXIMUM FLOW ANALYSIS
12.1 Problem definition and background
Network flow problems play a major role in computational graph theory and operations research (OR). Solving the max-flow problem is the key to solving many important graph problems, such
Frequency Frequency

Quantum Algorithm Implementations for Beginners 55
 Fig. 36. A simple directed graph representing flows and capacities. Conventionally, the state of the flow problem is indicated by the current flow relative to the capacity on any directed link using the notation f/c.
Fig. 37. The Ford-Fulkerson solution to the max-flow problem in three steps. Each step represents the application of an augmenting path to the previous flow state.
as finding a minimum cut set, and finding a maximal graph matching. The Ford-Fulkerson algo- rithm [44] is a landmark method that defines key heuristics for solving the max flow problem. The most important of these heuristics include the construction of a residual graph, and the notion of augmenting paths. For integer-capacity flows, Ford-Fulkerson has complexity O(f m) for m edges and max flow f . The Edmonds-Karp variant has complexity O(nm2) for n vertices and m edges. The quantum-accelerated classical algorithm discussed here [6] claims complexity O(n7/6√m).
The best classical implementations of the max-flow solver involve several important improve- ments [41], especially that of using breadth-first search to find the shortest augmenting path on each iteration. This is equivalent to constructing layered subgraphs for finding augmenting paths.
An illustration of the essential method introduced by Ford and Fulkerson can be described using Figures 36 and 37. At each link in the network, the current flow f and the capacity c are shown. Typically, the state of flow on the graph is designated by f /c, with the residual capacity implicitly given by c − f . In Figure 36, the initial flow has been set to zero.
The basic steps in the solution to the max-flow problem are illustrated by Figure 37. The algorithm begins on the left by considering the path [s,v,t]. Since 2 is the maximum capacity allowed along that path, all the flows on the path are tacitly set to that value. Implicitly, a reverse flow of -2 is also assigned to each edge so that the tacit flow may be “undone” if necessary. Next, the middle of the figure examines the lower path [s,w,t]. This path is constrained by a maximum capacity on the edge [s,w] of again 2. Finally, the path [s,v,w,t] is the only remaining path. It can only support the residual capacity of 1 on edge [s,v]. We can then read off the maximum flow result at the sink vertex t since the total flow must end there. The maximum flow is seen to be 5.
 
56 Abhijith J., et al.
While this method seems straightforward, without the efficiencies provided by the improvements of Edmonds and Karp, convergence might be slow for integer flows on large graphs, and may not converge at all for real-valued flows. The modification of always choosing the shortest next path in the residual network to augment, is what makes the algorithm practical. To see this, consider what would have happened if the path [s,v,w,t] had been chosen first. Since augmenting that path blocks the remaining paths, flows would have to be reversed before the algorithm could proceed.
Choosing the shortest path requires performing a breadth-first search whenever new flow values have been assigned to the residual graph. This is equivalent to building a layered set of subgraphs to partition the residual graph. This is the step that leads to the m2 complexity of Edmonds-Karp, and it is this step that is speeded up in the “quantized” version of the algorithm, leading to a complexity term of √m instead of m2.
12.2 Algorithm description
The Quantum algorithm described by Ambainis and Spalek is a “quantized” version of the Edmonds- Karp algorithm, that is, the classical algorithm with quantum acceleration. The key quantum component is a generalized version of Grover’s search algorithm that finds k items in an unsorted list of length L [20]. The algorithm is used in creating a layered subgraph data structure that is subsequently used to find the shortest augmenting path at a given iteration. Like in Section XI, we will be oblivious to the number of marked items Grover’s algorithm is searching for. So once again we have to use techniques from Ref.[20] while performing the search.
Here we will describe how to build a layered graph partition. In a layered graph partition each vertex in the graph is assigned to thew i-th layer such that edges of the graph only connect between i-th and (i + 1)-th layers. The key to “quantization” lies in using Grover’s search to build a layered graph partition by computing layer numbers for all vertices. The layers are represented by an array L indexing the vertices of the graph, and assigning to each element a subgraph layer number. The sink vertex at vertex zero is set to zero. The the algorithm proceeds according to the following pseudo-code described in Algorithm 11.
Algorithm 11 Layered graph partitioning
Input:
• Adjacency information of the graph (Adjacency matrix, list of edges,etc.)
• Source vertex s. Output:
• L such that L[i] is the layer number of the i-th vertex. Procedure:
Step1.SetL[s]=0andL[x]=∞forx 􏰯0
Step 2. Create a one-entry queue W = {s } (x = 0) while W 􏰯 φ do
Step 3a. Take the first vertex x from W .
Step 3b. Find by Grover search all its neighbors y with L[y] = ∞. Step 3c. Set L(y) = L[x] + 1, append y into W , and remove x from W
end while
Notice that the oracle for Grover search required for this algorithm is one that marks all the neighbours of x whose layer number is currently set to ∞. Grover’s search speeds up the layers assignment of the vertices by quickly finding all the entries in the layer array L that contain the value ∞. In practical terms, ∞ might simply be the largest value reachable in an n-qubit machine.
   
Quantum Algorithm Implementations for Beginners 57
The generalized Grover search would look for all such values without a priori knowing the number of such values. The size of a circuit required to do a full layered graph partitioning makes it impractical to implement it on the IBM machine. But the heart of the algorithm is Grover search, which we have already implemented earlier.
13 QUANTUM APPROXIMATE OPTIMIZATION ALGORITHM
13.1 Problem definition and background
Combinatorial optimization problems are pervasive and appear in applications such as hardware verification, artificial intelligence and compiler design, just to name a few. Some examples of combinatorial optimization problems include Knapsack, Traveling Saleman, Vehicle Routing, and Graph Coloring problems. A variety of combinatorial optimization problems including MaxSat, MaxCut, and MaxClique can be characterized by the following generic unconstrained discrete maximization problem,
m maximize: 􏰭Cα(z)
α=1
zi ∈{0,1}∀i∈{1,...,n}
(66)
In this generic formulation, there are n binary decisions variables, z, and m binary functions of those variables, C(z), called clauses. The challenge is to find the assignment of z that maximizes the number of clauses that can be satisfied. This is the so-called MaxSat problem, which is NP-Hard in general [64], and is an optimization variant of the well-known satisfiability problem, which is NP-Complete [31]. Hence, solving an instance of Eq. (66) in practice can be computationally challenging.
To provide a concrete example of Eq. (66), let us consider the MaxCut problem. As input, the MaxCut problem takes a graph G = (V , E), which is characterized by a set of nods V and a set of undirected edges E. The task is to partition the nodes into two sets, such that the number of edges crossing these sets is maximized. Figure 38 provides an illustrative example, in which a graph with five nodes and six edges is partitioned into two sets that result in a cut of size five.
Fig. 38. An illustration of the MaxCut problem.
In general, the MaxCut problem is characterized by the following unconstrained discrete maximiza- tion problem,
maximize: 􏰭 12(1−σiσj)
i,j∈E (67)
σi ∈{−1,1}∀i∈N
In this formulation, there is one binary decision variable for each node in the graph, indicating which set it belongs to. The objective function consists of one term for each edge in the graph.
                        5 Cut

58 Abhijith J., et al.
This term is 0 if the the nodes of that edge take the same value and 1 otherwise. Consequently, the optimal solution of (67) will be a maximal cut of the graph G. Interestingly, the form of Eq. (67) also highlights that finding a maximal cut of G is equivalent to finding a ground state of the antiferromagnet of G in an Ising model interpretation. In either case, it is clear that Eq. (67) conforms to the structure of Eq. (66). Note that the linear transform z = (σ + 1)/2 can be used to convert the variables from the σ ∈ {−1, 1} space to the z ∈ {0, 1} space.
13.2 Algorithm description
The Quantum Approximate Optimization Algorithm (QAOA) as proposed in [43] leverages gate- based quantum computing for finding high-quality solutions to combinatorial optimization problems that have the form of Eq. (66). To apply this algorithm the user first translates the clause functions Cα (z) into equivalent quantum clause Hamiltonians Cα and then selects a number of rounds r ≥ 1 and two angles per round, 0 ≤ β [k ] ≤ π and 0 ≤ γ [k ] ≤ 2π for the k -th round. The pseudocode for QAOA is given in Algorithm 12.
Algorithm 12 Quantum approximate optimization algorithm
Input:
• Number of rounds of optimization r
• Two size r array of angles, γ and β.
• Hamiltonians Cα corresponding to the clauses of the optimization problem.
Output:
• An approximation to the solution of problem in Eq. (66). Procedure:
Step 1. Construct the n-qubit uniform superposition state by applying H ⊗n to |0 . . . 0⟩ for 1 ≤ k ≤ r do
Step 2a. Apply 􏰬mα=1 e−iγ[k]Cα
Step 2b. Apply 􏰬nj=1 e−iβ[k]Xj end for
Step 3. We will call the state so constructed |β,γ⟩. The expectation value, 􏰫mα=1 ⟨β,γ|Cα|β,γ⟩,givesanapproximatesolutiontotheproblem.
For an appropriate selection of r , β , γ , this algorithm will give a high-quality solution to Eq. (66). As the number of rounds used increases, the quality of the solution produced by the above algorithm also increases provided that the angles chosen for the previous rounds are optimal. Conducting an exhaustive search over a fine grid is proposed in [43] for the selection of each round’s optimal β,γ angles. The use of a quantum-variational-eigensolver is also possible [74, 79].
The translation of the clauses to Hamiltonians and the determination of the final expectation value depends on the specific optimization problem being solved. To provide a concrete example of the generic QAOA formulation, let us consider its application to the MaxCut problem give in Eq. (67). It is important to note that the MaxCut problem is particularly advantageous for QAOA for the following reasons: (1) all of the clauses in the objective function have the same structure, hence only one clause Hamiltonian Cα needs to be designed; (2) Each clause only involves two decision variables, which keeps the structure of Cα relativity simple. The design of MaxCut clause
   
Quantum Algorithm Implementations for Beginners
59
 ibmqx2
1 1 1
0 2 3 0 2 3 0 2 3 4 4 4
Single Edge Triangle Triangle plus Edge
  Fig. 39. The CNOT connectivity and error rates of the ibmqx2 Computer (left) followed by the Single Edge (center left), Triangle (center right) and Four edge (right) graphs considered in the proof-of-concept experiments.
Hamiltonian is as follows,
C(i,j)= 12(1−σiσj) (68)
σi=−1 σi=1
􏰐0 1􏰑σj=−1
1 0 σj=1 |00⟩ |01⟩ |10⟩ |11⟩
(69)
0 0 􏰤01 􏰨􏰨00 􏰦00
0 0 |00⟩
00􏰥|01⟩
1 0􏰩􏰩|10⟩ (70) 00􏰧|11⟩
Ci,j = 21(I −Zi ⊗Zj) (71)
Eq. (68) presents the binary function used by each edge in the objective of Eq. (67). Eq. (69) shows the enumeration of all inputs and outputs of the binary function, and Eq. (70) illustrates how to encode these inputs and outputs into a quantum Hamiltonian. Finally, the quantum Hamiltonian in Eq. (70) can be compactly written as in Eq. (71).
These clause Hamiltonians can then be used in the QAOA algorithm. Notice that the clause Hamiltonians here are all combinations of Z gates. This makes finding the final expectation value very simple. For each run of the algorithm, one only needs to measure the final state in the computational basis. This measurement will give a bit string that corresponds to an assignment to the classical σi variables. The output of the algorithm is then found by estimating the expectation valueof􏰫i,j∈E 12(1−σiσj)overindependentrunsofthealgorithm.
13.3 QAOA MaxCut on ibmqx2
This section investigates the implementation of the QAOA MaxCut algorithm on the ibmqx2 quantum computer (Figure 39). The first challenge is to transform the QAOA algorithm from its mathematical form into a sequence of operations that are available in the IBM Quantum Experience platform. For the sake of convenience we will mention here the gates we will use in the ensuing

60
Abhijith J., et al.
discussion,
􏰐􏰑 􏰐 iλ 􏰑
1000 􏰤􏰨0 1 0 0􏰥􏰩
1
0 e
Hamiltonians. For the MaxCut Hamiltonian, this can be expanded as follows, 0000
q[0]
q[1] H
q[2] H
q[3] H
q[4] H
c5
U1 U1
(-0.62...) (-0.62...)
U3
(0.942...)
U1 U3 U1
U1
(-1.25...)
U3
(0.314...)
U1 U3
0 cos(θ /2) iλ , U3(θ,φ,λ)= iφ
−e sin(θ /2)
􏰩. 0010
U1(λ)=
The inner loop of the algorithm first requires the application of the γ angle with the clause
− i γ [ k ] ( I − Z a ⊗ Z e 2
􏰨 0 0 0 b =e 􏰦
e−iβ[k]X = e
􏰐cos(β[k]) −isin(β[k])􏰑
)
􏰧=􏰨 −iγ[k] 􏰩 (72) 􏰨0 0 e 0􏰩
0001
􏰦􏰧
e sin(θ/2) e
i(λ+φ)
cos(θ/2)
, CNOT=􏰨
􏰨0 0 0 1􏰩
􏰤􏰥
􏰨􏰨0 1 0 0􏰩􏰩 −iγ[k]􏰨 􏰩 􏰨􏰨0 0 1 0􏰩􏰩 0 􏰩
1000 􏰤􏰨 0 e − i γ [ k ] 0 0 􏰥􏰩
After some derivation, it is observed that this gate can be implemented as a combination of two CNOTgatesandoneU1(−γ)gate,asindicatedinFigure40.Itisalsointerestingtonotethealternate implementation of this gate in [30], which leverages a different variety of gate operations [96].
U1
(-gamma)
Fig. 40. An IBM Quantum Experience score illustrating an implementation of the MaxCut edge gate (72). The next term in the loop is the application of the β angle, which is expanded as follows,
Careful inspection of the IBM Quantum Experience gates reveals that this operation is implemented byU3(2βk,−π/2,π/2). So we need to apply this gate to every qubit in the register.
Putting all of these components together, Figure 41 presents an IBM Quantum Experience circuit for implementing QAOA for MaxCut on the “Triangle plus Edge” graph from Figure 39 using the following parameters,
r =2:γ1 =0.2·π =0.628.., γ2 =0.4·π =1.256..,
β1 =0.15·π =0.471.., β2 =0.05·π =0.157...
􏰦􏰧
  −iβ[k]
􏰔0 1􏰕
1 0 = i sin(β[k]) cos(β[k]) (73)
     (-0.62...) (0.942...)
U1 U3
(-0.62...) (0.942...)
U3
(0.942...)
(-1.25...)
(-1.25...)
U1
(-1.25...)
(0.314...)
U3
(0.314...)
U3
(0.314...)
   Fig. 41. An IBM Quantum Experience circuit for QAOA MaxCut with two rounds on a “Triangle plus Edge” graph.
1234

Quantum Algorithm Implementations for Beginners 61
13.4 A proof-of-concept experiment
With a basic implementation of QAOA for MaxCut in qiskit, a preliminary proof-of-concept study is conducted to investigate the effectiveness of QAOA for finding high-quality cuts in the a) Single Edge, b) Triangle and c) Triangle plus Edge graphs presented in Figure 39. This study compares three types of MaxCut computations: (1) Random assigns each node in the graph to one of the two sets uniformly at random; (2) Simulation executes the IBM Quantum Experience circuit via simulation on a classical computer; (3) Hardware executes the IBM Quantum Experience circuit on the ibmqx2 hardware. The simulation computation serves to demonstrate the mathematical correctness of the proposed QAOA circuit. The hardware computation demonstrates the viability of the circuit in a deployment scenario where environmental noise, intrinsic bias, and decoherence can have a significant impact on the results. The random computation serves to demonstrate that the hardware results are better than what one would expect by chance from pure noise. For each computation we give the expectation/mean of the returned solutions and the probability to sample the maximum cut. All of these computations are stochastic, therefore event probabilities on IBM Quantum Experience are computed based on 4096 independent runs of each computation.
a) The first experiment considers the Single Edge graph from Figure 39 (center left) and imple- ments a 1-round QAOA with the parameters
r=1:γ1=0.5·π, β1=0.125·π.
The results are summarized in Table 4. The simulation results indicate that the proposed score is mathematically sound and the hardware results indicate similar performance to the simulation, with a few additional errors. The random results indicate that both the simulation and hardware perform significantly better than random chance.
Table 4. MaxCut QAOA with one round on a Single Edge.
Random Simulation Hardware
Expected Size of a sampled cut 0.500 1.000 0.950 Probability of sampling a maximum cut 0.500 1.000 0.950
b) The second experiment considers the Triangle graph from Figure 39 (center right) with parameters
r=1:γ1=0.8·π, β1=0.4·π.
The results are summarized in Table 5. The simulation results indicate that the proposed circuit is mathematically sound. Even though the QAOA circuit for a Triangle is longer than the QAOA circuit for a Single Edge, the Hardware performance is better, most likely to the more favourable distribution of the cuts, also notable in Random.
Table 5. MaxCut QAOA with one round on a Triangle.
Random Simulation Hardware
Expected Size of a sampled cut 1.500 1.999 1.904 Probability of sampling a maximum cut 0.750 1.000 0.952
c) The third experiment considers the Triangle plus Edge graph from Figure 39 (right). We run QAOA both in a 1-round and a 2-round scenario, implemented with the following parameters,
      
62 Abhijith J., et al.
found through numerical grid searches with a resolution of π /1000 (1-round) and π /20, respectively (2-round):
r =1: γ1 =0.208·π, β1 =0.105·π. r =2: γ1 =0.2·π, β1 =0.15·π, γ2 =0.4·π, β2 =0.05·π.
The results are summarized in Table 6, the 2-round circuit is shown in Figure 41. Simulation and Hardware outperform Random both on 1-round and 2-round QAOA. However, the gains made by Simulation in 2-round over 1-round QAOA almost vanish on the Hardware. This degradation in performance is likely due to the double length in the circuit, making the experiment more susceptible to gate errors, environmental noise and qubit decoherence.
Table 6. MaxCut QAOA with several rounds on a Triangle plus Edge graph.
1-round QAOA 2-round QAOA
Random Simulation Hardware Simulation Hardware
Expected Size of a sampled cut 2.000 2.720 2.519 2.874 2.570 Probability of sampling a maximum cut 0.375 0.744 0.652 0.895 0.727
14 QUANTUM PRINCIPAL COMPONENT ANALYSIS
14.1 Problem definition and background
In data analysis, it is common to have many features, some of which are redundant or correlated. As an example, consider housing prices, which are a function of many features of the house, such as the number of bedrooms, number of bathrooms, square footage, lot size, date of construction, and the location of the house. Often, one is interested in reducing the number of features to the few, most important features. Here, by important, we mean features that capture the largest variance in the data. For example, if one is only considering houses on one particular street, then the location may not be important, while the square footage may capture a large variance.
Determining which features capture the largest variance is the goal of Principal Component Anaylsis (PCA) [78]. Mathematically, PCA involves taking the raw data (e.g., the feature vectors for various houses) and computing the covariance matrix, Σ. For example, for two features, X1 and X2, the covariance is given by
􏰐E(X1 ∗ X1) E(X1 ∗ X2)􏰑
Σ= E(X2∗X1) E(X2∗X2) , (74)
where E(A) is the expectation value of A, and we have assumed that E(X1) = E(X2) = 0. Next, one diagonalizes Σ such that the eigenvalues e1 ≥ e2 ≥ e3 ≥ · · · are listed in decreasing order. Again, for the two-feature case, this becomes
􏰐e1 0􏰑
Σ= 0 e . (75)
2
Once Σ is in this form, one can choose to keep the features with n-largest eigenvalues and discard the other features. Here, n is a free parameter that depends on how much one wants to reduce the dimensionality. Naturally, if there are only two features, one would consider n = 1, i.e., the single feature that captures the largest variance.
    
Quantum Algorithm Implementations for Beginners 63
As an example, consider the number of bedrooms and the square footage of several houses for sale in Los Alamos. Here is the raw data, taken from www.zillow.com, for 15 houses:
X1 = number of bedrooms = {4,3,4,4,3,3,3,3,4,4,4,5,4,3,4}
X2 = square footage = {3028, 1365, 2726, 2538, 1318, 1693, 1412, 1632, 2875, 3564, 4412, 4444, 4278, 3064, 3857} .
(76)
Henceforth, for scaling purposes, we will divide the square footage by 1000 and subtract off the mean of both features. Classically, we compute the covariance matrix and its eigenvalues to be the following:
eigenvalues of Σ.
14.2 Algorithm description
Before we discuss the algorithm we will provide a quick introduction to the concept of a density matrix. Density matrices are used to represent probabilistic mixtures of quantum states. Suppose that there is a quantum system whose state is not known, rather we know that it can be in one of M states, |ψi ⟩, each occurring with probability pi . The state of this system is then represented by a density matrix ρ, defined as
M
ρ=􏰭pi |ψi⟩⟨ψi|. (78)
i=1
If the state of a system is known (with probability 1) to be |ψ ⟩, then the density matrix would just be |ψ ⟩ ⟨ψ | and the system is said to be in a pure state. Otherwise, the system is said to be in a mixed state. So the density matrix can be seen as a generalization of the usual state representation with the extra ability to represent a probabilistic mixture of quantum states. From the definition of the density matrix it can be seen that it is a positive semi-definite matrix with unit trace. In fact, any matrix that satisfies these two properties can be interpreted as a density matrix. More details on the definition and interpretation of density matrices are given in the quantum tomography section (Section 20).
Density matrices are clearly more expressive than state vectors as state vectors can only represent pure states. But, even a system in a mixed state can be seen as a part of a larger system that is in a pure state. This process of converting a mixed state into a pure state of an enlarged system is called purification. A mixed state of an n qubit system can be purified by adding n more qubits and working with the 2n qubit system. Once purified, the joint system of 2n qubits will be in a pure state while the first n qubits will still be in the original mixed state. We will not discuss the transformations required to purify a state. Interested readers are referred to Ref. [77] for a complete discussion.
The quantum algorithm for performing PCA presented in Ref. [70] uses the density matrix representation. The algorithm discussed there has four main steps: (1) encode Σ in a quantum density matrix ρ (exploiting the fact that Σ is a positive semi-definite matrix), (2) prepare many copies of ρ, (3) perform the exponential SWAP operation on each copy and a target system, and (4) perform quantum phase estimation to determine the eigenvalues. For an implementation of this quantum PCA algorithm on a noisy simulator, we refer the reader to Ref. [66], which also gives a short-depth compilation of the exponential SWAP operation.
􏰐0.380952 0.573476􏰑 Σ = 0.573476 1.29693
, e1 = 1.57286 , e2 = 0.105029 . (77) We now discuss the quantum algorithm for doing the above calculation, i.e., for finding the

                          Tr(⌃) ⇤ (1  p1 p2(1  P))/2. (7) o
wlgaosridthismcuwssaesddiniscRuesfs.edXXinXRNefe.eXdXciXtaNtioened XciXta.tIiotnis XthXen. Isttrisaitghetnfosrtwrarigdhtofocrwalacrudlatoe cthalecueilgaetenvtahleuesigenvalues
aT o
( (
r ne
Tth wl
r
o Td
P
o
y c p
dn
m p
c dn p
e i
o P
c
o
a v
h
b
b
o es
i
=
p
b
b
vpRi b o
i u Pu
R
Ae m
Pu Mh
Ae Re
Mh Re
Re ,h
Q,
Re
Q
w
e t
e
o
r o
r
M
P
d
c
f⌃fromP,pasfollows:
e = Tr(⌃) ⇤ (1e += T1r(⌃e)2(⇤1=(1T+Pr()⌃)/)12⇤(12(+1  1P))/22(1  P ))/2 (6)
1 1 1 e1=Tr(⌃)⇤(1+ 1
f ⌃ from P, as follows: 2 2
Classical
FIG. 1:
ppp p
ofom⌃lloPfwr,osma: s Pfo,llaoswfso:llows: state preparation, quantifying the purity, and classical p lhgios railgtohrmithmiswsacshdeismcuassteidcianllRyef.dXivXiXdeNdeedupcitiantitoon fXoXu.rItsitsetphesn: sctrlaisgshitcfoarwl aprdret-opcraolccuelastseitnhge,eigenvalues
p p p p p
yhm,isainlgsdorsicthlhamesmwsiacasatdliicspcauolslsyetd-pdinrivoRicedef.esXdsiXnuXgp.NeiendtcoitaftoiounrXsXte.pItsi:s tchleanssstircaiaghltfporwea-rpdrtocceaslcsuilnatge,the eigenvalues p gaosridthismcuwssaesddiniscRuesfs.edXXinXRNefe.eXdXciXtaNtieoened=XcTiXtra(.⌃tIi)otn⇤is(1Xth+Xen. Ist1trisait2gh(h1etnfosrPtwr)a)ri/gd2htofocrwalacrudlatoe cthalecueilgaetenvtahleuesigenvalues(6)
= Tr(⌃e) ⇤=(1eT1+r=(⌃T)1r⇤(⌃(1)2+⇤(1(1e1P=)T)2/1r(2(1⌃e)2(⇤1P=(1)T)/Pr2()⌃)/)12⇤.(12(1  1P))/22(1.  P ))/2 . (6) (6)(7) (⌃)⇤(1+ 12(11P))/2 1 2 2 p 2 (6) e =Tr(⌃)⇤(1 1
e
f ⌃ from P, as follows: p p 2
ofomlloPw,sa: s follows:
hicslalsgosriicthamlppwoastd-ispcursosecdesinsiRnegf..XXe1X=NTeerd(⌃c)it⇤at(i1o+n X1X. I2t(i1s thPen))s/t2raightforward to calculate the eigenvalu(6es)
(7) (A⌃s)d⇤e(p1icted in1AFsidg2.ep(?1i?c,teAtdhPsiisdn)e)sFip/mi2cgpt.lee?d?ai,lngtohFriisgtph.smi?m?pi,slteshcaihslpgesomirmaiptpthilcmealalilysgosdcriihvteihdmeadtisiucpascllhiynet(mdo7iav)ftoiiduceradlslytuepdpisiv:nitdcoeladfsosuicpraslintpetproes-f:poucrolracsestsiescpianslg:p,crlea-spsriocaclespsri
e =Tr(⌃)⇤(1 12(1P))/2.
e = Tr(⌃e) ⇤=(1T2r(⌃)1⇤(12(1 1P))2/(21.  P ))/2 . (7) (7)
e = Tr(⌃) ⇤ (1 + 1  2(1  P ))/2 .
tate preparatsiotant,eqpuraenptsaitfreaya1titne=igopnTtr,herpqe(ua⌃prea)ua1nt⇤rt=iiot(fyn1T,i12,+nraqg(nu⌃dta)hn1ce⇤tlai(pfsy1Aus2i+rn(csi1gatyldt,phe1aPoepns)dpti)c-u2/pctr(2lrie1aotdsycs,eiscaiPsnanil)nd)pgF/c.o2lisagts-.spi?croa?lc,epsotssihnti-gsp.rosicmesspinleg. algor(i6t)hm is (s6c)hematicall
As depicted in Fig. ??, this simple algorithm is schemaptically divided up into four steps: classical pre-processing, epFiicgt.ed??i,ntCFhilsga.si?sm?icp, altehl iaPslgsroiemr-iptphlremocaeilsgsosrciihnthegmaitsicsaclhlyemdiavtidcaedlplyupdivinidtoedfoupr isntteopsf:oucrlastseicpasl: pcrlea-spsircoaclespsrien-gp,rocessing,
pp
taitse spcrhepeamrattioicna, lqlyuadntivifeyidine=gdTthure(p⌃pei)un⇤rt=ito(y1eT,12froa=(nu⌃drT)1rcs⇤(ltta⌃(eas1)ps2ti⇤(sec1:a(1lpcp+rl1Paoesp)ts)-a2i/1pcr(2ra1ao.ltc2eip(os1Prsnie)n,-)gp/Pq.2r)uo.)c/a2ens.tsifnygi,ng the purity, a(n7d) class(i7c)a(67l) post-pro nr,eApqsaurdaentptioicfnyt,eindqguinathnFetifgpy.uin?rig?t,yt,t2hhaeinspdsuicrmliatpysl,s2eiacanalldgopcroliastths-smpicraoislcepsscoshsietnm-gp.artoiceasllsyindgi.vided up into four steps: classical pre-processing,
64 Abhijith J., et al.
Classical Pre-processing
lassical post-processing.
tate preparation, quantifying the puritye, a=ndTcr(la⌃s)si⇤ca(l1post-1proc2e(s1singP. ))/2 . (7) State
2 Classical Pre-prCoclaessicnagl PCrela-pssroicaelssPinreg-processing
As depicted in Fig. ??, this simple algorithm is schematically divided up into four steps: classical pre-processing,
epFiicgt.ed??i,ntFh tate prepara
1m 2.Prepareqquuandtitumincsotamtpeu0teir..Thethirds†tepispuritycalculation,whichisthebulkofthequantumalgorithm.This
3. Act on the qudit with unitary G G
j+1j 0 m+1
involvesdoinga†Hadamard†onan0ancTillah,ew0hRichB
fobrej =im0p,.l.,em,ewnithedGm=oGre effi=ci1e.ntly on logical qubits than process t
c a h n o d o o s m e l a y s c e h t o o o f s e m a e s l e e t m o e f n mt s f e r l o e m m e G n t , s d f e r n o o m t e G d , G d e = n o t G e d , G . . . , = G G . , . . . , G .
4. Measure the4.qMudeiatswuri4te.htMhPeOeaqVsuuMdrietQtwh=iethquQPdOi,tV1wMithQP=O1, VwQMhe,rQ1emw=1eQtQyp,,icw1amhlleyrQetawke,e wtQyhpeir=cealwl0yieh0tay.kpeicQally=ta0kieh0Q. = 0ih0 .
1. Randomly choose a set of m elements from G, denoted G = G , ..., G . cqt2u.odnPitrtewhpieathrqeudqnuiitdtawitriytinhGsutnaitteGar0yif.oGr j =G0,f.o.,rm†j,=w0it,h..,Gm,=wGith G =1G.1 =m1.
ents from G, denjo+t1edj Gj+=1 jG ,...,G 0. m+10 m+1
3. Act on the qudit with unitary G G1 for jT=mh0e,..R,mB, wpirtohtGoco=lGgoes=as1.follows.
j+1j 0 m+1
4. Measurqeutbhietsq(ufrdoimt wdifftherPenOtVcoMpieQs o=f |ψQ⟩),,a1nd tQhen,awnohtehrerwHeadtyapmiacardllyontathke aQnci=lla.0Fihin0a.lly measuring ⟨Z⟩ on the
mG,denotedG= G,...,G . 0
eaqsudriettwhiethquPHdOiotVwMeivtheQrP,=gOiVvQeMn,tQ1h1e=cQoQnst,r1w1aihnetrQeofw2o,e.nwtlPyhper5irceqapulwlbayeirtseaykpoeqincQuaIlBldyM=it’as0kicienho0Qms.ptu=atte0re,ihp0r0.eip.aring many copies of ρ 0 0 0 0 2. Prepare qudi0t in stat0e 0i.
†
GG
rj4.G=M0ea,fos.u.r,rmejt,h=weiq0tuh,d.iG.t,wmi=th,GwPOitVhMG=Q1=1=.QG,1Q=,1w1.herewetypicallytakeQ=0ih0. +15.Repeatsteps2-4m0anytimme+s1into0order0tome+st1im0atep :=Pr(Q),theprobab0ilityofobtainingoutcomeQ. pespe1a-5tjsmteapnsy1t-i5mmesainytotiomrdeserinttooeosrtdimerateohepstiim,athtehepxpie,cGthateioenxpveacl0tuaetiofnpval(uaeveorfapged(aoveraagleldGo)v.er all G). 0
6. Repeat steps 1-5 many times into order tGo estimatGe hpGi, the expectatiGon value oGf pG (averaged over all G). is not possible. Hence, we consider a simpler algorithm as follows. In the special case where there
pfeospre2a-j4t sm=teapn0sy,2t.-i.4m,memsai,nytwotiomtrhdeserGinttooe=osrtdimGerateo pesti:=m=aP1t1er.(pQ ):=, thPer(pQro)b,atbhileitpyrobf aobitlaitiynionfgoobuttacionmineg Qout.come Q .
5. Repeat steps 2-4 many time0s into omrd+erG1to estimaGt0e p := P0r(Q ), the probability of obtaining0 o†utcome†0Q .
0thpenrios tu0
0 rdei5tp.aiRnrespqteauatdetits0tieinp.5s.t2aR-t4epme0aitn.51ys.tteRipmespe2es-am4itnmtsotaeopnrysd2te-irm4temosaeisntytiomtioamrtdeesprintot:o=eosPtridrm(eQratte)o,petshte:i=mparPotreb(aQpbil)i:,t=ythPoefr(poQrbotb)a,ainbtihinleigtyporuotfbcoaobmtilaeitinyQino.gf obutacionminegQou.t
2. Prepare qudit in state 0i. †2
ro3m. AcGt o,ndatehnnceiloqlautdgeidvtewsGithe=upnuirtiaGtyryPG,=..T.r,(Gρ )f.oTrhj.e=las0t,s.t.,emp i,swtoitchlaGssic=allGy comp=ut1e.the eigenvalues using Eqs. (79)-(80).
eaqsudriettwhiethquPdOitVwMithQP=OVQM,Q11=Qj+Q1,1w1mherQew,ewtyhpeircealwlyetaykpeic0Qally=tma0+kie1h0Q. = 0ih0. 000j000
16. RQepea,twstheperse1-w5emtaynpyictiamlleys itnatkoeorQder=to e0si3thi0.m.AatcethpGoGni, theeqx0puedcittatwionitvhaluenoitfaprGy(aGverageGd ovfeorraljl G=0).0, .., m, wit 0 are only two features, Σ and ρ0 are 2 × 2 matrices (one qubit states), and ρ can be purified to a pure
= Q , 1  Q , where we typically3t.aAkectQon=th0eih0qu. dit with unitarjy+1Gj G
for j = 0, ..
00 0 j+1
j
pespe1a-5t smteapnsys1tta-i5mteme|sψain⟩nytotniomtrwdeseorinqttouobeoistrtsdi.meSrautpeopheopssteiim,oatnhtehpepxreppie,actrhaetesioetnwxpoveacltuoaeptioefnspovfal(|uψaev⟩e,orfwapgheidc(haovuesreaasgleladGto)v.taerloafll4Gq)u.bits, GG GG
6. Repeat steps 1-5 many times into order to estimate hp i, the expectation value of p (averaged over all G). GG
,1Q ,wherewetypicallytakeQ = 0ih0. o0estimate 0p := Pr(Q ), the probability of ob0taining outcome Q .
ose0
cdotlo igmop0
G00 4.MeasurethequditwithPOVMQ= Q,1Q ,where
then the fifth qubit (on IBM’s computer) can be used as an ancilla to implement an algo0rithm tha0t order to estimate p := Pr(Q ), the probability of obtaining outcome Q .
4.MeasurethequditwithPOVMQ= Q,1Q , G02 000
determines the purity P := Tr(ρ ) of ρ. This algorithm was discussed, e.g., in Ref. [57]. It is then
o estimate hp i, the expectation value of p (averaged over all G).
to estimatGe p := Pr(Q ), the probGability of obtaining outcome Q .
to estimate hp i, the expectation value of p (averaged over all G).
G e =6T.r(RΣ)ep∗e(1at+sGt1ep−s21(1-5−mP)a)/n2y times into order to est(i7m9)ate hp i,
G00
5. Repeat steps 2-4 many times into order to estimate p
:=
straightforward to calculate the eigenvalues of Σ from P, as follows:
order to estimate hp i, the expectation value of p (averaged over all G).
G
elesmean0
st afocolnlotrwollsed.-0SWAP gat0e on two
0
G 0G G0 0 0 0
4. Measure the qudit with POVM Q = Q , 1 1.Q R,awnhderoe mweltypcichalolyotsaekeaQ se=t 0oihf0 .m elements from G, den 000
5. Repeat steps 2-4 many†times into† order to estimate p := Pr(Q ), the probability of obtaining outcome Q .
1. RandGomly ch0 oose a set of m elements from G,0 denoted G
cqt6u.odnRitetwpheietahqt usdtneiitpt6saw.r1iRyt-h5eGpmuenaitnt6Gyas.trteRyipfmeoGspre1esj-a5it=nGmtsot0ae,opnf.ory.s,dr1m†tej-irm5,=twemos0iaet,ishn.ty.ti,Gomtioam,rt=deweeshGirtpihnGtotiGo,eots=htr=ideme1Gera.xttpeoehceptsGa=ttimi,1o1tan.htevahelpxuGpe ieo,cftahptGeioe(nxapveacrluatageteoidofnopvGvear(luaevlleorGfag)p.eGd (oaveraglledGo).v
j+1 j j+1 j 0 3.ActonthequditwithunitaryG G forj=0,..,m,withG =G =1.
pesp4e.2a-M4tesmatesaupnrsye2t-ih4memeqsauindnyitotwiomirtdehsePrinOttoVoeMosrtdiQmje+ra=1teojQpes0t,i:1m1=aPtQer(0pQ,):w=,htehPrere(pQwreo)bt0,aytbphicleiatplymlry+o1bftaokbeitlaQitiyn0i=onfgo0obiuht0tac.ionminegQout.comeQ.
5. Repeat steps 2-4 many times into orderGto estimaGt0e p := P0r(Q ), the probability of obtaining0 outcome0Q .
G00 6. Repeat steps 1-5 many times into order to estimate hp i, the expectation value of p (averaged over all G).
m+10 m+1
5. Repeat steps 2-4 many times into order to estimat
GG
(67)
isg.sSi?mt?ap,tltehiapslrgseoipmriatprhlaemtaiilosgnosrcihthemaitsicsaclhlyemdiavtidcaedllyupdivinidtoedfoupr isntteopsf:oucrlastseicpasl: pcrlea-spsircoaclespsrien-gp,rocessing, tion, quantifying the purity, and clCalsassisciaclalpPosret-procceesssiningg.
 qguathnetifpyuinrigtyt,haenpducrlCiatlysa,ssiascinacladlpcPolCarseltsa-sspiscrioaocclacelepssPsosirsnietng-gp.rocceesssiningg.
d in Fig. ??, this simple algorithm is schematically divided up into four steps: classical pre-processing
te preparation State preparatioSntate prepaSrtaattieonpreparation Classica tion, quantifying the purity, and clCalsassisciaclalpPorset-procceesssiningg.
re-processing
Quantifying the purity State preparation
ifying the purity
State preparation Stat
eparation
CQlausasnictaiflyPinrge-tphreocpeusrsitnyg
QuantifyinQgutahnetpifuyrinitgythe purity C
State prepaSrtatieonpreparation Classical Pre-processing
Quantifying theQpuarnityifyinQg uthaentpifuyriintyg the purity Classical PCrela-spsrioccaelsPsirneg-processing
lassical Post-processing ClasSstiacatel Pproespta-prCaroltaicosesnsiscianlgPCoslat-spsircoaclesPsoinsgt-processing State prepaSrtatieonpreparation
Classical State Purity agl tPheosptu-rpitryocessing ClasSstiactael Pproespta-praroticoenssing
Quantifying the purity
Classical Post-processing
Classica ctors!⌃!⇢! 0iDvateacCvtleoacsrtsoicrasl!Po⌃st-!pro⇢ce!ssingivector Pe,e 0iD
Pre-processingClassical PCPorlsaetps-spairQcaoatcuiloeaPsnsotiinsftyg-ipnrgoctehsesipnugritCyalculation QuantifyinQgutahnetpifuyrinitgythe purity
Quanti
    Data
Classical Post-processing Quantifying the purity
ost-processing
Algorith0miDimatpalevmecetonrtsed!o⌃n !IBM⇢ !’s i
0iData Cvelacstsoicras0li!DPoa⌃stta-!pvroe⇢0ceit!soDsriasHntg!aiv⌃eecc!ttoorr⇢sH! ⌃ !i ve⇢c!tor Classical PColsats-spircoaclePssoinstg-processing
i vector
  Data vectDorasta!v⌃ect!ors⇢!⌃ !i v⇢ec!tor i vector Uprep
0iData vectors ! ⌃ ! ⇢ ! vector ! ⌃ ! ⇢ !AlgoirivthemctiomrAplegmoreitnhtmeAdliogmnoprIilteBhmMme’nsitme5
m’spo5un-tqIeBurbMit’sco5m-qpuubtietrcomputer mputer
SWAP 12
  !⇢! ivector
AlgorithmADlaigmtoarpviltehcmtDoernaismtae!pdvle⌃eocmnt!UoeIprnBrs⇢etpMe!d’s⌃on5!i-qIvBu⇢ebMc!titoC’srlca5osi-msqivcupaelbuctPittoCeorslcato-spmsircopacluesPtseoinrsgt-processPing e , e 0iData ve
 Classical Post-processing
mented on IBM’s 5-qubit computer Algorithm0iDimatpalevmecetnortsed!o⌃n !IBM⇢ !’s 5-qiuvbeicttocromputer
12
Algorithm imple Algorithm implemenCteodncolnusIiBonMs ’s 5-qubit computerAlgorithm implemente
 U Classical Post-processing ed on IBM’s 5-qubit computer
prep AlCgloarsistihcaml PiCmolsapts-lspeircmoaclenPsstoiensdtg-pornoceIBssMing’s 5-qubit computer
AlgorithmAligmorpiltehmenimtepdleomn eInCBtlaMesds’iscoan5l -PqIBousbMt-ipt’rsocc5oe-msqsiupnbug ittercomputer
n IBM’s 5-qubit computer
lassical Post-processing
Classical Post-processing C
ConclusioCnosnclusions
al Post-processing
Classical PColsats-spircoaclePssoinstg-processing
Conclusions
Conclusions Classica
Conclusions ConclusioCnos nclusions
tageTohfeRaBdviatnTthahageteaiodtfvisaRniBntasigetnetshoitfaitvReiBttioistsitnhasateetn-siptirteisvpeianrtsaoetnsiotsanitieav-nepdrteompsaetarastuteir-oepnmreaepnadtraemtrireoanrssuar(neSdmPmAenMeta)se,urraroenrmds et(nhStaPteArirMtocr)as,
Conclusions
toesbdte-mpimrorpcelesemsffibienecnigtiemendtplymlemornenleoteffigdiciamelnoqtrlueybeioffitnsctlioehgnaitnclaypl orqonucbelositgssitctoahmlaqonugbprairtopschetyhs.santopmrogcerassphtoy.mography.
tage of RB it that it is insensitive Ctolastsaictael-pProespta-prraotcieosnsinang d measurement errors (SPAM), and that it ca
i
dp-qleoumnbieItnBctMoed 5-quvbeictocro
nr,epqauranttioifny,in
As depicte ,
State pr C
QCualnatsisfyicin
Classical P
Data ve vectors
ectors ! ⌃ m imple
plement emented o
lassical fying the p
l Post-pro
ata vect ctors ! ⌃
The advan
na(SnPdAthMa)t,iatnc
Classic Ce l i ams sp i l ce aml e Pn
The advan
n
Sta l Pre-proc
Classical P Quantify Quantepreparati
tate prepara
C
d on IB
eaTdovfhaRenBRtaBigteptorhofatRtoTciBtohliestgRoitnheBsaetapnTsirstoihftoiesovllceRionwBtlsoseg.pnosrsteoiastioaevsc-epoftrlooelgplosatwerassat.ateis-opfnroelaplonawdrsam.tieoansuanredmmenetaseurreomrse(nStPeArrMor)s, (aSnPdAtMha)t, iatncdanthat it can e implemented more efficiently on logical qubits than process tomography.
l Post-pro
The advantage of RB it that it is insCenosnictilvuesitoConostnactleu-psiroenpsaration and measurement errors (SPAM), and that it can lmemoreenteeffidcCmienortnleyceoffilnucilseoingoticlnyalsoqnulboigtsicathlaqnubpirtosctehsasntopmrocgersaspthoym. ography.
Con
The CRBonpcrloutosciolngsoes as follows. Conclusions
e 1im. pRlaenmdeonmteldy mc1h.orRoesaenffidaocsmie1etn.lytoRlfycahmnodnoeoslmeoemglayicesancehltsoqouffrsboemimtaseGstleh,mtadnoeefnptmorsotfecerdeloesmGs teG=onm,tsdoGfegrnro,aom.pt.e.h,GdyG.,Gde=.notGed, G...,=G G. , ..., G .
Fig. 42. Schematic diagram for the quantum algorithm for 1PCA, inmthe spe1cial casme o1f only tmwo features. The The advantage of RB it that it is insensitive to state-preparation and measurement errors (SPAM), and that it can
RcoBl gporeostoacsofloglloewssa. s follows.
nTshietiRvBe ptrotsotcoaltgeo-epsraespfoalrloawtsi.on and measurement errors (SPAM), and that it can Conclusion first step is classical pre-processing: transforming the raw data into a covariance matrix Σ, then normalizing
eaedoi1vfm.aRpRnBltaeamnigtdeontomhtfealdRyt iBmcthoiostroeitsnhesffiaeatncsisetitntitsvolyfeinmtosoneneslstoeiagmttievce-aenplttrsqoeufprsbaotiramtatsteGti-ohp,nardenapenpadoroatmectdeieosansGstua=onrmedmoGmgernea,ta.p.se.hu,ryGr.eomrse.(nStPeArrMor)s, (aSnPdAtMha)t, iatncdanthat it can
1m
T2h. ePardepvanretaqgued2oi.tf PRinrBesptiatrtte2h.qa0Putidr.ietitpisainriensstqeauntdesit0ivine. sttoastteat0ei-.preparation and measurement errors (SPAM), and that it can
tlecmcaoeThanmotohsdlreotoeoenaqsmRtetsueffielBtadyb-acpspimciterethretenosop-rtoleoptcafyscoherermomoaffiaelantpngceisuiololaeoetentpnemgrstioraρacelafoyantns=mltcidofsoqoeΣnlufnem/slrlolbTsoeweiramgt(atsiΣn.ceosG)atnudm,hlt,rtsahqedmonmeufergnbnpoeriomprtnaotustescprGtdeiuefhs,yrGrasyirdnenTt.oe=gmornpmhsρoreoteo(tGencogSde1ratPas,aGsd.Apte.w.thv,rM=oyGram.-o)qm
e implemented more efficiently on logical qubits than process tomog1raphy. m
2. Prepare qudit in state 0i. † † † RcoBlgporeostoacsoUflopglrloeopewsnsa.esedfoedllotwosp.repare|ψ⟩.Thesecondstepistopreparetwocopiesof|ψ⟩byimplementingUprepona ts3.thAacnt opnrothces3qs.udAtoictmtwointgh3rt.hauepAnihcqttyua.rdoyintGtwhiethqGudniftoarwryjith=Gu0n,i.t.G,amryf,oGwrijth=G0,f.=.o,rmGj,=wi0t,h=..G,1m.,=wGith G =1G. = 1.
no,Gurgtbas1.rain,at(.gpdp.S.heu,tyPrGh.eo
mAasftaM.Ritte)B|cψ,a⟩ani, tanndtdhftianhatallytitdietitsecrmianinsiengntshietiuvnietartyo state-p 1. Randomly choose a set of m elements from G, denoted G = G , ..., G .
j+1 j Thj+e1adjvanj+ta1gej0 ofRmB+1itth0 atitm+is10insemns+i1tivetostate-preparat bTihtesRtBhaprnotopcrool gcoeessastfomllowosg.raphy. be implemented more efficiently on logical qubits than p
rdei1tp.aiRnreasnqtadutodemitl0yiin.chstoaotsee a0is.et of m elements from G, denoted G = G , ..., G .
mented
lassical
 􏰠
1G 6. Repeat steps 1-5 many times into order to estimat
 e2 = Tr(Σ)∗(1−􏰠1−2(1−P))/2. (80)
We remark that recently (after completion of this review article), a simpler algorithm for computing purity P was given in Ref. [27]. While the results presented in what follows use the approach in Ref. [57], the approach in Ref. [27] could lead to more accurate results.
As depicted in Fig. 42, this simple algorithm is schematically divided up into four steps: (1) classical pre-processing, (2) state preparation, (3) quantifying the purity, and (4) classical post-processing.
In the first step, the classical computer converts the raw data vectors into a covariance matrix Σ, then normalizes this matrix to form ρ = Σ/Tr(Σ), then purifies it to make a pure state |ψ ⟩, and finally computes the unitary Uprep needed to prepare |ψ ⟩ from a pair of qubits each initially in the |0⟩ state.

Quantum Algorithm Implementations for Beginners 65
In the second step, the quantum computer actually prepares the state |ψ ⟩, or in fact, two copies of |ψ ⟩, using Uprep, which can be decomposed as follows:
Uprep =(UA ⊗UB)CNOTAB(UA′ ⊗1B). (81)
Note that Uprep acts on two qubits, denoted A and B, and CNOTAB is a CNOT gate with A the controlqubitandBthetarget.ThesinglequbitunitariesUA,UB,andUA′ canbewritteninIBM’s standard form:
􏰐 cos(θ/2) −eiλsin(θ/2)􏰑
eiφ sin(θ/2) eiλ+φ cos(θ/2) , (82)
where the parameters θ , λ, and φ were calculated in the previous (classical pre-processing) step. The third step is purity calculation, which makes up the bulk of the quantum algorithm. As shown in Fig. 42, first one does a Hadamard on an ancilla. Let us denote the ancilla as C, while the other four qubits are denoted A, B, A′, and B′. During the state preparation step, qubits A and B
were prepared in state |ψ⟩ with the state of A being ρ. Likewise we have the state of A′ to be ρ. Next, qubit C is used to control a controlled-SWAP gate, where the targets of the controlled-SWAP are qubits A and A′. Then, another Hadamard is performed on C. Finally, C is measured in the Z basis. One can show that the final expectation value of Z on qubit C is precisely the purity of ρ, i.e.,
⟨Z⟩C =p0 −p1 =Tr(ρ2)=P, (83)
where p0 (p1) is the probability for the zero (one) outcome on C.
The fourth step is classical post-processing, where one converts P into the eigenvalues of Σ using
Eqs. (79) and (80).
14.3 Algorithm implemented on IBM’s 5-qubit computer
The actual gate sequence that we implemented on IBM’s 5-qubit computer is shown in Fig. 43. This involved a total of 16 CNOT gates. The decomposition of controlled-SWAP into one- and two-qubit gates is done first by relating it to the Toffoli gate:
controlled-SWAPCAB = (1C ⊗ CNOTBA)ToffoliCAB(1C ⊗ CNOTBA) (84)
and then decomposing the Toffoli gate, as in Ref. [91].
We note that the limited connectivity of IBM’s computer played a signficant role in determining
the algorithm. For example, we needed to implement a CNOT from q[1] to q[2], which required a circuit that reverses the direction of the CNOT from q[2] to q[1]. Also, we needed a CNOT from q[3] to q[1], which required a circuit involving a total of four CNOTs (from q[3] to q[2] and from q[2] to q[1]).
Our results are as follows. For the example given in Eq. (76), IBM’s 5-qubit simulator with 40960 trials gave:
e1 = 1.57492 , e2 = 0.102965 (IBM’s simulator) . (85) A comparison with Eq. (77) shows that IBM’s simulator essentially gave the correct answer. On the
other hand, IBM’s 5-qubit quantum computer with 40960 trials gave:
e1 = 0.838943 + 0.45396i , e2 = 0.838943 − 0.45396i (IBM’s Quantum Computer) . (86)
This is a non-sensical result, since the eigenvalues of a covariance matrix must be (non-negative) real numbers. So, unfortunately IBM’s quantum computer did not give the correct answer for this problem.

66 Abhijith J., et al.
       Fig. 43. Actual circuit for quantum PCA implemented on IBM’s 5-qubit simulator and quantum computer. The first three time slots in the score correspond to the state preparation step of the algorithm, and the subsequent time slots correspond to the purity calculation step. Due to connectivity reasons, we chose qubit q[3] as the ancilla and qubits q[1] and q[2] as the targets of the controlled-SWAP operation. We decomposed the controlled-SWAP operation into CNOT gates by first relating it to the Toffoli gate via Eq. (84), and then decomposing the Toffoli gate into CNOT gates [91].
15 QUANTUM SUPPORT VECTOR MACHINE
Support Vector Machines (SVM) are a class of supervised machine learning algorithms for binary classifications.ConsiderMdatapointsof{(x􏰆j,yj):j=1,2,...,M}.Herex􏰆j isaN-dimensional vector in data feature space, and yj is the label of the data, which is +1 or −1. SVM finds the hyperplane w􏰆 · x􏰆 + b = 0 that divides the data points into two categories so that w􏰆 · x􏰆j + b ≥ 1 when yj = +1 and w􏰆 · x􏰆j + b ≤ −1 when yj = −1, and that is maximally separated from the nearest data points on each category. Least Squares SVM (LS-SVM) is a version of SVM [102]. It approximates the hyperplane finding procedure of SVM by solving the following linear equation:
􏰒0 1􏰆T 􏰓􏰒b􏰓 􏰒0􏰓
1􏰆 K+γ−11 α􏰆 = y􏰆 . (87)
Here K is called the kernel matrix of dimension M × M, γ is a tuning parameter, and α􏰆 forms the normal vector w􏰆 where w􏰆 = 􏰫Mj =1 α j x􏰆j . Various definitions for the kernel matrix are available, but the quantum SVM [84] uses linear kernel: Ki j = x􏰆i · x􏰆j . Classically, the complexity of the LS-SVM is O􏰇M2(M + N)􏰈.
The quantum version of SVM performs the LS-SVM algorithm using quantum computers [84]. It calculates the kernel matrix using the quantum algorithm for inner product [69] on quantum random access memory [50], solves the linear equation using a quantum algorithm for solving linear equations [50], and performs the classification of a query data using the trained qubits with a quantum algorithm [84]. The overall complexity of the quantum SVM is O 􏰇 log N M 􏰈 .
The algorithm is summarized below:

Quantum Algorithm Implementations for Beginners 67
 Algorithm 13 Quantum SVM [84]
Input:
•Trainingdataset{(x􏰆j,yj):j =1,2,...,M}.
• A query data x􏰆. Output:
• Classification of x􏰆: +1 or −1. Procedure:
Step 1. Calculate kernel matrix Ki j = x􏰆i · x􏰆j using quantum inner product algorithm [69].
Step 2. Solve linear equation Eq. (87) and find |b, α􏰆⟩ using a quantum algorithm for solving linear equations [50] (training step).
Step 3. Perform classification of the query data x􏰆 against the training results |b, α􏰆⟩ using a quantum algorithm [84].
The inner product calculation to compute the kernel matrix cannot be done reliably in the currently available quantum processors. The other important part of the algorithm, which is linear system solving, can be quantized and has been dealt with in Section IV.
16 QUANTUM SIMULATION OF THE SCHRÖDINGER EQUATION 16.1 Problem definition and background
The Schrödinger’s equation describes the evolution of a wave function ψ (x , t ) for a given Hamil- tonian Hˆ of a quantum system:
∂ 􏰖 ħ 2 kˆ 2 􏰗
iħ∂tψ(x,t) = Hˆψ(x,t) = 2m +V(xˆ) ψ(x,t), (88)
  where the second equality illustrates the Hamiltonian of a particle of mass m in a potential V (x ). Simulating this equation starting with a known wave function ψ (x , 0) provides knowledge about the wavefunctionatagiventimetf andallowsdeterminationofobservationoutcomes.Forexample, 􏰍􏰍
􏰍ψ(x,tf )􏰍2 is the probability of finding a quantum particle at a position x at time tf .
Solving the Schrödinger’s equation numerically is a common approach since analytical solutions are only known for a handful of systems. On a classical computer, the numerical algorithm starts by defining a wave function on a discrete grid ψ (xi , 0) with a large number of points i ∈ [1, N ]. The form of the Hamiltonian, Eq. (88), allows one to split the system’s evolution on a single time step
∆t in two steps, which are easy to perform:
ψ(xi,tn+1) = e−iV(xi)∆tQFT†e−ik2∆tQFTψ(xi,tn), (89)
where we have assumed that ħ = 1 and m = 12 . And QFT and QFT† are the quantum Fourier transform and its inverse. The quantum state evolution thus consists of alternating application of the phase shift operators in the coordinate and momentum representations. These two representation are linked together by the Fourier Transformation as in the following example of a free space evolution of a quantum particle:
ψ(xi,tf ) = QFT† e−ik2tf QFTψ(xi,0), (90)
where V (x ) = 0 for a free particle.
We now discuss the quantum simulation of the Schrödinger’s equation similar to the one discussed
in [13], [98] that provides the wave function of the system at a given time tf . Finding a proper measurement on a quantum simulator that reveals information about the quantum system will

68 Abhijith J., et al.
􏰍􏰍
however be left out of the discussion. 􏰍ψ(x,tf )􏰍2 will be the only information we will be interested
in finding out.
16.2 Algorithm description
A quantum algorithm that performs a quantum simulation of one dimensional quantum systems was presented in [13]. The procedure is outlined in Algorithm 14.
Algorithm 14 Quantum simulation of Schrödinger equation [98], [13]
Input:
• Initial wave function
• Time step size, ∆t , and the number of time steps, T .
• The ability to apply phase shifts in the computational basis. • The potential function V .
Output:
• Final wave function at time tf = Tδt when evolved using the Schrödinger equation with the potential V .
Procedure:
Step 1. Encode the wave function on a N-point grid in a quantum state of n = log2(N)
qubits. The value of this discretized wavefunction on a grid point is equal to the value of the original wave function at the same point. The constant of proportionality must then be calculated by renormalizing the discretized wavefunction.
for 1 ≤ j ≤ T do
Step 2a. Apply the Quantum Fourier Transform (QFT) to go to the momentum
representation.
Step 2b. Apply a diagonal phase shift of the form |x⟩ → e−ix2∆t |x⟩ in the computa-
tional basis.
Step 2c. Apply the inverse Quantum Fourier Transform to come back to the position
representation.
Step 2d. Apply a phase shift of the form |x⟩ → e−iV (x)∆t |x⟩ .
end for
Step 3. Measure the state in the computational basis.
Figure 44 shows the following stages of the algorithm. The implementation of QFT was discussed in Section IV. Implementing phase shifts corresponding to arbitrary functions can be done using a series of controlled Z gates or CNOT gates [13]. Repeating the final measurement step over many independent runs will let us estimate the probabilities |ψ(x,tf )|2. We will now consider a 2-qubit example of the quantum simulation algorithm in the case of a free particle, V (x ) = 0.
Our initial wave function is a Π-function (a rectangular wave), which has {0, 1, 1, 0} representa- tion on a 2n -point grid for n = 2 qubits. Its representation by the state of the qubits is proportional to |0, 1⟩ + |1, 0⟩, which can be prepared by constructing the Bell state (see Fig. 1) and applying the X gate to the first qubit.
We define the 2-qubit QFT as QFT = SWAP12 H2 C2 􏰉P1 􏰇 π2 􏰈􏰊 H1, where C2P is a phase operator controlled from the second qubit. This transformation applies phase shifts to the probability amplitudes of the qubit states similar to the ones applied by the classical FFT to the function values. Hence, the resulting momentum representation is identical to the classical one in a sense that it is not centered around k = 0, which can be easily remedied by a single X1 gate.
   
Quantum Algorithm Implementations for Beginners 69
 Classical Pre-processing
"!, |%&amp;(()⟩ (+,, ∈ [0,0] %+ = %((+)
3 {5}, 7 = log; 0
@ %&lt;==%+3+ 5
+&gt;? A!BCDB
State ΔH step Preparation (HI/ΔH times)
0? 0? 0; 0; 0E 0E 0F 0F 0G 0G
Final State
        Fig. 44. The quantum simulation of the Schrödinger’s equation. The first stage is a classical pre-processing that encodes the wave function to available qubits and derives a state preparation operator that takes an all-zero state of a quantum computer to a desired state. The second stage prepares an initial state by implementing the state preparation operator Uˆprep on a quantum computer. The third stage is an iterative update looped over ∆t steps based on the operator splitting method.
 |0⟩
|0⟩ H X • X H P(π2) P(φ)
|0⟩ • H X P(2φ) •
P(2φ)
      •
•
P(π2) H • X H •
     Fig. 45. The quantum circuit implementation of a 2-qubit algorithm that solves the Schrödinger’s equation on a quantum computer. The initial state preparation is followed by the Quantum Fourier Transform and centering of the momentum representation. The single qubit phase shift transformations are followed by the two-qubit phase shift transformation that uses an ancillary qubit q[0]. The inverse Quantum Fourier Transform preceded by removing the centering operation completes the circuit and returns the wave function to the coordinate representation.
Themomentumencodingadoptedinthisdiscussionisk =−1􏰡φ 􏰇1+􏰫n 2∆t k=1
2n−kZk􏰈,where φ is a characteristic phase shift experienced by the state on a time step ∆t. In this representation −ik2∆t phase shift contains one and two qubit contributions that commute with each other and can be individually implemented. The one qubit phase shift gate has a straightforward implementation but the two qubit phase shift gate requires an ancillary qubit according to Ref. [77], which results in a three qubit implementation on a quantum computer. This implementation is captured in Fig 45 where removing the centering of the momentum representation and the inverse QFT have been
added in order to return to the coordinate representation.
16.3 Algorithm implemented on IBM’s 5-qubit computer
The implementation in Fig. 46 takes into account the topology of the chip and the availability of the gates such as U 1 and U 2. Finally, it performs a consolidation of the single qubit gates in order to reduce the number of physical operations on the qubits.
@
%&lt;HI ==J+3+ 5 +&gt;?
RQ Δ H U (
M TNOP
RQ Δ H S ;
M NOP
A!BCDB

70 Abhijith J., et al.
     Fig. 46. The quantum circuit implementation of a 2-qubit algorithm that solves the Schrödinger’s equation on the ibmqx4 quantum computer.
The circuit in Fig. 46 was run on the ibmqx4 quantum chip, where the maximum number of executions in a single run is 210. The probabilities of observing qubit states in the computational basis was measured for φ = 0, φ = π /2, φ = π , φ = 3π /2 and φ = 2π . We expect that as φ increases from 0 to π the wave function evolves from a Π-function to a uniform function to a function peaked at the ends of the interval. The consecutive increase returns the wave function back to the Π-function.
We started with the φ = 0 case that should have reproduced our initial state with ideal probabilities of {0, 0.5, 0.5, 0}. However, the observed probabilities were {0.173, 0.393, 0.351, 0.084}. Thus it was surprising to see that the φ = π/2 case was very close to expected probability of 0.25 with the observed values of {0.295, 0.257, 0.232, 0.216}. This surprise was however short lived as the φ = π case has reverted back large errors for observed probabilities: {0.479, 0.078, 0.107, 0.335}. The final two case had the following observed probabilities {0.333, 0.248, 0.220, 0.199} and {0.163, 0.419, 0.350, 0.068} respectively.
17 GROUND STATE OF THE TRANSVERSE ISING MODEL
In this section the ground state of the transverse Ising model is calculated using the variational quantum eigenvalue solver, and the result is compared to the exact results. This is a hybrid method that uses alternating rounds of classical and quantum computing.
In the previous section we saw how to simulate the evolution of a single quantum particle. But often, real world phenomena are dependent on the interactions between many different quantum systems. The study of many-body Hamiltonians that model physical systems is the central theme of condensed matter physics (CMP).
Many-body Hamiltonians are inherently hard to study on classical computers as the dimension of the Hilbert space grows exponentially with the number of particles in the system. But using a quantum computer we can study these many-body systems with less overhead as the number of qubits required only grows polynomialy.
17.1 Variational quantum eigenvalue solver
A central task in CMP is finding the ground state (lowest energy eigenstate) of a given Hamiltonian, H,
H|Ψ⟩ = Eд|Ψ⟩. (91)
Studying the ground state gives us information about the low temperature properties of the system. Once we know |Ψ⟩, we can deduce the physical properties from the wave function. In this section, we will describe how to use IBM Q to find the ground state energy of the transverse Ising model. We will not be using the ibmqx4 in this section. This is because the algorithm we use will require many rounds of optimization. Each round requires us to run a circuit on the quantum computer followed by a classical optimization step on a local machine. This process can

Quantum Algorithm Implementations for Beginners 71
 Fig. 47. Schematic view of the implementation of the variational quantum eigenvalue solver using a hybrid classical and quantum circuit. The figure is adopted from Ref. [79].
be automated easily using Qiskit. But the long queuing times in IBM Q makes repeated runs on the quantum processor impractical.
To find the eigenvalue of a Hamiltonian, we could use the quantum phase estimation algorithm that was discussed in Section IV. To do this we need the ability to perform controlled operations with the unitary U = exp(−iHδt/ħ), where δt is the time step. Then, by preparing different initial states |ψi ⟩ and repeating the phase estimation many times one can obtain, in principle, the whole spectrum of the eigenvalues and the corresponding eigenwave functions. For a general Hamiltonian, however, the implementation of a controlled U may be not straightforward. For realistic problems, the quantum phase estimation circuits have large depth. This requires qubits with long coherence times, which are not available at the time of writing. For CMP problems, we are mainly interested in the lowest eigenvalue for most cases.
To overcome these limitations, we use the recently developed variational quantum eigenvalue solver (VQES) [74, 79]. The basic idea is to take the advantages of both quantum and classical computers, as shown in Fig. 47. It allocates the classically easy tasks to classical computers and the other tasks to quantum computers. The algorithm is summarized as follows:
(1) Prepare a variational state |ψ (θi )⟩ with parameters θi . For an efficient algorithm, the number of variational parameters should grow linearly with the system size.
(2) Calculate the expectation value of the Hamiltonian using a quantum computer, E = ⟨ψ |H |ψ ⟩/⟨ψ |ψ ⟩.
(3) Use classical nonlinear optimizer algorithms to find new optimal θi . In this report, we will use therelaxationmethodτ0∂tθi =−∂E/∂θi,whereτ0 isaparametertocontroltherelaxation
rate.
(4) Iterate this procedure until convergence.
VQES has the following advantage: For most CMP problems, where the interaction is local, we can split the Hamiltonian into a summation over many terms. This means that we can parallelize the algorithm to speed up the computation. The quantum expectation calculations for one term in the Hamiltonian are relatively simple, thus no long coherence times are not required. On the

72 Abhijith J., et al.
  Ferromagnetic phase   Paramagentic phase h 𝑔# Quantum phase transition
 Fig.48. SchematicviewofthequantumphasesdescribedbythetransverseIsingmodel.Thearrowsrepresent the spin configuration in the ordered and disordered phases.
other hand, VQES also has limitations. Because of its variational nature, the trial wave function needs to be prepared carefully. This usually requires physical insights into the problem. The ground state eigenvalue and eigenwave function are biased by the choice of the trial wave functions. In addition, VQES requires communications between classical and quantum computers, which could be a bottleneck for the performance.
17.2 Simulation and results
We use VQES to find the ground state of the transverse Ising model (TIM) defined by H=−􏰭σzσz −h􏰭σx, (92)
ii+1 i ii
whereσz,σx arePaulimatricesandhistheexternalmagneticfield.Letusfirstreviewbrieflythe physical properties of this Hamiltonian. This Hamiltonian is invariant under the global rotation of spinalongthexaxisbyπ,RxHRx† =H,whereRx(π)istherotationoperator
RxσxRx† = σx, RxσzRx† = −σz. (93)
The TIM has two phases: When the transverse field h is small, the spins are ordered ferromagnetically and the rotational symmetry associated with Rx is broken. In the ordered phase, the quantum expectation value ⟨σ z ⟩ 􏰯 0. As h is increased, there is a quantum phase transition from the ordered phase to the disordered phase where ⟨σ z ⟩ = 0, as the rotational symmetry is restored. The phase diagram is shown schematically in Fig. 48.
Using the phase diagram as a guide, first we propose a product state as a trial wave function. The wave function can be written as
|ψi(θi)⟩ = 􏰮U(θi)|0i⟩. (94) i
Here U (θi ) is the unitary operation which describes the spin rotation along the y axis by an angle θi,
􏰐 cos(θi /2) − sin(θi /2) 􏰑 sin(θi /2) cos(θi /2)
U (θi ) =
where θi are the variational parameters. Here we have used the Bloch sphere representation for a
qubit state. For the TIM, we calculate the expectation value of
E =−⟨ψ|σzσz |ψ⟩, E =−⟨ψ|σx|ψ⟩. (95)
J,i i i+1 Z,i i
The quantum circuit to perform the preparation of the state and calculation of the expectations
value are shown in Fig. 49(a) andFig. 49(b) . We have
EJ,i = −[P(qi = 0) − P(qi = 1)][P(qi+1 = 0) − P(qi+1 = 1)], (96)
EZ,i = −[P(qi = 0) − P(qi = 1)], (97)
,

Quantum Algorithm Implementations for Beginners
73
         (a)
(b)
       (c)
Fig. 49. Quantum circuits to prepare the trial wave-functions. The single qubit unitaries in the text can be implemented using available gates in IBM Q. The first two circuits prepare unentangled trial states. Circuit (a) can be used to measure ⟨ψ | σ2z σ3z |ψ ⟩ . Circuit (b) can be used to measure the ⟨ψ | σ3x |ψ ⟩. Circuit (c) prepares the entangled trial state.
whereP(qi =0,1)isthemeasuredprobabilityforthequbitqi inthe|0⟩or|1⟩state.Aswementioned before, the communication bottleneck prevented us from implementing this on ibmqx4. We ran the code using the quantum simulator in Qiskit. The comparison of the results obtained from quantum simulation and analytical results are shown in Fig. 50. Our trial wave function works very well in the ordered phase, but the simulation results deviate from the exact solution in the quantum phase transition region. This discrepancy is caused by the fact that we have neglected the quantum entanglement in our trial wave function.
In a second set of experiments, we use a trial wave function that includes quantum entanglement. Because of the symmetry, |Ψi (θi )⟩ and Rx (π )|Ψi (θi )⟩ are two degenerate wave functions with the same energy. The trial wave function can be written as a linear superposition of these two degenerate wave functions
|ψi(θi)⟩ =α|Ψi(θi)⟩+βRx(π)|Ψi(θi)⟩. (98)
The first step is to prepare |ψi (θi )⟩ using quantum circuit. To prepare an arbitrary state in a quantum circuit is not trivial as it requires of the order of 2n CNOT gates, where n is the number of qubits [80]. The state in Eq. (98) can be prepared easily using the circuit in Fig. 49(c). Here we consider 4 spins. The first U0(θ,φ) operation transforms the state into
|0000⟩ → eiφ sin(θ/2)|1000⟩ + cos(θ/2)|0000⟩. The first CNOT transforms the state into
eiφ sin(θ/2)|1100⟩ + cos(θ/2)|0000⟩. The second CNOT transforms the state into
eiφ sin(θ/2)|1110⟩ + cos(θ/2)|0000⟩.

74 Abhijith J., et al.
 -��� (a)
-��� -��� -��� -���
(b) ��� ���
��� ��� ��� ���
���������� �� ��������� ���� ���������� �� ����
�����
��� ���
��� ��� �
��� ��� ���
      ��� ���
��� ��� �
��� ��� ���
���������� �� ��������� ���� ���������� �� ����
�����
���� ����
     Fig. 50. Comparison of the ground state energy (a) and average magnetization (b) Mx = ⟨ψ | 􏰫i σix |ψ ⟩/N obtained by using the trial wave functions in Eq. (94) and the exact results. Here we have used the periodic boundary condition. The simulations are run both on the quantum simulator (black symbols) and classical computers (red symbols). The mean-field results (blue line) are also displayed for comparison.
The third CNOT transforms the state into
eiφ sin(θ/2)|1111⟩ + cos(θ/2)|0000⟩.
Finally we apply U (θi ) rotation and we obtain the desired state in Eq. (98). Here
U0(θ,φ) =
􏰐 cos(θi /2) − sin(θi /2) 􏰑 eiφ sin(θi/2) eiφ cos(θi/2)
.
We then use VQES to find the ground state energy. As can be seen in Fig. 51, the new trial function nearly reproduces the exact results in the whole magnetic field region and improves upon the product state trial function.
18 QUANTUM PARTITION FUNCTION
18.1 Background on the partition function
Calculation or approximation of the partition function is a sub-step of inference problems in Markov networks [63]. Even for small networks, this calculation becomes intractable. Therefore an efficient
��
𝐸/𝑁�

Quantum Algorithm Implementations for Beginners 75
 ��� -��� -��� -��� -��� -���
���� ����� ����� ���� ������������ ������� ������� ������������
  -���
��� ��� ��� ��� ���
�
��� ���
    N=4
Fig. 51. (color online) Comparison of the ground state energy obtained by using the trial wave functions in Eqs. (94) and (98) and the exact result. Here we have used the periodic boundary condition. The number of spins is 4.
quantum algorithm for the partition function would make many problems in graphical model inference and learning tractable and scalable; the same holds for other problems in computational physics [7, 46, 48, 49].
The partition function is of particular interest for calculating probabilities from graphical models such as Markov random fields [63]. For this article, we consider the graphical model form known as thePottsmodel.LetΓ=(E,V)beaweightedgraphwithedgesetEandvertexsetV andn=|V|. In the q-state Potts model, each vertex can be in any of q discrete states. The Potts model is a generalization of the classical Ising model. In the classical Ising model q = 2, whereas in the Potts model q ≥ 2. The edge connecting vertices i and j has a weight Ji j which is also known as the interaction strength between corresponding states. The Potts model Hamiltonian for a particular stateconfigurationσ =(σ1,...,σn)is
H(σ) = −􏰭 Jijδσi,σj , (99) i∼j
where i ∼ j indicates that there exists an edge between vertices i and j; and where δσi,σj = 1 if σi = σj and 0 otherwise.
The probability of any particular configuration being realized in the Potts model at a given temperature, T , is given by the Gibbs distribution:
P(σ) = Z1e−βH(σ), (100) where β = 1/(kBT ) is the inverse temperature in energy units and kB is the Boltzmann constant.
The normalization factor, Z , is also known as the partition function:
Z = 􏰭e−βH(σ), (101) {σ}
�/�

76
FIG. 1:
FIG. 1: Abhijith J., et al.
This algorithm was discussed in Ref. XXX Need citation XX. It is then straightforward to calculate t
of ⌃ from P, as follows:
This algorithm was discussed in Ref. XXX Need citation XX. It is then straightforward to calculate t
 s:a b c
(a) Graph 100
state preparation, quantifying the purity, and classical post-processing.
vertices and
ab
abc −H(σ) p
 000 J +J +J
of⌃fromP,asfollow
As depicted in Fig. ??, this simple aleg2or=ithTmr(⌃is)s⇤ch(1ematic1ally2(d1ividPed))u/p2.into four steps: classical
Fig.52. (a)Simpleexamplewith(b)theenumerationofstateconfigurationsandthevalueoftheHamiltonian
for a fully-connected 3-vertex Ising model (q = 2 Potts model)
Quantifying the purity
Fig. 53. Overview of the quantum partition function algorithm.
be implemented more efficiently on logical qubits than process tomography.
possible state configurations, and so this is a sum over a large number of items and is generally intractable as
be implemented more efficiently on logical qubits than process tomography. T1h.eRRanBdpomroltyocohlogoosesaasetfoollfowms.elements from G, denoted G = G1,...,Gm .
well as difficult to approximate. The calculation of the partition function is #P-hard (i.e., it is a
2 1 . . PR r a e n p d a o r me l q y u c d h i t o o i n s e s t a a s t e e t 0 o i f . m e l e m e n t s f r o m G , d e n o t e d G = G , . . . , G .
counting problem which is at least as hard as the NP-hard class of decision p1roblems). There is no
known fully polynomial randomized approximat†ion scheme (fpras), and it is unlikely that there 23. PArcetpoanrethqeudqiutdiint swtaithe u0nii.tary Gj+1Gj for j = 0, .., m, with G0 = Gm+1 = 1.
exists one [49].
43. MAcetasounrethtehequqduidtitwwithithunPiOtaVryMGQ =G Qfo,r1j=Q0, .., mwh, ewreithweGty=picGally ta=ke1Q. j+1†j00 0m+10
J
ab bc ac
e =Tr(⌃)⇤(1+p12(1P))/2 1
001 Jab p
e =Tr(⌃)⇤(1 12(1P))/2. 2
e01=0 TrJ(⌃)⇤(1+ 12(1P))/2 1 ac
011 J bc
bc
As depicted in Fig. ??, this simple alg1o0r1ithmJ is schematically divided up into four steps: classical
with three
ac
statepreparation,quantifyingthepurity1,1a0ndcJlassicalpost-processing.
three edges.
Classical Pre-processing
111 Jab + Jbc + Jac
(b)
Classical Pre-processing State preparation
State preparation Quantifying the purity
Classical Post-processing
 Classical preprocessing

Gauss elimination
[n,k] code
Irreducible cyclic code via Shor’s
[n,k] code
State preparation and Classical Classical Post-processing
quantum Fourier transform
0iDatUa vectors ! ⌃ ! ⇢ ! prep QFT 
0iDatUa vectors ! ⌃ ! ⇢ ! prep
post-processing
    
 i vector i vector
   Shor’s alg
  Algorithm implemented on IBM’s 5-qubit comp
 Ai
 Algorithm implemented on IBM’s 5-qubit comp
Classical Post-processing
 Quit, if
not ICCC Repeat for each Z
uter uter
The advantage of RB it that it is insensitive to state-preparation and measurement errors (SPAM), a
Classical Post-processing
Conclusions
Conclusions
The advantage of RB it that it is insensitive to state-preparation and measurement errors (SPAM), a
The RB protocol goes as follows. n where {σ } means the full set of all possible state configurations. There are q
= 0ih0 .
54. RMepaesautrestehpesq2u-4dimt wanityhtPimOeVsMintQo o=rdeQr t,o1estiQmat,ewpher:=e wPer(tQyp)ic,atlhlye tparkoebaQbil=ity0oifh0ob.taining o
18.2 A simple example
00G00 Wegiveasmallexamplewithagraphofn = 3,V = {a,b,c},withedgesbetweenallpairsofvertices
65. Repeat steps 12-54 many times into order to estimate hpp :i=, tPhre(Qexp)e, ctthaetipornobvalbuielitoyf opf o(batvaeinrainggedo for three total edges, pictured in Figure 52a, and we use q = 2 for GbGinary stat0es on each vertex. TGo
demonstrate the calculation of the partition function, we first enumerate the configurations as
6. Repeat steps 1-5 many times into order to estimate hpGi, the expectation value of pG (averaged shown in Fig. 52b.
We plug the value of the Hamiltonian for each of the qn configurations into the partition function given in Eq. (101) to get the normalization constant:
Z=2eβ(Jab+Jbc+Jac)+2eβJab +2eβJbc +2eβJac. (102) Letting Jij = 1 for all i ∼ j, gives:
Z =2e3β +6eβ. (103)
      h h
p p
u uo o

Quantum Algorithm Implementations for Beginners 77
          Fig. 54. Circuit for preparing the first two qubits and quantum Fourier transform on 2 qubits.
18.3 Calculating the quantum partition function
An efficient quantum algorithm for the partition function is given by [49] for Potts models whose graph, Γ, has a topology such that it can be represented with an irreducible cyclic cocycle code (ICCC). This stipulation is non-intuitive and it takes a quantum algorithm to efficiently determine if a given graph meets this requirement. From the graph, Γ, calculate a cyclic code C(Γ) that represents the generating structure of the graph by using Gaussian elimination on the incidence matrix of the graph, and then use Shor’s algorithm to determine the irreducible set of code words χ . If the code is not irreducible, then we will not be able to efficiently calculate the partition function for this graph.
Assuming that the given graph is ICCC, the first step in the partition function algorithm is to calculate the Gauss sum of GFqk = 􏰠qkeiγ , where γ is a function of χ. The difficult part is to calculate γ , which can be done efficiently using the quantum Fourier transform (QFT). Using the set of values, {γ } for all of the words, { χ } in the code; we calculate the weight spectrum {Ai } of the code representing Γ. From this weights spectrum, the partition function Z can be efficiently calculated using classical computing.
18.4 Implementation of a quantum algorithm on the IBM Quantum Experience
We implemented one step of the full partition function algorithm using the IBM Quantum Experience.
The implemented algorithm is the 2-qubit quantum Fourier transform (QFT2), as the first step
in actual calculation of the partition function. The input to this step is the irreducible cocyclic
code. The irreducible cyclic code for the example problem of a 3-vertex Ising model is [1, −1] with
n = |V | = 3 and k = |E| −c(Γ) = 2, where c(Γ) is the number of connected components in the graph
Γ. This small example does meet the ICCC requirement (as checked through classical calculation), so
we will continue with the calculation of the partition function of the example without implementing
the quantum algorithm for checking this requirement. In the fully-connected 3-vertex Ising model |0⟩+|1⟩ |0⟩−|1⟩
example given, the input to QFT2 is q[0] = |+⟩ = √2 and q[1] = |−⟩ = √2 . In the sample
score shown in Fig. 54, these qubits are prepared before the barrier. The QFT2 algorithm, as given by the Qiskit Tutorial provided by IBM[3], is the rest of the code. The output bits should be read in reverse order. Some gates could be added at the end of the QFT2 algorithm to read the gates in the same order as the input.
The result from simulating 1000 shots gives P(γ = 1) = 0.47 and P(γ = 3) = 0.53. The results from running on the actual hardware are, P(γ = 0) = 0.077, P(γ = 1) = 0.462, P(γ = 2) = 0.075, and P(γ = 3) = 0.386. We can threshold the low-probability values of gamma, ensuring that no more

78 Abhijith J., et al.
than the maximum number (as given in [49]) of distinct values of gamma remain. These gammas are then plugged into the calculation of the weight spectrum and the partition function.
19 QUANTUM STATE PREPARATION
The problem of preparing an n-qubit state consists first of finding the unitary transformation that takes the N-dimensional vector (1,0,...0) to the desired state (α1, ..., αN ), where N = 2n, and then rendering the unitary transformation into a sequence of gates.
19.1 Single qubit state preparation
As discussed before, a single qubit quantum state |ψ ⟩ is represented as a superposition of |0⟩ and |1⟩ states |ψ ⟩ = α |0⟩ + β |1⟩, where |α |2 + |β |2 = 1. The sizes |α |2 and |β |2 represent the probability of |ψ ⟩ being |0⟩ or |1⟩. Up to a non-observable global phase, we may assume that α is real, so that |ψ⟩=cosθ |0⟩+eiφsinθ |1⟩forsomeanglesθ,φ.Inthisway,wecanrepresentthestateasapoint on the unit sphere with θ the co-latitude and φ the longitude. This is the well-known Bloch sphere representation. In this way, the problem of 1-qubit state preparation consists simply of finding the unitary transformation that takes the North pole to (α, β). In practice, this amounts to finding a sequence of available gates on actual hardware that will leave the qubit in the desired state, to a specified desired accuracy.
To prepare a specified state |ψ ⟩, we must find a 2 × 2 unitary matrix U taking the vector |0⟩ to |ψ ⟩. An obvious simple choice for U is
􏰐 cosθ −sinθe−iφ 􏰑 U = sinθeiφ cosθ
This gate is directly available in IBM Q and is implemented in a composite fashion on ibmqx4 at the hardware level. If our goal is to initialize a base state with the fewest possible standard gates, this may not be the best choice. Instead, it makes sense to consider a more general possible unitary operator whose first column is our desired base state, and then determine the requisite number of standard gates to obtain it.
Any 2 × 2 unitary matrix may be obtained by means of a product of three rotation matrices, up to a global phase
U =eiαRz(β)Ry(γ)Rz(δ)
where here Rz(β) = diag(eiβ/2,e−iβ/2) and Ry(γ) is related to Rz(γ) by Ry(γ) = SHRz(γ)HSZ. The rotation matrices Ry(γ) and Rz(β) correspond to the associated rotations of the unit sphere under the Bloch representation. In this way, the above decomposition is a reiteration of the standard Euler angle decomposition of elements of SO(3). Thus the problem of approximating an arbitrary quantum state is reduced to the problem of finding good approximations of Rz (γ ) for various values ofγ.
There has been a great deal of work done on finding efficient algorithms for approximating elements Rz (γ ) using universal gates to a specified accuracy. However, these algorithms tend to focus on the asymptotic efficiency: specifying approximations with the desired accuracy which are the generically optimal in the limit of small errors. From a practical point of view, this is an issue on current hardware, since representations tend to involve hundreds of standard gates, far outside the realm of what may be considered practical. For this reason, it makes sense to ask the question of how accurately one may initialize an arbitrary qubit with a specified number of gates.
We empirically observe that the maximum possible chordal distance from a point on the Bloch sphere to the set of exact states decreases exponentially with the number of gates. With 30 gates, every point is within a distance of 0.024 of a desired gate. Thus, to within an accuracy of about

Quantum Algorithm Implementations for Beginners 79
   Fig. 55. Possible exact state initializations using 10, 15, and 20 gates. With 20 gates, every point on the sphere is within a distance of approximately 0.072 of an exactly obtainable state. With 30 gates, every point is within 0.024
2.5%, we can represent any base state as a product of about 30 states. We do so by preserving the states generated by 30 gates, and then for any point finding the closest exact point.
19.2 Schmidt decomposition
The initialization of qubit states using more than one qubit is aided by the so-called Schmidt decomposition, which we now introduce. Specifically, the Schmidt decomposition allows one to initialize a 2n-qubit state by initializing a single n-qubit state, along with two specific n-qubit gates, combined together with n CNOT gates.
Mathematically, an arbitrary 2n-qubit state |ψ ⟩ may be represented as a superposition |ψ⟩ = 􏰭 􏰭 ai1,...,in,j1,...,jn |i1i2 ...inj1j2 ...jn⟩.
i1,...,in ∈{0,1} j1,...,jn ∈{0,1}
In a Schmidt decomposition, we obtain such a state by strategically choosing two orthonormal bases􏰍􏰍ξj􏰌,􏰍􏰍φj􏰌forj=1,...,2n oftheHilbertspaceofn-qubitstatesandthenwriting|ψ⟩asthe product
2n
|ψ⟩=􏰭λi |ξi⟩|φi⟩,
i=1
for some well-chosen λi ’s. Thebases􏰍􏰍ξj􏰌and􏰍􏰍φj􏰌mayberepresentedintermsoftwounitarymatricesU,V ∈U(2n),while
the λi ’s may be represented in terms of a single n-qubit state. We represent this latter state as B |00 . . . 0⟩ for some B ∈ U (2n ). Then from a quantum computing perspective, the product in the Schmidt decomposition may be accomplished by a quantum circuit combining U , V , and B with n CNOT gates as shown below for n = 6.
Let Cij denote the CNOT operator with control j and target i. Algebraically, the above circuit may be written as a unitary operator T ∈ U (22n ) of the form
T=(U⊗V)(C1 ⊗C2 ⊗···⊗Cn )(B⊗I). n+1 n+2 2n
We will use |e1⟩ , . . . , |e2n ⟩ to denote the standard computational basis for the space of n-qubit states, in the usual order. We view each of the elements ej as a vector in {0, 1}n . In this notation, the formation of CNOT gates above acts on simple tensors by sending
C1 ⊗C2 ⊗···⊗Cn :|e⟩􏰍e􏰌􏰅→|e⟩􏰍e +e􏰌, e,e ∈{0,1}n, n+1n+2 2ni􏰍ji􏰍ijij

80
Abhijith J., et al.
   B
•
•
•
•
  U
V
where addition in the above is performed modulo 2. Therefore the action of the operator T associated to the above circuit on the basis vector |00 . . . 0⟩ is
T|00...0⟩=(U⊗V)(C1 ⊗C2 ⊗···⊗Cn )(B⊗I)|00...0⟩ n+1 n+2 2n
  •
•
    Fig. 56. Schmidt decomposition.
2n =(U⊗V)(C1 ⊗C2 ⊗···⊗Cn)􏰭b |e⟩|e⟩
n+1n+2 2ni1i1 i=1
2n
=(U ⊗V)􏰭bi1 |ei⟩|ei⟩ i=1
2n
= 􏰭bi1(U |ei⟩)(V |ei⟩) = |ψ⟩ .
i=1
Thus we see that the above circuit performs precisely the sum desired from the Schmidt decompo-
sition.
TogettheprecisevaluesofU,V,andB,wewrite|ψ⟩=􏰫2n a |e⟩􏰍e􏰌forsomeconstants
i,j=1 ij i 􏰍j
ai j ∈ C and define A to be the 2n × 2n matrix whose entries are the ai j ’s. Then comparing this to
our previous expression for |ψ ⟩, we see
2n 2n
􏰭aij |ei⟩􏰍􏰍ej􏰌=􏰭bk1(U|ek⟩)(V|ek⟩). i,j=1 k=1
Multiplying on the left by ⟨ei | 􏰋ej 􏰍􏰍 this tells us 2n
aij = 􏰭bk1uikvjk, k=1
wherehereuik = ⟨ei|U|ek⟩andvjk = 􏰋ej􏰍􏰍V|ek⟩arethei,k’thandj,k’thentriesofU andV, respectively. Encoding this in matrix form, this tells us
Vdiag(bi1,...,bin)UT =A. ThentocalculatethevalueofU,V andthebi1’s,weusethefactthatV isunitarytocalculate:
A†A = UT †diag(|bi1|2, . . . , |bin |2)UT .
Thus if we let |λ1 |2, . . . , |λn |2 be the eigenvalues of A†A, and let U to be a unitary matrix satisfying UTA†AUT† =diag(|λ1|2,...,|λN|2),

Quantum Algorithm Implementations for Beginners 81
letbi1 =λi fori=1,...,nandlet
V =AUT†diag(λ1,...,λn)−1.
ThematrixU isunitary,andoneeasilychecksthatV isthereforealsounitary.Moreover􏰫i |bi1|2 = Tr(A†A) = 􏰫i |aij |2 = 1, and so the bi1’s are representative of an n-qubit state and can be taken as the first column of B. Readers familiar with singular value decompositions (SVD) will recognize that the Schmidt decomposition of a bipartite state is essentially the SVD of the coefficient matrix A associated with the state. The λi coefficients being the singular values of A.
19.3 Two-qubit state preparation
An arbitrary two-qubit state |ψ ⟩ is a linear combination of the four base states |00⟩ , |01⟩ , |10⟩ , |11⟩ such that the square sum of the magnitudes of the coefficients is 1. In terms of a quantum circuit, this is the simplest case of the circuit defined above in the Schmidt decomposition, and may be accomplished with three 1-qubit gates and exactly 1 CNOT gate, as featured in Fig. 57.
B•U V
Fig.57. Circuitfortwoqubit-statepreparation.ThechoiceofU,V,andBarecoveredcomprehensivelyinthe Schmidt decomposition description.
19.4 Two-qubit gate preparation
In order to initialize a four-qubit state, we require the initialization of arbitrary two-qubit gates. A two-qubit gate may be represented as an element U of SU (4). As it happens, any element of U (4) may be obtained by means of precisely 3 CNOT gates, combined with 7 1-qubit gates arranged in a circuit of the form given in Fig. 58.
CR1• A D • R2 R3 • B
Fig. 58. Circuit implementation of an arbitrary two qubit gate.
The proof of this is nontrivial and relies on a characterization of the image of SU (2)⊗2 in SU (4) using the Makhlin invariants. We do not aim to reproduce the proof here. Instead, we merely aim to provide a recipe by which one may successfully obtain any element of SU (4) via the above circuit and an appropriate choice of the one-qubit gates.
LetU ∈SU(4)betheelementwewishtoobtain.TochooseA,B,C,DandtheRi’s,letCij denote the CNOT gate with control on qubit i and target qubit j and define α , β , δ by
α=x+y,β=x+z,δ=y+z 222
foreix,eiy,eiz theeigenvaluesoftheoperatorU(Y ⊗Y)UT(Y ⊗Y).Thenset R1 =Rz(δ),R2 =Ry(β),R3 =Ry(α),E=C12(Sz ⊗Sx)

82 Abhijith J., et al.
  B•U V
•
•
C1 R1• A1 D1 • R2 R3 • B1
    C2 S1• A2 D2 • S2 S3 • B2
Fig. 59. Circuit for four qubit-state preparation. The four phases of the circuit are indicated in dashed boxes.
and also
V = eiπ/4(Z ⊗ I)C12(I ⊗ R3)C21(R1 ⊗ R2)C12(I ⊗ Sz†). 􏰛􏰛􏰛􏰛􏰛􏰛
DefineU,V byU =E†UEandV =E†VE.LetA,Bbethereal,unitarymatricesdiagonalizingthe 􏰛􏰛􏰛 􏰛􏰛􏰛􏰛
eigenvectorsofUUT andVVT,respectively.SetX =ATBandY =V†BTAU.ThenEXE† andEYE† areinSU(2)⊗2 andwechooseA,B,C,Dsuchthat
(ASZ† ) ⊗ (Beiπ/4) = EXE† and C ⊗ (SzD) = EYE†.
By virtue of this construction, the above circuit is algebraically identical to U .
19.5 Four qubit state preparation
From the above results that any two-qubit state requires 1 CNOT gate, any two-qubit operator requires three CNOT gates, and the Schmidt decomposition, we see that we should be able to write a circuit initializating any four-qubit state with only 9 CNOT gates in total, along with 17 one-qubit gates. This represents the second most simple case of the Schmidt decomposition, which we write in combinantion with our generic expression for 2-qubit gates as shown in Fig. 59. The above circuit naturally breaks down into four distinct stages, as shown by the separate groups surrounded by dashed lines. During the first stage, we initialize the first two qubits to a specific state relating to a Schmidt decomposition of the full 4 qubit state. Stage two consists of two CNOT gates relating the first and last qubits. Stages three and four are generic circuits representing the unitary operators associated to the orthonormal bases in the Schmidt decomposition.
The results of this circuit implemented on a quantum processor are given in Fig. 60. While the results when implemented on a simulator are given in Fig. 61.
20 QUANTUM TOMOGRAPHY
20.1 Problem definition and background
Quantum state estimation, or tomography, deals with the reconstruction of the state of a quantum system from measurements of several preparations of this state. In the context of quantum comput- ing, imagine that we start with the state |00⟩, and apply some quantum algorithm (represented by a unitary matrix U ) to the initial state, thus obtaining a state |ψ ⟩. We can measure this state in the computational z basis, or apply some rotation (represented by V ) in order to perform measurements in a different basis. Quantum state tomography aims to answer the following question: is it possi- ble to reconstruct the state |ψ ⟩ from a certain number of such measurements? Hence, quantum tomography is not a quantum algorithm per se, but it is an important procedure for certifying the performance of quantum algorithms and assessing the quality of the results that can be corrupted by decoherence, environmental noise, and biases, inevitably present in analogue machines, etc.

Quantum Algorithm Implementations for Beginners 83
 Fig. 60. Verification of 4 qubit state preparation on ibmqx2 which is a 5 qubit machine. The last qubit is not used in the circuit. The above histogram shows that, the state prepared in ibmqx2 has nonzero overlaps with basis states that are orthogonal to the target state to be prepared.
Fig. 61. Verification of the quantum circuit for four qubit-state preparation. The differences in the exact and the simulator results are due to statistical fluctuations arising from the probabilistic nature of quantum measurement. They will become closer to each other when the number of samples are increased.
Moreover similar procedures can be used for certifying the initial state, as well as for measuring the fidelity of gates.
A unique identification of state requires a sufficient number of tomographically complete measure- ments, meaning that the algorithm should be run several times. Unfortunately, because of the noise, it is impossible to obtain the exact same state |ψ ⟩ every time; instead, one should see a mixture of different states: |ψ1⟩, |ψ2⟩, . . ., |ψk ⟩. In general, there does not exist a single |ψ ⟩ describing this mixture. Therefore, we need a to use the density matrix representation of quantum states. We briefly discussed this representation in the context of quantum principal component analysis in Section XIV.
Letusdenotepi theprobabilityofoccurrenceofthestate|ψi⟩.Thedensitymatrixofthisensemble is given by,
ρ = 􏰭pi|ψi⟩⟨ψi|. (104) i
 
84 Abhijith J., et al.
Using this more general definition of the state, the expected value of an observable A is given by ⟨A⟩ = 􏰫 pi Tr⟨ψi |A|ψi ⟩ = Tr(Aρ). The density matrix has the following properties:
i
• Tr ρ = 1, i.e., probabilities sum to one;
• ρ = ρ†, and ρ ≽ 0, i.e., all eigenvalues are either positive or zero.
In a popular setting for quantum tomography [77], the set of measurement operators Pi are taken
as projectors that form several Postive Operator-Valued Measures (POVM), i.e., they satisfy 􏰫i Pi = I .
For single qubits, examples of such projectors in the computational basis are given by P0 = |0⟩⟨0|
and P1 = |1⟩⟨1|, and in the x-basis by P± = √1 (|0⟩ ± |1⟩) ⊗ √1 (⟨0| ± ⟨1|). Assume that the set of 22
projectors that we take represents a quorum, i.e., it provides sufficient information to identify the state of the system in the limit of a large number of observations, and that for each subset forming a POVM, m measurements are collected. Given the occurrences mi for each projector Pi , we can definetheassociatedempiricalfrequencyasωi =mi/m.Thenthequantumtomographyproblem can be stated as follows: reconstruct ρ from the set of couples of projectors and measurement frequencies {Pi , ωi }. In other words, we would like to “match” Tr(Pi ρ) and ωi . The next section presents a short overview of most popular general methods for the quantum state estimation.
20.2 Short survey of existing methods
Most popular methods for quantum tomography in the general case include:
(1) Linear inversion. In this method, we simply aim at inverting the system of equations Tr(Piρ) = ωi. Although being fast, for a finite number of measurements thus obtained estimation ρ􏰚 does not necessarily satisfy ρ􏰚 ≽ 0 (i.e., might contain negative eigenvalues) [56].
(2) Linear regression. This method corrects for the disadvantages of the linear inversion by solving a constrained quadratic optimization problem [83]:
ρ􏰚 = argmin 􏰭[Tr(Pi ρ) − ωi ]2 s.t. Tr ρ = 1 and ρ ≽ 0. ρi
The advantage of this method is that data does not need to be stored, but only the current estimation can be updated in the streaming fashion. However, this objective function implicitly assumes that the residuals are Gaussian-distributed, which does not necessarily hold in practice for a finite number of measurements.
(3) Maximum likelihood. In this by far most popular algorithm for quantum state estimation, one aims at maximizing the log-probability of observations [54, 56]:
ρ􏰚= argmax􏰭ωi lnTr(Piρ) s.t. Trρ = 1 and ρ ≽ 0. ρi
This is a convex problem that outputs a positive semidefinite (PSD) solution ρ􏰚 ≽ 0. However, it is often stated that the maximum likelihood (ML) method is slow, and several recent papers attempted to develop faster methods of gradient descent with projection to the space of PSD matrices, see e.g. [90]. Among other common criticisms of this method one can name the fact that ML might yield rank-deficient solutions, which results in an infinite conditional entropy that is often used as a metric of success of the reconstruction.
(4) Bayesian methods. This is a slightly more general approach compared to the ML method which includes some prior [18], or corrections to the basic ML objective, see e.g., the so-called Hedged ML [17]. However, it is not always clear how to choose these priors in practice. Markov Chain Monte Carlo Methods that are used for general priors are known to be slow.
Let us mention that there exist other state reconstruction methods that attempt to explore a particular known structure of the density matrix, such as compressed-sensing methods [51] in the

Quantum Algorithm Implementations for Beginners 85
         Fig. 62. Left: measurements of the single qubit state after the application of the Hadamard gate, in z, y and x basis. Right: experimental setup for testing the effects of decoherence.
case of low-rank solutions, and matrix product states [33] or neural networks based approaches [104] for pure states with limited entanglement, etc. One of the points we can conclude from this section is that the ultimately best general method for the quantum state tomography is not yet known. However, it seems that maximum likelihood is still the most widely discussed method in the literature; in what follows, we implement and test ML approach to quantum tomography on the IBM quantum computer.
20.3 Implementation of the Maximum Likelihood method on 5-qubit IBM QX
We present an efficient implementation of the ML method using a fast gradient descent with an optimal 2-norm projection [97] to the space of PSD matrices. In what follows, we apply quantum tomography to study the performance of the IBM Q.
20.3.1 Warm-up: Hadamard gate. Let us start with a simple one-qubit case of the Hadamard gate, see Fig. 62, Left. This gate transforms the initial qubit state |0⟩ as follows: H : |0⟩ → |+⟩x = √1 (|0⟩+|1⟩),
2
so that the density matrix should be close to ρ = |+⟩x ⟨+|x . In the limit of a large number of
measurements, we expect to see the following frequencies in the z, y, and x basis (all vector expressions are given in the computational basis):
􏰒1􏰓 1 􏰒0􏰓 1 1􏰒1􏰓 1 1􏰒1􏰓 1 1􏰒1􏰓 1􏰒1􏰓
0 →2, 1 →2, √2 i →2, √2 −i →2, √2 1 →1, √2 −1 →0.
We learn the estimated density matrix ρ􏰚from measurements in each basis using the maximum likelihood method, and look at the decomposition:
ρ􏰚 = λ 1 | ψ 1 ⟩ ⟨ ψ 1 | + λ 2 | ψ 2 ⟩ ⟨ ψ 2 | ,
which would allow us to see what eigenstates contribute to the density matrix, and what is their 􏰜1 1􏰝T
weight. Indeed, in the case of ideal observations we should get λ1 = 1, with |ψ1⟩ = √2 √2 , and 􏰜√1 −√1􏰝T
λ2 = 0 with |ψ2⟩ = 2 2 , corresponding to the original pure state associated with |+⟩x . Instead, we obtain the following results for the eigenvalues and associated eigenvectors after
8152 measurements (the maximum number in one run on IBM QX) in each basis (z,y,x): 􏰒0.715 − 0.012i􏰓 􏰒0.699 − 0.012i􏰓
λ1 =0.968→ 0.699 , λ2 =0.032→ −0.715 ,
i.e., in 96% of cases we observe the state close to |+⟩x , and the rest corresponds to the state which is close to |−⟩x . Note that the quantum simulator indicates that this amount of measurements is sufficient to estimate matrix elements of the density matrix with an error below 10−3 in the ideal noiseless case. In order to check the effect of decoherence, we apply a number of identity matrices (Fig. 62, Right) which forces an additional waiting on the system, and hence promotes decoherence

86 Abhijith J., et al.
     Fig. 63. Left: example of a measurement of the two-qubit maximally entangled state created with the combination of H, X and CNOT gates in the yz basis. Right: experimental setup for testing the effects of decoherence.
of the state. When applying 18 identity matrices, we obtain the following decomposition for ρ􏰚
􏰒0.727 − 0.032i􏰓 λ1 =0.940→ 0.686 ,
while application of 36 identity matrices results in 􏰒0.745 − 0.051i􏰓
|−⟩x , but also in the degradation of the eigenstates.
20.3.2 Maximally entangled state for two qubits. Let us now study the two-qubits maximally
entangled state, which is an important part of all quantum algorithms achieving quantum speed-up
over their classical counterparts. The state √1 (|10⟩ + |01⟩) we are interested in is produced by the 2
combination of H , X and C N OT gates as shown in Fig. 63, Left. We follow the same procedure as in the case of the Hadamard gate, described above, and first estimate the density matrix ρ􏰚using 8152 measurements for each of the zz, yy, xx, zx and yz basis, and then decompose it as ρ􏰚 =
λ1 =0.927→ 0.664 ,
The effect of decoherence is visible in both more frequent occurrence of the state that is close to
4 􏰜0 √1 √1 0􏰝T 􏰫i=1 λi |ψi ⟩⟨ψi |. Once again, ideally we should get λ1 = 1 associated with |ψ1⟩ = 2 2
.
Instead, the analysis of the leading eigenvalues indicates that the eigenstate which is close (although significantly distorted) to the theoretical “ground truth” |ψ1⟩ above occurs in the mixture only with probability 0.87:
 0.598 
λ1 = 0.793 →
−0.002 − 0.058i λ2 = 0.111 →  0.035 + 0.036i  .
−0.025 − 0.024i  0.677 
λ2 =0.060→
􏰒0.685 − 0.030i􏰓 −0.728 ,
λ2 =0.073→
 0.123 + 0.468i  
λ1 =0.871→
Our test of decoherence implemented using 18 identity matrices (see Figure 63, Right) shows that
λ2 =0.059→ −0.075−0.445i. 
 0.735 ,
−0.029 − 0.017i  0.454 − 0.022i 
the probability of the “original” entangled state decreases to 0.79: −0.025 − 0.012i
 0.997 
 0.664  
 0.747  ,
−0.017 − 0.008i  0.006 + 0.007i 

Interestingly enough, the second most probable eigenstate changes to the one that is close to |00⟩. This might serve as an indication of the presence of biases in the machine.
􏰒0.663 − 0.045i􏰓 −0.747 .

Quantum Algorithm Implementations for Beginners 87
The application of the quantum tomography state reconstruction to simple states in the IBM QX revealed an important level of noise and decoherence present in the machine. It would be interesting to check if the states can be protected by using the error correction schemes, which is the subject of the next section.
21 TESTS OF QUANTUM ERROR CORRECTION IN IBM Q
In this section, we study whether quantum error correction (QEC) can improve computation accuracy in ibmqx4. The practical answer to this question seems to be “No”. Although some error correction effects are observed in ibmqx4, improvements are not exponential and get completely spoiled by errors induced by extra gates and qubits needed for the error correction protocols.
21.1 Problem definition and background
As we have seen throughout this review, the quality of computation on actual quantum processors is degraded by errors in the system. This is because currently available chips are not fault tolerant. It is widely believed that once the inherent error rates of a quantum processor is sufficiently lowered, fault tolerant quantum computation will be possible using quantum error correction (QEC). The current error rates of the IBM Q machines are not small enough to allow fault tolerant computation. We refer the reader to a survey and introduction on QEC [37], while at the same time offering an alternative point of view that we support with a few experiments on the IBM chip. The central idea of QEC is to use entanglement to encode quantum superposition in a manner which is robust to errors. The exact encoding depends upon the kind of errors we want to protect against. In this section we will look at a simple encoding that will protect against bit flip errors. Here we encode a single qubit state,
|ψ ⟩ = C0 |0⟩ + C1 |1⟩, (105) |ψ⟩=C0|0⟩⊗nq +C1|1⟩⊗nq, (106)
where nq is the number of qubits representing a single qubit in calculations.
The assumption is that small probability errors will likely lead to unwanted flips of only one qubit(incasewhennq &gt;3thisnumbercanbebiggerbutwewillnotconsidermorecomplex situations here). Such errors produce states that are essentially different from those described by Equation (106). Measurements can then be used to fix a single qubit error using, for instance, a majority voting strategy. More complex errors are assumed to be exponentially suppressed, which
can be justified if qubits experience independent decoherence sources.
We question whether QEC can work to protect quantum computations that require many
quantum gate operations for the following reason. The main source of errors then is not spontaneous qubit decoherence but rather the finite fidelity of quantum gates. When quantum gates are applied to strongly entangled states, such as (106), they lead to highly correlated dynamics of all entangled qubits. We point out that errors introduced by such gates have essentially different nature from random uncorrelated qubit flips. Hence, gate-induced errors may not be treatable by standard error correction strategies when transitions are made between arbitrary unknown quantum state.
To explore this point, imagine that we apply a gate that rotates a qubit by an angle π/2. It √
switches superposition states |ψ±⟩ = (|0⟩ ± |1⟩)/ 2 into, respectively, |0⟩ or |1⟩ in the measurement basis. Let the initial state be |ψ+⟩ but we do not know this before the final measurement. Initially, we know only that initial state can be either |ψ+⟩ or |ψ−⟩. To find what it is, we rotate qubit to the measurement basis. The gate is not perfect, so the final state after the gate application is
using an entangled state, such as
|u⟩ = cos(δφ)|0⟩ + sin(δφ)|1⟩, (107)

88
Abhijith J., et al.
        √
Fig. 64. Quantum circuit that creates the state |+⟩ = (|0⟩ + |1⟩)/
to the identity operation, and then applies the gate that transforms the entangled state into the trivial state |0⟩.
with some error angle δφ ≪ 1. Measurement of this state would produce the wrong answer 1 with probability
P ≈ (δφ)2. (108)
The value 1 − P is called the fidelity of the gate. In IBM chip it is declared to be 0.99 at the time of writing, which is not much. It means that after about 30 gates we should loose control. Error correction strategies can increase the number of allowed gates by an order of magnitude even at such a fidelity if we encode one qubit in three.
In order to reduce this error, we can attempt to work with the 3-qubit version of the states in Eq. (106). For example, let us consider the desired gate that transfers states
√
|±⟩ = (|000⟩ ± |111⟩)/ 2, (109)
into states |000⟩ and |111⟩ in the measurement basis, respectively. This gate is protected in the sense that a single unwanted random qubit flip leads to final states that are easily corrected by majority voting.
However, this is not enough because now we have to apply the gate that makes a rotation by π /2 in the basis (109). The error in this rotation angle leads to the final state
|u⟩ = cos(δφ)|000⟩ + sin(δφ)|111⟩, (110)
i.e., this particular error cannot be treated with majority voting using our scheme because it flips all three qubits. On the other hand, this is precisely the type of errors that is most important when we have to apply many quantum gates because basic gate errors are mismatches between desired and received qubit rotation angles irrespectively of how the qubits are encoded. With nine qubits, we could protect the sign in Eq. 110 but this was beyond our hardware capabilities.
Based on these thoughts, traditional QEC may not succeed in achieving exponential suppression of errors related to non-perfect quantum gate fidelity. The latter is the main source of decoherence in quantum computing that involves many quantum gates. As error correction is often called the only and first application that matters before quantum computing becomes viable at large scale, this problem must be studied seriously and expeditiously. In the following subsection we report on our experimental studies of this problem with IBM’s 5-qubit chip.
21.2 Test 1: errors in single qubit control
First, let us perform trivial operation shown in Fig. 64: we create a superposition of two qubit states
√
|+⟩ = (|0⟩ + |1⟩)/ 2, (111)
2 then applies 16 T-gates that are equivalent

Quantum Algorithm Implementations for Beginners
89
          √
Fig. 65. Quantum circuit that creates state |−⟩ = (|000⟩ − |111⟩)/
to the identity operation, and then applies the gate that transforms the entangled GHZ state back into the trivial state |000⟩. Measurements that return 1 for only one of the three qubits are interpreted as the |000⟩ state at the end, while outcomes with two or three units are interpreted as the final state |111⟩.
then apply many gates that altogether do nothing, i.e., they just bring the qubit back to the superposition state (111). We need those gates just to accumulate some error while the qubit’s state is not trivial in the measurement basis. Finally, we apply the gate that transforms its state back to |0⟩.
Repeated experiments with measurements then produced wrong answer 13 times from 1000 samples. Thus, we estimate the error of the whole protocol, which did not use QEC, as
P1 = 0.013,
or 1.6%. This is consistent and even better than declared 1% single gate fidelity because we applied
totally 18 gates.
21.3 Test 2: errors in entangled 3 qubits control
√ Next, we consider the circuit in Fig. 65 that initially creates the GHZ state |−⟩ = (|000⟩ − |111⟩)/ 2,
then applies the same number, i.e. 16, of T -gates that lead to the same GHZ state. Then we apply the sub-circuit that brings the whole state back to |000⟩.
Our goal is to quantify the precision of identifying the final result with the state |000⟩. If a single error bit flip happens, we can interpret results |100⟩, |010⟩ and |001⟩ as |000⟩ using majority voting. If needed, we can then apply a proper pulse to correct for this. So, in such cases we can consider the error treatable. If the total sum of probabilities of the final state |000⟩ and final states with a single bit flipped is larger than P1 from the previous single-qubit test, then we say that the quantum error correction works, otherwise, it doesn’t. Our experiments showed that probabilities of events that lead to wrong final interpretation are as follows:
P110 = 0.006, P101 = 0.02, P011 = 0.016, P111 = 0.005.
Thus, the probability to get the wrong interpretation of the result as the final state |111⟩ of the
encoded qubit is
while the probability to get any error 1 − P000 = 0.16.
21.4 Discussion
Comparing results of the tests without and with QEC, we find that the implementation of a simple version of QEC does not improve the probability to interpret the final outcome correctly. The error probability of calculations without QEC gives a smaller probability of wrong interpretation,
P3 =P110 +P101 +P011 +P111 =0.047,
2 then applies 16 T-gates that are equivalent

90 Abhijith J., et al.
P1 = 1.3%, while the circuit with QEC gives an error probability P3 = 4.7%, even though we used majority voting that was supposed to suppress errors by about an order of magnitude.
More importantly, errors that lead to more than one qubit flip are not exponentially suppressed. For example, the probability P101 = 0.02 is close to the probability of a single bit flip event P010 = 0.029. We interpret this to mean that errors are not the results of purely random bit flip decoherence effects but rather follow from correlated errors induced by the finite precision of quantum gates. The higher error rate in 3-qubit case could be attributed to the much worse fidelity of the controlled-NOT gate. The circuit itself produces the absolutely correct result |000⟩ in 84% of simulations. If the remaining errors were produced by uncorrelated bit flips, we would see outcomes with more than one wrong bit flip with total probability less than 1% but we found that such events have a much larger total probability P3 = 4.7%.
In defense of QEC, we note that probabilities of single bit flip errors were still several times larger than probabilities of multiple (two or three) wrong qubit flip errors. This means that at least partly QEC works, i.e., it corrects the state to |000⟩ with 4.7% precision, versus the initially 16% in the wrong state. So, at least some part of the errors can be treated. However, an efficient error correction must show exponential suppression of errors, which was not observed in this test.
Summarizing, this brief test shows no improvements that would be required for efficient quantum error correction. The need to use more quantum gates and qubits to correct errors only leads to a larger probability of wrong interpretation of the final state. This problem will likely become increasingly much more important because without quantum error correction the whole idea of conventional quantum computing is not practically useful. Fortunately, IBM’s quantum chips can be used for experimental studies of this problem. We also would like to note that quantum computers can provide computational advantages beyond standard quantum algorithms and using only classical error correction [95]. So, they must be developed even if problems with quantum error correction prove detrimental for conventional quantum computing schemes at achievable hardware quality.
ACKNOWLEDGMENTS
We would like to acknowledge the help from numerous readers who pointed out errors and misprints in the earlier version of the manuscript. The code and implementations accompanying the paper can be found at https://github.com/lanl/quantum_algorithms.
REFERENCES
[1] ibmq-device-information. https://github.com/Qiskit/ibmq-device-information/tree/master/backends/tenerife/V1. Accessed: 14-12-2019.
[2] Scott Aaronson and Lijie Chen. Complexity-theoretic foundations of quantum supremacy experiments. In Ryan O’Donnell, editor, 32nd Computational Complexity Conference, CCC 2017, July 6-9, 2017, Riga, Latvia, volume 79 of LIPIcs, pages 22:1–22:67. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2017.
[3] Héctor Abraham, Ismail Yunus Akhalwaya, Gadi Aleksandrowicz ...., and yotamvakninibm. Qiskit: An open-source framework for quantum computing, 2019.
[4] A. Ambainis, H. Buhrman, P. Høyer, M. Karpinski, and P. Kurur. Quantum matrix verification. 2002.
[5] Andris Ambainis. Quantum walk algorithm for element distinctness. SIAM Journal on Computing, 37(1):210–239,
2007.
[6] Andris Ambainis and R. Spalec. Quantum algorithms for matching and network flows. in Lecture Notes in Computer
Science: STACS 2006, 3884, 2006.
[7] ItaiAradandZephLandau.Quantumcomputationandtheevaluationoftensornetworks.SIAMJournalonComputing,
39(7):3089–3121, 2010.
[8] Frank Arute, Kunal Arya, Ryan Babbush, Dave Bacon, Joseph C Bardin, Rami Barends, Rupak Biswas, Sergio Boixo,
Fernando GSL Brandao, David A Buell, et al. Quantum supremacy using a programmable superconducting processor. Nature, 574(7779):505–510, 2019.

Quantum Algorithm Implementations for Beginners 91
[9] Dave Bacon, Isaac L Chuang, and Aram W Harrow. The quantum schur and clebsch-gordan transforms: I. efficient qudit circuits. pages 1235–1244, 2007.
[10] Dave Bacon and Wim Van Dam. Recent progress in quantum algorithms. Communications of the ACM, 53(2):84–93, 2010.
[11] Stefanie Barz, Ivan Kassal, Martin Ringbauer, Yannick Ole Lipp, Borivoje Dakić, Alán Aspuru-Guzik, and Philip Walther. A two-qubit photonic quantum processor and its application to solving systems of linear equations. Scientific reports, 4, 2014.
[12] Robert Beals. Quantum computation of Fourier transforms over symmetric groups . In Proceedings of STOC, pages 48–53, 1997.
[13] Giuliano Benenti and Giuliano Strini. Quantum simulation of the single-particle Schrödinger equation. American Journal of Physics, 76(7):657–662, 2008.
[14] Charles H Bennett, Ethan Bernstein, Gilles Brassard, and Umesh Vazirani. Strengths and weaknesses of quantum computing. SIAM journal on Computing, 26(5):1510–1523, 1997.
[15] E. Bernstein and U. Vazirani. Quantum complexity theory. In Proc. of the Twenty-Fifth Annual ACM Symposium on Theory of Computing (STOC ’93), pages 11–20, 1993. DOI:10.1145/167088.167097.
[16] Dominic W Berry, Graeme Ahokas, Richard Cleve, and Barry C Sanders. Efficient quantum algorithms for simulating sparse hamiltonians. Communications in Mathematical Physics, 270(2):359–371, 2007.
[17] Robin Blume-Kohout. Hedged maximum likelihood quantum state estimation. Physical review letters, 105(20):200504, 2010.
[18] Robin Blume-Kohout. Optimal, reliable estimation of quantum states. New Journal of Physics, 12(4):043034, 2010.
[19] Otakar Borůvka. O jistém problému minimálním. Práce Mor. Přírodově d. spol. v Brnř (Acta Societ. Scient. Natur.
Moravicae), 3:37–58, 1926.
[20] Michel Boyer, Gilles Brassard, Peter Høyer, and Alain Tapp. Tight bounds on quantum searching. Fortschritte der
Physik: Progress of Physics, 46(4-5):493–505, 1998.
[21] G. Brassard et al. Quantum amplitude amplification and estimation. Quantum Computation and Quantum Information,
9, 2002.
[22] CarlosBravo-Prieto,RyanLaRose,MarcoCerezo,YigitSubasi,LukaszCincio,andPatrickJColes.Variationalquantum
linear solver: A hybrid algorithm for linear systems. arXiv preprint arXiv:1909.05820, 2019.
[23] H.BuhrmanandR.Spalek.Quantumverificationofmatrixproducts.ProceedingsoftheseventeenthannualACM-SIAM
symposium on Discrete algorithm, pages 880–889, 2006.
[24] X.-D. Cai, C. Weedbrook, Z.-E. Su, M.-C. Chen, M. Gu, M.-J. Zhu, L. Li, N.-L. Liu, C.-Y. Lu, and J.-W. Pan. Experimental
Quantum Computing to Solve Systems of Linear Equations. Physical Review Letters, 110(23):230501, June 2013.
[25] Kevin K. H. Cheung and Michele Mosca. Decomposing finite abelian groups. Quantum Info. Comput., 1(3):26–32,
October 2001.
[26] Andrew M Childs and Wim Van Dam. Quantum algorithms for algebraic problems. Reviews of Modern Physics, 82(1):1,
2010.
[27] Lukasz Cincio, Yiğit Subaşı, Andrew T Sornborger, and Patrick J Coles. Learning the quantum algorithm for state
overlap. New Journal of Physics, 20(11):113022, 2018.
[28] Jill Cirasella. Classical and quantum algorithms for finding cycles. MSc Thesis, pages 1–58, 2006.
[29] C. Codsil and H. Zhan. Discrete-time quantum walks and graph structures. pages 1–37, 2011.
[30] Rigetti Computing. Quantum approximate optimization algorithm. Published online at https://github.com/
rigetticomputing/grove, 2017. Accessed: 12/01/2017.
[31] StephenA.Cook.Thecomplexityoftheorem-provingprocedures.InProceedingsoftheThirdAnnualACMSymposium
on Theory of Computing, STOC ’71, pages 151–158, New York, NY, USA, 1971. ACM.
[32] D. Coppersmith and S. Winograd. Matrix multiplication via arithmetic progressions. Journal of symbolic computation,
(9):251–280, 1990.
[33] Marcus Cramer, Martin B Plenio, Steven T Flammia, Rolando Somma, David Gross, Stephen D Bartlett, Olivier
Landon-Cardinal, David Poulin, and Yi-Kai Liu. Efficient quantum state tomography. Nature communications, 1:149,
2010.
[34] Sanjoy Dasgupta, Christos H. Papadimitriou, and Umesh Vazirani. Algorithms. McGraw-Hill, Inc., New York, NY,
USA, 2008.
[35] M. Dehn. Über unendliche diskontinuierliche gruppen. Mathematische Annalen, 71(1):116–144, Mar 1911.
[36] D. Deutsch and R. Jozsa. Rapid solutions of problems by quantum computation. In Proc. of the Royal Society of London
A, pages 439–553, 1992.
[37] Simon J Devitt, William J Munro, and Kae Nemoto. Quantum error correction for beginners. Reports on Progress in
Physics, 76(7):076001, 2013.

92 Abhijith J., et al.
[38] B. L. Douglas and J. B. Wang. Efficient quantum circuit implementation of quantum walks. Physical Review A, 79(5):052335, 2009.
[39] Christoph Dürr, Mark Heiligman, Peter Høyer, and Mehdi Mhalla. Quantum query complexity of some graph problems. SIAM Journal on Computing, 35(6):1310–1328, 2006.
[40] Christoph Durr and Peter Hoyer. A quantum algorithm for finding the minimum. arXiv preprint quant-ph/9607014, 1996.
[41] Jack Edmonds and Richard M. Karp. Theoretical improvements in algorithmic efficiency for network flow problems. Journal of the ACM, 19 (2):248–264, 1972.
[42] Nayak F. Magniez A, J. Roland, and M. Santha. Search via quantum walk. SIAM Journal on Computing, 40(1):142–164, 2011.
[43] Edward Farhi, Jeffrey Goldstone, and Sam Gutmann. A quantum approximate optimization algorithm, 2014.
[44] L. R. Ford and D. R. Fulkerson. Maximal flow through a network. Canadian Journal of Mathematics, 8:399–404, 1956.
[45] R. Freivalds. Fast probabilistic algorithms. In Proc. of 8th Symp. on Math. Foundations of Computer Science, pages
57–69, 1979.
[46] Silvano Garnerone, Annalisa Marzuoli, and Mario Rasetti. Efficient quantum processing of 3-manifold topological
invariants. arXiv preprint quant-ph/0703037, 2007.
[47] Iulia M Georgescu, Sahel Ashhab, and Franco Nori. Quantum simulation. Reviews of Modern Physics, 86(1):153, 2014.
[48] Joseph Geraci. A new connection between quantum circuits, graphs and the ising partition function. Quantum
Information Processing, 7(5):227–242, 2008.
[49] Joseph Geraci and Daniel A Lidar. On the exact evaluation of certain instances of the Potts partition function by
quantum computers. Communications in Mathematical Physics, 279(3):735–768, 2008.
[50] Vittorio Giovannetti, Seth Lloyd, and Lorenzo Maccone. Quantum random access memory. 100:160501, 04, 2008.
[51] David Gross, Yi-Kai Liu, Steven T Flammia, Stephen Becker, and Jens Eisert. Quantum state tomography via
compressed sensing. Physical review letters, 105(15):150401, 2010.
[52] Lov K Grover. A fast quantum mechanical algorithm for database search. In Proceedings of the twenty-eighth annual
ACM symposium on Theory of computing, pages 212–219. ACM, 1996.
[53] Aram W Harrow, Avinatan Hassidim, and Seth Lloyd. Quantum algorithm for linear systems of equations. Physical
review letters, 103(15):150502, 2009.
[54] Zdenek Hradil. Quantum-state estimation. Physical Review A, 55(3):R1561, 1997.
[55] IBM Corporation. IBM Quantum Experience. Published online at https://quantumexperience.ng.bluemix.net, 2016.
Accessed: 12/01/2017.
[56] Daniel F. V. James, Paul G. Kwiat, William J. Munro, and Andrew G. White. Measurement of qubits. Phys. Rev. A,
64:052312, 2001.
[57] Sonika Johri, Damian S Steiger, and Matthias Troyer. Entanglement spectroscopy on a quantum computer. Physical
Review B, 96(19):195136, 2017.
[58] Stephan Jordan. Quantum Algorithm Zoo. Published online at https://math.nist.gov/quantum/zoo/, 2011. Accessed:
3/18/2018.
[59] Stephen P. Jordan. Fast quantum algorithms for approximating some irreducible representations of groups . pages
1–21, 2009.
[60] Petteri Kaski. Eigenvectors and spectra of cayley graphs, 2002.
[61] J. Kempe. Quantum random walks - an introductory overview. Contemporary Physics, 44(4):307–327, 2003.
[62] V. Kendon. Where to quantum walk. pages 1–13, 2011.
[63] Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques. Adaptive Computation
and Machine Learning. MIT Press, 2009.
[64] M W Krentel. The complexity of optimization problems. In Proceedings of the Eighteenth Annual ACM Symposium on
Theory of Computing, STOC ’86, pages 69–76, New York, NY, USA, 1986. ACM.
[65] Thaddeus D Ladd, Fedor Jelezko, Raymond Laflamme, Yasunobu Nakamura, Christopher Monroe, and Jeremy Lloyd
O’Brien. Quantum computers. Nature, 464(7285):45, 2010.
[66] R.LaRose,A.Tikku,É.O’Neel-Judy,L.Cincio,andP.J.Coles.Variationalquantumstatediagonalization.npjQuantum
Information, 5(1):57, 2019.
[67] R. J. Lipton and K. W. Regan. Quantum algorithms via linear algebra. 2014.
[68] Seth Lloyd, Silvano Garnerone, and Paolo Zanardi. Quantum algorithms for topological and geometric analysis of
data. Nature Communications, 2015.
[69] Seth Lloyd, Masoud Mohseni, and Patrick Rebentrost. Quantum algorithms for supervised and unsupervised machine
learning. arXiv preprint arXiv:1307.0411, 2013.
[70] Seth Lloyd, Masoud Mohseni, and Patrick Rebentrost. Quantum principal component analysis. Nature Physics,
10(9):631–633, 2014.

Quantum Algorithm Implementations for Beginners 93
[71] Neil B Lovett, Sally Cooper, Matthew Everitt, Matthew Trevers, and Viv Kendon. Universal quantum computation using the discrete-time quantum walk. Physical Review A, 81(4):042330, 2010.
[72] Frederic Magniez, Miklos Santha, and Mario Szegedy. Quantum algorithms for the triangle problem. SIAM J. Comput., pages 413–424, 2007.
[73] Enrique Martin-Lopez, Anthony Laing, Thomas Lawson, Roberto Alvarez, Xiao-Qi Zhou, and Jeremy L O’brien. Experimental realization of shor’s quantum factoring algorithm using qubit recycling. Nature photonics, 6(11):773–776, 2012.
[74] Jarrod R McClean, Jonathan Romero, Ryan Babbush, and Alán Aspuru-Guzik. The theory of variational hybrid quantum-classical algorithms. New Journal of Physics, 18(2):023023, 2016.
[75] Ashley Montanaro. Quantum algorithms: an overview. npj Quantum Information, 2:15023, 2016.
[76] Michele Mosca. Quantum algorithms. In Computational Complexity, pages 2303–2333. Springer, 2012.
[77] Michael A. Nielsen and Isaac L. Chuang. Quantum Computation and Quantum Information. Cambridge University
Press, Cambridge, United Kingdom, 2016. 10th Anniversary Edition.
[78] Karl Pearson. On lines and planes of closest fit to systems of points in space. Philosophical Magazine Series 6,
2(11):559–572, 1901.
[79] Alberto Peruzzo, Jarrod McClean, Peter Shadbolt, Man-Hong Yung, Xiao-Qi Zhou, Peter J. Love, Alán Aspuru-Guzik,
and Jeremy L. O’Brien. A variational eigenvalue solver on a photonic quantum processor. Nature Communications,
5:ncomms5213, July 2014.
[80] Martin Plesch and Časlav Brukner. Quantum-state preparation with universal gate decompositions. Phys. Rev. A,
83:032302, 2011.
[81] Carl Pomerance. A tale of two sieves. Notices Amer. Math. Soc, 43:1473–1485, 1996.
[82] John Preskill. Quantum computing and the entanglement frontier. Rapporteur talk at the 25th Solvay Conference on
Physics, 19-22 October 2011.
[83] Bo Qi, Zhibo Hou, Li Li, Daoyi Dong, Guoyong Xiang, and Guangcan Guo. Quantum state tomography via linear
regression estimation. Scientific reports, 3, 2013.
[84] Patrick Rebentrost, Masoud Mohseni, and Seth Lloyd. Quantum support vector machine for big data classification.
Physical review letters, 113(13):130503, 2014.
[85] E. Riefful and W. Polak. Quantum computing: A gentle introduction. 2011.
[86] R. L. Rivest, A. Shamir, and L. Adleman. A method for obtaining digital signatures and public-key cryptosystems.
Commun. ACM, 21(2):120–126, February 1978.
[87] Mehdi Saeedi and Igor L Markov. Synthesis and optimization of reversible circuits - a survey. ACM Computing
Surveys (CSUR), 45(2):21, 2013.
[88] Miklos Santha. Quantum walk based search algorithms. In International Conference on Theory and Applications of
Models of Computation, pages 31–46. Springer, 2008.
[89] N. Santhi. Quantum Netlist Compiler (QNC) software repository, November 2017. Applied for LANL LACC
authorization for unlimited open-source release, December 2017.
[90] Jiangwei Shang, Zhengyun Zhang, and Hui Khoon Ng. Superfast maximum-likelihood reconstruction for quantum
tomography. Physical Review A, 95(6):062336, 2017.
[91] Vivek V. Shende and Igor L. Markov. On the CNOT-cost of TOFFOLI gates. Quant. Inf. Comp., 9(5-6):461–486, 2009.
[92] Neil Shenvi, Julia Kempe, and K Birgitta Whaley. Quantum random-walk search algorithm. Physical Review A,
67(5):052307, 2003.
[93] Peter W Shor. Algorithms for quantum computation: Discrete logarithms and factoring. In Foundations of Computer
Science, 1994 Proceedings., 35th Annual Symposium on, pages 124–134. IEEE, 1994.
[94] Peter W. Shor. Polynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer.
SIAM Journal on Computing, 26(5):1484–1509, 1997.
[95] Nikolai A Sinitsyn. Computing with a single qubit faster than the computation quantum speed limit. Physics Letters
A, 382(7):477–481, 2018.
[96] Robert S. Smith, Michael J. Curtis, and William J. Zeng. A practical quantum instruction set architecture, 2016.
[97] John A Smolin, Jay M Gambetta, and Graeme Smith. Efficient method for computing the maximum-likelihood
quantum state from measurements with additive gaussian noise. Physical review letters, 108(7):070502, 2012.
[98] RolandoDSomma.Quantumsimulationsofonedimensionalquantumsystems.QuantumInformation&amp;Computation,
16(13-14):1125–1168, 2016.
[99] Robert Spalek et al. Quantum algorithms, lower bounds, and time-space tradeoffs. ILLC,Amsterdam, 2006.
[100] V. Strassen. Gaussian elimination is not optimal. Numerische Mathematik, (13):354–356, 1969.
[101] Yiğit Subaşı, Rolando D Somma, and Davide Orsucci. Quantum algorithms for systems of linear equations inspired
by adiabatic quantum computing. Physical review letters, 122(6):060504, 2019.

94 Abhijith J., et al.
[102] J.A.K.SuykensandJ.Vandewalle.Leastsquaressupportvectormachineclassifiers.NeuralProcess.Lett.,9(3):293–300, June 1999.
[103] IBM QX Team. IBM Q experience backend information. http://github.com/QISKit/ibmqx-backend-information, 2017. Last accessed: 12 December, 2017.
[104] Giacomo Torlai, Guglielmo Mazzola, Juan Carrasquilla, Matthias Troyer, Roger Melko, and Giuseppe Carleo. Neural- network quantum state tomography. Nature Physics, 14(5):447, 2018.
[105] Jaw-Shen Tsai. Toward a superconducting quantum computer. Proceedings of the Japan Academy, Series B, 86(4):275– 292, 2010.
[106] L.M.K.Vandersypen,M.Steffen,G.Breyta,C.S.Yannoni,M.H.Sherwood,andI.L.Chuang.Experimentalrealization of Shor’s quantum factoring algorithm using nuclear magnetic resonance. Nature, 414:883–887, December 2001.
[107] George F Viamontes, Igor L Markov, and John P Hayes. Graph-based simulation of quantum computation in the density matrix representation. Quantum Information and Computation II, 5436:285–296, 2004.
[108] Guifré Vidal. Efficient classical simulation of slightly entangled quantum computations. Physical review letters, 91(14):147902, 2003.
[109] Chu Ryang Wie. A quantum circuit to construct all maximal cliques using Grover’s search algorithm. pages 1–13, 2017.
[110] N. S. Yonofsky and M. A. Mannucci. Quantum computing for computer scientists. 2008.
[111] Yarui Zheng, Chao Song, Ming-Cheng Chen, Benxiang Xia, Wuxin Liu, Qiujiang Guo, Libo Zhang, Da Xu, Hui Deng, Keqiang Huang, et al. Solving systems of linear equations with a superconducting quantum processor. Physical
Review Letters, 118(21):210504, 2017.
</Text>
        </Document>
        <Document ID="BFDC9C19-07A3-430F-9824-6D12F472098F">
            <Title>deutsch-jozsa</Title>
            <Text> Rapid solution of problems by quantum computation
By David Deutsch1and Richard Jozsa2| 1Wolfson College, Oxford 0X2 6UD, U.K.
2St Edmund Hall, Oxford 0X1 4AR, U.K.
A class of problems is described which can be solved more efficiently by quantum computation than by any classical or stochastic method. The quantum computation solves the problem with certainty in exponentially less time than any classical deterministic computation.
The operation of any computing machine is necessarily a physical process. Nevertheless, the standard mathematical theory which is used to study the possibilities and limitations of computing (e.g. based on Turing machines) disallows quantum mechanical effects, in particular the presence of coherent superpositions during the computational evolution. A suitable notion of a quantum computer, which, like the Turing machine, is idealized as functioning faultlessly and having an unlimited memory capacity, but which is able to exploit quantum effects in a programmable way, has been formulated by one of us (Deutsch 1985). Quantum computers cannot compute any function which is not turing-computable, but they do provide new modes of computation for many classes of problem. In this paper we demonstrate the importance of quantum processes for issues in computational complexity. We describe a problem which can be solved more efficiently by a quantum computer than by any classical computer. The quantum computer solves the problem with certainty in exponentially less time than any classical deterministic computer, and in somewhat less time than the expected time of any classical
stochastic computer.
Let Uf be a device that computes a function/: Z m
after some time, output the value of
task which we shall be considering involves being given
determine some property G[f ](that is, some function G of the sequen
f[m—1)) in the least possible time.
In the analysis of this type of task, it is often an excellent approximation that the
internal workings of Uf are inaccessible, in which case Uf is known as an oracle for /. The approximation would be nearly exact if Uf were a new type of physical object with an unknown law of motion.
If Uf were simply a program for evaluating / on our computer, making the approximation is tantamount to assuming that there is no faster method of obtaining
f Present address: Departement I.R.O., Universite de Montreal, C.P. 6128 Succursale A, Montreal, Canada H3C 3J7.
Proc. R. Soc. Lond. A (1992) 439, 553-558 © 1992 The Royal Society Printed in Great Britain 553
Given an input will,
f(i).In general terms the c
and then using it to

 554 D. Deutsch and R. Jozsa
G[f] from the program U(fe.g. by a textual analysis) than act obtain sufficiently many values f(i) to determine G[f]. It seems obvious that this is true for all properties G- obvious, but like P ^ NP, hard to p
IfUfwerearom (read-onlymemory)containingasequenceofmintegersfromZn, the approximation is that there is no faster way of obtaining ] from Uf than reading from the r o m sufficiently many values to determine This is clearly not true in general - there could be physical ways of measuring G[f\ directly, like measuring the total spin if the values of values f(i) were stored as individual spin values - but it is a good description in many realistic situations.
It is useful to classify computational tasks into evaluations of functions and solutions of problems.In the case of functions, the task is to obtain the unique output that is the specified function of the input. For example, Uf, as we have defined it, evaluates the function/. In the case of solving problems the task is to obtain any one output that has a specified property. For example, to find a factor of a given composite number is a problem. Finding the least prime factor is a function evaluation.
When a classical deterministic (Turing) computer solves a problem, it always does so by evaluating a function. For example, a factorization program will always find the same factor of a given input. Which factor it finds could be specified by an additional constraint, narrowing the task to a function evaluation. Therefore when solving problems a classical computer cannot help performing a harder com­ putational task than the one it was set.
A stochastic computer (i.e. one containing a hardware random number generator) need not always evaluate functions because the course of its computation, and therefore its output, need not be uniquely determined by the input. However, this gives a stochastic computer little advantage over a Turing one in solving problems, for if every possible output of a stochastic computation has the specified property that solves the problem, what is the purpose of choosing numbers randomly in the course of the computation? One reason might be that there is a deterministic algorithm for solving the problem, which takes a parameter, and the running time depends on that parameter. If most values of the parameter give a short running time, but there are exceptional ones, which cannot easily be predicted, which give a long running time, it might be desirable to choose the parameter randomly if one wanted to reduce the expectation value of the running time.
A quantum computer (Deutsch 1985) is one in which quantum-mechanical interference can be harnessed to perform computations. Such a computation also need not necessarily evaluate functions when it is solving problems, because the state of its output might be a coherent superposition of states corresponding to different answers, each of which solves the problem. This allows quantum computers to solve problems by methods which are not available to any classical device.
Let us assume that, however Uwf orks, its oper mechanical process. Of course all physical processes conform to this assumption at some sufficiently complete level of description, possibly including their environment. But we mean that Uf can conveniently be made part of the coherent computation of
a quantum computer.
Let mn be a Hilbert space of dimension mn and let
{\i,j}}{ieZm, j e Z n()1)
be a fixed orthonormal basis in mn. Suppose that Uf operates by accepting input Proc. R. Soc. Loud. A (1992)

 Rapid solution byquantum comp
in any state | k,0) of the basis, representing the value and converting it to out in the state | k,f(k)},from which the value f(k) can be read off with probability 1. More generally, we may suppose that Uf effects the unitary evolution
( 2) where the addition in the expression j +f(i) is performed modulo n. Then, by the
linearity of quantum evolution,
m_*(|0,0&gt;+ ...+ |ra—1,0))
to the output state
m~5(|0,/(0)&gt;+ ... + |ra-l,/(ra-l)».
Thus, by running Uf only once, we have in some sense computed all m values off, in superposition. Elementary quantum measurement theory shows that no quantum measurement applied to the system in the state (4) can be used to obtain more than
one of the m values/(0), ...,/(m—1). However, it is possible to extract some joint properties G[f(0), ...,f(m—1)] of the m values, by measuring certain observab which are not diagonal in the basis (1). This is called the method of computation by quantum parallelism and is possible only with computers whose computations are coherent quantum processes. For examples see Deutsch (1985) and Jozsa (1991).
To date, all known computational tasks which can be performed more efficiently by quantum parallelism than by any classical method have the following two properties. Firstly, the answer is not obtained with certainty in a given time; that is, there is a certain probability that the program will report that it has failed, destroying the information about /, so that in general it has to be run repeatedly before the answer is obtained. Secondly, although on some occasions it runs faster than any classical algorithm, the quantum algorithm is on average no more efficient than a classical one. It can be shown (Deutsch 1985) that the second property must hold for at least one choice of input in the quantum computation of any function.
It is the purpose of this communication to describe a problem for which quantum parallelism gives a solution with certainty in a given time, and is absolutely more efficient than any classical or stochastic method.
The problem is as follows: Given a natural number N and an oracle for a function/: Z 2N^ Z 2,find a true statement in the list:
(A) / is not a constant function (at 0 or 1);
(B) the sequence/(0),...,/( 2N—1) of values of/ does not co Note that for any/, at least one of (A) or (B) is always true. It may be that both
are true, in which case either (A) or (B) is an acceptable solution. That is why the solution of this problem is not necessarily tantamount to the computation of a function. A stochastic or quantum algorithm for solving it may have the property that when (A) and (B) are both true, it returns either answer, randomly. But when only one of them is true, the algorithm must return that one with certainty.
Consider first the classical solution. We repeatedly run Uf to calculate values of/ in some order, say/(77(0)),/(77(l)),/(77(2)),..., where 77 is a permutation on Z 2N. We continue until we have enough information to prove that (A) or (B) is true. This is always achieved in at most A + l invocations of though many functions / will require fewer invocations. Representing a function / b y the 2A-sequence /(77(0)),..., f(77(22V—1)) of zeros and ones, we have the results of table 1.
Proc. R. Soc. Loud. A (1992)
Ufwill evolve the input s (3)
(4)

 556 D. Deutsch and R. Jozsa
Hence, given a large number of random/s, the average number of invocations of
required to solve the problem for each / is
N+l + S O ’ ^N-V (5)
2 iV~ 1 71= 2
i.e. approximately three invocations for large N. If we are exceptionally unlucky, or if the /s are not presented randomly, but perversely by someone who knows what algorithm we are going to use, we shall require N+l invocations. With a classical stochastic computer we can choose the permutation 77 randomly, a process which requires 0(ln(iV)) steps on average, and can thereby expect to solve the problem in approximately three invocations, though again in unlucky cases this may rise to
N + l invocations, plus an overhead of 0(Nln(N)) steps.
Now we present a method of solution using quantum parallelism. Let S be the
unitary operation defined by
This operation can be performed by a quantum computer (cf. Deutsch 1985) in a
fixed number of steps, independent of N and /. The state 1 2N-1
I0&gt; S M&gt; (?) VW) i=0
can be prepared, starting with the ‘blank’ input |0,0&gt;, in 0(ln(iV)) steps, independently of /. For example, if 2N is a power of two, this could be done by applying the elementary one-bit transformation
k &gt; ^ 7 2 ( b &gt; + ( - l ) * | l - a » ( ^ e Z 2) ( 8 )
successively to each of the log2(2iV) bits that hold the value in (7).
Given a quantum oracle Uf,apply the three operations S, memory locations prepared in the state |0&gt;. Then from (1), (6) and (7) the evolution
is
2N-1
*^“V(2A0 2 I*,/(»)&gt; 7= 0
5 -j^ 2 i V —1 "VW) (-1
Uf i 2N-1
The magnitude of the inner product
2N —1
m t &gt; \ 2N S (_!)/«
0
l
^ v m E {- iymii’0}=^(9)
(10)
uf 1
is zero when statement (B) is false, and unity when statement (A) is false. Therefore if, after performing the operations in (9), we measure the projection observable 10) &lt;01, and the outcome is 0, we can be sure that | was not parallel to |0&gt;, and hence that (A) is true. And if the outcome is 1, we can be sure that |^)&gt; was not
Proc. R. Soc. Loud. A (1992)
s\i,j) = (-iy\i,j).(6)

 number, n, of invocations of
Table 1
form of sequence decided no sequences decided
t0 ) (A)true
0 0 1 ...1 / A , x
i i o .../ true
1 1 ... 1 o) &lt;A) true
0 0 ... 0 0 (B) true 0 0 ... 0 1 (A) true 1 1 ... 10 (A) true
1 1 ... 1 1 (B) true
number of decided sequences, k
0 £2JV-2
_|_ £2iV-2 22V—3
4- 2 2N~3 22N - N
_j_ 22V-V
2n~i
+ 2v-i + 2v-x
+ 2v-i total:
probability of solving problem in
n invocations, 2 0
1 2
1
4
1 2n~1
1 2^
total: 1
uf
N N+l
1 2
3
Rapid solution by quantum computation
557
orthogonal to 10), and hence that (B) is true. The outcome must be either 0 or 1, because those are the only eigenvalues of any projection observable. Therefore the procedure cannot fail to establish the truth of either (A) or (B).
The measurement of 10) 1can be performed in 0(ln steps, by first performing the inverse of the transformation which prepared |&lt;^&gt; from a blank input |0,0), and then measuring the observable |0,0&gt;&lt;(0,0|, which is simply a matter of measuring each bit independently. The oracle Uf is invoked exactly twice in (9), and no other invocations are required. This is a clear improvement over the average of 3—2-JV+1 invocations required by the best classical or stochastic method, and a vast improvement over the worse case (A+l invocations) for either of those methods. Note that the problem is solved on each occasion with certainty.
It is interesting to compare the computational complexity of this problem relative with classical and quantum computers. In the classical case, polynomial equivalence class complexity theory (Garey &amp; Johnson 1979) is based on deterministic (d t m ) and non-deterministic (n d t m ) Turing machine models. We first note the result (referred to as (*)) that for any classical solution of our problem, using a d t m , there exists a function f : Z 2N^ Z 2which requires at least N + l invocations of the oracle. To see this, suppose that a d t m can solve the problem for every such / using only ^ invocations. Let / c be a constant function so that statement (A) is false and the machine must conclude that statement (B) is true. Then for any invocations, for inputs chosen in any way whatsoever, there exists a function g which agrees with f c at all Mhocices, and has exactly A zero values. Since, by assumption, the iff values
constitute the only information that the dtm has about the function, it cannot distinguish Ufc from Ug, i.e. it cannot conclude that statement (B) is true. The same argument applies to n d t m s , showing that the decision problem of whether B is true
or not, is not in the class NPth(ough the corresponding problem for A not in P).
To assess the complexity of the problem consider first an idealized situation in which the oracle is deemed to deliver its result in one computational step, and not to contribute to the size of the problem’s input data. Then the problem is specified
Proc. R. Soc. Loud. A (1992)

 558 D.Deutsch and Jozsa
by giving N,which has size
solution. The quantum solution, requiring only two invocations, and a time of O(lniV)) to set up the input state, solves the problem in polynomial time. Thus the problem is in QP, the quantum analogue of the class P.
If we wish, more realistically, to model the oracle’s size and running time, then we could assume the oracle size, for general/, to be 0(N), this being the size of the oracle which simply contains a ROM list of the function values. Also for any / there exists an oracle which operates in a time of0(\nN)e.g. to look up it could traverse a binary tree following the binary expansion of k. From these estimates, and (*), it follows that any classical computer requires at least polynomial time, whereas the quantum computer requires only logarithmic time, again providing an exponential saving.
If we restrict the input /s to a class of functions whose oracles have size less than p(\nN), where psia fixed polynomial unknown to the solver of the proble restricted problem requires exponential time in the classical case and only polynomial time in the quantum case. That is because for any given N this condition does not, from the solver’s point of view, exclude any function/: Z 2N-+Z2, so by the same argument that we used for the general problem, there cannot be a less-than- exponential classical solution even for the restricted problem.
References Deutsch, D. 1985 Proc. R. Soc. Lond. A 400, 97-117.
Deutsch, D. 1986 In Quantum concepts in space and time (ed. C. J. Isham &amp; R. Penrose). Oxford University Press.
Garey, M. R. &amp; Johnson, D. S. 1979 Computers and intractability. New York: W. H. Freeman. Jozsa, R. 1991 Proc. R. Soc. Lond. A 435, 563-574.
Received 27 April ;192accepted 15
Proc. R. Soc. Lond. A (1992)
0(\nN).Hence by (*), expone
</Text>
        </Document>
        <Document ID="45308655-101C-41E7-BC9F-FC8760BF5B14">
            <Title>Grover's Algorithm</Title>
            <Text>












Processing math: 100%
  
Learn Quantum Computation using Qiskit
What is Quantum?
0. Prerequisites
0.1 Setting Up Your Environment
0.2 Python and Jupyter Notebooks
1. Quantum States and Qubits
1.1 Introduction
1.2 The Atoms of Computation
1.3 Representing Qubit States
1.4 Single Qubit Gates
1.5 The Case for Quantum
2. Multiple Qubits and Entanglement
2.1 Introduction
2.2 Multiple Qubits and Entangled States
2.3 Phase Kickback
2.4 More Circuit Identities
2.5 Proving Universality
2.6 Classical Computation on a Quantum Computer
3. Quantum Protocols and Quantum Algorithms
3.1 Defining Quantum Circuits
3.2 Quantum Teleportation
3.3 Superdense Coding
3.4 Deutsch-Jozsa Algorithm
3.5 Bernstein-Vazirani Algorithm
3.6 Simon's Algorithm
3.7 Quantum Fourier Transform
3.8 Quantum Phase Estimation
3.9 Shor's Algorithm
3.10 Grover's Algorithm
3.11 Quantum Counting
3.12 Quantum Key Distribution
4. Quantum Algorithms for Applications
4.1 Applied Quantum Algorithms
4.1.1 Solving Linear Systems of Equations using HHL
4.1.2 Simulating Molecules using VQE
4.1.3 Solving combinatorial optimization problems using QAOA
4.1.4 Solving Satisfiability Problems using Grover's Algorithm
4.1.5 Hybrid quantum-classical Neural Networks with PyTorch and Qiskit
4.2 Implementations of Recent Quantum Algorithms
4.2.1 Variational Quantum Linear Solver
5. Investigating Quantum Hardware Using Quantum Circuits
5.1 Introduction to Quantum Error Correction using Repetition Codes
5.2 Measurement Error Mitigation
5.3 Randomized Benchmarking
5.4 Measuring Quantum Volume
6. Investigating Quantum Hardware Using Microwave Pulses
6.1 Calibrating Qubits with Qiskit Pulse
6.2 Accessing Higher Energy States
6.3 Introduction to Transmon Physics
6.4 Circuit Quantum Electrodynamics
7. Problem Sets &amp; Exercises
Set 1. Classical Logic Gates with Quantum Circuits
Set 2. Basic Synthesis of Single-Qubit Gates
Set 3. Building the Best AND Gate
8. Appendix
8.1 Linear Algebra
8.2 Qiskit
9. Games &amp; Demos
Hello Qiskit Game
Estimating Pi Using Quantum Phase Estimation Algorithm
Interactivity Index
Powered by Jupyter Book


Grover's Algorithm
In this section, we introduce Grover's algorithm and how it can be used to solve unstructured search problems. We then implement the quantum algorithm using Qiskit, and run on a simulator and device.

Contents

Introduction
Example: 2 Qubits
2.1 Simulation
2.2 Device
Example: 3 Qubits
3.1 Simulation
3.2 Device
Problems
Solving Sudoku using Grover's Algorithm
References
1. Introduction

You have likely heard that one of the many advantages a quantum computer has over a classical computer is its superior speed searching databases. Grover's algorithm demonstrates this capability. This algorithm can speed up an unstructured search problem quadratically, but its uses extend beyond that; it can serve as a general trick or subroutine to obtain quadratic run time improvements for a variety of other algorithms. This is called the amplitude amplification trick.

Unstructured Search 

Suppose you are given a large list of N items. Among these items there is one item with a unique property that we wish to locate; we will call this one the winner w. Think of each item in the list as a box of a particular color. Say all items in the list are gray except the winner w, which is purple.



To find the purple box -- the marked item -- using classical computation, one would have to check on average N/2 of these boxes, and in the worst case, all N of them. On a quantum computer, however, we can find the marked item in roughly 
√
N
steps with Grover's amplitude amplification trick. A quadratic speedup is indeed a substantial time-saver for finding marked items in long lists. Additionally, the algorithm does not use the list's internal structure, which makes it generic; this is why it immediately provides a quadratic quantum speed-up for many classical problems.

Creating an Oracle 

For the examples in this textbook, our 'database' is comprised of all the possible computational basis states our qubits can be in. For example, if we have 3 qubits, our list is the states |000⟩,|001⟩,…|111⟩ (i.e the states |0⟩→|7⟩).

Grover’s algorithm solves oracles that add a negative phase to the solution states. I.e. for any state |x⟩ in the computational basis:

Uω|x⟩={ |x⟩ifx≠ω	−|x⟩ifx=ω 
This oracle will be a diagonal matrix, where the entry that correspond to the marked item will have a negative phase. For example, if we have three qubits and ω=101, our oracle will have the matrix:

Uω=[ 1	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	−1	0	0	0	0	0	0	0	0	1	0	0	0	0	0	0	0	0	1 ] 						←ω=101			 
What makes Grover’s algorithm so powerful is how easy it is to convert a problem to an oracle of this form. There are many computational problems in which it’s difficult to find a solution, but relatively easy to verify a solution. For example, we can easily verify a solution to a sudoku by checking all the rules are satisfied. For these problems, we can create a function f that takes a proposed solution x, and returns f(x)=0 if x is not a solution (x≠ω) and f(x)=1 for a valid solution (x=ω). Our oracle can then be described as:

Uω|x⟩=(−1)f(x)|x⟩
and the oracle's matrix will be a diagonal matrix of the form:

Uω=[ (−1)f(0)	0	⋯	0	0	(−1)f(1)	⋯	0	⋮	0	⋱	⋮	0	0	⋯	(−1)f(2n) ]
Circuit Construction of a Grover Oracle (click to expand)
For the next part of this chapter, we aim to teach the core concepts of the algorithm. We will create example oracles where we know ω beforehand, and not worry ourselves with whether these oracles are useful or not. At the end of the chapter, we will cover a short example where we create an oracle to solve a problem (sudoku).

Amplitude Amplification

So how does the algorithm work? Before looking at the list of items, we have no idea where the marked item is. Therefore, any guess of its location is as good as any other, which can be expressed in terms of a uniform superposition: |s⟩=
1
√
N
 
∑
N−1
x=0
|x⟩.

If at this point we were to measure in the standard basis {|x⟩}, this superposition would collapse, according to the fifth quantum law, to any one of the basis states with the same probability of 
1
N
 
=
1
2n
 
. Our chances of guessing the right value w is therefore 1 in 2n, as could be expected. Hence, on average we would need to try about N=2n times to guess the correct item.

Enter the procedure called amplitude amplification, which is how a quantum computer significantly enhances this probability. This procedure stretches out (amplifies) the amplitude of the marked item, which shrinks the other items' amplitude, so that measuring the final state will return the right item with near-certainty.

This algorithm has a nice geometrical interpretation in terms of two reflections, which generate a rotation in a two-dimensional plane. The only two special states we need to consider are the winner |w⟩ and the uniform superposition |s⟩. These two vectors span a two-dimensional plane in the vector space CN. They are not quite perpendicular because |w⟩ occurs in the superposition with amplitude N−1/2 as well. We can, however, introduce an additional state |s′⟩ that is in the span of these two vectors, which is perpendicular to |w⟩ and is obtained from |s⟩ by removing |w⟩ and rescaling.

Step 1: The amplitude amplification procedure starts out in the uniform superposition |s⟩, which is easily constructed from |s⟩=H⊗n|0⟩n.



The left graphic corresponds to the two-dimensional plane spanned by perpendicular vectors |w⟩ and |s′⟩ which allows to express the initial state as |s⟩=sinθ|w⟩+cosθ|s′⟩, where θ=arcsin⟨s|w⟩=arcsin
1
√
N
 
. The right graphic is a bar graph of the amplitudes of the state |s⟩ for the case N=22=4. The average amplitude is indicated by a dashed line.

Step 2: We apply the oracle reflection Uf to the state |s⟩.



Geometrically this corresponds to a reflection of the state |s⟩ about |s′⟩. This transformation means that the amplitude in front of the |w⟩ state becomes negative, which in turn means that the average amplitude has been lowered.

Step 3: We now apply an additional reflection (Us) about the state |s⟩: Us=2|s⟩⟨s|−1. This transformation maps the state to UsUf|s⟩ and completes the transformation.



Two reflections always correspond to a rotation. The transformation UsUf rotates the initial state |s⟩ closer towards the winner |w⟩. The action of the reflection Us in the amplitude bar diagram can be understood as a reflection about the average amplitude. Since the average amplitude has been lowered by the first reflection, this transformation boosts the negative amplitude of |w⟩ to roughly three times its original value, while it decreases the other amplitudes. We then go to step 2 to repeat the application. This procedure will be repeated several times to zero in on the winner.

After t steps we will be in the state |ψt⟩ where: |ψt⟩=(UsUf)t|s⟩.

How many times do we need to apply the rotation? It turns out that roughly 
√
N
 rotations suffice. This becomes clear when looking at the amplitudes of the state |ψ⟩. We can see that the amplitude of |w⟩ grows linearly with the number of applications ∼tN−1/2. However, since we are dealing with amplitudes and not probabilities, the vector space's dimension enters as a square root. Therefore it is the amplitude, and not just the probability, that is being amplified in this procedure.

In the case that there are multiple solutions, M, it can be shown that roughly 
√
(N/M)
rotations will suffice.



2. Example: 2 Qubits

Let's first have a look at the case of Grover's algorithm for N=4 which is realized with 2 qubits. In this particular case, only one rotation is required to rotate the initial state |s⟩ to the winner |w⟩[3]:

Following the above introduction, in the case N=4 we have
θ=arcsin
1
2
 
=
π
6
 
.
After t steps, we have
(UsUω)t|s⟩=sinθt|ω⟩+cosθt|s′⟩,
where
θt=(2t+1)θ.
In order to obtain |ω⟩ we need θt=
π
2
 
, which with θ=
π
6
 
inserted above results to t=1. This implies that after t=1 rotation the searched element is found.
We will now follow through an example using a specific oracle.

Oracle for |ω⟩=|11⟩ 

Let's look at the case |w⟩=|11⟩. The oracle Uω in this case acts as follows:

Uω|s⟩=Uω
1
2
 
(|00⟩+|01⟩+|10⟩+|11⟩)=
1
2
 
(|00⟩+|01⟩+|10⟩−|11⟩).
or:

Uω=[ 1	0	0	0	0	1	0	0	0	0	1	0	0	0	0	−1 ]
which you may recognise as the controlled-Z gate. Thus, for this example, our oracle is simply the controlled-Z gate:



Reflection Us

In order to complete the circuit we need to implement the additional reflection Us=2|s⟩⟨s|−1. Since this is a reflection about |s⟩, we want to add a negative phase to every state orthogonal to |s⟩.

One way we can do this is to use the operation that transforms the state |s⟩→|0⟩, which we already know is the Hadamard gate applied to each qubit:

H⊗n|s⟩=|0⟩
Then we apply a circuit that adds a negative phase only to the state |0⟩:

U0
1
2
 
(|00⟩+|01⟩+|10⟩+|11⟩)=
1
2
 
(|00⟩−|01⟩−|10⟩−|11⟩)
i.e. the signs of each state are flipped except for |00⟩. As can easily be verified, one way of implementing U0 is the following circuit:



Finally, we do the operation that transforms the state |0⟩→|s⟩ (the H-gate again):

H⊗nU0H⊗n=Us
The complete circuit for Us looks like this:



Full Circuit for |w⟩=|11⟩

Since in the particular case of N=4 only one rotation is required we can combine the above components to build the full circuit for Grover's algorithm for the case |w⟩=|11⟩:



2.1 Qiskit Implementation

We now implement Grover's algorithm for the above case of 2 qubits for |w⟩=|11⟩.

#initialization
import matplotlib.pyplot as plt
import numpy as np

# importing Qiskit
from qiskit import IBMQ, Aer, QuantumCircuit, ClassicalRegister, QuantumRegister, execute
from qiskit.providers.ibmq import least_busy
from qiskit.quantum_info import Statevector

# import basic plot tools
from qiskit.visualization import plot_histogram
 try
We start by preparing a quantum circuit with two qubits:

n = 2
grover_circuit = QuantumCircuit(n)
 try
Then we simply need to write out the commands for the circuit depicted above. First, we need to initialize the state |s⟩. Let's create a general function (for any number of qubits) so we can use it again later:

def initialize_s(qc, qubits):
    """Apply a H-gate to 'qubits' in qc"""
    for q in qubits:
        qc.h(q)
    return qc
 try
grover_circuit = initialize_s(grover_circuit, [0,1])
grover_circuit.draw()
 try
Apply the Oracle for |w⟩=|11⟩. This oracle is specific to 2 qubits:

grover_circuit.cz(0,1) # Oracle
grover_circuit.draw()
 try
We now want to apply the diffuser (Us). As with the circuit that initialises |s⟩, we'll create a general diffuser (for any number of qubits) so we can use it later in other problems.

# Diffusion operator (U_s)
grover_circuit.h([0,1])
grover_circuit.z([0,1])
grover_circuit.cz(0,1)
grover_circuit.h([0,1])
grover_circuit.draw()
 try
This is our finished circuit.

2.1.1 Experiment with Simulators

Let's run the circuit in simulation. First, we can verify that we have the correct statevector:

sv_sim = Aer.get_backend('statevector_simulator')
job_sim = execute(grover_circuit, sv_sim)
statevec = job_sim.result().get_statevector()
from qiskit_textbook.tools import vector2latex
vector2latex(statevec, pretext="|\\psi\\rangle =")
 try
|ψ⟩=[ 0	0	0	1 ]
As expected, the amplitude of every state that is not |11⟩ is 0, this means we have a 100% chance of measuring |11⟩:

grover_circuit.measure_all()

qasm_simulator = Aer.get_backend('qasm_simulator')
shots = 1024
results = execute(grover_circuit, backend=qasm_simulator, shots=shots).result()
answer = results.get_counts()
plot_histogram(answer)
 try
2.1.2 Experiment with Real Devices 

We can run the circuit a real device as below.

# Load IBM Q account and get the least busy backend device
provider = IBMQ.load_account()
device = least_busy(provider.backends(filters=lambda x: x.configuration().n_qubits &gt;= 3 and 
                                   not x.configuration().simulator and x.status().operational==True))
print("Running on current least busy device: ", device)
 try
/usr/local/anaconda3/lib/python3.7/site-packages/qiskit/providers/ibmq/ibmqfactory.py:192: UserWarning: Timestamps in IBMQ backend properties, jobs, and job results are all now in local time instead of UTC.
  warnings.warn('Timestamps in IBMQ backend properties, jobs, and job results '
Running on current least busy device:  ibmq_burlington
# Run our circuit on the least busy backend. Monitor the execution of the job in the queue
from qiskit.tools.monitor import job_monitor
job = execute(grover_circuit, backend=device, shots=1024, optimization_level=3)
job_monitor(job, interval = 2)
 try
Job Status: job has successfully run
# Get the results from the computation
results = job.result()
answer = results.get_counts(grover_circuit)
plot_histogram(answer)
 try
We confirm that in the majority of the cases the state |11⟩ is measured. The other results are due to errors in the quantum computation.

3. Example: 3 Qubits

We now go through the example of Grover's algorithm for 3 qubits with two marked states |101⟩ and |110⟩, following the implementation found in Reference [2]. The quantum circuit to solve the problem using a phase oracle is:



Apply Hadamard gates to 3 qubits initialised to |000⟩ to create a uniform superposition:
|ψ1⟩=
1
√
8
 
(|000⟩+|001⟩+|010⟩+|011⟩+|100⟩+|101⟩+|110⟩+|111⟩)
Mark states |101⟩ and |110⟩ using a phase oracle:
|ψ2⟩=
1
√
8
 
(|000⟩+|001⟩+|010⟩+|011⟩+|100⟩−|101⟩−|110⟩+|111⟩)
Perform the reflection around the average amplitude:
Apply Hadamard gates to the qubits
|ψ3a⟩=
1
2
 
(|000⟩+|011⟩+|100⟩−|111⟩)
Apply X gates to the qubits
|ψ3b⟩=
1
2
 
(−|000⟩+|011⟩+|100⟩+|111⟩)
Apply a doubly controlled Z gate between the 1, 2 (controls) and 3 (target) qubits
|ψ3c⟩=
1
2
 
(−|000⟩+|011⟩+|100⟩−|111⟩)
Apply X gates to the qubits
|ψ3d⟩=
1
2
 
(−|000⟩+|011⟩+|100⟩−|111⟩)
Apply Hadamard gates to the qubits
|ψ3e⟩=
1
√
2
 
(−|101⟩−|110⟩)
Measure the 3 qubits to retrieve states |101⟩ and |110⟩
Note that since there are 2 solutions and 8 possibilities, we will only need to run one iteration (steps 2 &amp; 3).

3.1 Qiskit Implementation

We now implement Grover's algorithm for the above example for 3-qubits and searching for two marked states |101⟩ and |110⟩. Note: Remember that Qiskit orders it's qubits the opposite way round to this resource, so the circuit drawn will appear flipped about the horizontal.

We create a phase oracle that will mark states |101⟩ and |110⟩ as the results (step 1).

qc = QuantumCircuit(3)
qc.cz(0, 2)
qc.cz(1, 2)
oracle_ex3 = qc.to_gate()
oracle_ex3.name = "U$_\omega$"
 try
In the last section, we used a diffuser specific to 2 qubits, in the cell below we will create a general diffuser for any number of qubits.

Details: Creating a General Diffuser (click to expand)
def diffuser(nqubits):
    qc = QuantumCircuit(nqubits)
    # Apply transformation |s&gt; -&gt; |00..0&gt; (H-gates)
    for qubit in range(nqubits):
        qc.h(qubit)
    # Apply transformation |00..0&gt; -&gt; |11..1&gt; (X-gates)
    for qubit in range(nqubits):
        qc.x(qubit)
    # Do multi-controlled-Z gate
    qc.h(nqubits-1)
    qc.mct(list(range(nqubits-1)), nqubits-1)  # multi-controlled-toffoli
    qc.h(nqubits-1)
    # Apply transformation |11..1&gt; -&gt; |00..0&gt;
    for qubit in range(nqubits):
        qc.x(qubit)
    # Apply transformation |00..0&gt; -&gt; |s&gt;
    for qubit in range(nqubits):
        qc.h(qubit)
    # We will return the diffuser as a gate
    U_s = qc.to_gate()
    U_s.name = "$U_s$"
    return U_s
 try
We'll now put the pieces together, with the creation of a uniform superposition at the start of the circuit and a measurement at the end. Note that since there are 2 solutions and 8 possibilities, we will only need to run one iteration.

n = 3
grover_circuit = QuantumCircuit(n)
grover_circuit = initialize_s(grover_circuit, [0,1,2])
grover_circuit.append(oracle_ex3, [0,1,2])
grover_circuit.append(diffuser(n), [0,1,2])
grover_circuit.measure_all()
grover_circuit.draw()
 try
3.1.1 Experiment with Simulators

We can run the above circuit on the simulator.

backend = Aer.get_backend('qasm_simulator')
results = execute(grover_circuit, backend=backend, shots=1024).result()
answer = results.get_counts()
plot_histogram(answer)
 try
As we can see, the algorithm discovers our marked states |101⟩ and |110⟩.

3.1.2 Experiment with Real Devices 

We can run the circuit on the real device as below.

backend = least_busy(provider.backends(filters=lambda x: x.configuration().n_qubits &gt;= 3 and 
                                   not x.configuration().simulator and x.status().operational==True))
print("least busy backend: ", backend)
 try
least busy backend:  ibmq_valencia
# Run our circuit on the least busy backend. Monitor the execution of the job in the queue
from qiskit.tools.monitor import job_monitor
job = execute(grover_circuit, backend=backend, shots=1024, optimization_level=3)
job_monitor(job, interval = 2)
 try
Job Status: job has successfully run
# Get the results from the computation
results = job.result()
answer = results.get_counts(grover_circuit)
plot_histogram(answer)
 try
As we can (hopefully) see, there is a higher chance of measuring |101⟩ and |110⟩. The other results are due to errors in the quantum computation.

4. Problems

The function grover_problem_oracle below takes a number of qubits (n), and a variant and returns an n-qubit oracle. The function will always return the same oracle for the same n and variant. You can see the solutions to each oracle by setting print_solutions = True when calling grover_problem_oracle.

from qiskit_textbook.problems import grover_problem_oracle
## Example Usage
n = 4
oracle = grover_problem_oracle(n, variant=1)  # 0th variant of oracle, with n qubits
qc = QuantumCircuit(n)
qc.append(oracle, [0,1,2,3])
qc.draw()
 try
grover_problem_oracle(4, variant=2) uses 4 qubits and has 1 solution.
a. How many iterations do we need to have a &gt; 90% chance of measuring this solution?
b. Use Grover's algorithm to find this solution state. c. What happens if we apply more iterations the the number we calculated in problem 1a above? Why?

With 2 solutions and 4 qubits, how many iterations do we need for a &gt;90% chance of measuring a solution? Test your answer using the oracle grover_problem_oracle(4, variant=1) (which has two solutions).

Create a function, grover_solver(oracle, iterations) that takes as input:

A Grover oracle as a gate (oracle)
An integer number of iterations (iterations)
and returns a QuantumCircuit that performs Grover's algorithm on the 'oracle' gate, with 'iterations' iterations.

5. Solving Sudoku using Grover's Algorithm

The oracles used throughout this chapter so far have been created with prior knowledge of their solutions. We will now solve a simple problem using Grover's algorithm, for which we do not necessarily know the solution beforehand. Our problem is a 2×2 binary sudoku, which in our case has two simple rules:

No column may contain the same value twice
No row may contain the same value twice
If we assign each square in our sudoku to a variable like so:



we want our circuit to output a solution to this sudoku.

5.1 Turning the Problem into a Circuit

To create the oracle, we simply need to create a classical circuit that checks whether the state of our variable bits is a valid solution. Since we need to check down both columns and across both rows, there are 4 conditions we need to check:

v0 ≠ v1   # check along top row
v2 ≠ v3   # check along bottom row
v0 ≠ v2   # check down left column
v1 ≠ v3   # check down right column
Remember we are comparing classical (computational basis) states. For convenience, we can compile this set of comparisons into a list of clauses:

clause_list = [[0,1],
               [0,2],
               [1,3],
               [2,3]]
 try
We will assign the value of each variable to a bit in our circuit. To check these clauses computationally, we will use the XOR gate (we came across this in the atoms of computation).

def XOR(qc, a, b, output):
    qc.cx(a, output)
    qc.cx(b, output)
 try
Convince yourself that the output0 bit in the circuit below will only be flipped if input0 ≠ input1:

# We will use separate registers to name the bits
in_qubits = QuantumRegister(2, name='input')
out_qubit = QuantumRegister(1, name='output')
qc = QuantumCircuit(in_qubits, out_qubit)
XOR(qc, in_qubits[0], in_qubits[1], out_qubit)
qc.draw()
 try
This circuit checks whether input0 == input1 and stores the output to output0. To check each clause, we repeat this circuit for each pairing in clause_list and store the output to a new bit:

# Create separate registers to name bits
var_qubits = QuantumRegister(4, name='v')  # variable bits
clause_qubits = QuantumRegister(4, name='c')  # bits to store clause-checks

# Create quantum circuit
qc = QuantumCircuit(var_qubits, clause_qubits)

# Use XOR gate to check each clause
i = 0
for clause in clause_list:
    XOR(qc, clause[0], clause[1], clause_qubits[i])
    i += 1

qc.draw()
 try
The final state of the bits c0, c1, c2, c3 will only all be 1 in the case that the assignments of v0, v1, v2, v3 are a solution to the sudoku. To complete our checking circuit, we want a single bit to be 1 if (and only if) all the clauses are satisfied, this way we can look at just one bit to see if our assignment is a solution. We can do this using a multi-controlled-Toffoli-gate:

# Create separate registers to name bits
var_qubits = QuantumRegister(4, name='v')
clause_qubits = QuantumRegister(4, name='c')
output_qubit = QuantumRegister(1, name='out')
qc = QuantumCircuit(var_qubits, clause_qubits, output_qubit)

# Compute clauses
i = 0
for clause in clause_list:
    XOR(qc, clause[0], clause[1], clause_qubits[i])
    i += 1

# Flip 'output' bit if all clauses are satisfied
qc.mct(clause_qubits, output_qubit)

qc.draw()
 try
The circuit above takes as input an initial assignment of the bits v0, v1, v2 and v3, and all other bits should be initialised to 0. After running the circuit, the state of the out0 bit tells us if this assignment is a solution or not; out0 = 0 means the assignment is not a solution, and out0 = 1 means the assignment is a solution.

Important: Before you continue, it is important you fully understand this circuit and are convinced it works as stated in the paragraph above.

5.2 Uncomputing, and Completing the Oracle 

We can now turn this checking circuit into a Grover oracle using phase kickback. To recap, we have 3 registers:

One register which stores our sudoku variables (we'll say x=v3,v2,v1,v0)
One register that stores our clauses (this starts in the state |0000⟩ which we'll abbreviate to |0⟩)
And one qubit (|out0⟩) that we've been using to store the output of our checking circuit.
To create an oracle, we neeed our circuit (Uω) to perform the transformation:

Uω|x⟩|0⟩|out0⟩=|x⟩|0⟩|out0⊕f(x)⟩
If we set the out0 qubit to the superposition state |−⟩ we have:

Uω|x⟩|0⟩|−⟩	=Uω|x⟩|0⟩⊗
1
√
2
 
(|0⟩−|1⟩)		=|x⟩|0⟩⊗
1
√
2
 
(|0⊕f(x)⟩−|1⊕f(x)⟩) 
If f(x)=0, then we have the state:

=|x⟩|0⟩⊗
1
√
2
 
(|0⟩−|1⟩)		=|x⟩|0⟩|−⟩ 
(i.e. no change). But if f(x)=1 (i.e. x=ω), we introduce a negative phase to the |−⟩ qubit:

=|x⟩|0⟩⊗
1
√
2
 
(|1⟩−|0⟩)		=|x⟩|0⟩⊗−
1
√
2
 
(|0⟩−|1⟩)		=−|x⟩|0⟩|−⟩ 
This is a functioning oracle that uses two auxiliary registers in the state |0⟩|−⟩:

Uω|x⟩|0⟩|−⟩={ |x⟩|0⟩|−⟩forx≠ω	−|x⟩|0⟩|−⟩forx=ω 
To adapt our checking circuit into a Grover oracle, we need to guarantee the bits in the second register (c) are always returned to the state |0000⟩ after the computation. To do this, we simply repeat the part of the circuit that computes the clauses which guarantees c0 = c1 = c2 = c3 = 0 after our circuit has run. We call this step 'uncomputation'.

var_qubits = QuantumRegister(4, name='v')
clause_qubits = QuantumRegister(4, name='c')
output_qubit = QuantumRegister(1, name='out')
cbits = ClassicalRegister(4, name='cbits')
qc = QuantumCircuit(var_qubits, clause_qubits, output_qubit, cbits)

def sudoku_oracle(qc, clause_list, var_qubits, clause_qubits, cbits):
    # Compute clauses
    i = 0
    for clause in clause_list:
        XOR(qc, clause[0], clause[1], clause_qubits[i])
        i += 1

    # Flip 'output' bit if all clauses are satisfied
    qc.mct(clause_qubits, output_qubit)

    # Uncompute clauses to reset clause-checking bits to 0
    i = 0
    for clause in clause_list:
        XOR(qc, clause[0], clause[1], clause_qubits[i])
        i += 1

sudoku_oracle(qc, clause_list, var_qubits, clause_qubits, cbits)
qc.draw()
 try
In summary, the circuit above performs:

Uω|x⟩|0⟩|out0⟩={ |x⟩|0⟩|out0⟩forx≠ω	|x⟩|0⟩⊗X|out0⟩forx=ω 
and if the initial state of |out0⟩=|−⟩,:

Uω|x⟩|0⟩|−⟩={ |x⟩|0⟩|−⟩forx≠ω	−|x⟩|0⟩|−⟩forx=ω 
5.3 The Full Algorithm 

All that's left to do now is to put this oracle into Grover's algorithm!

var_qubits = QuantumRegister(4, name='v')
clause_qubits = QuantumRegister(4, name='c')
output_qubit = QuantumRegister(1, name='out')
cbits = ClassicalRegister(4, name='cbits')
qc = QuantumCircuit(var_qubits, clause_qubits, output_qubit, cbits)

# Initialise 'out0' in state |-&gt;
qc.initialize([1, -1]/np.sqrt(2), output_qubit)

# Initialise qubits in state |s&gt;
qc.h(var_qubits)
qc.barrier()  # for visual separation

## First Iteration
# Apply our oracle
sudoku_oracle(qc, clause_list, var_qubits, clause_qubits, cbits)
qc.barrier()  # for visual separation
# Apply our diffuser
qc.append(diffuser(4), [0,1,2,3])

## Second Iteration
sudoku_oracle(qc, clause_list, var_qubits, clause_qubits, cbits)
qc.barrier()  # for visual separation
# Apply our diffuser
qc.append(diffuser(4), [0,1,2,3])

# Measure the variable qubits
qc.measure(var_qubits, cbits)

qc.draw()
 try
 # Simulate and plot results
qasm_simulator = Aer.get_backend('qasm_simulator')
result = execute(qc, backend=qasm_simulator, shots=1024).result()
plot_histogram(result.get_counts())
 try
There are two bit strings with a much higher probability of measurement than any of the others, 0110 and 1001. These correspond to the assignments:

v0 = 0
v1 = 1
v2 = 1
v3 = 0
and

v0 = 1
v1 = 0
v2 = 0
v3 = 1
which are the two solutions to our sudoku! Hopefully it is now clearer as to how we can create Grover oracles from real problems.

6. References

L. K. Grover (1996), "A fast quantum mechanical algorithm for database search", Proceedings of the 28th Annual ACM Symposium on the Theory of Computing (STOC 1996), doi:10.1145/237814.237866, arXiv:quant-ph/9605043
C. Figgatt, D. Maslov, K. A. Landsman, N. M. Linke, S. Debnath &amp; C. Monroe (2017), "Complete 3-Qubit Grover search on a programmable quantum computer", Nature Communications, Vol 8, Art 1918, doi:10.1038/s41467-017-01904-7, arXiv:1703.10535
I. Chuang &amp; M. Nielsen, "Quantum Computation and Quantum Information", Cambridge: Cambridge University Press, 2000.
import qiskit
qiskit.__qiskit_version__
 try
{'qiskit-terra': '0.15.1',
 'qiskit-aer': '0.6.1',
 'qiskit-ignis': '0.4.0',
 'qiskit-ibmq-provider': '0.8.0',
 'qiskit-aqua': '0.7.5',
 'qiskit': '0.20.0'}
〈 Shor's Algorithm
Quantum Counting 〉
This page was created by The Jupyter Book Community
Cookie Preferences and Do Not Sell My Info</Text>
        </Document>
        <Document ID="20BCB30A-BD7B-4DB7-B43A-533F07F217F8">
            <Title>grover</Title>
            <Text>   ARTICLE
DOI: 10.1038/s41467-017-01904-7 OPEN
Complete 3-Qubit Grover search on a programmable quantum computer
C. Figgatt 1, D. Maslov1,2, K.A. Landsman1, N.M. Linke1, S. Debnath1 &amp; C. Monroe1,3
The Grover quantum search algorithm is a hallmark application of a quantum computer with a well-known speedup over classical searches of an unsorted database. Here, we report results for a complete three-qubit Grover search algorithm using the scalable quantum computing technology of trapped atomic ions, with better-than-classical performance. Two methods of state marking are used for the oracles: a phase-flip method employed by other experimental demonstrations, and a Boolean method requiring an ancilla qubit that is directly equivalent to the state marking scheme required to perform a classical search. We also report the deterministic implementation of a Toffoli-4 gate, which is used along with Toffoli-3 gates to construct the algorithms; these gates have process fidelities of 70.5% and 89.6%, respectively.
  1 Joint Quantum Institute, Department of Physics, Joint Center for Quantum Information and Computer Science, University of Maryland, College Park, MD 20742, USA. 2 National Science Foundation, Arlington, VA 22230, USA. 3 IonQ Inc., College Park, MD 20742, USA. Correspondence and requests for materials should be addressed to C.F. (email: cfiggatt@umd.edu)
NATURE COMMUNICATIONS|8:1918 |DOI: 10.1038/s41467-017-01904-7|www.nature.com/naturecommunications 1
1234567890

ARTICLE
NATURE COMMUNICATIONS | DOI: 10.1038/s41467-017-01904-7
 Searching large databases is an important problem with
search strategy, which consists of a single query followed by a
random guess in the event the query failed. In the two-solution
case (t = 2), where two states are marked as correct answers
during the oracle stage and both states’ amplitudes are amplified
in the algorithm’s amplification stage, the probability of mea-
suring one of the two correct answers is 100% for the quantum
case, as compared to 13 % 46:4% for the classical case. The 28
algorithm is performed with both a phase oracle, which has been previously demonstrated on other experimental systems, and a Boolean oracle, which requires more resources but is directly comparable to a classical search. All quantum solutions are shown to outperform their classical counterparts.
Results
Oracles. We examine two alternative methods of encoding the marked state within the oracle. While both methods are mathe- matically equivalent16, only one is directly comparable to a classical search. The Boolean method requires the use of an ancilla qubit initialized to |1〉, as shown in Fig. 1b. The oracle is determined by constructing a circuit out of NOT and Ck(NOT) (k ≤ n) gates such that, were the oracle circuit to be implemented classically, the ancilla bit would flip if and only if the input to the circuit is one of the marked states. By using classically available gates, this oracle formulation is directly equivalent to the classical search algorithm, and therefore can most convin- cingly demonstrate the quantum algorithm’s superiority. On a quantum computer, because the initialization sets up an equal superposition of all possible input states, the Cn(NOT) gate targeted on the ancilla provides a phase kickback that flips the phase of the marked state(s) in the data qubits. An example oracle is shown in Fig. 1c to illustrate this. The phase method of oracle implementation does not require the ancilla qubit. Instead, the
A
Amplification
N–1 N–1
|b〉 (2A+􏰀m)|m〉+(2A–􏰀b) |b〉
broad applications. The Grover search algorithm1,2 provides
a powerful method for quantum computers to perform
searches with a quadratic speedup in the number of required
database queries over classical computers. It is an optimal search
algorithm for a quantum computer3, and has further applications
as a subroutine for other quantum algorithms4,5. Searches with 6–12
two qubits have been demonstrated on a variety of platforms and proposed for others13, but larger search spaces have only been demonstrated on a non-scalable NMR system14.
The Grover search algorithm has four stages: initialization, oracle, amplification, and measurement, as shown in Fig. 1a. The initialization stage creates an equal superposition of all states. The oracle stage marks the solution(s) by flipping the sign of that state’s amplitude. The amplification stage performs a reflection about the mean, thus increasing the amplitude of the marked state. Finally, the algorithm output is measured. For a search database of size N, the single-shot probability of measuring the correct answer is maximized to near-unity by repeating the oracle and amplifi- cation stages O((N)1/2) times1,2. By comparison, a classical search algorithm will get the correct answer after an average of N/2 queries of the oracle. For large databases, this quadratic speedup represents a significant advantage for quantum computers.
Here, we implement the Grover search algorithm using a scalable trapped atomic ion system15 on n = 3 qubits, which corresponds to a search database of size N = 2n = 8. The algorithm is executed for all eight possible single-result oracles and all 28 possible two-result oracles. All searches are performed with a single iteration. For a single-solution algorithm (t = 1), the algorithmic probability of measuring the correct state after one
NNN42 N N N1 8 8 7
h
a
i 2  2
N2t 2ðNtÞ 1 5 2
þ pffiffiffi 1⁄4 pffiffi 1⁄4 78:125% , com-
iteration is t 
pared to t þNt  t 1⁄4 1 þ7 1 1⁄4 25% for the optimal classical
     Initialize
Oracle
 b Init Amplification
c Init
|0〉 H X |0〉 H
|0〉 H
Oracle
Amplification
N–1 |x〉
x=0
–􏰀m |m〉+􏰀b b=0,b≠m
Repeat O ( N) times
b=0,b≠m
   |q1〉 : |0〉 H
|q2〉 : |0〉 H
|q3〉 : |0〉 H
|qa〉 : |1〉 H H |1〉 H H |1
Oracle
d Init Amplification
⎪ 4√2 4√2 H X Z X H ⎭
|q1〉 : |0〉 H |q2〉 : |0〉 H |q3〉 : |0〉 H
Oracle
H XX H H XX H H XZX H
e Init Oracle Amplification
|0〉H HX XH
|0〉 H H X X H 1 (|011〉+|101〉)
H X H X H X
X H X H X H
X H X H X
X H ⎫
X H ⎪⎬ 5 |011〉+ 1 Σx≠011|x〉
Z
 |0〉 H Z Z H X Z X H
√2
Fig. 1 The Grover search algorithm. a Evolution of relative amplitudes for each state during a Grover search algorithm. The initialization stage creates an
equal superposition of all possible input states, so the amplitude αx = 1 for all basis states |x〉. The oracle stage marks the desired state, so the amplitude αm
of the marked state |m〉 becomes negative while the amplitudes αb of the unmarked states |b〉, b ≠ m remain unchanged. The amplification stage performs a
reflection about the mean vector PN1 jxi, which has amplitude A 1⁄4 1 PN1 αx 1⁄4 1 ðαm þ ðN  1Þαb Þ, to amplify the marked state. An appropriate x1⁄40 N x1⁄40 N
number of repetitions of the oracle and amplification stages will maximize the amplitude of the correct answer. All qubit states are normalized by the factor 1
pffiffi. The algorithm can also be generalized to mark and amplify the amplitude of t desired states. b General circuit diagram for a Grover search algorithm N 16
using a Boolean oracle, depicted using standard quantum circuit diagram notation . The last qubit qa is the ancilla qubit. c Example of single-solution Boolean oracle marking the |011〉 state. d General circuit diagram for a Grover search algorithm using a phase oracle. e Example of two-solution phase oracle marking the |011〉 and |101〉 states
2 NATURE COMMUNICATIONS | 8: 1918 | DOI: 10.1038/s41467-017-01904-7 | www.nature.com/naturecommunications

NATURE COMMUNICATIONS | DOI: 10.1038/s41467-017-01904-7
ARTICLE
 oracle is implemented with a circuit consisting of Z and Ck(Z) (k ≤ n − 1) gates that directly flip the phase(s) of the state(s) to be marked (Fig. 1d, e).
Experimental setup. The experiments presented here were per- formed on a programmable quantum computer consisting of a linear chain of five trapped 171Yb+ ions17,18 that are laser cooled near the motional ground state. Qubits are comprised of the first- order magnetic-field-insensitive pair of clock states in the hyperfine-split 2S1/2 manifold, with |0〉 ≡ |F = 0; mF = 0〉 and |1〉 ≡ |F = 1; mF = 0〉 having a 12.642821 GHz frequency difference. Optical pumping initializes all qubits to the |0〉 state. We execute modular one- and two-qubit gates through Raman transitions driven by a beat note between counter-propagating beams from a pulsed laser19, which couples the qubit transition to the collective transverse modes of motion of the ion chain. The qubit–motion interaction provides entangling two-qubit Ising gates17,20,21. A pulse segmentation scheme modulates the amplitude and phase of the Raman laser to drive high-fidelity entangling gates using all modes of motion22,23. Individual optical addressing of each ion with one Raman beam provides arbitrary single-qubit rotations (R(θ,φ)) as well as gates between arbitrary pairs of ions (XX(χ)) (see Methods for details). State-dependent fluorescence detection with each ion mapped to a separate photomultiplier tube (PMT) channel allows for individual ion readout15.
b
|q1〉 |q2〉 |qt〉
|q1〉
|q2〉
XX (π8) π
π
|q〉 ··· t
c
π Controlled-NOT (CNOT) gates constructed from an XX 4 gate
a1 1
 0.5
0 000
Detected
Ry Rx Ry Rx Rx
111
000
111
Input
0.5
0
XX ( 4 )
1
0.8
0.6
0.4
0.2
0
     =
··· ···
XX (8)
π R􏰁 XX (8)
π Ry XX( )
        R􏰁
1
0.8
0.6
0.4
0.2
0 0000
1000
π R􏰁 8)
4
 XX (
Toffoli gates. Successful demonstration of the Grover search algorithm first requires the implementation of its subroutines.
  Detected
Since XXπ21⁄4 XXπ, we can add single-qubit rotations to 84
1111 0000
controlled-V operation is available such that V2 = U27.
Fig. 2 Toffoli implementation. a Measured truth table for a Toffoli-3 gate. The average process fidelity is 89.6(2)%, corrected for a 1.5% average state preparation and measurement (SPAM) error. b Abbreviated circuit for implementing Toffoli-3 (see Methods for details). c Measured truth table for a Toffoli-4 gate performed with three controls, one target, and one ancilla qubit. The average process fidelity is 70.5(3)%, corrected for a 1.9% average SPAM error
construct a Toffoli-3 gate with minimal use of two-qubit gates, as
shown in Fig. 2b (see Methods for a detailed circuit diagram). This
Boolean oracles
000 001 010 011 100 101 110 111
ASP(%) SSO(%)
34(1) 80(2) 38(1) 83(2) 40(1) 85(2) 41(1) 86(2) 31(1) 76(2) 35(1) 81(2) 41(1) 85(2) 50(1) 90(2)
Phase oracles
000 010 100 110 Detected state
ASP(%) SSO(%)
1000
1111
Input
unitary C2(U) operation can be performed with five two-qubit
interactions (two CNOTs, two C(V)s, and one C(V†)) if a
and single-qubit rotations (Methods) have been demonstrated on this system previously15. Here, we show results for a controlled- controlled-NOT (C2(NOT)), or Toffoli-3, gate, with a process fidelity of 89.6(2)% (Fig. 2a). Toffoli-3 gates have been previously performed in NMR systems24 and ion traps25, including this system26. We employed a limited tomography procedure to verify that the Toffoli-3 gate performed had no spurious phases on the outputs (Supplementary Note 1; Supplementary Fig. 1).
 Our Toffoli-3 gate is constructed from five two-qubit gates (three XXπ and two XXπ gates) in a manner similar to the
8 4 14
Toffoli gate demonstrated in ref. . Any doubly-controlled
compares favorably to the six two-qubit gates that would be
necessary if only CNOT (or equivalently, XXπ) gates were 4
available. These constructions also provide for the implementation of C(Z) and C2(Z) gates, which can be constructed by adding a few single-qubit rotations to a CNOT or Toffoli-3 gate, respectively
50 50.2(7) 89(1) 40
   000 010 100 110 Detected state
Fig. 3 Single-solution algorithm. Results from a single iteration of a single-solution Grover search algorithm performed on a 3-qubit database. Data for the Boolean oracle formulation are shown on the left, and data for the phase oracle formulation are shown on the right. The plots show the probability of detecting each output state. All values shown are percents, with a theoretical ASP of 78.1% and theoretical SSO of 100%. Data are corrected for average SPAM errors of 1%
NATURE COMMUNICATIONS|8:1918 |DOI: 10.1038/s41467-017-01904-7|www.nature.com/naturecommunications 3
34.1(7) 79(1)
33.3(7) 78(1) 46.4(7) 87(1) 42.7(7) 86(1) 55.1(7) 91(1) 41.4(7) 85(1) 46.5(7) 84(1)
30 20 10 0
Marked state
Probability
Probability

ARTICLE
NATURE COMMUNICATIONS | DOI: 10.1038/s41467-017-01904-7
 Boolean oracles
ASP(%) SSO(%)
Phase oracles
ASP(%) SSO(%)
77(1) 77(1) 79(1) 79(1) 77(1) 75(1) 74.7(9) 72(1) 79(1) 79(1) 69(1) 69(1) 74(1) 73(1) 79(1) 79(1) 72(1) 71(1) 79(1) 78(1) 80(1) 79(1) 82(1) 81(1) 73(1) 72(1) 73(1) 73(1) 70(1) 70(1) 73.8(9) 69.7(9) 74(1) 73(1) 75(1) 74(1) 74(1) 74(1) 74(1) 74(1) 75(1) 75(1) 80(1) 78(1) 72(1) 71(1) 66.7(9) 67(1) 75.5(9) 71(1) 72(1) 71(1) 77(1) 77(1) 80(1) 80(1)
    000,001 000,010 000,011 000,100 000,101 000,110 000,111 001,010 001,011 001,100 001,101 001,110 001,111 010,011 010,100 010,101 010,110 010,111 011,100 011,101 011,110 011,111 100,101 100,110 100,111 101,110 101,111 110,111
67(1) 67(1) 66(1) 66(1) 66(1) 66(1) 68(1) 68(1) 65(1) 65(1) 62(1) 62(1) 66(1) 66(1) 64(1) 64(1) 71(1) 71(1) 68(1) 67(1) 69(1) 69(1) 60(1) 60(1) 65(1) 65(1) 75(1) 75(1) 66(1) 65(1) 65(1) 64(1) 72(1) 72(1) 73(1) 72(1) 65(1) 65(1) 66(1) 66(1) 73(1) 73(1) 74(1) 74(1) 74(1) 74(1) 67(1) 66(1) 64(1) 64(1) 65(1) 65(1) 70(1) 69(1) 74(1) 74(1)
50
40
30
20
10
0
 000 010 100 110 Detected state
000 010 100 110
Detected state
Fig. 4 Two-solution algorithm. Results from the execution of a two-solution Grover search algorithm performed on a 3-qubit database. Data for the Boolean oracle formulation are shown on the left, and data for the phase oracle formulation are shown on the right. The plots show the probability of detecting each output state. All values shown are percents. The ASP is the sum of the probabilities of detecting each of the two marked states. Data are corrected for average SPAM errors of 1%
  Table 1 Single-solution oracles
                                            Table of all oracles used for the single-solution Grover search algorithm
   4 NATURE COMMUNICATIONS | 8: 1918 | DOI: 10.1038/s41467-017-01904-7 | www.nature.com/naturecommunications
Marked state

NATURE COMMUNICATIONS | DOI: 10.1038/s41467-017-01904-7 ARTICLE
   Table 2 Two-solution oracles
                                                                                                                                      Table of all oracles used for the two-solution Grover search algorithm
   NATURE COMMUNICATIONS|8:1918 |DOI: 10.1038/s41467-017-01904-7|www.nature.com/naturecommunications 5

ARTICLE
NATURE COMMUNICATIONS | DOI: 10.1038/s41467-017-01904-7
 (see Methods for circuits). For all circuits, the single-qubit
rotations are further optimized to minimize total rotation time28.
We use a related strategy to construct a Toffoli-4 gate, and
report an average process fidelity of 70.5(3)% (Fig. 2c). Using the
methods described in ref. 29, we construct a circuit with three
ASP is calculated by summing the probabilities of measuring each of the two marked states. The squared statistical overlap (SSO) measures the statistical overlap between the measured and
control qubits, one target, and one ancilla qubit, requiring 11 two-
ej is the expected population and mj is the measured population for each state j30. Additionally, all of the data shown in this paper is corrected to account for state preparation and measurement (SPAM) errors (see figure captions for values), similar to the method proposed in ref. 31 while also accounting for multi-ion crosstalk15. All uncertainties given are statistical uncertainties based on the number of experiments performed.
The single iteration, single-solution Grover search algorithm shown in Fig. 3 has a theoretical ASP of 78.1%, as discussed above. The SSO takes into account that the seven unmarked states then have equal expected probabilities totaling 21.9% of being measured. For all Boolean oracles, the average ASP is 38.9(4)% and the average SSO is 83.2(7)%, while phase oracles have an average ASP of 43.7(2)% and an average SSO of 84.9(4)%; the reduced use of resources in the phase oracles (10 XX(χ) gates and 3 qubits for phase oracles compared to 16 XX(χ) gates and 5 qubits for Boolean oracles) results in better performance, as expected. These results compare favorably with the classical ASP of 25%.
The two-solution Grover search algorithm shown in Fig. 4 has a theoretical ASP of 100%, as discussed above. For all Boolean oracles, the average ASP is 67.9(2)% and the average SSO is 67.6 (2)%, while phase oracles have an average ASP of 75.3(2)% and an average SSO of 74.4(2)%; the reduced use of resources in the phase oracles (6–8 XX(χ) gates and three qubits for phase oracles compared to 10–14 XX(χ) gates and four qubits for Boolean oracles) results in better performance, as expected. For all oracles in both cases, the two states with the highest measurement probability are also the two marked states. These results compare favorably with the classical ASP of 46.4%.
Outlook. We note that this implementation of the Grover search algorithm scales linearly in the two-qubit gate count and ancilla
qubit gates (see Methods for circuit). By again using both XXπ π 4
and XX 8 gates, we are able to save one two-qubit gate relative to a construction limited to CNOT gates29.
Data. Figures 3 and 4 show the results, respectively, of single- and two-solution Grover search algorithms, each using both the Boolean and phase marking methods (see Methods for optimized circuits performed.). All possible oracles are tested to demonstrate a complete Grover search (Tables 1, 2). Two figures of merit are provided with the data for each oracle. The algorithm success probability (ASP) is the probability of measuring the marked state as the experimental outcome. For the two-solution algorithm, the
a
|q〉
|qc〉
=
|qt〉 c
|qc〉
=
|qt〉 Z
Rz (􏰄)
=
Rx (􏰄)
  b
R y ( 2π )
Fig. 5 One- and two-qubit composite gates. χct is the parameter for the XX gate between the two qubits. Let α = sgn(χct). a Rz(θ) gate implementation using Rx(θ) and Ry(θ) gates. b CNOT gate implementation using XX(χ), Rx(θ), Ry(θ), and Rz(θ) gates. c Controlled-Z gate implementation using XX (χ), Rx(θ), and Ry(θ) gates
a
|q1〉 |q2〉 | q t 〉
|q1〉 |q2〉 |qt〉
b
|q1〉 |q2〉 |qt〉
|q1〉 |q2〉 |qt〉
=
R x ( 4π ) ···
Ry (– 2π )
PN pffiffiffiffiffiffiffiffi2 expected populations for all states: SSO 1⁄4 j1⁄40 ejmj , where
   R y ( 􏰀 2π )
XX (􏰀 4π )
Ry (– 􏰀 2π )
Rz (– 2π )
  Rx (– 2π )
   Ry (– 2π )
Rx (– 2π )
R y ( 2π )
 XX (􏰀 π4 )
   R y ( 􏰀 2π )
R x ( 􏰀 2π )
Ry (– 􏰀 2π )
 XX (􏰂 8π )
  Ry (– 􏰂 2π )
Rx (􏰂 3π ) 4
   XX (􏰀 4π )
   Ry (– 􏰃 2π )
R x ( 􏰃 2π )
R (− 2π , ( 􏰃+1 ) π − P) 32
 XX (􏰃 8π )
 XX (􏰂 8π )
 R y ( 􏰂 2π )
    XX (􏰀 4π )
 R (− 􏰀􏰂􏰃 2π , ( 􏰀􏰂+1 ) π − 􏰀􏰂􏰃P) 32
     Ry (– 􏰂 2π )
Rx (􏰂3π ) 4
XX (􏰂 8π )
XX (􏰃 8π )
R ( π , − 􏰀 􏰂 􏰃 4π )
     Z
··· ···
=
··· ··· ···
R y ( 2π )
R x ( 4π )
XX (􏰀 4π )
   Ry (– 􏰃 2π )
R x ( 􏰃 2π )
R (− 2π , ( 􏰃+1 ) π − P) 32
 XX (􏰃 π ) 8
 XX (􏰂 8π )
 R y ( 􏰂 2π )
    XX (􏰀 4π )
  R (− 􏰀􏰂􏰃 2π , ( 􏰀􏰂+1 ) π − 􏰀􏰂􏰃P) 32
R ( π , − 􏰀 􏰂 􏰃 4π )
 XX (􏰃 8π )
R y ( – 2π )
   Fig. 6 Three-qubit composite gates. Three-qubit composite gates using XX(χ), R (θ), R (θ), and R(θ,φ) gates. Let α = sgn(χ ), β = sgn(χ ), γ = sgn(χ ), and qffiffi xy 12 1t 2t
P 1⁄4 arcsin 23 . a Toffoli-3 gate implementation. b Controlled-controlled-Z (CCZ) gate implementation
6 NATURE COMMUNICATIONS | 8: 1918 | DOI: 10.1038/s41467-017-01904-7 | www.nature.com/naturecommunications

NATURE COMMUNICATIONS | DOI: 10.1038/s41467-017-01904-7
ARTICLE
   |q1〉 |q2〉 |q3〉 |qt〉 |qa〉
|q1〉 ···
|q2〉 ···
|q3〉 ···
|qt〉 ···
R y ( 2π ) =
R x ( 4π )
      XX (􏰀2 4π )
X X ( 􏰀 2 4π )
     XX (􏰀2 4π )
 R (−􏰀t π, Qπ)
 X X ( 􏰀 1 4π )
 R y ( 􏰀 t 4π )
 R x ( – 􏰀 2 2π )
 X X ( 􏰀 2 4π )
R y ( 􏰀 t 4π )
      Ry (– 􏰂 2π )
R x ( 􏰂 2π )
R (− 2π , ( 􏰂+1 ) π − P) 32
X X ( 􏰀 3 4π )
  XX (􏰂 π ) 8
   |qa〉
|q1〉 ···
|q2〉 ···
|q3〉 ···
|qt〉 ··· |qa〉 ···
|q1〉 ···
|q2〉 ···
|q3〉 ···
|qt〉 ··· |qa〉 ···
···
XX (􏰀1 8π )
   R (– 􏰀 π ) yt4
Rx (􏰀t 3π ) 4
    R (π,− 􏰀3􏰀t􏰂 4π )
X X ( 􏰀 3 4π )
 Rx(−􏰀1 π)
   R(−􏰀3􏰀t 􏰂 2π , ( 􏰀3􏰀t+1 32
)π − 􏰀3􏰀t􏰂P)
XX (􏰀3 4π )
 XX (􏰂 π ) 8
    X X ( 􏰀 3 4π )
R y ( 􏰀 t 4π )
    XX (􏰀1 4π )
Ry (–􏰀1􏰀2 2π )
      XX (􏰀2 4π )
X X ( 􏰀 2 4π )
Ry (– 2π )
    XX (􏰀2 4π )
 R (−􏰀t π, Qπ)
 XX (􏰀1 4π )
 R (􏰀 π ) yt4
 R (– 􏰀 π ) x22
 X X ( 􏰀 2 4π )
 Fig. 7 Toffoli-4 gate. Toffoli-4 gate implementation using XX(χ), R (θ), R (θ), and R(θ, φ) gates. Let α = sgn(χ ), α = sgn(χ ), α = sgn(χ ), α = sgn(χ ),
qffiffi x y β=sgn(χ3t),P1⁄4arcsin 23 ,andQ1⁄481ð43α2αtÞ
count for increasing search database size as a function of
the number of qubits n, and for a constant number of solutions
t. For a database of size N=2n stored on n qubits, the
amplification stage requires one Toffoli-n gate, and the t-solution
oracle stage requires at worst t Toffoli-n (for a phase oracle)
or Toffoli-(n + 1) (for a Boolean oracle) gates; optimal oracles
for particular sets of marked states may require even
fewer two-qubit gates. The method used here to construct
the Toffoli-4 circuit scales to Toffoli-n gates as 6n − 13 in the
1 1a 2 2a 3 3a t ta
ππ1
two-qubit gate count and as in the ancilla count . This maximally entangling for χ 1⁄4 ± , so XX j00i 1⁄4 pffiffiðj00i  ij11iÞ.
paves the way for more extensive use of the Grover search algorithm in solving larger problems on quantum computers, including using the circuit as a subroutine for other quantum algorithms.
Methods
Circuit diagrams. Here we present detailed circuit diagrams for all of the operations presented in the paper above, shown in terms of the R(θ,φ) and XX(χ) gates directly implemented by the experiment. The single-qubit rotation is defined as
!
: ð1Þ Rotations about the X-axis (Rx(θ)) are achieved by setting φ = 0, and rotations
about the Y-axis (Ry(θ)) are achieved by setting φ 1⁄4 π2. Rotations about the Z-axis (Rz(θ)) are comprised of three rotations about axes in the XY plane, as demon- strated in Fig. 5a.
Two-qubit XX gates are combined with rotation R gates to construct the composite gates needed for the Grover search algorithm implementation. The parameter χ can be positive or negative, depending on what ion pair is chosen and the particulars of the pulse segmentation solution chosen for the ion pair in question; the sign of χ (sgn(χ)) is determined experimentally for each ion pair. Consequently, some composite gate circuits include rotations with parameters that depend on sgn(χ). Composite gates were constructed by starting with known circuits, converting constituent parts into R and XX gates using lower-level constructions, and then optimizing the circuit. First, the number of XX gates
was minimized (as in the Toffoli-3 gate, described in the main text). Second,
the single-qubit gates were optimized by minimizing the sum of all rotation angles θ, as this minimizes the total time for the experiment. Additional details can be found in refs. 28,29.
The two-qubit CNOT and controlled-Z gates are shown in Fig. 5b, c. They each require one XX gate and several rotations. The three-qubit gates used here are the Toffoli-3 and controlled-controlled-Z (CCZ) gates, shown in Fig. 6a, b. The Toffoli- 3 gate requires two control qubits (q1 and q2) and one target qubit (qt). Finally, the four-qubit Toffoli-4 gate is shown in Fig. 7. It governs a four-qubit interaction between three control qubits (q1, q2, and q3) and one target qubit (qt), and it additionally requires an ancilla qubit (qa).
cos θ2 Rðθ;φÞ1⁄4 ieiφsinθ
ieiφ sin θ2 cosθ
Ry (􏰀1􏰀2 2π )
The two-qubit entangling gate is
0 cosðχÞ 0
0 isinðχÞ1 isinðχÞ 0 C
2 442
22
NATURE COMMUNICATIONS|8:1918 |DOI: 10.1038/s41467-017-01904-7|www.nature.com/naturecommunications 7
X X ( 􏰀 1 4π )
B XXðχÞ 1⁄4 B@
0 cosðχÞ
0 isinðχÞ isinðχÞ 0
cosðχÞ 0 CA: ð2Þ 0 cosðχÞ
The parameter χ can be varied continuously by adjusting the overall power applied
to the gate, but the gates used here require only χ 1⁄4 ±π or χ 1⁄4 ±π. The gate is n329 48
R y ( 􏰀 t 4π )

ARTICLE
NATURE COMMUNICATIONS | DOI: 10.1038/s41467-017-01904-7
 a
|q1〉 : |0〉 |q2〉 : |0〉 |q3〉 : |0〉 |qa〉 : |0〉
 R y ( – 2π )
 R y ( – 2π )
 R y ( – 2π )
 R y ( – 2π )
 Rx (π)
 Rx (π)
 Rx (π)
b
|q1〉 |q2〉 |q3〉 |qa〉
···
···
···
···
  Rx (􏰂 3π ) 4
 R x ( 􏰃 2π )
 R x ( π4 )
 Rx (π)
 Ry (1 − 􏰂) π2
XX (􏰂 8π )
     Ry (1 − 􏰃) π2
 XX (􏰂 8π )
XX (􏰃 8π )
R (− 2π , ( 􏰃+1 ) π − P) 32
XX (􏰀 4π )
   Ry (π)
  R y ( π2 )
  Ry (􏰂 − 1) π2
   XX (􏰀 4π )
   R (− 􏰀􏰂􏰃 2π , ( 􏰀􏰂+1 ) π − 􏰀􏰂􏰃P) 32
R ( π , − 􏰀 􏰂 􏰃 4π )
Ry (− π2 )
 XX (􏰃 8π )
 Ry (π)
     Fig. 8 Grover search algorithm circuits. Grover search algorithm implementation by substage using XX(χ), Rx(θ), Ry(θ), and R(θ, φ) gates. The circuits shownareforusewithBooleanoracles;removingtheancillaqubit|q〉producesthenecessarycircuitsforusewithaphaseoracle.Letα=sgn(χ ),β=sgn
qffiffi a 12 (χ1t), γ = sgn(χ2t), and P 1⁄4 arcsin 23 . a Grover initialization stage implementation. b Grover amplification stage implementation
The Grover search algorithm is implemented using circuits that are equivalent to those shown in Fig. 1b, d, but with the initialization and amplification stages optimized to minimize gate times, as shown in Fig. 8a, b. The circuits shown are for use with Boolean oracles; in the phase oracle case, the ancilla qubit qa is simply omitted. To preserve the modularity of the algorithm, the initialization stage and amplification stage were each optimized without regard to the contents of the oracle, so each possible oracle can simply be inserted into the algorithm without making any changes to the other stages.
Received: 1 May 2017 Accepted: 25 October 2017
 Oracles for the Grover search algorithm were constructed using a combination References
of reversible and classical logic synthesis techniques. For Boolean oracles, reversible logic synthesis was employed to find a set of X, CN(NOT) gates that marked the desired state(s) for each oracle. For phase oracles, EXOR polynomial synthesis was used to find a set of Z, CN(Z) gates that marked the desired state(s) for each oracle. For example, for Boolean oracles, the selection was limited to the classically available X (or NOT) and CN(NOT) gates, and a reversible circuit was constructed such that the output bit (corresponding to the ancilla qubit in the quantum oracle) would be flipped if and only if a marked state was used as the input to the circuit. While there are many possible circuit constructions for each oracle, the oracle chosen for implementation was one that first minimized the number of two-qubit interactions required, and then minimized the number of single-qubit interactions needed. The synthesis techniques used are scalable and can be applied to oracles of any size. The oracles used here were implemented as per the circuit diagrams shown in Table 1 for single-solution oracles and Table 2 for two-solution oracles.
Other quantum algorithms may be implemented on this system in a similar fashion. First, decompose the algorithm’s subroutines into high-level circuits. Second, optimize those circuits to minimize the number of two-qubit interactions required. Third, decompose the high-level circuits into physical-level R and XX gates. Finally, perform further optimizations to first minimize the number of two- qubit XX gates required, and then to minimize the total rotation time (the sum of all rotation angles θ) across all R gates. However, since the optimization of quantum circuits is QMA-Hard, we anticipate that future improvements in algorithm design, circuit synthesis, and circuit optimization techniques may result in more efficient circuit implementations, facilitating increased experimental performance.
Data availability. All relevant data are available from the corresponding author upon request.
1. Grover, L. K. Quantum Mechanics helps in searching for a needle in a haystack. Phys. Rev. Lett. 79, 325–328 (1997).
2. Boyer, M., Brassard, G., Høyer, P. &amp; Tapp, A. Tight bounds on quantum searching. Fortschr. Phys. 46, 493–505 (1998).
3. Bennett, C., Bernstein, E., Brassard, G. &amp; Vazirani, U. Strengths and weaknesses of quantum computing. SIAM J. Comput. 26, 1510–1523 (1997).
4. Magniez, F., Santha, M. &amp; Szegedy, M. Quantum algorithms for the triangle problem. SIAM J. Comput. 37, 413–424 (2007).
5. Dürr, C., Heiligman, M., Høyer, P. &amp; Mhalla, M. Quantum query complexity of some graph problems. SIAM J. Comput. 35, 1310–1328 (2006).
6. Chuang, I. L., Gershenfeld, N. &amp; Kubinec, M. Experimental implementation of fast quantum searching. Phys. Rev. Lett. 80, 3408–3411 (1998).
7. Bhattacharya, N., van Linden van den Heuvell, H. B. &amp; Spreeuw, R. J. C. Implementation of quantum search algorithm using classical fourier optics. Phys. Rev. Lett. 88, 137901 (2002).
8. Brickman, K.-A. et al. Implementation of Grover’s quantum search algorithm in a scalable system. Phys. Rev. A 72, 050306(R) (2005).
9. Walther, P. et al. Experimental one-way quantum computing. Nature 434, 169–176 (2005).
10. DiCarlo, L. et al. Demonstration of two-qubit algorithms with a superconducting quantum processor. Nature 460, 240–244 (2009).
11. Barz, S. et al. Demonstration of blind quantum computing. Science 335, 303–308 (2012).
12. Manning, T. Quantum Information Processing with Trapped Ion Chains (PhD thesis, University of Maryland, 2014).
13. Mølmer, K., Isenhower, L. &amp; Saffman, M. Efficient Grover search with Rydberg blockade. J. Phys. B At. Mol. Opt. Phys. 44, 184016 (2011).
14. Vandersypen, L. M. K. et al. Implementation of a three-quantum-bit search algorithm. Appl. Phys. Lett. 76, 646–648 (2000).
15. Debnath, S. et al. Demonstration of a small programmable quantum computer module using atomic qubits. Nature 536, 63–66 (2016).
8 NATURE COMMUNICATIONS | 8: 1918 | DOI: 10.1038/s41467-017-01904-7 | www.nature.com/naturecommunications

NATURE COMMUNICATIONS | DOI: 10.1038/s41467-017-01904-7
ARTICLE
 16. Nielsen, M. A. &amp; Chuang, I. L. Quantum Computation and Quantum Information: 10th Anniversary Edition. 10th edn, (Cambridge University Press, New York, 2011).
17. Milburn, G., Schneider, S. &amp; James, D. Ion trap quantum computing with warm ions. Fortschr. Phys. 48, 801–810 (2000).
18. Olmschenk, S. et al. Manipulation and detection of a trapped Yb+ hyperfine qubit. Phys. Rev. A 76, 052314 (2007).
19. Hayes, D. et al. Entanglement of atomic qubits using an optical frequency comb. Phys. Rev. Lett. 104, 140501 (2010).
20. Solano, E., de Matos Filho, R. L. &amp; Zagury, N. Deterministic bell states and measurement of the motional state of two trapped ions. Phys. Rev. A 59, R2539–R2543 (1999).
21. Mølmer, K. &amp; Sørensen, A. Multiparticle entanglement of hot trapped ions. Phys. Rev. Lett. 82, 1835–1838 (1999).
22. Zhu, S.-L., Monroe, C. &amp; Duan, L.-M. Arbitrary-speed quantum gates within large ion crystals through minimum control of laser beams. Europhys. Lett. 73, 485 (2006).
23. Choi, T. et al. Optimal quantum control of multimode couplings between trapped ion qubits for scalable entanglement. Phys. Rev. Lett. 112, 190502 (2014).
24. Cory, D. G., Price, M. D. &amp; Havel, T. F. Nuclear magnetic resonance spectroscopy: an experimentally accessible paradigm for quantum computing. Physica D 120, 82–101 (1998).
25. Monz, T. et al. Realization of the quantum toffoli gate with trapped ions. Phys. Rev. Lett. 102, 040501 (2009).
26. Linke, N. M. et al. Experimental comparison of two quantum computing architectures. Proc. Natl Acad. Sci. USA 114, 3305–3310 (2017).
27. Barenco, A. et al. Elementary gates for quantum computation. Phys. Rev. A 52, 3457–3467 (1995).
28. Maslov, D. Basic circuit compilation techniques for an ion-trap quantum machine. New J. Phys. 19, 023035 (2017).
29. Maslov, D. Advantages of using relative-phase Toffoli gates with an application to multiple control Toffoli optimization. Phys. Rev. A 93, 022311 (2016).
30. Chiaverini, J. et al. Implementation of the semiclassical quantum fourier
transform in a scalable system. Science 308, 997–1000 (2005).
31. Shen, C. &amp; Duan, L.-M. Correcting detection errors in quantum state engineering through data processing. New J. Phys. 14, 053053 (2012).
Acknowledgements
We thank S. Kimmel for helpful discussions. Circuits were drawn using the qcircuit. tex package. This work was supported by the ARO with funds from the IARPA
LogiQ program, the AFOSR MURI program, and the NSF Physics Frontier Center at JQI. This material was partially based on work supported by the National Science Foundation during D.M.’s assignment at the Foundation. Any opinion, finding, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.
Author contributions
C.F., D.M., N.M.L., S.D. and C.M. designed the research; C.F., K.A.L., N.M.L., S.D. and C.M. collected and analyzed data; D.M. contributed to the theory; and C.F., D.M., K.A.L., N.M.L., S.D. and C.M. contributed to the manuscript.
Additional information
Supplementary Information accompanies this paper at doi:10.1038/s41467-017-01904-7. Competing interests: C.M. is the co-founder and chief scientist at IonQ, Inc. The
remaining authors declare no competing financial interests.
Reprints and permission information is available online at http://npg.nature.com/
reprintsandpermissions/
Publisher's note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
Open Access This article is licensed under a Creative Commons
Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/ licenses/by/4.0/.
© The Author(s) 2017
 NATURE COMMUNICATIONS|8:1918 |DOI: 10.1038/s41467-017-01904-7|www.nature.com/naturecommunications 9
</Text>
        </Document>
        <Document ID="308B0151-7B62-48E1-BD42-2201A911DF5F">
            <Title>Shor's Algorithm</Title>
            <Text>  
Learn Quantum Computation using Qiskit
What is Quantum?
0. Prerequisites
0.1 Setting Up Your Environment
0.2 Python and Jupyter Notebooks
1. Quantum States and Qubits
1.1 Introduction
1.2 The Atoms of Computation
1.3 Representing Qubit States
1.4 Single Qubit Gates
1.5 The Case for Quantum
2. Multiple Qubits and Entanglement
2.1 Introduction
2.2 Multiple Qubits and Entangled States
2.3 Phase Kickback
2.4 More Circuit Identities
2.5 Proving Universality
2.6 Classical Computation on a Quantum Computer
3. Quantum Protocols and Quantum Algorithms
3.1 Defining Quantum Circuits
3.2 Quantum Teleportation
3.3 Superdense Coding
3.4 Deutsch-Jozsa Algorithm
3.5 Bernstein-Vazirani Algorithm
3.6 Simon's Algorithm
3.7 Quantum Fourier Transform
3.8 Quantum Phase Estimation
3.9 Shor's Algorithm
3.10 Grover's Algorithm
3.11 Quantum Counting
3.12 Quantum Key Distribution
4. Quantum Algorithms for Applications
4.1 Applied Quantum Algorithms
4.1.1 Solving Linear Systems of Equations using HHL
4.1.2 Simulating Molecules using VQE
4.1.3 Solving combinatorial optimization problems using QAOA
4.1.4 Solving Satisfiability Problems using Grover's Algorithm
4.1.5 Hybrid quantum-classical Neural Networks with PyTorch and Qiskit
4.2 Implementations of Recent Quantum Algorithms
4.2.1 Variational Quantum Linear Solver
5. Investigating Quantum Hardware Using Quantum Circuits
5.1 Introduction to Quantum Error Correction using Repetition Codes
5.2 Measurement Error Mitigation
5.3 Randomized Benchmarking
5.4 Measuring Quantum Volume
6. Investigating Quantum Hardware Using Microwave Pulses
6.1 Calibrating Qubits with Qiskit Pulse
6.2 Accessing Higher Energy States
6.3 Introduction to Transmon Physics
6.4 Circuit Quantum Electrodynamics
7. Problem Sets &amp; Exercises
Set 1. Classical Logic Gates with Quantum Circuits
Set 2. Basic Synthesis of Single-Qubit Gates
Set 3. Building the Best AND Gate
8. Appendix
8.1 Linear Algebra
8.2 Qiskit
9. Games &amp; Demos
Hello Qiskit Game
Estimating Pi Using Quantum Phase Estimation Algorithm
Interactivity Index
Powered by Jupyter Book

Shor's Algorithm
Shor’s algorithm is famous for factoring integers in polynomial time. Since the best-known classical algorithm requires superpolynomial time to factor the product of two primes, the widely used cryptosystem, RSA, relies on factoring being impossible for large enough integers.
In this chapter we will focus on the quantum part of Shor’s algorithm, which actually solves the problem of period finding. Since a factoring problem can be turned into a period finding problem in polynomial time, an efficient period finding algorithm can be used to factor integers efficiently too. For now its enough to show that if we can compute the period of $a^x\bmod N$ efficiently, then we can also efficiently factor. Since period finding is a worthy problem in its own right, we will first solve this, then discuss how this can be used to factor in section 5.
import matplotlib.pyplot as plt
import numpy as np
from qiskit import QuantumCircuit, Aer, execute
from qiskit.visualization import plot_histogram
from math import gcd
from numpy.random import randint
from tabulate import tabulate
from fractions import Fraction
print("Imports Successful")
 try
Imports Successful
1. The Problem: Period Finding 
Let’s look at the periodic function:
$$ f(x) = a^x \bmod{N}$$
Reminder: Modulo &amp; Modular Arithmetic (Click here to expand)
where $a$ and $N$ are positive integers, $a$ is less than $N$, and they have no common factors. The period, or order ($r$), is the smallest (non-zero) integer such that:
$$a^r \bmod N = 1 $$
We can see an example of this function plotted on the graph below. Note that the lines between points are to help see the periodicity and do not represent the intermediate values between the x-markers.
N = 35
a = 3

# Calculate the plotting data
xvals = np.arange(35)
yvals = [np.mod(a**x, N) for x in xvals]

# Use matplotlib to display it nicely
fig, ax = plt.subplots()
ax.plot(xvals, yvals, linewidth=1, linestyle='dotted', marker='x')
ax.set(xlabel='$x$', ylabel='$%i^x$ mod $%i$' % (a, N),
       title="Example of Periodic Function in Shor's Algorithm")
try: # plot r on the graph
    r = yvals[1:].index(1) +1 
    plt.annotate(text='', xy=(0,1), xytext=(r,1), arrowprops=dict(arrowstyle='&lt;-&gt;'))
    plt.annotate(text='$r=%i$' % r, xy=(r/3,1.5))
except:
    print('Could not find period, check a &lt; N and have no common factors.')
 try
2. The Solution 
Shor’s solution was to use quantum phase estimation on the unitary operator:
$$ U|y\rangle \equiv |ay \bmod N \rangle $$
To see how this is helpful, let’s work out what an eigenstate of U might look like. If we started in the state $|1\rangle$, we can see that each successive application of U will multiply the state of our register by $a \pmod N$, and after $r$ applications we will arrive at the state $|1\rangle$ again. For example with $a = 3$ and $N = 35$:
$$\begin{aligned} U|1\rangle &amp;= |3\rangle &amp; \\ U^2|1\rangle &amp;= |9\rangle \\ U^3|1\rangle &amp;= |27\rangle \\ &amp; \vdots \\ U^{(r-1)}|1\rangle &amp;= |12\rangle \\ U^r|1\rangle &amp;= |1\rangle \end{aligned}$$
ax.set(xlabel='Number of applications of U', ylabel='End state of register',
       title="Effect of Successive Applications of U")
fig
 try
So a superposition of the states in this cycle ($|u_0\rangle$) would be an eigenstate of $U$:
$$|u_0\rangle = \tfrac{1}{\sqrt{r}}\sum_{k=0}^{r-1}{|a^k \bmod N\rangle} $$
Click to Expand: Example with $a = 3$ and $N=35$
This eigenstate has an eigenvalue of 1, which isn’t very interesting. A more interesting eigenstate could be one in which the phase is different for each of these computational basis states. Specifically, let’s look at the case in which the phase of the $k$th state is proportional to $k$:
$$\begin{aligned} |u_1\rangle &amp;= \tfrac{1}{\sqrt{r}}\sum_{k=0}^{r-1}{e^{-\tfrac{2\pi i k}{r}}|a^k \bmod N\rangle}\\[10pt] U|u_1\rangle &amp;= e^{\tfrac{2\pi i}{r}}|u_1\rangle \end{aligned} $$
Click to Expand: Example with $a = 3$ and $N=35$
This is particularly interesting eigenvalue as it contains $r$. in fact, $r$ has to be included to make sure the phase differences between the $r$ computational basis states are equal. This is not the only eigenstate with this behaviour, to generalise this further, we can multiply an integer, $s$, to this phase difference, which will show up in our eigenvalue:
$$\begin{aligned} |u_s\rangle &amp;= \tfrac{1}{\sqrt{r}}\sum_{k=0}^{r-1}{e^{-\tfrac{2\pi i s k}{r}}|a^k \bmod N\rangle}\\[10pt] U|u_s\rangle &amp;= e^{\tfrac{2\pi i s}{r}}|u_s\rangle \end{aligned} $$
Click to Expand: Example with $a = 3$ and $N=35$
We now have a unique eigenstate for each integer value of $s$ where $0 &lt; s &lt; r-1$. Very conveniently, if we sum up all these eigenstates, the different phases cancel out all computational basis states except $|1\rangle$:
$$ \tfrac{1}{\sqrt{r}}\sum_{s=0}^{r-1} |u_s\rangle = |1\rangle$$
Click to Expand: Example with $a = 7$ and $N=15$
Since the computational basis state $|1\rangle$ is a superposition of these eigenstates, which means if we do QPE on $U$ using the state $|1\rangle$, we will measure a phase:
$$\phi = \frac{s}{r}$$
Where $s$ is a random integer between $0$ and $r-1$. We finally use the continued fractions algorithm on $\phi$ to find $r$. The circuit diagram looks like this (note that this diagram uses Qiskit's qubit ordering convention):


We will next demonstrate Shor’s algorithm using Qiskit’s simulators. For this demonstration we will provide the circuits for $U$ without explanation, but in section 4 we will discuss how circuits for $U^{2^j}$ can be constructed efficiently.
3. Qiskit Implementation 
In this example we will solve the period finding problem for $a=7$ and $N=15$. We provide the circuits for $U$ where:
$$U|y\rangle = |ay\bmod 15\rangle $$
without explanation. To create $U^x$, we will simply repeat the circuit $x$ times. In the next section we will discuss a general method for creating these circuits efficiently. The function c_amod15 returns the controlled-U gate for a, repeated power times.
def c_amod15(a, power):
    """Controlled multiplication by a mod 15"""
    if a not in [2,7,8,11,13]:
        raise ValueError("'a' must be 2,7,8,11 or 13")
    U = QuantumCircuit(4)        
    for iteration in range(power):
        if a in [2,13]:
            U.swap(0,1)
            U.swap(1,2)
            U.swap(2,3)
        if a in [7,8]:
            U.swap(2,3)
            U.swap(1,2)
            U.swap(0,1)
        if a == 11:
            U.swap(1,3)
            U.swap(0,2)
        if a in [7,11,13]:
            for q in range(4):
                U.x(q)
    U = U.to_gate()
    U.name = "%i^%i mod 15" % (a, power)
    c_U = U.control()
    return c_U
 try
We will use 8 counting qubits:
# Specify variables
n_count = 8 # number of counting qubits
a = 7
 try
We also provide the circuit for the inverse QFT (you can read more about the QFT in the quantum Fourier transform chapter):
def qft_dagger(n):
    """n-qubit QFTdagger the first n qubits in circ"""
    qc = QuantumCircuit(n)
    # Don't forget the Swaps!
    for qubit in range(n//2):
        qc.swap(qubit, n-qubit-1)
    for j in range(n):
        for m in range(j):
            qc.cu1(-np.pi/float(2**(j-m)), m, j)
        qc.h(j)
    qc.name = "QFT†"
    return qc
 try
With these building blocks we can easily construct the circuit for Shor's algorithm:
# Create QuantumCircuit with n_count counting qubits
# plus 4 qubits for U to act on
qc = QuantumCircuit(n_count + 4, n_count)

# Initialise counting qubits
# in state |+&gt;
for q in range(n_count):
    qc.h(q)
    
# And ancilla register in state |1&gt;
qc.x(3+n_count)

# Do controlled-U operations
for q in range(n_count):
    qc.append(c_amod15(a, 2**q), 
             [q] + [i+n_count for i in range(4)])

# Do inverse-QFT
qc.append(qft_dagger(n_count), range(n_count))

# Measure circuit
qc.measure(range(n_count), range(n_count))
qc.draw('text')
 try
      ┌───┐                                                            »
 q_0: ┤ H ├───────■────────────────────────────────────────────────────»
      ├───┤       │                                                    »
 q_1: ┤ H ├───────┼──────────────■─────────────────────────────────────»
      ├───┤       │              │                                     »
 q_2: ┤ H ├───────┼──────────────┼──────────────■──────────────────────»
      ├───┤       │              │              │                      »
 q_3: ┤ H ├───────┼──────────────┼──────────────┼──────────────■───────»
      ├───┤       │              │              │              │       »
 q_4: ┤ H ├───────┼──────────────┼──────────────┼──────────────┼───────»
      ├───┤       │              │              │              │       »
 q_5: ┤ H ├───────┼──────────────┼──────────────┼──────────────┼───────»
      ├───┤       │              │              │              │       »
 q_6: ┤ H ├───────┼──────────────┼──────────────┼──────────────┼───────»
      ├───┤       │              │              │              │       »
 q_7: ┤ H ├───────┼──────────────┼──────────────┼──────────────┼───────»
      └───┘┌─────┴┼──────┐┌─────┴┼──────┐┌─────┴┼──────┐┌─────┴┼──────┐»
 q_8: ─────┤0     │      ├┤0     │      ├┤0     │      ├┤0     │      ├»
           │             ││             ││             ││             │»
 q_9: ─────┤1            ├┤1            ├┤1            ├┤1            ├»
           │  7^1 mod 15 ││  7^2 mod 15 ││  7^4 mod 15 ││  7^8 mod 15 │»
q_10: ─────┤2            ├┤2            ├┤2            ├┤2            ├»
      ┌───┐│             ││             ││             ││             │»
q_11: ┤ X ├┤3            ├┤3            ├┤3            ├┤3            ├»
      └───┘└─────────────┘└─────────────┘└─────────────┘└─────────────┘»
 c_0: ═════════════════════════════════════════════════════════════════»
                                                                       »
 c_1: ═════════════════════════════════════════════════════════════════»
                                                                       »
 c_2: ═════════════════════════════════════════════════════════════════»
                                                                       »
 c_3: ═════════════════════════════════════════════════════════════════»
                                                                       »
 c_4: ═════════════════════════════════════════════════════════════════»
                                                                       »
 c_5: ═════════════════════════════════════════════════════════════════»
                                                                       »
 c_6: ═════════════════════════════════════════════════════════════════»
                                                                       »
 c_7: ═════════════════════════════════════════════════════════════════»
                                                                       »
«                                                                       »
« q_0: ─────────────────────────────────────────────────────────────────»
«                                                                       »
« q_1: ─────────────────────────────────────────────────────────────────»
«                                                                       »
« q_2: ─────────────────────────────────────────────────────────────────»
«                                                                       »
« q_3: ─────────────────────────────────────────────────────────────────»
«                                                                       »
« q_4: ───────■─────────────────────────────────────────────────────────»
«             │                                                         »
« q_5: ───────┼───────────────■─────────────────────────────────────────»
«             │               │                                         »
« q_6: ───────┼───────────────┼───────────────■─────────────────────────»
«             │               │               │                         »
« q_7: ───────┼───────────────┼───────────────┼────────────────■────────»
«      ┌──────┴───────┐┌──────┴───────┐┌──────┴───────┐┌──────┴┼───────┐»
« q_8: ┤0             ├┤0             ├┤0             ├┤0      │       ├»
«      │              ││              ││              ││               │»
« q_9: ┤1             ├┤1             ├┤1             ├┤1              ├»
«      │  7^16 mod 15 ││  7^32 mod 15 ││  7^64 mod 15 ││  7^128 mod 15 │»
«q_10: ┤2             ├┤2             ├┤2             ├┤2              ├»
«      │              ││              ││              ││               │»
«q_11: ┤3             ├┤3             ├┤3             ├┤3              ├»
«      └──────────────┘└──────────────┘└──────────────┘└───────────────┘»
« c_0: ═════════════════════════════════════════════════════════════════»
«                                                                       »
« c_1: ═════════════════════════════════════════════════════════════════»
«                                                                       »
« c_2: ═════════════════════════════════════════════════════════════════»
«                                                                       »
« c_3: ═════════════════════════════════════════════════════════════════»
«                                                                       »
« c_4: ═════════════════════════════════════════════════════════════════»
«                                                                       »
« c_5: ═════════════════════════════════════════════════════════════════»
«                                                                       »
« c_6: ═════════════════════════════════════════════════════════════════»
«                                                                       »
« c_7: ═════════════════════════════════════════════════════════════════»
«                                                                       »
«      ┌───────┐┌─┐                     
« q_0: ┤0      ├┤M├─────────────────────
«      │       │└╥┘┌─┐                  
« q_1: ┤1      ├─╫─┤M├──────────────────
«      │       │ ║ └╥┘┌─┐               
« q_2: ┤2      ├─╫──╫─┤M├───────────────
«      │       │ ║  ║ └╥┘┌─┐            
« q_3: ┤3      ├─╫──╫──╫─┤M├────────────
«      │  QFT† │ ║  ║  ║ └╥┘┌─┐         
« q_4: ┤4      ├─╫──╫──╫──╫─┤M├─────────
«      │       │ ║  ║  ║  ║ └╥┘┌─┐      
« q_5: ┤5      ├─╫──╫──╫──╫──╫─┤M├──────
«      │       │ ║  ║  ║  ║  ║ └╥┘┌─┐   
« q_6: ┤6      ├─╫──╫──╫──╫──╫──╫─┤M├───
«      │       │ ║  ║  ║  ║  ║  ║ └╥┘┌─┐
« q_7: ┤7      ├─╫──╫──╫──╫──╫──╫──╫─┤M├
«      └───────┘ ║  ║  ║  ║  ║  ║  ║ └╥┘
« q_8: ──────────╫──╫──╫──╫──╫──╫──╫──╫─
«                ║  ║  ║  ║  ║  ║  ║  ║ 
« q_9: ──────────╫──╫──╫──╫──╫──╫──╫──╫─
«                ║  ║  ║  ║  ║  ║  ║  ║ 
«q_10: ──────────╫──╫──╫──╫──╫──╫──╫──╫─
«                ║  ║  ║  ║  ║  ║  ║  ║ 
«q_11: ──────────╫──╫──╫──╫──╫──╫──╫──╫─
«                ║  ║  ║  ║  ║  ║  ║  ║ 
« c_0: ══════════╩══╬══╬══╬══╬══╬══╬══╬═
«                   ║  ║  ║  ║  ║  ║  ║ 
« c_1: ═════════════╩══╬══╬══╬══╬══╬══╬═
«                      ║  ║  ║  ║  ║  ║ 
« c_2: ════════════════╩══╬══╬══╬══╬══╬═
«                         ║  ║  ║  ║  ║ 
« c_3: ═══════════════════╩══╬══╬══╬══╬═
«                            ║  ║  ║  ║ 
« c_4: ══════════════════════╩══╬══╬══╬═
«                               ║  ║  ║ 
« c_5: ═════════════════════════╩══╬══╬═
«                                  ║  ║ 
« c_6: ════════════════════════════╩══╬═
«                                     ║ 
« c_7: ═══════════════════════════════╩═
«                                       
Let's see what results we measure:
backend = Aer.get_backend('qasm_simulator')
results = execute(qc, backend, shots=2048).result()
counts = results.get_counts()
plot_histogram(counts)
 try
Since we have 3 qubits, these results correspond to measured phases of:
rows, measured_phases = [], []
for output in counts:
    decimal = int(output, 2)  # Convert (base 2) string to decimal
    phase = decimal/(2**n_count) # Find corresponding eigenvalue
    measured_phases.append(phase)
    # Add these values to the rows in our table:
    rows.append(["%s(bin) = %i(dec)" % (output, decimal), 
                 "%i/%i = %.2f" % (decimal, 2**n_count, phase)])
# Can use tabulate to print the rows this as a nice ASCII table:
print(tabulate(rows, 
               headers=["Register Output", "Phase"], 
               colalign=("left","right")))
 try
Register Output                    Phase
------------------------  --------------
00000000(bin) = 0(dec)      0/256 = 0.00
10000000(bin) = 128(dec)  128/256 = 0.50
01000000(bin) = 64(dec)    64/256 = 0.25
11000000(bin) = 192(dec)  192/256 = 0.75
We can now use the continued fractions algorithm to attempt to find $s$ and $r$. Python has this functionality built in: We can use the fractions module to turn a float into a Fraction object, for example:
Fraction(0.666)
 try
Fraction(5998794703657501, 9007199254740992)
5998794703657501/9007199254740992
 try
0.666
Because this gives fractions that return the result exactly (in this case, 0.6660000...), this can give gnarly results like the one above. We can use the .limit_denominator() method to get the fraction that most closely resembles our float, with denominator below a certain value:
# Get fraction that most closely resembles 0.666
# with denominator &lt; 15
Fraction(0.666).limit_denominator(15)
 try
Fraction(2, 3)
Much nicer! The order (r) must be less than N, so we will set the maximum denominator to be 15:
rows = []
for phase in measured_phases:
    frac = Fraction(phase).limit_denominator(15)
    rows.append([phase, "%i/%i" % (frac.numerator, frac.denominator), frac.denominator])
# Print as nice ASCII table
print(tabulate(rows, 
               headers=["Phase", "Fraction", "Guess for r"], 
               colalign=('right','right','right')))
 try
  Phase    Fraction    Guess for r
-------  ----------  -------------
      0         0/1              1
    0.5         1/2              2
   0.25         1/4              4
   0.75         3/4              4
We can see that two of the measured eigenvalues provided us with the correct result: $r=4$, and we can see that Shor’s algorithm has a chance of failing. These bad results are because $s = 0$, or because $s$ and $r$ are not coprime and instead of $r$ we are given a factor of $r$. The easiest solution to this is to simply repeat the experiment until we get a satisfying result for $r$.
Quick Exercise 

Modify the circuit above for values of $a = 2, 8, 11$ and $13$. What results do you get and why?
4. Modular Exponentiation 
You may have noticed that the method of creating the $U^{2^j}$ gates by repeating $U$ grows exponentially with $j$ and will not result in a polynomial time algorithm. We want a way to create the operator:
$$ U^{2^j}|y\rangle = |a^{2^j}y \bmod N \rangle $$
that grows polynomially with $j$. Fortunately, calculating:
$$ a^{2^j} \bmod N$$
efficiently is possible. Classical computers can use an algorithm known as repeated squaring to calculate an exponential. In our case, since we are only dealing with exponentials of the form $2^j$, the repeated squaring algorithm becomes very simple:
def a2jmodN(a, j, N):
    """Compute a^{2^j} (mod N) by repeated squaring"""
    for i in range(j):
        a = np.mod(a**2, N)
    return a
 try
a2jmodN(7, 2049, 53)
 try
47
If an efficient algorithm is possible in Python, then we can use the same algorithm on a quantum computer. Unfortunately, despite scaling polynomially with $j$, modular exponentiation circuits are not straightforward and are the bottleneck in Shor’s algorithm. A beginner-friendly implementation can be found in reference [1].
5. Factoring from Period Finding 
Not all factoring problems are difficult; we can spot an even number instantly and know that one of its factors is 2. In fact, there are specific criteria for choosing numbers that are difficult to factor, but the basic idea is to choose the product of two large prime numbers.
A general factoring algorithm will first check to see if there is a shortcut to factoring the integer (is the number even? Is the number of the form $N = a^b$?), before using Shor’s period finding for the worst-case scenario. Since we aim to focus on the quantum part of the algorithm, we will jump straight to the case in which N is the product of two primes.
Example: Factoring 15 

To see an example of factoring on a small number of qubits, we will factor 15, which we all know is the product of the not-so-large prime numbers 3 and 5.
N = 15
 try
The first step is to choose a random number, $x$, between $1$ and $N-1$:
np.random.seed(1) # This is to make sure we get reproduceable results
a = randint(2, 15)
print(a)
 try
7
Next we quickly check it isn't already a non-trivial factor of $N$:
from math import gcd # greatest common divisor
gcd(a, 15)
 try
1
Great. Next, we do Shor's order finding algorithm for a = 7 and N = 15. Remember that the phase we measure will be $s/r$ where:
$$ a^r \bmod N = 1 $$
and $s$ is a random integer between 0 and $r-1$.
def qpe_amod15(a):
    n_count = 3
    qc = QuantumCircuit(4+n_count, n_count)
    for q in range(n_count):
        qc.h(q)     # Initialise counting qubits in state |+&gt;
    qc.x(3+n_count) # And ancilla register in state |1&gt;
    for q in range(n_count): # Do controlled-U operations
        qc.append(c_amod15(a, 2**q), 
                 [q] + [i+n_count for i in range(4)])
    qc.append(qft_dagger(n_count), range(n_count)) # Do inverse-QFT
    qc.measure(range(n_count), range(n_count))
    # Simulate Results
    backend = Aer.get_backend('qasm_simulator')
    # Setting memory=True below allows us to see a list of each sequential reading
    result = execute(qc, backend, shots=1, memory=True).result()
    readings = result.get_memory()
    print("Register Reading: " + readings[0])
    phase = int(readings[0],2)/(2**n_count)
    print("Corresponding Phase: %f" % phase)
    return phase
 try
From this phase, we can easily find a guess for $r$:
np.random.seed(3) # This is to make sure we get reproduceable results
phase = qpe_amod15(a) # Phase = s/r
Fraction(phase).limit_denominator(15) # Denominator should (hopefully!) tell us r
 try
Register Reading: 000
Corresponding Phase: 0.000000
Fraction(0, 1)
frac = Fraction(phase).limit_denominator(15)
s, r = frac.numerator, frac.denominator
print(r)
 try
1
Now we have $r$, we might be able to use this to find a factor of $N$. Since:
$$a^r \bmod N = 1 $$
then:
$$(a^r - 1) \bmod N = 0 $$
which mean $N$ must divide $a^r-1$. And if $r$ is also even, then we can write:
$$a^r -1 = (a^{r/2}-1)(a^{r/2}+1)$$
(if $r$ is not even, we cannot go further and must try again with a different value for $a$). There is then a high probability that the greatest common divisor of either $a^{r/2}-1$, or $a^{r/2}+1$ is a factor of $N$ [2]:
guesses = [gcd(a**(r//2)-1, N), gcd(a**(r//2)+1, N)]
print(guesses)
 try
[15, 1]
The cell below repeats the algorithm until at least one factor of 15 is found. You should try re-running the cell a few times to see how it behaves.
a = 7
factor_found = False
attempt = 0
while not factor_found:
    attempt += 1
    print("\nAttempt %i:" % attempt)
    phase = qpe_amod15(a) # Phase = s/r
    frac = Fraction(phase).limit_denominator(15) # Denominator should (hopefully!) tell us r
    r = frac.denominator
    print("Result: r = %i" % r)
    if phase != 0:
        # Guesses for factors are gcd(x^{r/2} ±1 , 15)
        guesses = [gcd(a**(r//2)-1, 15), gcd(a**(r//2)+1, 15)]
        print("Guessed Factors: %i and %i" % (guesses[0], guesses[1]))
        for guess in guesses:
            if guess != 1 and (15 % guess) == 0: # Check to see if guess is a factor
                print("*** Non-trivial factor found: %i ***" % guess)
                factor_found = True
 try
Attempt 1:
Register Reading: 000
Corresponding Phase: 0.000000
Result: r = 1

Attempt 2:
Register Reading: 100
Corresponding Phase: 0.500000
Result: r = 2
Guessed Factors: 3 and 1
*** Non-trivial factor found: 3 ***
6. References 
Stephane Beauregard, Circuit for Shor's algorithm using 2n+3 qubits, arXiv:quant-ph/0205095
M. Nielsen and I. Chuang, Quantum Computation and Quantum Information, Cambridge Series on Information and the Natural Sciences (Cambridge University Press, Cambridge, 2000). (Page 633)
import qiskit
qiskit.__qiskit_version__
 try
{'qiskit-terra': '0.14.2',
 'qiskit-aer': '0.5.2',
 'qiskit-ignis': '0.3.3',
 'qiskit-ibmq-provider': '0.7.2',
 'qiskit-aqua': '0.7.3',
 'qiskit': '0.19.6'}
〈 Quantum Phase Estimation
Grover's Algorithm 〉
This page was created by The Jupyter Book Community</Text>
        </Document>
        <Document ID="90B86704-8752-4DF0-97C3-868359CFC739">
            <Title>teleportation</Title>
            <Text>I Fundamental concepts
1 Introduction and overview
Science offers the boldest metaphysics of the age. It is a thoroughly human construct, driven by the faith that if we dream, press to discover, explain, and dream again, thereby plunging repeatedly into new terrain, the world will some- how come clearer and we will grasp the true strangeness of the universe. And the strangeness will all prove to be connected, and make sense.
– Edward O. Wilson
Information is physical.
– Rolf Landauer
What are the fundamental concepts of quantum computation and quantum information? How did these concepts develop? To what uses may they be put? How will they be pre- sented in this book? The purpose of this introductory chapter is to answer these questions by developing in broad brushstrokes a picture of the field of quantum computation and quantum information. The intent is to communicate a basic understanding of the central concepts of the field, perspective on how they have been developed, and to help you decide how to approach the rest of the book.
Our story begins in Section 1.1 with an account of the historical context in which quantum computation and quantum information has developed. Each remaining section in the chapter gives a brief introduction to one or more fundamental concepts from the field: quantum bits (Section 1.2), quantum computers, quantum gates and quantum cir- cuits (Section 1.3), quantum algorithms (Section 1.4), experimental quantum information processing (Section 1.5), and quantum information and communication (Section 1.6).
Along the way, illustrative and easily accessible developments such as quantum tele- portation and some simple quantum algorithms are given, using the basic mathematics taught in this chapter. The presentation is self-contained, and designed to be accessible even without a background in computer science or physics. As we move along, we give pointers to more in-depth discussions in later chapters, where references and suggestions for further reading may also be found.
If as you read you’re finding the going rough, skip on to a spot where you feel more comfortable. At points we haven’t been able to avoid using a little technical lingo which won’t be completely explained until later in the book. Simply accept it for now, and come back later when you understand all the terminology in more detail. The emphasis in this first chapter is on the big picture, with the details to be filled in later.
1.1 Global perspectives
Quantum computation and quantum information is the study of the information process- ing tasks that can be accomplished using quantum mechanical systems. Sounds pretty
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

2 Introduction and overview
 simple and obvious, doesn’t it? Like many simple but profound ideas it was a long time before anybody thought of doing information processing using quantum mechanical sys- tems. To see why this is the case, we must go back in time and look in turn at each of the fields which have contributed fundamental ideas to quantum computation and quantum information – quantum mechanics, computer science, information theory, and cryptography. As we take our short historical tour of these fields, think of yourself first as a physicist, then as a computer scientist, then as an information theorist, and finally as a cryptographer, in order to get some feel for the disparate perspectives which have come together in quantum computation and quantum information.
1.1.1 History of quantum computation and quantum information
Our story begins at the turn of the twentieth century when an unheralded revolution was underway in science. A series of crises had arisen in physics. The problem was that the theories of physics at that time (now dubbed classical physics) were predicting absurdities such as the existence of an ‘ultraviolet catastrophe’ involving infinite energies, or electrons spiraling inexorably into the atomic nucleus. At first such problems were resolved with the addition of ad hoc hypotheses to classical physics, but as a better understanding of atoms and radiation was gained these attempted explanations became more and more convoluted. The crisis came to a head in the early 1920s after a quarter century of turmoil, and resulted in the creation of the modern theory of quantum mechanics. Quantum mechanics has been an indispensable part of science ever since, and has been applied with enormous success to everything under and inside the Sun, including the structure of the atom, nuclear fusion in stars, superconductors, the structure of DNA, and the elementary particles of Nature.
What is quantum mechanics? Quantum mechanics is a mathematical framework or set of rules for the construction of physical theories. For example, there is a physical theory known as quantum electrodynamics which describes with fantastic accuracy the interac- tion of atoms and light. Quantum electrodynamics is built up within the framework of quantum mechanics, but it contains specific rules not determined by quantum mechanics. The relationship of quantum mechanics to specific physical theories like quantum elec- trodynamics is rather like the relationship of a computer’s operating system to specific applications software – the operating system sets certain basic parameters and modes of operation, but leaves open how specific tasks are accomplished by the applications.
The rules of quantum mechanics are simple but even experts find them counter- intuitive, and the earliest antecedents of quantum computation and quantum information may be found in the long-standing desire of physicists to better understand quantum mechanics. The best known critic of quantum mechanics, Albert Einstein, went to his grave unreconciled with the theory he helped invent. Generations of physicists since have wrestled with quantum mechanics in an effort to make its predictions more palatable. One of the goals of quantum computation and quantum information is to develop tools which sharpen our intuition about quantum mechanics, and make its predictions more transparent to human minds.
For example, in the early 1980s, interest arose in whether it might be possible to use quantum effects to signal faster than light – a big no-no according to Einstein’s theory of relativity. The resolution of this problem turns out to hinge on whether it is possible to clone an unknown quantum state, that is, construct a copy of a quantum state. If cloning were possible, then it would be possible to signal faster than light using quantum effects.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Global perspectives 3
 However, cloning – so easy to accomplish with classical information (consider the words in front of you, and where they came from!) – turns out not to be possible in general in quantum mechanics. This no-cloning theorem, discovered in the early 1980s, is one of the earliest results of quantum computation and quantum information. Many refinements of the no-cloning theorem have since been developed, and we now have conceptual tools which allow us to understand how well a (necessarily imperfect) quantum cloning device might work. These tools, in turn, have been applied to understand other aspects of quantum mechanics.
A related historical strand contributing to the development of quantum computation and quantum information is the interest, dating to the 1970s, of obtaining complete con- trol over single quantum systems. Applications of quantum mechanics prior to the 1970s typically involved a gross level of control over a bulk sample containing an enormous number of quantum mechanical systems, none of them directly accessible. For example, superconductivity has a superb quantum mechanical explanation. However, because a su- perconductor involves a huge (compared to the atomic scale) sample of conducting metal, we can only probe a few aspects of its quantum mechanical nature, with the individual quantum systems constituting the superconductor remaining inaccessible. Systems such as particle accelerators do allow limited access to individual quantum systems, but again provide little control over the constituent systems.
Since the 1970s many techniques for controlling single quantum systems have been developed. For example, methods have been developed for trapping a single atom in an ‘atom trap’, isolating it from the rest of the world and allowing us to probe many different aspects of its behavior with incredible precision. The scanning tunneling microscope has been used to move single atoms around, creating designer arrays of atoms at will. Electronic devices whose operation involves the transfer of only single electrons have been demonstrated.
Why all this effort to attain complete control over single quantum systems? Setting aside the many technological reasons and concentrating on pure science, the principal answer is that researchers have done this on a hunch. Often the most profound insights in science come when we develop a method for probing a new regime of Nature. For example, the invention of radio astronomy in the 1930s and 1940s led to a spectacular sequence of discoveries, including the galactic core of the Milky Way galaxy, pulsars, and quasars. Low temperature physics has achieved its amazing successes by finding ways to lower the temperatures of different systems. In a similar way, by obtaining complete control over single quantum systems, we are exploring untouched regimes of Nature in the hope of discovering new and unexpected phenomena. We are just now taking our first steps along these lines, and already a few interesting surprises have been discovered in this regime. What else shall we discover as we obtain more complete control over single quantum systems, and extend it to more complex systems?
Quantum computation and quantum information fit naturally into this program. They provide a useful series of challenges at varied levels of difficulty for people devising methods to better manipulate single quantum systems, and stimulate the development of new experimental techniques and provide guidance as to the most interesting directions in which to take experiment. Conversely, the ability to control single quantum systems is essential if we are to harness the power of quantum mechanics for applications to quantum computation and quantum information.
Despite this intense interest, efforts to build quantum information processing systems
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

4 Introduction and overview
 have resulted in modest success to date. Small quantum computers, capable of doing dozens of operations on a few quantum bits (or qubits) represent the state of the art in quantum computation. Experimental prototypes for doing quantum cryptography – a way of communicating in secret across long distances – have been demonstrated, and are even at the level where they may be useful for some real-world applications. However, it remains a great challenge to physicists and engineers of the future to develop techniques for making large-scale quantum information processing a reality.
Let us turn our attention from quantum mechanics to another of the great intellectual triumphs of the twentieth century, computer science. The origins of computer science are lost in the depths of history. For example, cuneiform tablets indicate that by the time of Hammurabi (circa 1750 B.C.) the Babylonians had developed some fairly sophisticated algorithmic ideas, and it is likely that many of those ideas date to even earlier times.
The modern incarnation of computer science was announced by the great mathemati- cian Alan Turing in a remarkable 1936 paper. Turing developed in detail an abstract notion of what we would now call a programmable computer, a model for computation now known as the Turing machine, in his honor. Turing showed that there is a Universal Turing Machine that can be used to simulate any other Turing machine. Furthermore, he claimed that the Universal Turing Machine completely captures what it means to per- form a task by algorithmic means. That is, if an algorithm can be performed on any piece of hardware (say, a modern personal computer), then there is an equivalent algorithm for a Universal Turing Machine which performs exactly the same task as the algorithm running on the personal computer. This assertion, known as the Church–Turing thesis in honor of Turing and another pioneer of computer science, Alonzo Church, asserts the equivalence between the physical concept of what class of algorithms can be performed on some physical device with the rigorous mathematical concept of a Universal Turing Machine. The broad acceptance of this thesis laid the foundation for the development of a rich theory of computer science.
Not long after Turing’s paper, the first computers constructed from electronic com- ponents were developed. John von Neumann developed a simple theoretical model for how to put together in a practical fashion all the components necessary for a computer to be fully as capable as a Universal Turing Machine. Hardware development truly took off, though, in 1947, when John Bardeen, Walter Brattain, and Will Shockley developed the transistor. Computer hardware has grown in power at an amazing pace ever since, so much so that the growth was codified by Gordon Moore in 1965 in what has come to be known as Moore’s law, which states that computer power will double for constant cost roughly once every two years.
Amazingly enough, Moore’s law has approximately held true in the decades since the 1960s. Nevertheless, most observers expect that this dream run will end some time during the first two decades of the twenty-first century. Conventional approaches to the fabrication of computer technology are beginning to run up against fundamental difficulties of size. Quantum effects are beginning to interfere in the functioning of electronic devices as they are made smaller and smaller.
One possible solution to the problem posed by the eventual failure of Moore’s law is to move to a different computing paradigm. One such paradigm is provided by the theory of quantum computation, which is based on the idea of using quantum mechanics to perform computations, instead of classical physics. It turns out that while an ordinary computer can be used to simulate a quantum computer, it appears to be impossible to
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Global perspectives 5
 perform the simulation in an efficient fashion. Thus quantum computers offer an essential speed advantage over classical computers. This speed advantage is so significant that many researchers believe that no conceivable amount of progress in classical computation would be able to overcome the gap between the power of a classical computer and the power of a quantum computer.
What do we mean by ‘efficient’ versus ‘inefficient’ simulations of a quantum computer? Many of the key notions needed to answer this question were actually invented before the notion of a quantum computer had even arisen. In particular, the idea of efficient and inefficient algorithms was made mathematically precise by the field of computational complexity. Roughly speaking, an efficient algorithm is one which runs in time polynomial in the size of the problem solved. In contrast, an inefficient algorithm requires super- polynomial (typically exponential) time. What was noticed in the late 1960s and early 1970s was that it seemed as though the Turing machine model of computation was at least as powerful as any other model of computation, in the sense that a problem which could be solved efficiently in some model of computation could also be solved efficiently in the Turing machine model, by using the Turing machine to simulate the other model of computation. This observation was codified into a strengthened version of the Church– Turing thesis:
Any algorithmic process can be simulated efficiently using a Turing machine.
The key strengthening in the strong Church–Turing thesis is the word efficiently. If the strong Church–Turing thesis is correct, then it implies that no matter what type of machine we use to perform our algorithms, that machine can be simulated efficiently using a standard Turing machine. This is an important strengthening, as it implies that for the purposes of analyzing whether a given computational task can be accomplished efficiently, we may restrict ourselves to the analysis of the Turing machine model of computation.
One class of challenges to the strong Church–Turing thesis comes from the field of analog computation. In the years since Turing, many different teams of researchers have noticed that certain types of analog computers can efficiently solve problems believed to have no efficient solution on a Turing machine. At first glance these analog computers appear to violate the strong form of the Church–Turing thesis. Unfortunately for analog computation, it turns out that when realistic assumptions about the presence of noise in analog computers are made, their power disappears in all known instances; they cannot efficiently solve problems which are not efficiently solvable on a Turing machine. This lesson – that the effects of realistic noise must be taken into account in evaluating the efficiency of a computational model – was one of the great early challenges of quantum computation and quantum information, a challenge successfully met by the development of a theory of quantum error-correcting codes and fault-tolerant quantum computation. Thus, unlike analog computation, quantum computation can in principle tolerate a finite amount of noise and still retain its computational advantages.
The first major challenge to the strong Church–Turing thesis arose in the mid 1970s, when Robert Solovay and Volker Strassen showed that it is possible to test whether an in- teger is prime or composite using a randomized algorithm. That is, the Solovay–Strassen test for primality used randomness as an essential part of the algorithm. The algorithm did not determine whether a given integer was prime or composite with certainty. Instead, the algorithm could determine that a number was probably prime or else composite with
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

6 Introduction and overview
 certainty. By repeating the Solovay–Strassen test a few times it is possible to determine with near certainty whether a number is prime or composite. The Solovay-Strassen test was of especial significance at the time it was proposed as no deterministic test for pri- mality was then known, nor is one known at the time of this writing. Thus, it seemed as though computers with access to a random number generator would be able to efficiently perform computational tasks with no efficient solution on a conventional deterministic Turing machine. This discovery inspired a search for other randomized algorithms which has paid off handsomely, with the field blossoming into a thriving area of research.
Randomized algorithms pose a challenge to the strong Church–Turing thesis, suggest- ing that there are efficiently soluble problems which, nevertheless, cannot be efficiently solved on a deterministic Turing machine. This challenge appears to be easily resolved by a simple modification of the strong Church–Turing thesis:
Any algorithmic process can be simulated efficiently using a probabilistic Turing machine.
This ad hoc modification of the strong Church–Turing thesis should leave you feeling rather queasy. Might it not turn out at some later date that yet another model of computa- tion allows one to efficiently solve problems that are not efficiently soluble within Turing’s model of computation? Is there any way we can find a single model of computation which is guaranteed to be able to efficiently simulate any other model of computation?
Motivated by this question, in 1985 David Deutsch asked whether the laws of physics could be use to derive an even stronger version of the Church–Turing thesis. Instead of adopting ad hoc hypotheses, Deutsch looked to physical theory to provide a foundation for the Church–Turing thesis that would be as secure as the status of that physical theory. In particular, Deutsch attempted to define a computational device that would be capable of efficiently simulating an arbitrary physical system. Because the laws of physics are ultimately quantum mechanical, Deutsch was naturally led to consider computing devices based upon the principles of quantum mechanics. These devices, quantum analogues of the machines defined forty-nine years earlier by Turing, led ultimately to the modern conception of a quantum computer used in this book.
At the time of writing it is not clear whether Deutsch’s notion of a Universal Quan- tum Computer is sufficient to efficiently simulate an arbitrary physical system. Proving or refuting this conjecture is one of the great open problems of the field of quantum computation and quantum information. It is possible, for example, that some effect of quantum field theory or an even more esoteric effect based in string theory, quantum gravity or some other physical theory may take us beyond Deutsch’s Universal Quan- tum Computer, giving us a still more powerful model for computation. At this stage, we simply don’t know.
What Deutsch’s model of a quantum computer did enable was a challenge to the strong form of the Church–Turing thesis. Deutsch asked whether it is possible for a quantum computer to efficiently solve computational problems which have no efficient solution on a classical computer, even a probabilistic Turing machine. He then constructed a simple example suggesting that, indeed, quantum computers might have computational powers exceeding those of classical computers.
This remarkable first step taken by Deutsch was improved in the subsequent decade by many people, culminating in Peter Shor’s 1994 demonstration that two enormously important problems – the problem of finding the prime factors of an integer, and the so-
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Global perspectives 7
 called ‘discrete logarithm’ problem – could be solved efficiently on a quantum computer. This attracted widespread interest because these two problems were and still are widely believed to have no efficient solution on a classical computer. Shor’s results are a power- ful indication that quantum computers are more powerful than Turing machines, even probabilistic Turing machines. Further evidence for the power of quantum computers came in 1995 when Lov Grover showed that another important problem – the problem of conducting a search through some unstructured search space – could also be sped up on a quantum computer. While Grover’s algorithm did not provide as spectacular a speed- up as Shor’s algorithms, the widespread applicability of search-based methodologies has excited considerable interest in Grover’s algorithm.
At about the same time as Shor’s and Grover’s algorithms were discovered, many people were developing an idea Richard Feynman had suggested in 1982. Feynman had pointed out that there seemed to be essential difficulties in simulating quantum mechan- ical systems on classical computers, and suggested that building computers based on the principles of quantum mechanics would allow us to avoid those difficulties. In the 1990s several teams of researchers began fleshing this idea out, showing that it is indeed possible to use quantum computers to efficiently simulate systems that have no known efficient simulation on a classical computer. It is likely that one of the major applications of quantum computers in the future will be performing simulations of quantum mechan- ical systems too difficult to simulate on a classical computer, a problem with profound scientific and technological implications.
What other problems can quantum computers solve more quickly than classical com- puters? The short answer is that we don’t know. Coming up with good quantum algo- rithms seems to be hard. A pessimist might think that’s because there’s nothing quantum computers are good for other than the applications already discovered! We take a differ- ent view. Algorithm design for quantum computers is hard because designers face two difficult problems not faced in the construction of algorithms for classical computers. First, our human intuition is rooted in the classical world. If we use that intuition as an aid to the construction of algorithms, then the algorithmic ideas we come up with will be classical ideas. To design good quantum algorithms one must ‘turn off’ one’s classical intuition for at least part of the design process, using truly quantum effects to achieve the desired algorithmic end. Second, to be truly interesting it is not enough to design an algorithm that is merely quantum mechanical. The algorithm must be better than any existing classical algorithm! Thus, it is possible that one may find an algorithm which makes use of truly quantum aspects of quantum mechanics, that is nevertheless not of widespread interest because classical algorithms with comparable performance charac- teristics exist. The combination of these two problems makes the construction of new quantum algorithms a challenging problem for the future.
Even more broadly, we can ask if there are any generalizations we can make about the power of quantum computers versus classical computers. What is it that makes quantum computers more powerful than classical computers – assuming that this is indeed the case? What class of problems can be solved efficiently on a quantum computer, and how does that class compare to the class of problems that can be solved efficiently on a classical computer? One of the most exciting things about quantum computation and quantum information is how little is known about the answers to these questions! It is a great challenge for the future to understand these questions better.
Having come up to the frontier of quantum computation, let’s switch to the history
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

8 Introduction and overview
 of another strand of thought contributing to quantum computation and quantum infor- mation: information theory. At the same time computer science was exploding in the 1940s, another revolution was taking place in our understanding of communication. In 1948 Claude Shannon published a remarkable pair of papers laying the foundations for the modern theory of information and communication.
Perhaps the key step taken by Shannon was to mathematically define the concept of information. In many mathematical sciences there is considerable flexibility in the choice of fundamental definitions. Try thinking naively for a few minutes about the following question: how would you go about mathematically defining the notion of an information source? Several different answers to this problem have found widespread use; however, the definition Shannon came up with seems to be far and away the most fruitful in terms of increased understanding, leading to a plethora of deep results and a theory with a rich structure which seems to accurately reflect many (though not all) real-world communications problems.
Shannon was interested in two key questions related to the communication of in- formation over a communications channel. First, what resources are required to send information over a communications channel? For example, telephone companies need to know how much information they can reliably transmit over a given telephone cable. Second, can information be transmitted in such a way that it is protected against noise in the communications channel?
Shannon answered these two questions by proving the two fundamental theorems of information theory. The first, Shannon’s noiseless channel coding theorem, quantifies the physical resources required to store the output from an information source. Shan- non’s second fundamental theorem, the noisy channel coding theorem, quantifies how much information it is possible to reliably transmit through a noisy communications channel. To achieve reliable transmission in the presence of noise, Shannon showed that error-correcting codes could be used to protect the information being sent. Shannon’s noisy channel coding theorem gives an upper limit on the protection afforded by error- correcting codes. Unfortunately, Shannon’s theorem does not explicitly give a practically useful set of error-correcting codes to achieve that limit. From the time of Shannon’s pa- pers until today, researchers have constructed more and better classes of error-correcting codes in their attempts to come closer to the limit set by Shannon’s theorem. A sophisti- cated theory of error-correcting codes now exists offering the user a plethora of choices in their quest to design a good error-correcting code. Such codes are used in a multitude of places including, for example, compact disc players, computer modems, and satellite communications systems.
Quantum information theory has followed with similar developments. In 1995, Ben Schumacher provided an analogue to Shannon’s noiseless coding theorem, and in the process defined the ‘quantum bit’ or ‘qubit’ as a tangible physical resource. However, no analogue to Shannon’s noisy channel coding theorem is yet known for quantum in- formation. Nevertheless, in analogy to their classical counterparts, a theory of quantum error-correction has been developed which, as already mentioned, allows quantum com- puters to compute effectively in the presence of noise, and also allows communication over noisy quantum channels to take place reliably.
Indeed, classical ideas of error-correction have proved to be enormously important in developing and understanding quantum error-correcting codes. In 1996, two groups working independently, Robert Calderbank and Peter Shor, and Andrew Steane, discov-
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Global perspectives 9
 ered an important class of quantum codes now known as CSS codes after their initials. This work has since been subsumed by the stabilizer codes, independently discovered by Robert Calderbank, Eric Rains, Peter Shor and Neil Sloane, and by Daniel Gottesman. By building upon the basic ideas of classical linear coding theory, these discoveries greatly facilitated a rapid understanding of quantum error-correcting codes and their application to quantum computation and quantum information.
The theory of quantum error-correcting codes was developed to protect quantum states against noise. What about transmitting ordinary classical information using a quantum channel? How efficiently can this be done? A few surprises have been discovered in this arena. In 1992 Charles Bennett and Stephen Wiesner explained how to transmit two classical bits of information, while only transmitting one quantum bit from sender to receiver, a result dubbed superdense coding.
Even more interesting are the results in distributed quantum computation. Imagine you have two computers networked, trying to solve a particular problem. How much communication is required to solve the problem? Recently it has been shown that quan- tum computers can require exponentially less communication to solve certain problems than would be required if the networked computers were classical! Unfortunately, as yet these problems are not especially important in a practical setting, and suffer from some undesirable technical restrictions. A major challenge for the future of quantum compu- tation and quantum information is to find problems of real-world importance for which distributed quantum computation offers a substantial advantage over distributed classical computation.
Let’s return to information theory proper. The study of information theory begins with the properties of a single communications channel. In applications we often do not deal with a single communications channel, but rather with networks of many channels. The subject of networked information theory deals with the information carrying properties of such networks of communications channels, and has been developed into a rich and intricate subject.
By contrast, the study of networked quantum information theory is very much in its infancy. Even for very basic questions we know little about the information carrying abil- ities of networks of quantum channels. Several rather striking preliminary results have been found in the past few years; however, no unifying theory of networked information theory exists for quantum channels. One example of networked quantum information theory should suffice to convince you of the value such a general theory would have. Imagine that we are attempting to send quantum information from Alice to Bob through a noisy quantum channel. If that channel has zero capacity for quantum information, then it is impossible to reliably send any information from Alice to Bob. Imagine instead that we consider two copies of the channel, operating in synchrony. Intuitively it is clear (and can be rigorously justified) that such a channel also has zero capacity to send quan- tum information. However, if we instead reverse the direction of one of the channels, as illustrated in Figure 1.1, it turns out that sometimes we can obtain a non-zero capacity for the transmission of information from Alice to Bob! Counter-intuitive properties like this illustrate the strange nature of quantum information. Better understanding the in- formation carrying properties of networks of quantum channels is a major open problem of quantum computation and quantum information.
Let’s switch fields one last time, moving to the venerable old art and science of cryp- tography. Broadly speaking, cryptography is the problem of doing communication or
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

10 Introduction and overview
                                              Figure 1.1. Classically, if we have two very noisy channels of zero capacity running side by side, then the combined channel has zero capacity to send information. Not surprisingly, if we reverse the direction of one of the channels, we still have zero capacity to send information. Quantum mechanically, reversing one of the zero capacity channels can actually allow us to send information!
computation involving two or more parties who may not trust one another. The best known cryptographic problem is the transmission of secret messages. Suppose two parties wish to communicate in secret. For example, you may wish to give your credit card num- ber to a merchant in exchange for goods, hopefully without any malevolent third party intercepting your credit card number. The way this is done is to use a cryptographic protocol. We’ll describe in detail how cryptographic protocols work later in the book, but for now it will suffice to make a few simple distinctions. The most important distinction is between private key cryptosystems and public key cryptosystems.
The way a private key cryptosystem works is that two parties, ‘Alice’ and ‘Bob’, wish to communicate by sharing a private key, which only they know. The exact form of the key doesn’t matter at this point – think of a string of zeroes and ones. The point is that this key is used by Alice to encrypt the information she wishes to send to Bob. After Alice encrypts she sends the encrypted information to Bob, who must now recover the original information. Exactly how Alice encrypts the message depends upon the private key, so that to recover the original message Bob needs to know the private key, in order to undo the transformation Alice applied.
Unfortunately, private key cryptosystems have some severe problems in many contexts. The most basic problem is how to distribute the keys? In many ways, the key distribution problem is just as difficult as the original problem of communicating in private – a malevolent third party may be eavesdropping on the key distribution, and then use the intercepted key to decrypt some of the message transmission.
One of the earliest discoveries in quantum computation and quantum information was that quantum mechanics can be used to do key distribution in such a way that Alice and Bob’s security can not be compromised. This procedure is known as quantum cryptog- raphy or quantum key distribution. The basic idea is to exploit the quantum mechanical principle that observation in general disturbs the system being observed. Thus, if there is an eavesdropper listening in as Alice and Bob attempt to transmit their key, the presence of the eavesdropper will be visible as a disturbance of the communications channel Alice and Bob are using to establish the key. Alice and Bob can then throw out the key bits established while the eavesdropper was listening in, and start over. The first quantum cryptographic ideas were proposed by Stephen Wiesner in the late 1960s, but unfortu-
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Global perspectives 11
 nately were not accepted for publication! In 1984 Charles Bennett and Gilles Brassard, building on Wiesner’s earlier work, proposed a protocol using quantum mechanics to distribute keys between Alice and Bob, without any possibility of a compromise. Since then numerous quantum cryptographic protocols have been proposed, and experimental prototypes developed. At the time of this writing, the experimental prototypes are nearing the stage where they may be useful in limited-scale real-world applications.
The second major type of cryptosystem is the public key cryptosystem. Public key cryptosystems don’t rely on Alice and Bob sharing a secret key in advance. Instead, Bob simply publishes a ‘public key’, which is made available to the general public. Alice can make use of this public key to encrypt a message which she sends to Bob. What is interesting is that a third party cannot use Bob’s public key to decrypt the message! Strictly speaking, we shouldn’t say cannot. Rather, the encryption transformation is chosen in a very clever and non-trivial way so that it is extremely difficult (though not impossible) to invert, given only knowledge of the public key. To make inversion easy, Bob has a secret key matched to his public key, which together enable him to easily perform the decryption. This secret key is not known to anybody other than Bob, who can therefore be confident that only he can read the contents of Alice’s transmission, to the extent that it is unlikely that anybody else has the computational power to invert the encryption, given only the public key. Public key cryptosystems solve the key distribution problem by making it unnecessary for Alice and Bob to share a private key before communicating.
Rather remarkably, public key cryptography did not achieve widespread use until the mid-1970s, when it was proposed independently by Whitfield Diffie and Martin Hellman, and by Ralph Merkle, revolutionizing the field of cryptography. A little later, Ronald Rivest, Adi Shamir, and Leonard Adleman developed the RSA cryptosystem, which at the time of writing is the most widely deployed public key cryptosystem, believed to offer a fine balance of security and practical usability. In 1997 it was disclosed that these ideas – public key cryptography, the Diffie–Hellman and RSA cryptosystems – were actually invented in the late 1960s and early 1970s by researchers working at the British intelligence agency GCHQ.
The key to the security of public key cryptosystems is that it should be difficult to invert the encryption stage if only the public key is available. For example, it turns out that inverting the encryption stage of RSA is a problem closely related to factoring. Much of the presumed security of RSA comes from the belief that factoring is a problem hard to solve on a classical computer. However, Shor’s fast algorithm for factoring on a quantum computer could be used to break RSA! Similarly, there are other public key cryptosystems which can be broken if a fast algorithm for solving the discrete logarithm problem – like Shor’s quantum algorithm for discrete logarithm – were known. This practical application of quantum computers to the breaking of cryptographic codes has excited much of the interest in quantum computation and quantum information.
We have been looking at the historical antecedents for quantum computation and quantum information. Of course, as the field has grown and matured, it has sprouted its own subfields of research, whose antecedents lie mainly within quantum computation and quantum information.
Perhaps the most striking of these is the study of quantum entanglement. Entangle- ment is a uniquely quantum mechanical resource that plays a key role in many of the most interesting applications of quantum computation and quantum information; en- tanglement is iron to the classical world’s bronze age. In recent years there has been a
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

12 Introduction and overview
 tremendous effort trying to better understand the properties of entanglement considered as a fundamental resource of Nature, of comparable importance to energy, information, entropy, or any other fundamental resource. Although there is as yet no complete theory of entanglement, some progress has been made in understanding this strange property of quantum mechanics. It is hoped by many researchers that further study of the properties of entanglement will yield insights that facilitate the development of new applications in quantum computation and quantum information.
1.1.2 Future directions
We’ve looked at some of the history and present status of quantum computation and quantum information. What of the future? What can quantum computation and quan- tum information offer to science, to technology, and to humanity? What benefits does quantum computation and quantum information confer upon its parent fields of computer science, information theory, and physics? What are the key open problems of quantum computation and quantum information? We will make a few very brief remarks about these overarching questions before moving onto more detailed investigations.
Quantum computation and quantum information has taught us to think physically about computation, and we have discovered that this approach yields many new and exciting capabilities for information processing and communication. Computer scientists and information theorists have been gifted with a new and rich paradigm for explo- ration. Indeed, in the broadest terms we have learned that any physical theory, not just quantum mechanics, may be used as the basis for a theory of information processing and communication. The fruits of these explorations may one day result in information processing devices with capabilities far beyond today’s computing and communications systems, with concomitant benefits and drawbacks for society as a whole.
Quantum computation and quantum information certainly offer challenges aplenty to physicists, but it is perhaps a little subtle what quantum computation and quantum information offers to physics in the long term. We believe that just as we have learned to think physically about computation, we can also learn to think computationally about physics. Whereas physics has traditionally been a discipline focused on understanding ‘elementary’ objects and simple systems, many interesting aspects of Nature arise only when things become larger and more complicated. Chemistry and engineering deal with such complexity to some extent, but most often in a rather ad hoc fashion. One of the messages of quantum computation and information is that new tools are available for traversing the gulf between the small and the relatively complex: computation and algorithms provide systematic means for constructing and understanding such systems. Applying ideas from these fields is already beginning to yield new insights into physics. It is our hope that this perspective will blossom in years to come into a fruitful way of understanding all aspects of physics.
We’ve briefly examined some of the key motivations and ideas underlying quantum computation and quantum information. Over the remaining sections of this chapter we give a more technical but still accessible introduction to these motivations and ideas, with the hope of giving you a bird’s-eye view of the field as it is presently poised.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

1.2 Quantum bits
The bit is the fundamental concept of classical computation and classical information. Quantum computation and quantum information are built upon an analogous concept, the quantum bit, or qubit for short. In this section we introduce the properties of single and multiple qubits, comparing and contrasting their properties to those of classical bits.
What is a qubit? We’re going to describe qubits as mathematical objects with certain specific properties. ‘But hang on’, you say, ‘I thought qubits were physical objects.’ It’s true that qubits, like bits, are realized as actual physical systems, and in Section 1.5 and Chapter 7 we describe in detail how this connection between the abstract mathematical point of view and real systems is made. However, for the most part we treat qubits as abstract mathematical objects. The beauty of treating qubits as abstract entities is that it gives us the freedom to construct a general theory of quantum computation and quantum information which does not depend upon a specific system for its realization.
What then is a qubit? Just as a classical bit has a state – either 0 or 1 – a qubit also has a state. Two possible states for a qubit are the states |0⟩ and |1⟩, which as you might guess correspond to the states 0 and 1 for a classical bit. Notation like ‘| ⟩’ is called the Dirac notation, and we’ll be seeing it often, as it’s the standard notation for states in quantum mechanics. The difference between bits and qubits is that a qubit can be in a state other than |0⟩ or |1⟩. It is also possible to form linear combinations of states, often called superpositions:
|ψ⟩ = α|0⟩ + β |1⟩. (1.1)
The numbers α and β are complex numbers, although for many purposes not much is lost by thinking of them as real numbers. Put another way, the state of a qubit is a vector in a two-dimensional complex vector space. The special states |0⟩ and |1⟩ are known as computational basis states, and form an orthonormal basis for this vector space.
We can examine a bit to determine whether it is in the state 0 or 1. For example, computers do this all the time when they retrieve the contents of their memory. Rather remarkably, we cannot examine a qubit to determine its quantum state, that is, the values of α and β. Instead, quantum mechanics tells us that we can only acquire much more restricted information about the quantum state. When we measure a qubit we get either the result 0, with probability |α|2, or the result 1, with probability |β|2. Naturally, |α|2 + |β|2 = 1, since the probabilities must sum to one. Geometrically, we can interpret this as the condition that the qubit’s state be normalized to length 1. Thus, in general a qubit’s state is a unit vector in a two-dimensional complex vector space.
This dichotomy between the unobservable state of a qubit and the observations we can make lies at the heart of quantum computation and quantum information. In most of our abstract models of the world, there is a direct correspondence between elements of the abstraction and the real world, just as an architect’s plans for a building are in correspondence with the final building. The lack of this direct correspondence in quantum mechanics makes it difficult to intuit the behavior of quantum systems; however, there is an indirect correspondence, for qubit states can be manipulated and transformed in ways which lead to measurement outcomes which depend distinctly on the different properties of the state. Thus, these quantum states have real, experimentally verifiable consequences, which we shall see are essential to the power of quantum computation and quantum information.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Quantum bits 13
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

14 Introduction and overview
 The ability of a qubit to be in a superposition state runs counter to our ‘common sense’ understanding of the physical world around us. A classical bit is like a coin: either heads or tails up. For imperfect coins, there may be intermediate states like having it balanced on an edge, but those can be disregarded in the ideal case. By contrast, a qubit can exist in a continuum of states between |0⟩ and |1⟩ – until it is observed. Let us emphasize again that when a qubit is measured, it only ever gives ‘0’ or ‘1’ as the measurement result – probabilistically. For example, a qubit can be in the state
11
√ |0⟩+√ |1⟩, (1.2)
22
which, when measured, gives the result 0 fifty percent (|1/√2|2) of the time, and the result 1 fifty percent of the time. We will return often to this state, which is sometimes denoted |+⟩.
Despite this strangeness, qubits are decidedly real, their existence and behavior ex- tensively validated by experiments (discussed in Section 1.5 and Chapter 7), and many different physical systems can be used to realize qubits. To get a concrete feel for how a qubit can be realized it may be helpful to list some of the ways this realization may occur: as the two different polarizations of a photon; as the alignment of a nuclear spin in a uniform magnetic field; as two states of an electron orbiting a single atom such as shown in Figure 1.2. In the atom model, the electron can exist in either the so-called ‘ground’ or ‘excited’ states, which we’ll call |0⟩ and |1⟩, respectively. By shining light on the atom, with appropriate energy and for an appropriate length of time, it is possible to move the electron from the |0⟩ state to the |1⟩ state and vice versa. But more interestingly, by reducing the time we shine the light, an electron initially in the state |0⟩ can be moved ‘halfway’ between |0⟩ and |1⟩, into the |+⟩ state.
            Figure 1.2. Qubit represented by two electronic levels in an atom.
Naturally, a great deal of attention has been given to the ‘meaning’ or ‘interpretation’ that might be attached to superposition states, and of the inherently probabilistic nature of observations on quantum systems. However, by and large, we shall not concern ourselves with such discussions in this book. Instead, our intent will be to develop mathematical and conceptual pictures which are predictive.
One picture useful in thinking about qubits is the following geometric representation.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

(1.3)
where θ, φ and γ are real numbers. In Chapter 2 we will see that we can ignore the factor of eiγ out the front, because it has no observable effects, and for that reason we can effectively write
|ψ⟩ = cos θ|0⟩ + eiφ sin θ|1⟩. (1.4) 22
The numbers θ and φ define a point on the unit three-dimensional sphere, as shown in Figure 1.3. This sphere is often called the Bloch sphere; it provides a useful means of visualizing the state of a single qubit, and often serves as an excellent testbed for ideas about quantum computation and quantum information. Many of the operations on single qubits which we describe later in this chapter are neatly described within the Bloch sphere picture. However, it must be kept in mind that this intuition is limited because there is no simple generalization of the Bloch sphere known for multiple qubits.
|0ñ z
y φ
|1ñ
Figure 1.3. Bloch sphere representation of a qubit.
How much information is represented by a qubit? Paradoxically, there are an infinite number of points on the unit sphere, so that in principle one could store an entire text of Shakespeare in the infinite binary expansion of θ. However, this conclusion turns out to be misleading, because of the behavior of a qubit when observed. Recall that measurement of a qubit will give only either 0 or 1. Furthermore, measurement changes the state of a qubit, collapsing it from its superposition of |0⟩ and |1⟩ to the specific state consistent with the measurement result. For example, if measurement of |+⟩ gives 0, then the post-measurement state of the qubit will be |0⟩. Why does this type of collapse occur? Nobody knows. As discussed in Chapter 2, this behavior is simply one of the fundamental postulates of quantum mechanics. What is relevant for our purposes is that from a single measurement one obtains only a single bit of information about the state of the qubit, thus resolving the apparent paradox. It turns out that only if infinitely many
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Quantum bits 15
 Because |α|2 + |β|2 = 1, we may rewrite Equation (1.1) as 􏰐θ θ􏰑
|ψ⟩ = eiγ cos 2|0⟩ + eiφ sin 2|1⟩ ,
            x
|ψ⟩ θ
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

16 Introduction and overview
 identically prepared qubits were measured would one be able to determine α and β for a qubit in the state given in Equation (1.1).
But an even more interesting question to ask might be: how much information is represented by a qubit if we do not measure it? This is a trick question, because how can one quantify information if it cannot be measured? Nevertheless, there is something conceptually important here, because when Nature evolves a closed quantum system of qubits, not performing any ‘measurements’, she apparently does keep track of all the continuous variables describing the state, like α and β. In a sense, in the state of a qubit, Nature conceals a great deal of ‘hidden information’. And even more interestingly, we will see shortly that the potential amount of this extra ‘information’ grows exponentially with the number of qubits. Understanding this hidden quantum information is a question that we grapple with for much of this book, and which lies at the heart of what makes quantum mechanics a powerful tool for information processing.
1.2.1 Multiple qubits
Hilbert space is a big place.
– Carlton Caves
Suppose we have two qubits. If these were two classical bits, then there would be four possible states, 00, 01, 10, and 11. Correspondingly, a two qubit system has four com- putational basis states denoted |00⟩,|01⟩,|10⟩,|11⟩. A pair of qubits can also exist in superpositions of these four states, so the quantum state of two qubits involves associating a complex coefficient – sometimes called an amplitude – with each computational basis state, such that the state vector describing the two qubits is
|ψ⟩ = α00|00⟩ + α01|01⟩ + α10|10⟩ + α11|11⟩. (1.5)
Similar to the case for a single qubit, the measurement result x (= 00, 01, 10 or 11) occurs
with probability |αx|2, with the state of the qubits after the measurement being |x⟩. The
condition that probabilities sum to one is therefore expressed by the normalization
′ α00|00⟩ + α01|01⟩
|ψ ⟩ = 􏰠|α00|2 + |α01|2 . (1.6)
􏰠
Note how the post-measurement state is re-normalized by the factor |α00|2 + |α01|2 so that it still satisfies the normalization condition, just as we expect for a legitimate quantum state.
An important two qubit state is the Bell state or EPR pair,
|00⟩ + |11⟩
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
􏰶
22
|α | = 1, where the notation ‘{0, 1} ’ means ‘the set of strings x
condition that
of length two with each letter being either zero or one’. For a two qubit system, we could measure just a subset of the qubits, say the first qubit, and you can probably guess how this works: measuring the first qubit alone gives 0 with probability |α00|2 +|α01|2, leaving the post-measurement state
2 x∈{0,1}
   √
. (1.7) This innocuous-looking state is responsible for many surprises in quantum computation
  2
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

and quantum information. It is the key ingredient in quantum teleportation and super- dense coding, which we’ll come to in Section 1.3.7 and Section 2.3, respectively, and the prototype for many other interesting quantum states. The Bell state has the property that upon measuring the first qubit, one obtains two possible results: 0 with probability 1/2, leaving the post-measurement state |φ′⟩ = |00⟩, and 1 with probability 1/2, leaving |φ′⟩ = |11⟩. As a result, a measurement of the second qubit always gives the same result as the measurement of the first qubit. That is, the measurement outcomes are correlated. Indeed, it turns out that other types of measurements can be performed on the Bell state, by first applying some operations to the first or second qubit, and that interesting correlations still exist between the result of a measurement on the first and second qubit. These correlations have been the subject of intense interest ever since a famous paper by Einstein, Podolsky and Rosen, in which they first pointed out the strange properties of states like the Bell state. EPR’s insights were taken up and greatly improved by John Bell, who proved an amazing result: the measurement correlations in the Bell state are stronger than could ever exist between classical systems. These results, described in de- tail in Section 2.6, were the first intimation that quantum mechanics allows information processing beyond what is possible in the classical world.
More generally, we may consider a system of n qubits. The computational basis states of this system are of the form |x1x2 . . . xn⟩, and so a quantum state of such a system is specified by 2n amplitudes. For n = 500 this number is larger than the estimated number of atoms in the Universe! Trying to store all these complex numbers would not be possible on any conceivable classical computer. Hilbert space is indeed a big place. In principle, however, Nature manipulates such enormous quantities of data, even for systems containing only a few hundred atoms. It is as if Nature were keeping 2500 hidden pieces of scratch paper on the side, on which she performs her calculations as the system evolves. This enormous potential computational power is something we would very much like to take advantage of. But how can we think of quantum mechanics as computation?
1.3 Quantum computation
Changes occurring to a quantum state can be described using the language of quantum computation. Analogous to the way a classical computer is built from an electrical circuit containing wires and logic gates, a quantum computer is built from a quantum circuit containing wires and elementary quantum gates to carry around and manipulate the quantum information. In this section we describe some simple quantum gates, and present several example circuits illustrating their application, including a circuit which teleports qubits!
1.3.1 Single qubit gates
Classical computer circuits consist of wires and logic gates. The wires are used to carry information around the circuit, while the logic gates perform manipulations of the infor- mation, converting it from one form to another. Consider, for example, classical single bit logic gates. The only non-trivial member of this class is the       gate, whose operation is defined by its truth table, in which 0 → 1 and 1 → 0, that is, the 0 and 1 states are interchanged.
Can an analogous quantum       gate for qubits be defined? Imagine that we had some process which took the state |0⟩ to the state |1⟩, and vice versa. Such a process
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Quantum computation 17
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

18 Introduction and overview
 would obviously be a good candidate for a quantum analogue to the       gate. However, specifying the action of the gate on the states |0⟩ and |1⟩ does not tell us what happens to superpositions of the states |0⟩ and |1⟩, without further knowledge about the properties of quantum gates. In fact, the quantum       gate acts linearly, that is, it takes the state
α|0⟩ + β|1⟩ (1.8) to the corresponding state in which the role of |0⟩ and |1⟩ have been interchanged,
α|1⟩ + β|0⟩. (1.9)
Why the quantum       gate acts linearly and not in some nonlinear fashion is a very interesting question, and the answer is not at all obvious. It turns out that this linear behavior is a general property of quantum mechanics, and very well motivated empirically; moreover, nonlinear behavior can lead to apparent paradoxes such as time travel, faster- than-light communication, and violations of the second laws of thermodynamics. We’ll explore this point in more depth in later chapters, but for now we’ll just take it as given.
There is a convenient way of representing the quantum       gate in matrix form, which follows directly from the linearity of quantum gates. Suppose we define a matrix X to represent the quantum       gate as follows:
􏰒􏰓
X≡ 0 1 . (1.10) 10
(The notation X for the quantum is used for historical reasons.) If the quantum state α|0⟩ + β|1⟩ is written in a vector notation as
􏰒α􏰓
β , (1.11)
with the top entry corresponding to the amplitude for |0⟩ and the bottom entry the amplitude for |1⟩, then the corresponding output from the quantum       gate is
􏰒α􏰓 􏰒β􏰓
Xβ=α. (1.12)
Notice that the action of the       gate is to take the state |0⟩ and replace it by the state corresponding to the first column of the matrix X. Similarly, the state |1⟩ is replaced by the state corresponding to the second column of the matrix X.
So quantum gates on a single qubit can be described by two by two matrices. Are there any constraints on what matrices may be used as quantum gates? It turns out that there are. Recall that the normalization condition requires |α|2 + |β|2 = 1 for a quantum state α|0⟩ + β|1⟩. This must also be true of the quantum state |ψ′⟩ = α′|0⟩ + β′|1⟩ after the gate has acted. It turns out that the appropriate condition on the matrix representing the gate is that the matrix U describing the single qubit gate be unitary, that is U†U = I, where U† is the adjoint of U (obtained by transposing and then complex conjugating U), and I is the two by two identity matrix. For example, for the       gate it is easy to verify that X†X = I.
Amazingly, this unitarity constraint is the only constraint on quantum gates. Any unitary matrix specifies a valid quantum gate! The interesting implication is that in contrast to the classical case, where only one non-trivial single bit gate exists – the
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
      Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

|1⟩ into (|0⟩ − |1⟩)/
Quantum computation 19
    |0ñ zzz
yyy xxx
0+1
2
              |1ñ
Figure 1.4. Visualization of the Hadamard gate on the Bloch sphere, acting on the input state (|0 + |1)/ 2.
gate – there are many non-trivial single qubit gates. Two important ones which we shall use later are the Z gate:
􏰒􏰓
Z≡ 1 0 , (1.13) 0 −1
which leaves |0⟩ unchanged, and flips the sign of |1⟩ to give −|1⟩, and the Hadamard gate,
1􏰒1 1􏰓
H≡√2 1 −1 . (1.14)
√
   This gate is sometimes described as being like a ‘square-root of       ’ gate, in that it turns
√
a |0⟩ into (|0⟩ + |1⟩)/ 2 (first column of H), ‘halfway’ between |0⟩ and |1⟩, and turns
 √
2 (second column of H), which is also ‘halfway’ between |0⟩ and |1⟩. Note, however, that H2 is not a       gate, as simple algebra shows that H2 = I, and
thus applying H twice to a state does nothing to it.
The Hadamard gate is one of the most useful quantum gates, and it is worth trying to
visualize its operation by considering the Bloch sphere picture. In this picture, it turns out that single qubit gates correspond to rotations and reflections of the sphere. The Hadamard operation is just a rotation of the sphere about the yˆ axis by 90◦, followed by a rotation about the xˆ axis by 180◦, as illustrated in Figure 1.4. Some important single qubit gates are shown in Figure 1.5, and contrasted with the classical case.
xx
Figure 1.5. Single bit (left) and qubit (right) logic gates.
There are infinitely many two by two unitary matrices, and thus infinitely many single
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.
                                                                                                     
20 Introduction and overview
 qubit gates. However, it turns out that the properties of the complete set can be under- stood from the properties of a much smaller set. For example, as explained in Box 1.1, an arbitrary single qubit unitary gate can be decomposed as a product of rotations
􏰒cosγ −sinγ􏰓
2 2, (1.15)
  sin γ cos γ 22
  and a gate which we’ll later understand as being a rotation about the zˆ axis, 􏰒e−iβ/2 0􏰓
0 eiβ/2 , (1.16)
together with a (global) phase shift – a constant multiplier of the form eiα. These gates can be broken down further – we don’t need to be able to do these gates for arbitrary α, β and γ, but can build arbitrarily good approximations to such gates using only certain special fixed values of α, β and γ. In this way it is possible to build up an arbitrary single qubit gate using a finite set of quantum gates. More generally, an arbitrary quantum computation on any number of qubits can be generated by a finite set of gates that is said to be universal for quantum computation. To obtain such a universal set we first need to introduce some quantum gates involving multiple qubits.
   Box 1.1: Decomposing single qubit operations
In Section 4.2 starting on page 174 we prove that an arbitrary 2×2 unitary matrix may be decomposed as
􏰒e−iβ/2
U=eiα
0
where α, β, γ, and δ are real-valued. Notice that the second matrix is just an ordinary rotation. It turns out that the first and last matrices can also be understood as rotations in a different plane. This decomposition can be used to give an exact prescription for performing an arbitrary single qubit quantum logic gate.
0 􏰓􏰒cosγ −sinγ 􏰓􏰒e−iδ/2 0 􏰓
2 2, ,(1.17)
  eiβ/2 sin γ cos γ 0 eiδ/2 22
   1.3.2 Multiple qubit gates
Now let us generalize from one to multiple qubits. Figure 1.6 shows five notable multiple bit classical gates, the       ,     ,       (exclusive-     ),         and       gates. An important theoretical result is that any function on bits can be computed from the composition of
gates alone, which is thus known as a universal gate. By contrast, the       alone or even together with       is not universal. One way of seeing this is to note that applying an       gate does not change the total parity of the bits. As a result, any circuit involving only       and       gates will, if two inputs x and y have the same parity, give outputs with the same parity, restricting the class of functions which may be computed, and thus precluding universality.
The prototypical multi-qubit quantum logic gate is the controlled-       or         gate. This gate has two input qubits, known as the control qubit and the target qubit, respec- tively. The circuit representation for the         is shown in the top right of Figure 1.6; the top line represents the control qubit, while the bottom line represents the target
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
    Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

a NOTa ab aANDb (a) (b)
ab aORb ab aXORb
Quantum computation 21
                         (c) (e) ab
(f) ab
(d)
          aNANDb= aNORb=
                            Figure 1.6. On the left are some standard single and multiple bit gates, while on the right is the prototypical multiple qubit gate, the controlled-       . The matrix representation of the controlled-       , UCN , is written with respect to the amplitudes for |00, |01, |10, and |11, in that order.
qubit. The action of the gate may be described as follows. If the control qubit is set to 0, then the target qubit is left alone. If the control qubit is set to 1, then the target qubit is flipped. In equations:
|00⟩ → |00⟩; |01⟩ → |01⟩; |10⟩ → |11⟩; |11⟩ → |10⟩. (1.18)
Another way of describing the         is as a generalization of the classical       gate, since the action of the gate may be summarized as |A, B⟩ → |A, B ⊕ A⟩, where ⊕ is addition modulo two, which is exactly what the       gate does. That is, the control qubit and the target qubit are       ed and stored in the target qubit.
Yet another way of describing the action of the         is to give a matrix represen- tation, as shown in the bottom right of Figure 1.6. You can easily verify that the first column of UCN describes the transformation that occurs to |00⟩, and similarly for the other computational basis states, |01⟩, |10⟩, and |11⟩. As for the single qubit case, the requirement that probability be conserved is expressed in the fact that UCN is a unitary matrix, that is, U† U = I.
We noticed that the         can be regarded as a type of generalized-       gate. Can other classical gates such as the         or the regular       gate be understood as unitary gates in a sense similar to the way the quantum       gate represents the classical gate? It turns out that this is not possible. The reason is because the       and gates are essentially irreversible or non-invertible. For example, given the output A ⊕ B from an       gate, it is not possible to determine what the inputs A and B were; there is an irretrievable loss of information associated with the irreversible action of the       gate. On the other hand, unitary quantum gates are always invertible, since the inverse of a unitary matrix is also a unitary matrix, and thus a quantum gate can always be inverted by another quantum gate. Understanding how to do classical logic in this reversible or invertible sense will be a crucial step in understanding how to harness the power of
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
CN CN
       Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

22 Introduction and overview
 quantum mechanics for computation. We’ll explain the basic idea of how to do reversible computation in Section 1.4.1.
Of course, there are many interesting quantum gates other than the controlled-       . However, in a sense the controlled-       and single qubit gates are the prototypes for all other gates because of the following remarkable universality result: Any multiple qubit logic gate may be composed from         and single qubit gates. The proof is given in Section 4.5, and is the quantum parallel of the universality of the         gate.
1.3.3 Measurements in bases other than the computational basis
We’ve described quantum measurements of a single qubit in the state α|0⟩ + β|1⟩ as yielding the result 0 or 1 and leaving the qubit in the corresponding state |0⟩ or |1⟩, with respective probabilities |α|2 and |β|2. In fact, quantum mechanics allows somewhat more versatility in the class of measurements that may be performed, although certainly nowhere near enough to recover α and β from a single measurement!
Note that the states |0⟩ and |1⟩ represent just one of many possible choices of basis √
states for a qubit. Another possible choice is the set |+⟩ ≡ (|0⟩ + |1⟩)/ 2 and |−⟩ ≡ √
(|0⟩ − |1⟩)/ 2. An arbitrary state |ψ⟩ = α|0⟩ + β|1⟩ can be re-expressed in terms of the states |+⟩ and |−⟩:
|+⟩ + |−⟩ |+⟩ − |−⟩ α + β α − β |ψ⟩=α|0⟩+β|1⟩=α √ +β √ = √ |+⟩+ √ |−⟩. (1.19)
2222
It turns out that it is possible to treat the |+⟩ and |−⟩ states as though they were the com- putational basis states, and measure with respect to this new basis. Naturally, measuring with respect to the |+⟩, |−⟩ basis results in the result ‘+’ with probability |α+β|2/2 and the result ‘−’ with probability |α − β|2/2, with corresponding post-measurement states |+⟩ and |−⟩, respectively.
More generally, given any basis states |a⟩ and |b⟩ for a qubit, it is possible to express an arbitrary state as a linear combination α|a⟩+β|b⟩ of those states. Furthermore, provided the states are orthonormal, it is possible to perform a measurement with respect to the |a⟩,|b⟩ basis, giving the result a with probability |α|2 and b with probability |β|2. The orthonormality constraint is necessary in order that |α|2 + |β|2 = 1 as we expect for probabilities. In an analogous way it is possible in principle to measure a quantum system of many qubits with respect to an arbitrary orthonormal basis. However, just because it is possible in principle does not mean that such a measurement can be done easily, and we return later to the question of how efficiently a measurement in an arbitrary basis can be performed.
There are many reasons for using this extended formalism for quantum measure- ments, but ultimately the best one is this: the formalism allows us to describe observed experimental results, as we will see in our discussion of the Stern–Gerlach experiment in Section 1.5.1. An even more sophisticated and convenient (but essentially equivalent) formalism for describing quantum measurements is described in the next chapter, in Section 2.2.3.
1.3.4 Quantum circuits
We’ve already met a few simple quantum circuits. Let’s look in a little more detail at the elements of a quantum circuit. A simple quantum circuit containing three quantum gates is shown in Figure 1.7. The circuit is to be read from left-to-right. Each line
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
          Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

in the circuit represents a wire in the quantum circuit. This wire does not necessarily correspond to a physical wire; it may correspond instead to the passage of time, or perhaps to a physical particle such as a photon – a particle of light – moving from one location to another through space. It is conventional to assume that the state input to the circuit is a computational basis state, usually the state consisting of all |0⟩s. This rule is broken frequently in the literature on quantum computation and quantum information, but it is considered polite to inform the reader when this is the case.
The circuit in Figure 1.7 accomplishes a simple but useful task – it swaps the states of the two qubits. To see that this circuit accomplishes the swap operation, note that the sequence of gates has the following sequence of effects on a computational basis state |a, b⟩,
|a,b⟩ −→ |a,a⊕b⟩
−→ |a ⊕ (a ⊕ b), a ⊕ b⟩ = |b, a ⊕ b⟩
−→ |b, (a ⊕ b) ⊕ b⟩ = |b, a⟩ , (1.20)
where all additions are done modulo 2. The effect of the circuit, therefore, is to inter- change the state of the two qubits.
Figure 1.7. Circuit swapping two qubits, and an equivalent schematic symbol notation for this common and useful circuit.
There are a few features allowed in classical circuits that are not usually present in quantum circuits. First of all, we don’t allow ‘loops’, that is, feedback from one part of the quantum circuit to another; we say the circuit is acyclic. Second, classical circuits allow wires to be ‘joined’ together, an operation known as           , with the resulting single wire containing the bitwise     of the inputs. Obviously this operation is not reversible and therefore not unitary, so we don’t allow           in our quantum circuits. Third, the inverse operation,             , whereby several copies of a bit are produced is also not allowed in quantum circuits. In fact, it turns out that quantum mechanics forbids the copying of a qubit, making the             operation impossible! We’ll see an example of this in the next section when we attempt to design a circuit to copy a qubit.
As we proceed we’ll introduce new quantum gates as needed. It’s convenient to in- troduce another convention about quantum circuits at this point. This convention is illustrated in Figure 1.8. Suppose U is any unitary matrix acting on some number n of qubits, so U can be regarded as a quantum gate on those qubits. Then we can define a controlled-U gate which is a natural extension of the controlled-       gate. Such a gate has a single control qubit, indicated by the line with the black dot, and n target qubits, indicated by the boxed U. If the control qubit is set to 0 then nothing happens to the target qubits. If the control qubit is set to 1 then the gate U is applied to the target qubits. The prototypical example of the controlled-U gate is the controlled-       gate, which is a controlled-U gate with U = X, as illustrated in Figure 1.9.
Another important operation is measurement, which we represent by a ‘meter’ symbol,
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Quantum computation 23
                                Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

24 Introduction and overview
          Figure 1.8. Controlled-U gate.
Figure 1.9. Two different representations for the controlled-       .
as shown in Figure 1.10. As previously described, this operation converts a single qubit state |ψ⟩ = α|0⟩ + β|1⟩ into a probabilistic classical bit M (distinguished from a qubit by drawing it as a double-line wire), which is 0 with probability |α|2, or 1 with probability |β|2.
                             111     %vv   111 1111 %%%%
    %   
Figure 1.10. Quantum circuit symbol for measurement.
We shall find quantum circuits useful as models of all quantum processes, including but not limited to computation, communication, and even quantum noise. Several simple examples illustrate this below.
1.3.5 Qubit copying circuit?
The         gate is useful for demonstrating one particularly fundamental property of quantum information. Consider the task of copying a classical bit. This may be done using a classical         gate, which takes in the bit to copy (in some unknown state x) and a ‘scratchpad’ bit initialized to zero, as illustrated in Figure 1.11. The output is two bits, both of which are in the same state x.
Suppose we try to copy a qubit in the unknown state |ψ⟩ = a |0⟩ + b |1⟩ in the same manner by using a         gate. The input state of the two qubits may be written as
􏰜􏰝
a|0⟩ + b|1⟩ |0⟩ = a|00⟩ + b|10⟩, (1.21)
The function of         is to negate the second qubit when the first qubit is 1, and thus the output is simply a |00⟩ + b |11⟩. Have we successfully copied |ψ⟩? That is, have we created the state |ψ⟩|ψ⟩? In the case where |ψ⟩ = |0⟩ or |ψ⟩ = |1⟩ that is indeed what this circuit does; it is possible to use quantum circuits to copy classical information encoded as a |0⟩ or a |1⟩. However, for a general state |ψ⟩ we see that
|ψ⟩|ψ⟩ = a2|00⟩ + ab|01⟩ + ab|10⟩ + b2|11⟩. (1.22)
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
    1111
       Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Quantum computation 25
   xx x
Figure 1.11. Classical and quantum circuits to ‘copy’ an unknown bit or qubit.
Comparing with a|00⟩ + b|11⟩, we see that unless ab = 0 the ‘copying circuit’ above does not copy the quantum state input. In fact, it turns out to be impossible to make a copy of an unknown quantum state. This property, that qubits cannot be copied, is known as the no-cloning theorem, and it is one of the chief differences between quantum and classical information. The no-cloning theorem is discussed at more length in Box 12.1 on page 532; the proof is very simple, and we encourage you to skip ahead and read the proof now.
There is another way of looking at the failure of the circuit in Figure 1.11, based on the intuition that a qubit somehow contains ‘hidden’ information not directly accessible to measurement. Consider what happens when we measure one of the qubits of the state a|00⟩ + b|11⟩. As previously described, we obtain either 0 or 1 with probabilities |a|2 and |b|2. However, once one qubit is measured, the state of the other one is completely determined, and no additional information can be gained about a and b. In this sense, the extra hidden information carried in the original qubit |ψ⟩ was lost in the first measure- ment, and cannot be regained. If, however, the qubit had been copied, then the state of the other qubit should still contain some of that hidden information. Therefore, a copy cannot have been created.
1.3.6 Example: Bell states
Let’s consider a slightly more complicated circuit, shown in Figure 1.12, which has a
Hadamard gate followed by a         , and transforms the four computational basis states
xx y xÅy
                                          according to the table given. As an explicit example, the Hadamard gate takes the input
√√ |00⟩ to (|0⟩ + |1⟩)|0⟩/ 2, and then the         gives the output state (|00⟩ + |11⟩)/ 2.
  Note how this works: first, the Hadamard transform puts the top qubit in a superposition; this then acts as a control input to the         , and the target gets inverted only when the control is 1. The output states
|00⟩ + |11⟩ |β00⟩ = √
2
|01⟩ + |10⟩ |β01⟩ = √
; ;
; and
,
are known as the Bell states, or sometimes the EPR states or EPR pairs, after some of the people – Bell, and Einstein, Podolsky, and Rosen – who first pointed out the strange properties of states like these. The mnemonic notation |β00⟩,|β01⟩,|β10⟩,|β11⟩ may be
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
    2 |00⟩ − |11⟩
(1.23)
(1.24)
(1.25)
(1.26)
|β10⟩ = √
|01⟩ − |10⟩
  |β11⟩ = √
2 2
  Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

26 Introduction and overview understood via the equations
|βxy⟩ ≡ √ where y ̄ is the negation of y.
In
|01⟩ |10⟩ |11⟩
 |0, y⟩ + (−1)x|1, y ̄⟩
, (1.27)
  2
√
|00⟩   (|00⟩ + |11⟩)/ 2 ≡ |β00⟩
   Out
      √
2 ≡ |β01⟩
√
2 ≡ |β10 ⟩
√
2 ≡ |β11 ⟩
          (|01⟩ + |10⟩)/ (|00⟩ − |11⟩)/ (|01⟩ − |10⟩)/
                    Figure 1.12. Quantum circuit to create Bell states, and its input–ouput quantum ‘truth table’.
1.3.7 Example: quantum teleportation
We will now apply the techniques of the last few pages to understand something non- trivial, surprising, and a lot of fun – quantum teleportation! Quantum teleportation is a technique for moving quantum states around, even in the absence of a quantum commu- nications channel linking the sender of the quantum state to the recipient.
Here’s how quantum teleportation works. Alice and Bob met long ago but now live far apart. While together they generated an EPR pair, each taking one qubit of the EPR pair when they separated. Many years later, Bob is in hiding, and Alice’s mission, should she choose to accept it, is to deliver a qubit |ψ⟩ to Bob. She does not know the state of the qubit, and moreover can only send classical information to Bob. Should Alice accept the mission?
Intuitively, things look pretty bad for Alice. She doesn’t know the state |ψ⟩ of the qubit she has to send to Bob, and the laws of quantum mechanics prevent her from determining the state when she only has a single copy of |ψ⟩ in her possession. What’s worse, even if she did know the state |ψ⟩, describing it precisely takes an infinite amount of classical information since |ψ⟩ takes values in a continuous space. So even if she did know |ψ⟩, it would take forever for Alice to describe the state to Bob. It’s not looking good for Alice. Fortunately for Alice, quantum teleportation is a way of utilizing the entangled EPR pair in order to send |ψ⟩ to Bob, with only a small overhead of classical communication.
In outline, the steps of the solution are as follows: Alice interacts the qubit |ψ⟩ with her half of the EPR pair, and then measures the two qubits in her possession, obtaining one of four possible classical results, 00, 01, 10, and 11. She sends this information to Bob. Depending on Alice’s classical message, Bob performs one of four operations on his half of the EPR pair. Amazingly, by doing this he can recover the original state |ψ⟩!
The quantum circuit shown in Figure 1.13 gives a more precise description of quantum teleportation. The state to be teleported is |ψ⟩ = α|0⟩+β|1⟩, where α and β are unknown amplitudes. The state input into the circuit |ψ0⟩ is
|ψ0⟩ = |ψ⟩|β00⟩ (1.28)
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

111 1111
 111 1111
    %vv   111 %%%% 1111
   %   
    %vv   111
%%%% 1111     %   
Quantum computation 27
                                                                                                               Figure 1.13. Quantum circuit for teleporting a qubit. The two top lines represent Alice’s system, while the bottom line is Bob’s system. The meters represent measurement, and the double lines coming out of them carry classical bits (recall that single lines denote qubits).
1􏰜􏰝
= √ α|0⟩(|00⟩ + |11⟩) + β|1⟩(|00⟩ + |11⟩) , (1.29)
2
where we use the convention that the first two qubits (on the left) belong to Alice, and the third qubit to Bob. As we explained previously, Alice’s second qubit and Bob’s qubit start out in an EPR state. Alice sends her qubits through a         gate, obtaining
  1􏰜􏰝 |ψ1⟩ = √ α|0⟩(|00⟩ + |11⟩) + β|1⟩(|10⟩ + |01⟩) .
2
She then sends the first qubit through a Hadamard gate, obtaining
1􏰜􏰝 |ψ2⟩ = 2 α(|0⟩ + |1⟩)(|00⟩ + |11⟩) + β(|0⟩ − |1⟩)(|10⟩ + |01⟩) .
(1.30)
   (1.31) This state may be re-written in the following way, simply by regrouping terms:
1􏰜􏰇􏰈􏰇􏰈 |ψ2⟩ = 2 |00⟩ α|0⟩ + β|1⟩ + |01⟩ α|1⟩ + β|0⟩
􏰇 􏰈 􏰇 􏰈􏰝
+ |10⟩ α|0⟩ − β|1⟩ + |11⟩ α|1⟩ − β|0⟩ .
(1.32)
 This expression naturally breaks down into four terms. The first term has Alice’s qubits in the state |00⟩, and Bob’s qubit in the state α|0⟩ + β|1⟩ – which is the original state |ψ⟩. If Alice performs a measurement and obtains the result 00 then Bob’s system will be in the state |ψ⟩. Similarly, from the previous expression we can read off Bob’s post- measurement state, given the result of Alice’s measurement:
00 􏰅−→ |ψ3(00)⟩ ≡ 01 􏰅−→ |ψ3(01)⟩ ≡ 10 􏰅−→ |ψ3(10)⟩ ≡ 11 􏰅−→ |ψ3(11)⟩ ≡
􏰜􏰝
α|0⟩ + β|1⟩ 􏰜􏰝 α|1⟩ + β|0⟩ 􏰜􏰝 α|0⟩ − β|1⟩ 􏰜􏰝
α|1⟩ − β|0⟩ .
(1.33) (1.34) (1.35) (1.36)
Depending on Alice’s measurement outcome, Bob’s qubit will end up in one of these four possible states. Of course, to know which state it is in, Bob must be told the result of Alice’s measurement – we will show later that it is this fact which prevents teleportation
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

28 Introduction and overview
 from being used to transmit information faster than light. Once Bob has learned the mea- surement outcome, Bob can ‘fix up’ his state, recovering |ψ⟩, by applying the appropriate quantum gate. For example, in the case where the measurement yields 00, Bob doesn’t need to do anything. If the measurement is 01 then Bob can fix up his state by applying the X gate. If the measurement is 10 then Bob can fix up his state by applying the Z gate. If the measurement is 11 then Bob can fix up his state by applying first an X and then a Z gate. Summing up, Bob needs to apply the transformation ZM1 XM2 (note how time goes from left to right in circuit diagrams, but in matrix products terms on the right happen first) to his qubit, and he will recover the state |ψ⟩.
There are many interesting features of teleportation, some of which we shall return to later in the book. For now we content ourselves with commenting on a couple of aspects. First, doesn’t teleportation allow one to transmit quantum states faster than light? This would be rather peculiar, because the theory of relativity implies that faster than light information transfer could be used to send information backwards in time. Fortunately, quantum teleportation does not enable faster than light communication, because to complete the teleportation Alice must transmit her measurement result to Bob over a classical communications channel. We will show in Section 2.4.3 that without this classical communication, teleportation does not convey any information at all. The classical channel is limited by the speed of light, so it follows that quantum teleportation cannot be accomplished faster than the speed of light, resolving the apparent paradox.
A second puzzle about teleportation is that it appears to create a copy of the quan- tum state being teleported, in apparent violation of the no-cloning theorem discussed in Section 1.3.5. This violation is only illusory since after the teleportation process only the target qubit is left in the state |ψ⟩, and the original data qubit ends up in one of the computational basis states |0⟩ or |1⟩, depending upon the measurement result on the first qubit.
What can we learn from quantum teleportation? Quite a lot! It’s much more than just a neat trick one can do with quantum states. Quantum teleportation emphasizes the interchangeability of different resources in quantum mechanics, showing that one shared EPR pair together with two classical bits of communication is a resource at least the equal of one qubit of communication. Quantum computation and quantum information has revealed a plethora of methods for interchanging resources, many built upon quantum teleportation. In particular, in Chapter 10 we explain how teleportation can be used to build quantum gates which are resistant to the effects of noise, and in Chapter 12 we show that teleportation is intimately connected with the properties of quantum error-correcting codes. Despite these connections with other subjects, it is fair to say that we are only beginning to understand why it is that quantum teleportation is possible in quantum mechanics; in later chapters we endeavor to explain some of the insights that make such an understanding possible.
1.4 Quantum algorithms
What class of computations can be performed using quantum circuits? How does that class compare with the computations which can be performed using classical logical circuits? Can we find a task which a quantum computer may perform better than a classical computer? In this section we investigate these questions, explaining how to perform classical computations on quantum computers, giving some examples of problems for
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Quantum algorithms 29 which quantum computers offer an advantage over classical computers, and summarizing
the known quantum algorithms.
1.4.1 Classical computations on a quantum computer
Can we simulate a classical logic circuit using a quantum circuit? Not surprisingly, the answer to this question turns out to be yes. It would be very surprising if this were not the case, as physicists believe that all aspects of the world around us, including classical logic circuits, can ultimately be explained using quantum mechanics. As pointed out earlier, the reason quantum circuits cannot be used to directly simulate classical circuits is because unitary quantum logic gates are inherently reversible, whereas many classical logic gates such as the         gate are inherently irreversible.
Any classical circuit can be replaced by an equivalent circuit containing only reversible elements, by making use of a reversible gate known as the Toffoli gate. The Toffoli gate has three input bits and three output bits, as illustrated in Figure 1.14. Two of the bits are control bits that are unaffected by the action of the Toffoli gate. The third bit is a target bit that is flipped if both control bits are set to 1, and otherwise is left alone. Note that applying the Toffoli gate twice to a set of bits has the effect (a, b, c) → (a, b, c ⊕ ab) → (a, b, c), and thus the Toffoli gate is a reversible gate, since it has an inverse – itself.
Inputs Outputs
a b c a b c 000000 001001 010010 011011 100100 101101 110111 111110
Figure 1.14. Truth table for the Toffoli gate, and its circuit representation.
The Toffoli gate can be used to simulate         gates, as shown in Figure 1.15, and can also be used to do             , as shown in Figure 1.16. With these two operations it becomes possible to simulate all other elements in a classical circuit, and thus an arbitrary classical circuit can be simulated by an equivalent reversible circuit.
The Toffoli gate has been described as a classical gate, but it can also be implemented as a quantum logic gate. By definition, the quantum logic implementation of the Toffoli gate simply permutes computational basis states in the same way as the classical Toffoli gate. For example, the quantum Toffoli gate acting on the state |110⟩ flips the third qubit because the first two are set, resulting in the state |111⟩. It is tedious but not difficult to write this transformation out as an 8 by 8 matrix, U, and verify explicitly that U is a unitary matrix, and thus the Toffoli gate is a legitimate quantum gate. The quantum Toffoli gate can be used to simulate irreversible classical logic gates, just as the classical
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
                                       Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

30 Introduction and overview
                              Figure 1.15. Classical circuit implementing a         gate using a Toffoli gate. The top two bits represent the input to the         , while the third bit is prepared in the standard state 1, sometimes known as an ancilla state. The output from the         is on the third bit.
Figure 1.16.             with the Toffoli gate, with the second bit being the input to the             (and the other two bits standard ancilla states), and the output from             appearing on the second and third bits.
Toffoli gate was, and ensures that quantum computers are capable of performing any computation which a classical (deterministic) computer may do.
What if the classical computer is non-deterministic, that is, has the ability to generate
random bits to be used in the computation? Not surprisingly, it is easy for a quantum
computer to simulate this. To perform such a simulation it turns out to be sufficient to
                    produce random fair coin tosses, which can be done by preparing a qubit in the state
√
|0⟩, sending it through a Hadamard gate to produce (|0⟩ + |1⟩)/ 2, and then measuring
 the state. The result will be |0⟩ or |1⟩ with 50/50 probability. This provides a quantum computer with the ability to efficiently simulate a non-deterministic classical computer.
Of course, if the ability to simulate classical computers were the only feature of quan- tum computers there would be little point in going to all the trouble of exploiting quantum effects! The advantage of quantum computing is that much more powerful functions may be computed using qubits and quantum gates. In the next few sections we explain how to do this, culminating in the Deutsch–Jozsa algorithm, our first example of a quantum algorithm able to solve a problem faster than any classical algorithm.
1.4.2 Quantum parallelism
Quantum parallelism is a fundamental feature of many quantum algorithms. Heuristi- cally, and at the risk of over-simplifying, quantum parallelism allows quantum computers to evaluate a function f(x) for many different values of x simultaneously. In this section we explain how quantum parallelism works, and some of its limitations.
Suppose f(x) : {0,1} → {0,1} is a function with a one-bit domain and range. A
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Quantum algorithms 31
 convenient way of computing this function on a quantum computer is to consider a two qubit quantum computer which starts in the state |x, y⟩. With an appropriate sequence of logic gates it is possible to transform this state into |x, y ⊕ f (x)⟩, where ⊕ indicates addition modulo 2; the first register is called the ‘data’ register, and the second register the ‘target’ register. We give the transformation defined by the map |x, y⟩ → |x, y ⊕ f (x)⟩ a name, Uf , and note that it is easily shown to be unitary. If y = 0, then the final state of the second qubit is just the value f (x). (In Section 3.2.5 we show that given a classical circuit for computing f there is a quantum circuit of comparable efficiency which computes the transformation Uf on a quantum computer. For our purposes it can be considered to be a black box.)
                                         Figure 1.17. Quantum circuit for evaluating f(0) and f(1) simultaneously. Uf is the quantum circuit which takes inputs like |x, y to |x, y ⊕ f (x).
Consider the circuit shown in Figure 1.17, which applies Uf to an input not in the computational basis. Instead, the data register is prepared in the superposition (|0⟩ +
2, which can be created with a Hadamard gate acting on |0⟩. Then we apply Uf , resulting in the state:
 |1⟩)/
√
|0, f (0)⟩ + |1, f (1)⟩
√
2
. (1.37)
  This is a remarkable state! The different terms contain information about both f(0) and f (1); it is almost as if we have evaluated f (x) for two values of x simultaneously, a feature known as ‘quantum parallelism’. Unlike classical parallelism, where multiple circuits each built to compute f(x) are executed simultaneously, here a single f(x) circuit is employed to evaluate the function for multiple values of x simultaneously, by exploiting the ability of a quantum computer to be in superpositions of different states.
This procedure can easily be generalized to functions on an arbitrary number of bits, by using a general operation known as the Hadamard transform, or sometimes the Walsh– Hadamard transform. This operation is just n Hadamard gates acting in parallel on n qubits. For example, shown in Figure 1.18 is the case n = 2 with qubits initially prepared as |0⟩, which gives
􏰐 |0⟩ + |1⟩ 􏰑 􏰐 |0⟩ + |1⟩ 􏰑 |00⟩ + |01⟩ + |10⟩ + |11⟩
√2 √2 = 2 (1.38)
as output. We write H⊗2 to denote the parallel action of two Hadamard gates, and read ‘⊗’ as ‘tensor’. More generally, the result of performing the Hadamard transform on n
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
     Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

32 Introduction and overview qubits initially in the all |0⟩ state is
 1 √2n
􏰸
x
|x⟩ ,
(1.39)
  where the sum is over all possible values of x, and we write H⊗n to denote this action. That is, the Hadamard transform produces an equal superposition of all computational basis states. Moreover, it does this extremely efficiently, producing a superposition of 2n states using just n gates.
Figure 1.18. The Hadamard transform H⊗2 on two qubits.
Quantum parallel evaluation of a function with an n bit input x and 1 bit output, f (x), can thus be performed in the following manner. Prepare the n + 1 qubit state |0⟩⊗n|0⟩, then apply the Hadamard transform to the first n qubits, followed by the quantum circuit implementing Uf . This produces the state
􏰸
x
In some sense, quantum parallelism enables all possible values of the function f to be
evaluated simultaneously, even though we apparently only evaluated f once. However,
this parallelism is not immediately useful. In our single qubit example, measurement of the
                        1 √2n
|x⟩|f (x)⟩ . (1.40)
  state gives only either |0, f (0)⟩ or |1, f (1)⟩! Similarly, in the general case, measurement of
thestate􏰶 |x,f(x)⟩wouldgiveonlyf(x)forasinglevalueofx.Ofcourse,aclassical x
computer can do this easily! Quantum computation requires something more than just
quantum parallelism to be useful; it requires the ability to extract information about more
than one value of f(x) from superposition states like 􏰶 |x,f(x)⟩. Over the next two x
sections we investigate examples of how this may be done.
1.4.3 Deutsch’s algorithm
A simple modification of the circuit in Figure 1.17 demonstrates how quantum circuits
can outperform classical ones by implementing Deutsch’s algorithm (we actually present
a simplified and improved version of the original algorithm; see ‘History and further
reading’ at the end of the chapter). Deutsch’s algorithm combines quantum parallelism
with a property of quantum mechanics known as interference. As before, let us use the √
Hadamard gate to prepare the first qubit as the superposition (|0⟩ + |1⟩)/ 2, but now
The input state
|ψ0⟩ = |01⟩
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 √
2, using a Hadamard gate applied to the state |1⟩. Let us follow the states along to see what happens in this
 let us prepare the second qubit y as the superposition (|0⟩ − |1⟩)/ circuit, shown in Figure 1.19.
(1.41)
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Quantum algorithms 33
                                                                              Figure 1.19. Quantum circuit implementing Deutsch’s algorithm.
is sent through two Hadamard gates to give
􏰒 |0⟩ + |1⟩ 􏰓 􏰒 |0⟩ − |1⟩ 􏰓 |ψ1⟩ = √ √ .
22
(1.42) 2 then we obtain
    √
the state (−1)f(x)|x⟩(|0⟩ − |1⟩)/ 2. Applying Uf to |ψ1⟩ therefore leaves us with one of
 A little thought shows that if we apply U √
to the state |x⟩(|0⟩ − |1⟩)/
 two possibilities:
|ψ2⟩ = ⎪ ⎪⎩
f
􏰒|0⟩+|1⟩􏰓􏰒|0⟩−|1⟩􏰓 ± √ 2 √ 2
􏰒|0⟩ − |1⟩􏰓 􏰒|0⟩ − |1⟩􏰓 ± √ √
⎧⎪ ⎪ ⎪ ⎪⎨
i f f ( 0 ) = f ( 1 ) i f f ( 0 ) ̸ = f ( 1 ) .
        22
The final Hadamard gate on the first qubit thus gives us
(1.43)
(1.44)
⎧⎪
⎪⎨ ±|0⟩
􏰒|0⟩ − |1⟩􏰓
|ψ3⟩ = ±|f(0) ⊕ f(1)⟩ √ , (1.45)
2
  |ψ3⟩ = ⎪
⎪⎩ ±|1⟩
􏰒 | 0 ⟩ − | 1 ⟩ 􏰓 √2
􏰒|0⟩ − |1⟩􏰓
if f(0) = f(1) iff(0)̸=f(1).
√
Realizing that f (0) ⊕ f (1) is 0 if f (0) = f (1) and 1 otherwise, we can rewrite this result
  concisely as
2
  so by measuring the first qubit we may determine f (0) ⊕ f (1). This is very interesting indeed: the quantum circuit has given us the ability to determine a global property of f(x), namely f(0)⊕f(1), using only one evaluation of f(x)! This is faster than is possible with a classical apparatus, which would require at least two evaluations.
This example highlights the difference between quantum parallelism and classical randomized algorithms. Naively, one might think that the state |0⟩|f(0)⟩ + |1⟩|f(1)⟩ corresponds rather closely to a probabilistic classical computer that evaluates f(0) with probability one-half, or f (1) with probability one-half. The difference is that in a classical computer these two alternatives forever exclude one another; in a quantum computer it is
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

34 Introduction and overview
 possible for the two alternatives to interfere with one another to yield some global property of the function f, by using something like the Hadamard gate to recombine the different alternatives, as was done in Deutsch’s algorithm. The essence of the design of many quantum algorithms is that a clever choice of function and final transformation allows efficient determination of useful global information about the function – information which cannot be attained quickly on a classical computer.
1.4.4 The Deutsch–Jozsa algorithm
Deutsch’s algorithm is a simple case of a more general quantum algorithm, which we shall refer to as the Deutsch–Jozsa algorithm. The application, known as Deutsch’s problem, may be described as the following game. Alice, in Amsterdam, selects a number x from 0 to 2n − 1, and mails it in a letter to Bob, in Boston. Bob calculates some function f(x) and replies with the result, which is either 0 or 1. Now, Bob has promised to use a function f which is of one of two kinds; either f(x) is constant for all values of x, or else f(x) is balanced, that is, equal to 1 for exactly half of all the possible x, and 0 for the other half. Alice’s goal is to determine with certainty whether Bob has chosen a constant or a balanced function, corresponding with him as little as possible. How fast can she succeed?
In the classical case, Alice may only send Bob one value of x in each letter. At worst, Alice will need to query Bob at least 2n/2+1 times, since she may receive 2n/2 0s before finally getting a 1, telling her that Bob’s function is balanced. The best deterministic classical algorithm she can use therefore requires 2n/2 + 1 queries. Note that in each letter, Alice sends Bob n bits of information. Furthermore, in this example, physical distance is being used to artificially elevate the cost of calculating f(x), but this is not needed in the general problem, where f(x) may be inherently difficult to calculate.
If Bob and Alice were able to exchange qubits, instead of just classical bits, and if Bob agreed to calculate f (x) using a unitary transform Uf , then Alice could achieve her goal in just one correspondence with Bob, using the following algorithm.
Analogously to Deutsch’s algorithm, Alice has an n qubit register to store her query in, and a single qubit register which she will give to Bob, to store the answer in. She begins by preparing both her query and answer registers in a superposition state. Bob will evaluate f(x) using quantum parallelism and leave the result in the answer register. Alice then interferes states in the superposition using a Hadamard transform on the query register, and finishes by performing a suitable measurement to determine whether f was constant or balanced.
The specific steps of the algorithm are depicted in Figure 1.20. Let us follow the states through this circuit. The input state
|ψ0⟩ = |0⟩⊗n|1⟩ (1.46)
is similar to that of Equation (1.41), but here the query register describes the state of n qubits all prepared in the |0⟩ state. After the Hadamard transform on the query register and the Hadamard gate on the answer register we have
|x⟩ 􏰒|0⟩−|1⟩􏰓
√2n √2 . (1.47)
􏰸
|ψ1⟩ =
The query register is now a superposition of all values, and the answer register is in an
    Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
x∈{0,1}n
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Quantum algorithms 35
                                                                                     Figure 1.20. Quantum circuit implementing the general Deutsch–Jozsa algorithm. The wire with a ‘/’ through it represents a set of n qubits, similar to the common engineering notation.
evenly weighted superposition of 0 and 1. Next, the function f is evaluated (by Bob) usingUf :|x,y⟩→|x,y⊕f(x)⟩,giving
|ψ2⟩ =
√2n √2 . (1.48)
􏰸 (−1)f(x)|x⟩ 􏰒|0⟩ − |1⟩􏰓
    x
Alice now has a set of qubits in which the result of Bob’s function evaluation is stored in the amplitude of the qubit superposition state. She now interferes terms in the super- position using a Hadamard transform on the query register. To determine the result of the Hadamard transform it helps to first calculate the effect of the Hadamard transform on a state |x⟩. By checking the cases x = 0 and x = 1 separately we see that for a single qubit H|x⟩ = 􏰶 (−1)xz|z⟩/√2. Thus
 z
H⊗n|x1, . . . , xn⟩ = z1,...,zn √2n
􏰶 (−1)x1z1+···+xnzn|z1,...,zn⟩ This can be summarized more succinctly in the very useful equation
.
(1.49)
  and (1.48) we can now evaluate |ψ3⟩, |ψ3⟩ =
􏰶 (−1)x·z|z⟩
H⊗n|x⟩ = z
where x · z is the bitwise inner product of x and z, modulo 2. Using this equation
zx
√2n ,
􏰸 􏰸 (−1)x·z+f (x)|z⟩ 􏰒 |0⟩ − |1⟩ 􏰓
(1.50)
  2n √2 . (1.51) Alice now observes the query register. Note that the amplitude for the state |0⟩⊗n is
   􏰶 (−1)f(x)/2n. Let’s look at the two possible cases – f constant and f balanced – to x
discern what happens. In the case where f is constant the amplitude for |0⟩⊗n is +1 or −1, depending on the constant value f(x) takes. Because |ψ3⟩ is of unit length it follows that all the other amplitudes must be zero, and an observation will yield 0s for all qubits in the query register. If f is balanced then the positive and negative contributions to the amplitude for |0⟩⊗n cancel, leaving an amplitude of zero, and a measurement must yield a result other than 0 on at least one qubit in the query register. Summarizing, if Alice
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

36 Introduction and overview
measures all 0s then the function is constant; otherwise the function is balanced. The
Deutsch–Jozsa algorithm is summarized below.
Algorithm: Deutsch–Jozsa
Inputs: (1) A black box Uf which performs the transformation
|x⟩|y⟩ → |x⟩|y ⊕ f (x)⟩, for x ∈ {0, . . . , 2n − 1} and f (x) ∈ {0, 1}. It is promised that f(x) is either constant for all values of x, or else f(x) is balanced, that is, equal to 1 for exactly half of all the possible x, and 0 for the other half.
Outputs: 0 if and only if f is constant.
Runtime: One evaluation of Uf . Always succeeds.
 Procedure:
1. |0⟩⊗n |1⟩
initialize state
create superposition using Hadamard gates
calculate function f using Uf perform Hadamard transform
measure to obtain final output z
􏰒􏰓 1 􏰸 |0⟩−|1⟩
2n −1
2. → √2n |x⟩
􏰸 x=0
3. → (−1)f (x) |x⟩
√2 􏰒|0⟩−|1⟩􏰓
    √
  4. →
5. → z
zx
√2n √2
x2􏰒􏰓 􏰸􏰸(−1)x·z+f(x)|z⟩ |0⟩−|1⟩
    We’ve shown that a quantum computer can solve Deutsch’s problem with one evalu- ation of the function f compared to the classical requirement for 2n/2 + 1 evaluations. This appears impressive, but there are several important caveats. First, Deutsch’s prob- lem is not an especially important problem; it has no known applications. Second, the comparison between classical and quantum algorithms is in some ways an apples and oranges comparison, as the method for evaluating the function is quite different in the two cases. Third, if Alice is allowed to use a probabilistic classical computer, then by asking Bob to evaluate f(x) for a few randomly chosen x she can very quickly determine with high probability whether f is constant or balanced. This probabilistic scenario is perhaps more realistic than the deterministic scenario we have been considering. Despite these caveats, the Deutsch–Jozsa algorithm contains the seeds for more impressive quan- tum algorithms, and it is enlightening to attempt to understand the principles behind its operation.
Exercise 1.1: (Probabilistic classical algorithm) Suppose that the problem is not to distinguish between the constant and balanced functions with certainty, but rather, with some probability of error ε &lt; 1/2. What is the performance of the best classical algorithm for this problem?
1.4.5 Quantum algorithms summarized
The Deutsch–Jozsa algorithm suggests that quantum computers may be capable of solving some computational problems much more efficiently than classical computers. Unfortu- nately, the problem it solves is of little practical interest. Are there more interesting
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

problems whose solution may be obtained more efficiently using quantum algorithms? What are the principles underlying such algorithms? What are the ultimate limits of a quantum computer’s computational power?
Broadly speaking, there are three classes of quantum algorithms which provide an advantage over known classical algorithms. First, there is the class of algorithms based upon quantum versions of the Fourier transform, a tool which is also widely used in classical algorithms. The Deutsch–Jozsa algorithm is an example of this type of algo- rithm, as are Shor’s algorithms for factoring and discrete logarithm. The second class of algorithms is quantum search algorithms. The third class of algorithms is quantum simulation, whereby a quantum computer is used to simulate a quantum system. We now briefly describe each of these classes of algorithms, and then summarize what is known or suspected about the computational power of quantum computers.
Quantum algorithms based upon the Fourier transform
The discrete Fourier transform is usually described as transforming a set x0,...,xN−1 of N complex numbers into a set of complex numbers y0,...,yN−1 defined by
j=0
Of course, this transformation has an enormous number of applications in many branches of science; the Fourier transformed version of a problem is often easier than the original problem, enabling a solution.
The Fourier transform has proved so useful that a beautiful generalized theory of Fourier transforms has been developed which goes beyond the definition (1.52). This general theory involves some technical ideas from the character theory of finite groups, and we will not attempt to describe it here. What is important is that the Hadamard transform used in the Deutsch–Jozsa algorithm is an example of this generalized class of Fourier transforms. Moreover, many of the other important quantum algorithms also involve some type of Fourier transform.
The most important quantum algorithms known, Shor’s fast algorithms for factoring and discrete logarithm, are two examples of algorithms based upon the Fourier trans- form defined in Equation (1.52). The Equation (1.52) does not appear terribly quantum mechanical in the form we have written it. Imagine, however, that we define a linear transformation U on n qubits by its action on computational basis states |j⟩, where 0 ≤ j ≤ 2n − 1,
( 1 . 5 3 )
yk ≡ √N
e xj . (1.52)
N−1
1 􏰸 2πijk/N
Quantum algorithms 37
   | j ⟩ −→ √ 2 n
n
2n −1
1 􏰸 2πijk/2
e | k ⟩ .
  k=0
It can be checked that this transformation is unitary, and in fact can be realized as a quantum circuit. Moreover, if we write out its action on superpositions,
2n−1 􏰸
⎡⎤
2n−1
e x j | k ⟩ = y k | k ⟩ , ( 1 . 5 4 )
k=0
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
2n−1 2n−1
1􏰸⎣􏰸2πijk/2 ⎦ 􏰸
x j | j ⟩ −→ √ 2 n
we see that it corresponds to a vector notation for the Fourier transform (1.52) for the
case N = 2n.
n
  j=0
k=0 j=0
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

38 Introduction and overview
 How quickly can we perform the Fourier transform? Classically, the fast Fourier trans- form takes roughly N log(N) = n2n steps to Fourier transform N = 2n numbers. On a quantum computer, the Fourier transform can be accomplished using about log2(N) = n2 steps, an exponential saving! The quantum circuit to do this is explained in Chapter 5.
This result seems to indicate that quantum computers can be used to very quickly compute the Fourier transform of a vector of 2n complex numbers, which would be fantastically useful in a wide range of applications. However, that is not exactly the case; the Fourier transform is being performed on the information ‘hidden’ in the amplitudes of the quantum state. This information is not directly accessible to measurement. The catch, of course, is that if the output state is measured, it will collapse each qubit into the state |0⟩ or |1⟩, preventing us from learning the transform result yk directly. This example speaks to the heart of the conundrum of devising a quantum algorithm. On the one hand, we can perform certain calculations on the 2n amplitudes associated with n qubits far more efficiently than would be possible on a classical computer. But on the other hand, the results of such a calculation are not available to us if we go about it in a straightforward manner. More cleverness is required in order to harness the power of quantum computation.
Fortunately, it does turn out to be possible to utilize the quantum Fourier transform to efficiently solve several problems that are believed to have no efficient solution on a classical computer. These problems include Deutsch’s problem, and Shor’s algorithms for discrete logarithm and factoring. This line of thought culminated in Kitaev’s discovery of a method to solve the Abelian stabilizer problem, and the generalization to the hidden subgroup problem,
Let f be a function from a finitely generated group G to a finite set X such that f is constant on the cosets of a subgroup K, and distinct on each coset. Given a quantum black box for performing the unitary transform U|g⟩|h⟩ = |g⟩|h⊕f(g)⟩, for g ∈ G, h ∈ X, and ⊕ an appropriately chosen binary operation on X, find a generating set for K.
The Deutsch–Jozsa algorithm, Shor’s algorithms, and related ‘exponentially fast’ quan- tum algorithms can all be viewed as special cases of this algorithm. The quantum Fourier transform and its applications are described in Chapter 5.
Quantum search algorithms
A completely different class of algorithms is represented by the quantum search algorithm,
whose basic principles were discovered by Grover. The quantum search algorithm solves
the following problem: Given a search space of size N , and no prior knowledge about the
structure of the information in it, we want to find an element of that search space satisfying
a known property. How long does it take to find an element satisfying that property?
Classically, this problem requires approximately N operations, but the quantum search
N operations.
The quantum search algorithm offers only a quadratic speedup, as opposed to the more impressive exponential speedup offered by algorithms based on the quantum Fourier transform. However, the quantum search algorithm is still of great interest, since search- ing heuristics have a wider range of application than the problems solved using the quan- tum Fourier transform, and adaptations of the quantum search algorithm may have utility
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 algorithm allows it to be solved using approximately
√
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Quantum algorithms 39 for a very wide range of problems. The quantum search algorithm and its applications
are described in Chapter 6.
Quantum simulation
Simulating naturally occurring quantum mechanical systems is an obvious candidate for a task at which quantum computers may excel, yet which is believed to be difficult on a classical computer. Classical computers have difficulty simulating general quantum systems for much the same reasons they have difficulty simulating quantum computers – the number of complex numbers needed to describe a quantum system generally grows exponentially with the size of the system, rather than linearly, as occurs in classical systems. In general, storing the quantum state of a system with n distinct components takes something like cn bits of memory on a classical computer, where c is a constant which depends upon details of the system being simulated, and the desired accuracy of the simulation.
By contrast, a quantum computer can perform the simulation using kn qubits, where k is again a constant which depends upon the details of the system being simulated. This allows quantum computers to efficiently perform simulations of quantum mechanical systems that are believed not to be efficiently simulatable on a classical computer. A significant caveat is that even though a quantum computer can simulate many quantum systems far more efficiently than a classical computer, this does not mean that the fast simulation will allow the desired information about the quantum system to be obtained. When measured, a kn qubit simulation will collapse into a definite state, giving only kn bits of information; the cn bits of ‘hidden information’ in the wavefunction is not entirely accessible. Thus, a crucial step in making quantum simulations useful is development of systematic means by which desired answers can be efficiently extracted; how to do this is only partially understood.
Despite this caveat, quantum simulation is likely to be an important application of quantum computers. The simulation of quantum systems is an important problem in many fields, notably quantum chemistry, where the computational constraints imposed by classical computers make it difficult to accurately simulate the behavior of even mod- erately sized molecules, much less the very large molecules that occur in many important biological systems. Obtaining faster and more accurate simulations of such systems may therefore have the welcome effect of enabling advances in other fields in which quantum phenomena are important.
In the future we may discover a physical phenomenon in Nature which cannot be efficiently simulated on a quantum computer. Far from being bad news, this would be wonderful! At the least, it will stimulate us to extend our models of computation to encompass the new phenomenon, and increase the power of our computational models beyond the existing quantum computing model. It also seems likely that very interesting new physical effects will be associated with any such phenomenon!
Another application for quantum simulation is as a general method to obtain insight into other quantum algorithms; for example, in Section 6.2 we explain how the quantum search algorithm can be viewed as the solution to a problem of quantum simulation. By approaching the problem in this fashion it becomes much easier to understand the origin of the quantum search algorithm.
Finally, quantum simulation also gives rise to an interesting and optimistic ‘quantum corollary’ to Moore’s law. Recall that Moore’s law states that the power of classical
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

40 Introduction and overview
 computers will double once every two years or so, for constant cost. However, suppose we are simulating a quantum system on a classical computer, and want to add a single qubit (or a larger system) to the system being simulated. This doubles or more the memory requirements needed for a classical computer to store a description of the state of the quantum system, with a similar or greater cost in the time needed to simulate the dynamics. The quantum corollary to Moore’s law follows from this observation, stating that quantum computers are keeping pace with classical computers provided a single qubit is added to the quantum computer every two years. This corollary should not be taken too seriously, as the exact nature of the gain, if any, of quantum computation over classical is not yet clear. Nevertheless, this heuristic statement helps convey why we should be interested in quantum computers, and hopeful that they will one day be able to outperform the most powerful classical computers, at least for some applications.
The power of quantum computation
How powerful are quantum computers? What gives them their power? Nobody yet knows the answers to these questions, despite the suspicions fostered by examples such as fac- toring, which strongly suggest that quantum computers are more powerful than classical computers. It is still possible that quantum computers are no more powerful than classical computers, in the sense that any problem which can be efficiently solved on a quantum computer can also be efficiently solved on a classical computer. On the other hand, it may eventually be proved that quantum computers are much more powerful than classi- cal computers. We now take a brief look at what is known about the power of quantum computation.
Computational complexity theory is the subject of classifying the difficulty of vari- ous computational problems, both classical and quantum, and to understand the power of quantum computers we will first examine some general ideas from computational com- plexity. The most basic idea is that of a complexity class. A complexity class can be thought of as a collection of computational problems, all of which share some common feature with respect to the computational resources needed to solve those problems.
Two of the most important complexity classes go by the names P and NP. Roughly speaking, P is the class of computational problems that can be solved quickly on a classical computer. NP is the class of problems which have solutions which can be quickly checked on a classical computer. To understand the distinction between P and NP, consider the problem of finding the prime factors of an integer, n. So far as is known there is no fast way of solving this problem on a classical computer, which suggests that the problem is not in P. On the other hand, if somebody tells you that some number p is a factor of n, then we can quickly check that this is correct by dividing p into n, so factoring is a problem in NP.
It is clear that P is a subset of NP, since the ability to solve a problem implies the ability to check potential solutions. What is not so clear is whether or not there are problems in NP that are not in P. Perhaps the most important unsolved problem in theoretical computer science is to determine whether these two classes are different:
?
P ̸= NP. (1.55)
Most researchers believe that NP contains problems that are not in P. In particular, there is an important subclass of the NP problems, the NP-complete problems, that are
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Quantum algorithms 41
 of especial importance for two reasons. First, there are thousands of problems, many highly important, that are known to be NP-complete. Second, any given NP-complete problem is in some sense ‘at least as hard’ as all other problems in NP. More precisely, an algorithm to solve a specific NP-complete problem can be adapted to solve any other problem in NP, with a small overhead. In particular, if P ̸= NP, then it will follow that no NP-complete problem can be efficiently solved on a classical computer.
It is not known whether quantum computers can be used to quickly solve all the problems in NP, despite the fact that they can be used to solve some problems – like factoring – which are believed by many people to be in NP but not in P. (Note that factoring is not known to be NP-complete, otherwise we would already know how to efficiently solve all problems in NP using quantum computers.) It would certainly be very exciting if it were possible to solve all the problems in NP efficiently on a quantum computer. There is a very interesting negative result known in this direction which rules out using a simple variant of quantum parallelism to solve all the problems in NP. Specifically, one approach to the problem of solving problems in NP on a quantum computer is to try to use some form of quantum parallelism to search in parallel through all the possible solutions to the problem. In Section 6.6 we will show that no approach based upon such a search-based methodology can yield an efficient solution to all the problems in NP. While it is disappointing that this approach fails, it does not rule out that some deeper structure exists in the problems in NP that will allow them all to be solved quickly using a quantum computer.
P and NP are just two of a plethora of complexity classes that have been defined. Another important complexity class is PSPACE. Roughly speaking, PSPACE consists of those problems which can be solved using resources which are few in spatial size (that is, the computer is ‘small’), but not necessarily in time (‘long’ computations are fine). PSPACE is believed to be strictly larger than both P and NP although, again, this has never been proved. Finally, the complexity class BPP is the class of problems that can be solved using randomized algorithms in polynomial time, if a bounded probability of error (say 1/4) is allowed in the solution to the problem. BPP is widely regarded as being, even more so than P, the class of problems which should be considered efficiently soluble on a classical computer. We have elected to concentrate here on P rather than BPP because P has been studied in more depth, however many similar ideas and conclusions arise in connection with BPP.
What of quantum complexity classes? We can define BQP to be the class of all com- putational problems which can be solved efficiently on a quantum computer, where a bounded probability of error is allowed. (Strictly speaking this makes BQP more analo- gous to the classical complexity class BPP than to P, however we will ignore this subtlety for the purposes of the present discussion, and treat it as the analogue of P.) Exactly where BQP fits with respect to P, NP and PSPACE is as yet unknown. What is known is that quantum computers can solve all the problems in P efficiently, but that there are no problems outside of PSPACE which they can solve efficiently. Therefore, BQP lies somewhere between P and PSPACE, as illustrated in Figure 1.21. An important implication is that if it is proved that quantum computers are strictly more powerful than classical computers, then it will follow that P is not equal to PSPACE. Proving this latter result has been attempted without success by many computer scientists, suggesting that it may be non-trivial to prove that quantum computers are more powerful than classical computers, despite much evidence in favor of this proposition.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

42 Introduction and overview
  PSPACE NP
P
Figure 1.21. The relationship between classical and quantum complexity classes. Quantum computers can quickly solve any problem in P, and it is known that they can’t solve problems outside of PSPACE quickly. Where quantum computers fit between P and PSPACE is not known, in part because we don’t even know whether PSPACE is bigger than P!
We won’t speculate further on the ultimate power of quantum computation now, preferring to wait until after we have better understood the principles on which fast quantum algorithms are based, a topic which occupies us for most of Part II of this book. What is already clear is that the theory of quantum computation poses interesting and significant challenges to the traditional notions of computation. What makes this an important challenge is that the theoretical model of quantum computation is believed to be experimentally realizable, because – to the best of our knowledge – this theory is consistent with the way Nature works. If this were not so then quantum computation would be just another mathematical curiosity.
1.5 Experimental quantum information processing
Quantum computation and quantum information is a wonderful theoretical discovery, but its central concepts, such as superpositions and entanglement, run counter to the intuition we garner from the everyday world around us. What evidence do we have that these ideas truly describe how Nature operates? Will the realization of large-scale quantum
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
BQP?
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Experimental quantum information processing 43
 computers be experimentally feasible? Or might there be some principle of physics which fundamentally prohibits their eventual scaling? In the next two sections we address these questions. We begin with a review of the famous ‘Stern–Gerlach’ experiment, which provides evidence for the existence of qubits in Nature. We then widen our scope, addressing the broader problem of how to build practical quantum information processing systems.
1.5.1 The Stern–Gerlach experiment
The qubit is a fundamental element for quantum computation and quantum information. How do we know that systems with the properties of qubits exist in Nature? At the time of writing there is an enormous amount of evidence that this is so, but in the early days of quantum mechanics the qubit structure was not at all obvious, and people struggled with phenomena that we may now understand in terms of qubits, that is, in terms of two level quantum systems.
A decisive (and very famous) early experiment indicating the qubit structure was conceived by Stern in 1921 and performed with Gerlach in 1922 in Frankfurt. In the original Stern–Gerlach experiment, hot atoms were ‘beamed’ from an oven through a magnetic field which caused the atoms to be deflected, and then the position of each atom was recorded, as illustrated in Figure 1.22. The original experiment was done with silver atoms, which have a complicated structure that obscures the effects we are discussing. What we describe below actually follows a 1927 experiment done using hydrogen atoms. The same basic effect is observed, but with hydrogen atoms the discussion is easier to follow. Keep in mind, though, that this privilege wasn’t available to people in the early 1920s, and they had to be very ingenious to think up explanations for the more complicated effects they observed.
Hydrogen atoms contain a proton and an orbiting electron. You can think of this elec- tron as a little ‘electric current’ around the proton. This electric current causes the atom to have a magnetic field; each atom has what physicists call a ‘magnetic dipole moment’. As a result each atom behaves like a little bar magnet with an axis corresponding to the axis the electron is spinning around. Throwing little bar magnets through a magnetic field causes the magnets to be deflected by the field, and we expect to see a similar deflection of atoms in the Stern–Gerlach experiment.
How the atom is deflected depends upon both the atom’s magnetic dipole moment – the axis the electron is spinning around – and the magnetic field generated by the Stern– Gerlach device. We won’t go through the details, but suffice to say that by constructing the Stern–Gerlach device appropriately, we can cause the atom to be deflected by an amount that depends upon the zˆ component of the atom’s magnetic dipole moment, where zˆ is some fixed external axis.
Two major surprises emerge when this experiment is performed. First, since the hot atoms exiting the oven would naturally be expected to have their dipoles oriented randomly in every direction, it would follow that there would be a continuous distribution of atoms seen at all angles exiting from the Stern–Gerlach device. Instead, what is seen is atoms emerging from a discrete set of angles. Physicists were able to explain this by assuming that the magnetic dipole moment of the atoms is quantized, that is, comes in discrete multiples of some fundamental amount.
This observation of quantization in the Stern–Gerlach experiment was surprising to physicists of the 1920s, but not completely astonishing because evidence for quantization
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

44 Introduction and overview
 effects in other systems was becoming widespread at that time. What was truly surpris- ing was the number of peaks seen in the experiment. The hydrogen atoms being used were such that they should have had zero magnetic dipole moment. Classically, this is surprising in itself, since it corresponds to no orbital motion of the electron, but based on what was known of quantum mechanics at that time this was an acceptable notion. Since the hydrogen atoms would therefore have zero magnetic moment, it was expected that only one beam of atoms would be seen, and this beam would not be deflected by the magnetic field. Instead, two beams were seen, one deflected up by the magnetic field, and the other deflected down!
This puzzling doubling was explained after considerable effort by positing that the electron in the hydrogen atom has associated with it a quantity called spin. This spin is not in any way associated to the usual rotational motion of the electron around the proton; it is an entirely new quantity to be associated with an electron. The great physicist Heisenberg labeled the idea ‘brave’ at the time it was suggested, and it is a brave idea, since it introduces an essentially new physical quantity into Nature. The spin of the electron is posited to make an extra contribution to the magnetic dipole moment of a hydrogen atom, in addition to the contribution due to the rotational motion of the electron.
GG GG
GG
Figure 1.22. Abstract schematic of the Stern–Gerlach experiment. Hot hydrogen atoms are beamed from an oven
through a magnetic field, causing a deflection either up (| + Z) or down (| − Z).
What is the proper description of the spin of the electron? As a first guess, we might hypothesize that the spin is specified by a single bit, telling the hydrogen atom to go up or down. Additional experimental results provide further useful information to determine if this guess needs refinement or replacement. Let’s represent the original Stern–Gerlach apparatus as shown in Figure 1.22. Its outputs are two beams of atoms, which we shall call |+Z⟩ and |−Z⟩. (We’re using suggestive notation which looks quantum mechanical, but of course you’re free to use whatever notation you prefer.) Now suppose we cascade two Stern–Gerlach apparatus together, as shown in Figure 1.23. We arrange it so that the second apparatus is tipped sideways, so the magnetic field deflects atoms along the xˆ axis. In our thought-experiment we’ll block off the |−Z⟩ output from the first Stern–Gerlach apparatus, while the | + Z⟩ output is sent through a second apparatus oriented along the xˆ axis. A detector is placed at the final output to measure the distribution of atoms along the xˆ axis.
A classical magnetic dipole pointed in the +zˆ direction has no net magnetic moment in the xˆ direction, so we might expect that the final output would have one central peak. However, experimentally it is observed that there are two peaks of equal intensity! So perhaps these atoms are peculiar, and have definite magnetic moments along each axis, independently. That is, maybe each atom passing through the second apparatus can be
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
                               Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Experimental quantum information processing 45
                 GG GG
         GG
           GG GG Figure 1.23. Cascaded Stern–Gerlach measurements.
described as being in a state we might write as |+Z⟩|+X⟩ or |+Z⟩|−X⟩, to indicate the two values for spin that might be observed.
                                           GG GG GG
            GG
Another experiment, shown in Figure 1.24, can test this hypothesis by sending one beam of the previous output through a second zˆ oriented Stern–Gerlach apparatus. If the atoms had retained their | + Z⟩ orientation, then the output would be expected to have only one peak, at the | + Z⟩ output. However, again two beams are observed at the final output, of equal intensity. Thus, the conclusion would seem to be that contrary to classical expectations, a | + Z⟩ state consists of equal portions of | + X⟩ and | − X⟩ states, and a | + X⟩ state consists of equal portions of | + Z⟩ and | − Z⟩ states. Similar conclusions can be reached if the Stern–Gerlach apparatus is aligned along some other axis, like the yˆ axis.
The qubit model provides a simple explanation of this experimentally observed be- havior. Let |0⟩ and |1⟩ be the states of a qubit, and make the assignments
               GG GG GG Figure 1.24. Three stage cascaded Stern–Gerlach measurements.
                          | + Z⟩ ← |0⟩
| − Z⟩ ← |1⟩ √
|+X⟩←(|0⟩+|1⟩)/ 2. √
|−X⟩ ← (|0⟩−|1⟩)/ 2
(1.56) (1.57) (1.58) (1.59)
  Then the results of the cascaded Stern–Gerlach experiment can be explained by assuming
that the zˆ Stern–Gerlach apparatus measures the spin (that is, the qubit) in the computa-
tional basis |0⟩, |1⟩, and the xˆ Stern–Gerlach apparatus measures the spin with respect to √√
the basis (|0⟩ + |1⟩)/ 2, (|0⟩ − |1⟩)/ 2. For example, in the cascaded zˆ-xˆ -zˆ experiment,
properly predicts results from this type of cascaded Stern–Gerlach experiment.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
  √
2 after exiting the first Stern–Gerlach experiment, then the probability for obtaining | + X⟩ out of the second apparatus is 1/2, and the probability for | − X⟩ is 1/2. Similarly, the probability for obtaining | + Z⟩ out of the third apparatus is 1/2. A qubit model thus
 if we assume that the spins are in the state |+Z⟩ = |0⟩ = (|+X⟩+|−X⟩)/
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

46 Introduction and overview
 This example demonstrates how qubits could be a believable way of modeling systems in Nature. Of course it doesn’t establish beyond all doubt that the qubit model is the correct way of understanding electron spin – far more experimental corroboration is required. Nevertheless, because of many experiments like these, we now believe that electron spin is best described by the qubit model. What is more, we believe that the qubit model (and generalizations of it to higher dimensions; quantum mechanics, in other words) is capable of describing every physical system. We now turn to the question of what systems are especially well adapted to quantum information processing.
1.5.2 Prospects for practical quantum information processing
Building quantum information processing devices is a great challenge for scientists and engineers of the third millennium. Will we rise to meet this challenge? Is it possible at all? Is it worth attempting? If so, how might the feat be accomplished? These are difficult and important questions, to which we essay brief answers in this section, to be expanded upon throughout the book.
The most fundamental question is whether there is any point of principle that prohibits us from doing one or more forms of quantum information processing? Two possible obstructions suggest themselves: that noise may place a fundamental barrier to useful quantum information processing; or that quantum mechanics may fail to be correct.
Noise is without a doubt a significant obstruction to the development of practical quantum information processing devices. Is it a fundamentally irremovable obstruction that will forever prevent the development of large-scale quantum information process- ing devices? The theory of quantum error-correcting codes strongly suggests that while quantum noise is a practical problem that needs to be addressed, it does not present a fundamental problem of principle. In particular, there is a threshold theorem for quan- tum computation, which states, roughly speaking, that provided the level of noise in a quantum computer can be reduced below a certain constant ‘threshold’ value, quantum error-correcting codes can be used to push it down even further, essentially ad infini- tum, for a small overhead in the complexity of the computation. The threshold theorem makes some broad assumptions about the nature and magnitude of the noise occurring in a quantum computer, and the architecture available for performing quantum computa- tion; however, provided those assumptions are satisfied, the effects of noise can be made essentially negligible for quantum information processing. Chapters 8, 10 and 12 discuss quantum noise, quantum error-correction and the threshold theorem in detail.
A second possibility that may preclude quantum information processing is if quan- tum mechanics is incorrect. Indeed, probing the validity of quantum mechanics (both relativistic and non-relativistic) is one reason for being interested in building quantum information processing devices. Never before have we explored a regime of Nature in which complete control has been obtained over large-scale quantum systems, and perhaps Nature may reveal some new surprises in this regime which are not adequately explained by quantum mechanics. If this occurs, it will be a momentous discovery in the history of science, and can be expected to have considerable consequences in other areas of science and technology, as did the discovery of quantum mechanics. Such a discovery might also impact quantum computation and quantum information; however, whether the impact would enhance, detract or not affect the power of quantum information processing can- not be predicted in advance. Until and unless such effects are found we have no way of knowing how they might affect information processing, so for the remainder of this book
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Experimental quantum information processing 47
 we go with all the evidence to date and assume that quantum mechanics is a complete and correct description of the world.
Given that there is no fundamental obstacle to building quantum information process- ing devices, why should we invest enormous amounts of time and money in the attempt to do so? We have already discussed several reasons for wanting to do so: practical appli- cations such as quantum cryptography and the factoring of large composite numbers; and the desire to obtain fundamental insights into Nature and into information processing.
These are good reasons, and justify a considerable investment of time and money in the effort to build quantum information processing devices. However, it is fair to say that a clearer picture of the relative power of quantum and classical information processing is needed in order to assess their relative merits. To obtain such a picture requires further theoretical work on the foundations of quantum computation and quantum information. Of particular interest is a decisive answer to the question ‘Are quantum computers more powerful than classical computers?’ Even if the answer to such a question eludes us for the time being, it would be useful to have a clear path of interesting applications at varying levels of complexity to aid researchers aiming to experimentally realize quantum information processing. Historically, the advance of technology is often hastened by the use of short- to medium-term incentives as a stepping-stone to long-term goals. Consider that microprocessors were initially used as controllers for elevators and other simple devices, before graduating to be the fundamental component in personal computers (and then on to who-knows-what). Below we sketch out a path of short- to medium-term goals for people interested in achieving the long-term goal of large-scale quantum information processing.
Surprisingly many small-scale applications of quantum computation and quantum in- formation are known. Not all are as flashy as cousins like the quantum factoring algorithm, but the relative ease of implementing small-scale applications makes them extremely im- portant as medium-term goals in themselves.
Quantum state tomography and quantum process tomography are two elementary processes whose perfection is of great importance to quantum computation and quantum information, as well as being of independent interest in their own right. Quantum state tomography is a method for determining the quantum state of a system. To do this, it has to overcome the ‘hidden’ nature of the quantum state – remember, the state can’t be directly determined by a measurement – by performing repeated preparations of the same quantum state, which is then measured in different ways in order to build up a complete description of the quantum state. Quantum process tomography is a more ambitious (but closely related) procedure to completely characterize the dynamics of a quantum system. Quantum process tomography can, for example, be used to characterize the performance of an alleged quantum gate or quantum communications channel, or to determine the types and magnitudes of different noise processes in a system. Beside obvious applica- tions to quantum computation and quantum information, quantum process tomography can be expected to have significant applications as a diagnostic tool to aid in the eval- uation and improvement of primitive operations in any field of science and technology where quantum effects are important. Quantum state tomography and quantum process tomography are described in more detail in Chapter 8.
Various small-scale communications primitives are also of great interest. We have al- ready mentioned quantum cryptography and quantum teleportation. The former is likely to be useful in practical applications involving the distribution of a small amount of key
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

48 Introduction and overview
 material that needs to be highly secure. The uses of quantum teleportation are perhaps more open to question. We will see in Chapter 12 that teleportation may be an extremely useful primitive for transmitting quantum states between distant nodes in a network, in the presence of noise. The idea is to focus one’s efforts on distributing EPR pairs between the nodes that wish to communicate. The EPR pairs may be corrupted during commu- nication, but special ‘entanglement distillation’ protocols can then be used to ‘clean up’ the EPR pairs, enabling them to be used to teleport quantum states from one location to another. In fact, procotols based upon entanglement distillation and teleportation of- fer performance superior to more conventional quantum error-correction techniques in enabling noise free communication of qubits.
What of the medium-scale? A promising medium-scale application of quantum in- formation processing is to the simulation of quantum systems. To simulate a quantum system containing even a few dozen ‘qubits’ (or the equivalent in terms of some other basic system) strains the resources of even the largest supercomputers. A simple calcu- lation is instructive. Suppose we have a system containing 50 qubits. To describe the state of such a system requires 250 ≈ 1015 complex amplitudes. If the amplitudes are stored to 128 bits of precision, then it requires 256 bits or 32 bytes in order to store each amplitude, for a total of 32 × 1015 bytes of information, or about 32 thousand terabytes of information, well beyond the capacity of existing computers, and corresponding to about the storage capacity that might be expected to appear in supercomputers during the second decade of the twenty-first century, presuming that Moore’s law continues on schedule. 90 qubits at the same level of precision requires 32 × 1027 bytes, which, even if implemented using single atoms to represent bits, would require kilograms (or more) of matter.
How useful will quantum simulations be? It seems likely that conventional methods will still be used to determine elementary properties of materials, such as bond strengths and basic spectroscopic properties. However, once the basic properties are well understood, it seems likely that quantum simulation will be of great utility as a laboratory for the design and testing of properties of novel molecules. In a conventional laboratory setup, many different types of ‘hardware’ – chemicals, detectors, and so on – may be required to test a wide variety of possible designs for a molecule. On a quantum computer, these different types of hardware can all be simulated in software, which is likely to be much less expensive and much faster. Of course, final design and testing must be performed with real physical systems; however, quantum computers may enable a much larger range of potential designs to be explored and evaluated en route to a better final design. It is interesting to note that such ab initio calculations to aid in the design of new molecules have been attempted on classical computers; however, they have met with limited success due to the enormous computational resources needed to simulate quantum mechanics on a classical computer. Quantum computers should be able to do much better in the relatively near future.
What of large-scale applications? Aside from scaling up applications like quantum simulation and quantum cryptography, relatively few large-scale applications are known: the factoring of large numbers, taking discrete logarithms, and quantum searching. In- terest in the first two of these derives mainly from the negative effect they would have of limiting the viability of existing public key cryptographic systems. (They might also be of substantial practical interest to mathematicians interested in these problems sim- ply for their own sake.) So it does not seem likely that factoring and discrete logarithm
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Experimental quantum information processing 49
 will be all that important as applications for the long run. Quantum searching may be of tremendous use because of the wide utility of the search heuristic, and we discuss some possible applications in Chapter 6. What would really be superb are many more large-scale applications of quantum information processing. This is a great goal for the future!
Given a path of potential applications for quantum information processing, how can it be achieved in real physical systems? At the small scale of a few qubits there are already several working proposals for quantum information processing devices. Perhaps the easiest to realize are based upon optical techniques, that is, electromagnetic radiation. Simple devices like mirrors and beamsplitters can be used to do elementary manipulations of photons. Interestingly, a major difficulty has been producing single photons on demand; experimentalists have instead opted to use schemes which produce single photons ‘every now and then’, at random, and wait for such an event to occur. Quantum cryptography, superdense coding, and quantum teleportation have all been realized using such optical techniques. A major advantage of the optical techniques is that photons tend to be highly stable carriers of quantum mechanical information. A major disadvantage is that photons don’t directly interact with one another. Instead, the interaction has to be mediated by something else, like an atom, which introduces additional noise and complications into the experiment. An effective interaction between two photons is set up, which essentially works in two steps: photon number one interacts with the atom, which in turn interacts with the second photon, causing an overall interaction between the two photons.
An alternative scheme is based upon methods for trapping different types of atom: there is the ion trap, in which a small number of charged atoms are trapped in a confined space; and neutral atom traps, for trapping uncharged atoms in a confined space. Quantum information processing schemes based upon atom traps use the atoms to store qubits. Electromagnetic radiation also shows up in these schemes, but in a rather different way than in what we referred to as the ‘optical’ approach to quantum information processing. In these schemes, photons are used to manipulate the information stored in the atoms themselves, rather than as the place the information is stored. Single qubit quantum gates can be performed by applying appropriate pulses of electromagnetic radiation to individual atoms. Neighboring atoms can interact with one another via (for example) dipole forces that enable quantum gates to be accomplished. Moreover, the exact nature of the interaction between neighboring atoms can be modified by applying appropriate pulses of electromagnetic radiation to the atoms, giving the experimentalist control over what gates are performed in the system. Finally, quantum measurement can be accomplished in these systems using the long established quantum jumps technique, which implements with superb accuracy the measurements in the computational basis used for quantum computation.
Another class of quantum information processing schemes is based upon Nuclear Magnetic Resonance, often known by its initials, NMR. These schemes store quantum information in the nuclear spin of atoms in a molecule, and manipulate that information using electromagnetic radiation. Such schemes pose special difficulties, because in NMR it is not possible to directly access individual nuclei. Instead, a huge number (typically around 1015) of essentially identical molecules are stored in solution. Electromagnetic pulses are applied to the sample, causing each molecule to respond in roughly the same way. You should think of each molecule as being an independent computer, and the sample as containing a huge number of computers all running in parallel (classically).
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

50 Introduction and overview
 NMR quantum information processing faces three special difficulties that make it rather different from other quantum information processing schemes. First, the molecules are typically prepared by letting them equilibrate at room temperature, which is so much higher than typical spin flip energies that the spins become nearly completely randomly oriented. This fact makes the initial state rather more ‘noisy’ than is desirable for quantum information processing. How this noise may be overcome is an interesting story that we tell in Chapter 7. A second problem is that the class of measurements that may be performed in NMR falls well short of the most general measurements we would like to perform in quantum information processing. Nevertheless, for many instances of quantum information processing the class of measurements allowed in NMR is sufficient. Third, because molecules cannot be individually addressed in NMR you might ask how it is that individual qubits can be manipulated in an appropriate way. Fortunately, different nuclei in the molecule can have different properties that allow them to be individually addressed – or at least addressed at a sufficiently fine-grained scale to allow the operations essential for quantum computation.
Many of the elements required to perform large-scale quantum information processing can be found in existing proposals: superb state preparation and quantum measurements can be performed on a small number of qubits in the ion trap; superb dynamics can be performed in small molecules using NMR; fabrication technology in solid state systems allows designs to be scaled up tremendously. A single system having all these elements would be a long way down the road to a dream quantum computer. Unfortunately, all these systems are very different, and we are many, many years from having large-scale quantum computers. However, we believe that the existence of all these properties in existing (albeit different) systems does bode well for the long-term existence of large- scale quantum information processors. Furthermore, it suggests that there is a great deal of merit to pursuing hybrid designs which attempt to marry the best features of two or more existing technologies. For example, there is much work being done on trapping atoms inside electromagnetic cavities. This enables flexible manipulation of the atom inside the cavity via optical techniques, and makes possible real-time feedback control of single atoms in ways unavailable in conventional atom traps.
To conclude, note that it is important not to assess quantum information processing as though it were just another technology for information processing. For example, it is tempting to dismiss quantum computation as yet another technological fad in the evolution of the computer that will pass in time, much as other fads have passed – for example, the ‘bubble memories’ widely touted as the next big thing in memory during the early 1980s. This is a mistake, since quantum computation is an abstract paradigm for information processing that may have many different implementations in technology. One can compare two different proposals for quantum computing as regards their technological merits – it makes sense to compare a ‘good’ proposal to a ‘bad’ proposal – however even a very poor proposal for a quantum computer is of a different qualitative nature from a superb design for a classical computer.
1.6 Quantum information
The term ‘quantum information’ is used in two distinct ways in the field of quantum computation and quantum information. The first usage is as a broad catch-all for all manner of operations that might be interpreted as related to information processing
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Quantum information 51
 using quantum mechanics. This use encompasses subjects such as quantum computation, quantum teleportation, the no-cloning theorem, and virtually all other topics in this book. The second use of ‘quantum information’ is much more specialized: it refers to the study of elementary quantum information processing tasks. It does not typically include, for example, quantum algorithm design, since the details of specific quantum algorithms are beyond the scope of ‘elementary’. To avoid confusion we will use the term ‘quantum information theory’ to refer to this more specialized field, in parallel with the widely used term ‘(classical) information theory’ to describe the corresponding classical field. Of course, the term ‘quantum information theory’ has a drawback of its own – it might be seen as implying that theoretical considerations are all that matter! Of course, this is not the case, and experimental demonstration of the elementary processes studied by
quantum information theory is of great interest.
The purpose of this section is to introduce the basic ideas of quantum information
theory. Even with the restriction to elementary quantum information processing tasks, quantum information theory may look like a disordered zoo to the beginner, with many apparently unrelated subjects falling under the ‘quantum information theory’ rubric. In part, that’s because the subject is still under development, and it’s not yet clear how all the pieces fit together. However, we can identify a few fundamental goals uniting work on quantum information theory:
(1) Identify elementary classes of static resources in quantum mechanics. An example is the qubit. Another example is the bit; classical physics arises as a special case of quantum physics, so it should not be surprising that elementary static resources appearing in classical information theory should also be of great relevance in quantum information theory. Yet another example of an elementary class of static resources is a Bell state shared between two distant parties.
(2) Identify elementary classes of dynamical processes in quantum mechanics. A simple example is memory, the ability to store a quantum state over some period of time. Less trivial processes are quantum information transmission between two parties, Alice and Bob; copying (or trying to copy) a quantum state, and the process of protecting quantum information processing against the effects of noise.
(3) Quantify resource tradeoffs incurred performing elementary dynamical processes. For example, what are the minimal resources required to reliably transfer quantum information between two parties using a noisy communications channel?
Similar goals define classical information theory; however, quantum information theory is broader in scope than classical information theory, for quantum information theory includes all the static and dynamic elements of classical information theory, as well as additional static and dynamic elements.
The remainder of this section describes some examples of questions studied by quan- tum information theory, in each case emphasizing the fundamental static and dynamic elements under consideration, and the resource tradeoffs being considered. We begin with an example that will appear quite familiar to classical information theorists: the problem of sending classical information through a quantum channel. We then begin to branch out and explore some of the new static and dynamic processes present in quantum mechan- ics, such as quantum error-correction, the problem of distinguishing quantum states, and entanglement transformation. The chapter concludes with some reflections on how the
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

52 Introduction and overview
tools of quantum information theory can be applied elsewhere in quantum computation
and quantum information.
1.6.1 Quantum information theory: example problems
Classical information through quantum channels
The fundamental results of classical information theory are Shannon’s noiseless channel coding theorem and Shannon’s noisy channel coding theorem. The noiseless channel coding theorem quantifies how many bits are required to store information being emitted by a source of information, while the noisy channel coding theorem quantifies how much information can be reliably transmitted through a noisy communications channel.
What do we mean by an information source? Defining this notion is a fundamental problem of classical and quantum information theory, one we’ll re-examine several times. For now, let’s go with a provisional definition: a classical information source is described by a set of probabilities pj , j = 1, 2, . . . , d. Each use of the source results in the ‘letter’ j being emitted, chosen at random with probability pj, independently for each use of the source. For instance, if the source were of English text, then the numbers j might correspond to letters of the alphabet and punctuation, with the probabilities pj giving the relative frequencies with which the different letters appear in regular English text. Although it is not true that the letters in English appear in an independent fashion, for our purposes it will be a good enough approximation.
Regular English text includes a considerable amount of redundancy, and it is possible to
exploit that redundancy to compress the text. For example, the letter ‘e’ occurs much more
frequently in regular English text than does the letter ‘z’. A good scheme for compressing
English text will therefore represent the letter ‘e’ using fewer bits of information than
it uses to represent ‘z’. Shannon’s noiseless channel coding theorem quantifies exactly
how well such a compression scheme can be made to work. More precisely, the noiseless
channel coding theorem tells us that a classical source described by probabilities pj can be
 compressed so that on average each use of the source can be represented using H(pj) bits
of information, where H(pj) ≡ −􏰶 pj log(pj) is a function of the source probability j
distribution known as the Shannon entropy. Moreover, the noiseless channel coding theorem tells us that to attempt to represent the source using fewer bits than this will result in a high probability of error when the information is decompressed. (Shannon’s noiseless channel coding theorem is discussed in much greater detail in Chapter 12.)
Shannon’s noiseless coding theorem provides a good example where the goals of infor- mation theory listed earlier are all met. Two static resources are identified (goal number 1): the bit and the information source. A two-stage dynamic process is identified (goal 2), compressing an information source, and then decompressing to recover the information source. Finally a quantitative criterion for determining the resources consumed (goal 3) by an optimal data compression scheme is found.
Shannon’s second major result, the noisy channel coding theorem, quantifies the amount of information that can be reliably transmitted through a noisy channel. In par- ticular, suppose we wish to transfer the information being produced by some information source to another location through a noisy channel. That location may be at another point in space, or at another point in time – the latter is the problem of storing information in the presence of noise. The idea in both instances is to encode the information being produced using error-correcting codes, so that any noise introduced by the channel can be corrected at the other end of the channel. The way error-correcting codes achieve this
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Quantum information 53
 is by introducing enough redundancy into the information sent through the channel so that even after some of the information has been corrupted it is still possible to recover the original message. For example, suppose the noisy channel is for the transmission of single bits, and the noise in the channel is such that to achieve reliable transmission each bit produced by the source must be encoded using two bits before being sent through the channel. We say that such a channel has a capacity of half a bit, since each use of the channel can be used to reliably convey roughly half a bit of information. Shannon’s noisy channel coding theorem provides a general procedure for calculating the capacity of an arbitrary noisy channel.
Shannon’s noisy channel coding theorem also achieves the three goals of information theory we stated earlier. Two types of static resources are involved (goal 1), the informa- tion source, and the bits being sent through the channel. Three dynamical processes are involved (goal 2). The primary process is the noise in the channel. To combat this noise we perform the dual processes of encoding and decoding the state in an error-correcting code. For a fixed noise model, Shannon’s theorem tells us how much redundancy must be introduced by an optimal error-correction scheme if reliable information transmission is to be achieved (goal 3).
For both the noiseless and noisy channel coding theorems Shannon restricted himself to storing the output from an information source in classical systems – bits and the like. A natural question for quantum information theory is what happens if the storage medium is changed so that classical information is transmitted using quantum states as the medium. For example, it may be that Alice wishes to compress some classical information produced by an information source, transmitting the compressed information to Bob, who then decompresses it. If the medium used to store the compressed information is a quantum state, then Shannon’s noiseless channel coding theorem cannot be used to determine the optimal compression and decompression scheme. One might wonder, for example, if using qubits allows a better compression rate than is possible classically. We’ll study this question in Chapter 12, and prove that, in fact, qubits do not allow any significant saving in the amount of communication required to transmit information over a noiseless channel.
Naturally, the next step is to investigate the problem of transmitting classical informa- tion through a noisy quantum channel. Ideally, what we’d like is a result that quantifies the capacity of such a channel for the transmission of information. Evaluating the capac- ity is a very tricky job for several reasons. Quantum mechanics gives us a huge variety of noise models, since it takes place in a continuous space, and it is not at all obvious how to adapt classical error-correction techniques to combat the noise. Might it be advanta- geous, for example, to encode the classical information using entangled states, which are then transmitted one piece at a time through the noisy channel? Or perhaps it will be advantageous to decode using entangled measurements? In Chapter 12 we’ll prove the HSW (Holevo–Schumacher–Westmoreland) theorem, which provides a lower bound on the capacity of such a channel. Indeed, it is widely believed that the HSW theorem provides an exact evaluation of the capacity, although a complete proof of this is not yet known! What remains at issue is whether or not encoding using entangled states can be used to raise the capacity beyond the lower bound provided by the HSW theorem. All evidence to date suggests that this doesn’t help raise the capacity, but it is still a fasci- nating open problem of quantum information theory to determine the truth or falsity of this conjecture.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

54 Introduction and overview
Quantum information through quantum channels
Classical information is, of course, not the only static resource available in quantum mechanics. Quantum states themselves are a natural static resource, even more natural than classical information. Let’s look at a different quantum analogue of Shannon’s coding theorems, this time involving the compression and decompression of quantum states.
To begin, we need to define some quantum notion of an information source, analogous to the classical definition of an information source. As in the classical case, there are several different ways of doing this, but for the sake of definiteness let’s make the provisional definition that a quantum source is described by a set of probabilities pj and corresponding quantum states |ψj⟩. Each use of the source produces a state |ψj⟩ with probability pj, with different uses of the source being independent of one another.
Is it possible to compress the output from such a quantum mechanical source? Consider the case of a qubit source which outputs the state |0⟩ with probability p and the state |1⟩ with probability 1 − p. This is essentially the same as a classical source emitting single bits, either 0 with probability p, or 1 with probability 1 − p, so it is not surprising that similar techniques can be used to compress the source so that only H (p, 1 − p) qubits are required to store the compressed source, where H(·) is again the Shannon entropy function.
What if the source had instead been producing the state |0⟩ with probability p, and √
  the state (|0⟩ + |1⟩)/ 2 with probability 1 − p? The standard techniques of classical data compression no longer apply, since in general it is not possible for us to distinguish
√
the states |0⟩ and (|0⟩ + |1⟩)/ 2. Might it still be possible to perform some type of
 compression operation?
It turns out that a type of compression is still possible, even in this instance. What is interesting is that the compression may no longer be error-free, in the sense that the quan- tum states being produced by the source may be slightly distorted by the compression– decompression procedure. Nevertheless, we require that this distortion ought to become very small and ultimately negligible in the limit of large blocks of source output being compressed. To quantify the distortion we introduce a fidelity measure for the com- pression scheme, which measures the average distortion introduced by the compression scheme. The idea of quantum data compression is that the compressed data should be recovered with very good fidelity. Think of the fidelity as being analogous to the proba- bility of doing the decompression correctly – in the limit of large block lengths, it should tend towards the no error limit of 1.
Schumacher’s noiseless channel coding theorem quantifies the resources required to do quantum data compression, with the restriction that it be possible to recover the source with fidelity close to 1. In the case of a source producing orthogonal quantum states |ψj⟩ with probabilities pj Schumacher’s theorem reduces to telling us that the source may be compressed down to but not beyond the classical limit H(pj). However, in the more general case of non-orthogonal states being produced by the source, Schumacher’s theorem tells us how much a quantum source may be compressed, and the answer is not the Shannon entropy H(pj)! Instead, a new entropic quantity, the von Neumann entropy, turns out to be the correct answer. In general, the von Neumann entropy agrees with the Shannon entropy if and only if the states |ψj ⟩ are orthogonal. Otherwise, the von Neumann entropy for the source pj , |ψj ⟩ is in general strictly smaller than the Shannon entropy H(pj). Thus, for example, a source producing the state |0⟩ with probability p
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

√
and (|0⟩ + |1⟩)/ 2 with probability 1 − p can be reliably compressed using fewer than
H (p, 1 − p) qubits per use of the source!
The basic intuition for this decrease in resources required can be understood quite
√ easily. Suppose the source emitting states |0⟩ with probability p and (|0⟩ + |1⟩)/ 2 with
Quantum information 55
   probability 1 − p is used a large number n times. Then by the law of large numbers, with high probability the source emits about np copies of |0⟩ and n(1 − p) copies of
√
(|0⟩ + |1⟩)/ 2. That is, it has the form
 􏰐 |0⟩ + |1⟩ 􏰑⊗n(1−p)
|0⟩⊗np √
, (1.60)
  2
up to re-ordering of the systems involved. Suppose we expand the product of |0⟩ + |1⟩ terms on the right hand side. Since n(1 − p) is large, we can again use the law of large numbers to deduce that the terms in the product will be roughly one-half |0⟩s and one- half |1⟩s. That is, the |0⟩ + |1⟩ product can be well approximated by a superposition of states of the form
|0⟩⊗n(1−p)/2 |1⟩⊗n(1−p)/2 . (1.61) Thus the state emitted by the source can be approximated as a superposition of terms of
the form
|0⟩⊗n(1+p)/2 |1⟩⊗n(1−p)/2 . (1.62)
How many states of this form are there? Roughly n choose n(1 + p)/2, which by Stir- ling’s approximation is equal to N ≡ 2nH[(1+p)/2,(1−p)/2]. A simple compression method then is to label all states of the form (1.62) |c1⟩ through |cN⟩. It is possible to per- form a unitary transform on the n qubits emitted from the source that takes |cj⟩ to |j⟩|0⟩⊗n−nH[(1+p)/2,(1−p)/2] , since j is an nH[(1 + p)/2, (1 − p)/2] bit number. The com- pression operation is to perform this unitary transformation, and then drop the final n − nH [(1 + p)/2, (1 − p)/2] qubits, leaving a compressed state of nH [(1 + p)/2, (1 − p)/2] qubits. To decompress we append the state |0⟩⊗n−nH[(1+p)/2,(1−p)/2] to the compressed state, and perform the inverse unitary transformation.
This procedure for quantum data compression and decompression results in a storage
requirement of H [(1 + p)/2, (1 − p)/2] qubits per use of the source, which whenever
p ≥ 1/3 is an improvement over the H (p, 1 − p) qubits we might naively have expected
from Shannon’s noiseless channel coding theorem. In fact, Schumacher’s noiseless chan-
nel coding theorem allows us to do somewhat better even than this, as we will see in
Chapter 12; however, the essential reason in that construction is the same as the reason
√
we were able to compress here: we exploited the fact that |0⟩ and (|0⟩ + |1⟩)/ 2 are not
 orthogonal. Intuitively, the states contain some redundancy since both have a component in the |0⟩ direction, which results in more physical similarity than would be obtained from orthogonal states. It is this redundancy that we have exploited in the coding scheme just described, and which is used in the full proof of Schumacher’s noiseless channel coding theorem. Note that the restriction p ≥ 1/3 arises because when p &lt; 1/3 this particular scheme doesn’t exploit the redundancy in the states: we end up effectively increasing the redundancy present in the problem! Of course, this is an artifact of the particular scheme we have chosen, and the general solution exploits the redundancy in a much more sensible way to achieve data compression.
Schumacher’s noiseless channel coding theorem is an analogue of Shannon’s noiseless
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

56 Introduction and overview
 channel coding theorem for the compression and decompression of quantum states. Can we find an analogue of Shannon’s noisy channel coding theorem? Considerable progress on this important question has been made, using the theory of quantum error-correcting codes; however, a fully satisfactory analogue has not yet been found. We review some of what is known about the quantum channel capacity in Chapter 12.
Quantum distinguishability
Thus far all the dynamical processes we have considered – compression, decompression, noise, encoding and decoding error-correcting codes – arise in both classical and quantum information theory. However, the introduction of new types of information, such as quantum states, enlarges the class of dynamical processes beyond those considered in classical information theory. A good example is the problem of distinguishing quantum states. Classically, we are used to being able to distinguish different items of information, at least in principle. In practice, of course, a smudged letter ‘a’ written on a page may be very difficult to distinguish from a letter ‘o’, but in principle it is possible to distinguish between the two possibilities with perfect certainty.
On the other hand, quantum mechanically it is not always possible to distinguish between arbitrary states. For example, there is no process allowed by quantum mechanics
√
that will reliably distinguish between the states |0⟩ and (|0⟩ + |1⟩)/ 2. Proving this
 rigorously requires tools we don’t presently have available (it is done in Chapter 2),
but by considering examples it’s pretty easy to convince oneself that it is not possible.
Suppose, for example, that we try to distinguish the two states by measuring in the
computational basis. Then, if we have been given the state |0⟩, the measurement will √
yield 0 with probability 1. However, when we measure (|0⟩ + |1⟩)/ 2 the measurement yields 0 with probability 1/2 and 1 with probability 1/2. Thus, while a measurement
result of 1 implies that state must have been (|0⟩ + |1⟩)/
 2, since it couldn’t have been |0⟩, we can’t infer anything about the identity of the quantum state from a measurement
result of 0.
This indistinguishability of non-orthogonal quantum states is at the heart of quantum
computation and quantum information. It is the essence of our assertion that a quan- tum state contains hidden information that is not accessible to measurement, and thus plays a key role in quantum algorithms and quantum cryptography. One of the central problems of quantum information theory is to develop measures quantifying how well non-orthogonal quantum states may be distinguished, and much of Chapters 9 and 12 is concerned with this goal. In this introduction we’ll limit ourselves to pointing out two interesting aspects of indistinguishability – a connection with the possibility of faster- than-light communication, and an application to ‘quantum money.’
Imagine for a moment that we could distinguish between arbitrary quantum states.
We’ll show that this implies the ability to communicate faster than light, using entan-
glement. Suppose Alice and Bob share an entangled pair of qubits in the state (|00⟩ + √
|11⟩)/ 2. Then, if Alice measures in the computational basis, the post-measurement
states will be |00⟩ with probability 1/2, and |11⟩ with probability 1/2. Thus Bob’s sys-
tem is either in the state |0⟩, with probability 1/2, or in the state |1⟩, with probability
1/2. Suppose, however, that Alice had instead measured in the |+⟩, |−⟩ basis. Recall that √√
|0⟩ = (|+⟩ + |−⟩)/ 2 and |1⟩ = (|+⟩ − |−⟩)/ 2. A little algebra shows that the initial √
state of Alice and Bob’s system may be rewritten as (| + +⟩ + | − −⟩)/ 2. Therefore, if Alice measures in the |+⟩, |−⟩ basis, the state of Bob’s system after the measurement
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
√
     Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

will be |+⟩ or |−⟩ with probability 1/2 each. So far, this is all basic quantum mechanics. But if Bob had access to a device that could distinguish the four states |0⟩, |1⟩, |+⟩, |−⟩ from one another, then he could tell whether Alice had measured in the computational basis, or in the |+⟩, |−⟩ basis. Moreover, he could get that information instantaneously, as soon as Alice had made the measurement, providing a means by which Alice and Bob could achieve faster-than-light communication! Of course, we know that it is not possible to distinguish non-orthogonal quantum states; this example shows that this restriction is also intimately tied to other physical properties which we expect the world to obey.
The indistinguishability of non-orthogonal quantum states need not always be a hand-
icap. Sometimes it can be a boon. Imagine that a bank produces banknotes imprinted
with a (classical) serial number, and a sequence of qubits each in either the state |0⟩ √
or (|0⟩ + |1⟩)/ 2. Nobody but the bank knows what sequence of these two states is
embedded in the note, and the bank maintains a list matching serial numbers to em-
bedded states. The note is impossible to counterfeit exactly, because it is impossible
for a would-be counterfeiter to determine with certainty the state of the qubits in the
original note, without destroying them. When presented with the banknote a merchant
(of certifiable repute) can verify that it is not a counterfeit by calling the bank, telling
them the serial number, and then asking what sequence of states were embedded in
the note. They can then check that the note is genuine by measuring the qubits in the
√√
|0⟩, |1⟩ or (|0⟩ + |1⟩)/ 2, (|0⟩ − |1⟩)/ 2 basis, as directed by the bank. With probability
Quantum information 57
    which increases exponentially to one with the number of qubits checked, any would-be counterfeiter will be detected at this stage! This idea is the basis for numerous other quantum cryptographic protocols, and demonstrates the utility of the indistinguishability of non-orthogonal quantum states.
Exercise 1.2: Explain how a device which, upon input of one of two non-orthogonal quantum states |ψ⟩ or |φ⟩ correctly identified the state, could be used to build a device which cloned the states |ψ⟩ and |φ⟩, in violation of the no-cloning theorem. Conversely, explain how a device for cloning could be used to distinguish non-orthogonal quantum states.
Creation and transformation of entanglement
Entanglement is another elementary static resource of quantum mechanics. Its properties are amazingly different from those of the resources most familiar from classical informa- tion theory, and they are not yet well understood; we have at best an incomplete collage of results related to entanglement. We don’t yet have all the language needed to under- stand the solutions, but let’s at least look at two information-theoretic problems related to entanglement.
Creating entanglement is a simple dynamical process of interest in quantum informa- tion theory. How many qubits must two parties exchange if they are to create a particular entangled state shared between them, given that they share no prior entanglement? A second dynamical process of interest is transforming entanglement from one form into another. Suppose, for example, that Alice and Bob share between them a Bell state, and wish to transform it into some other type of entangled state. What resources do they need to accomplish this task? Can they do it without communicating? With classical communication only? If quantum communication is required then how much quantum communication is required?
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

58 Introduction and overview
 Answering these and more complex questions about the creation and transformation of entanglement forms a fascinating area of study in its own right, and also promises to give insight into tasks such as quantum computation. For example, a distributed quantum computation may be viewed as simply a method for generating entanglement between two or more parties; lower bounds on the amount of communication that must be done to perform such a distributed quantum computation then follow from lower bounds on the amount of communication that must be performed to create appropriate entangled states.
1.6.2 Quantum information in a wider context
We have given but the barest glimpse of quantum information theory. Part III of this book discusses quantum information theory in much greater detail, especially Chapter 11, which deals with fundamental properties of entropy in quantum and classical information theory, and Chapter 12, which focuses on pure quantum information theory.
Quantum information theory is the most abstract part of quantum computation and quantum information, yet in some sense it is also the most fundamental. The question driving quantum information theory, and ultimately all of quantum computation and quantum information, is what makes quantum information processing tick? What is it that separates the quantum and the classical world? What resources, unavailable in a classical world, are being utilized in a quantum computation? Existing answers to these questions are foggy and incomplete; it is our hope that the fog may yet lift in the years to come, and we will obtain a clear appreciation for the possibilities and limitations of quantum information processing.
Problem 1.1: (Feynman-Gates conversation) Construct a friendly imaginary discussion of about 2000 words between Bill Gates and Richard Feynman, set in the present, on the future of computation. (Comment: You might like to try waiting until you’ve read the rest of the book before attempting this question. See the ‘History and further reading’ below for pointers to one possible answer for this question.)
Problem 1.2: What is the most significant discovery yet made in quantum computation and quantum information? Write an essay of about 2000 words for an educated lay audience about the discovery. (Comment: As for the previous problem, you might like to try waiting until you’ve read the rest of the book before attempting this question.)
History and further reading
Most of the material in this chapter is revisited in more depth in later chapters. Therefore the historical references and further reading below are limited to material which does not recur in later chapters.
Piecing together the historical context in which quantum computation and quantum information have developed requires a broad overview of the history of many fields. We have tried to tie this history together in this chapter, but inevitably much background material was omitted due to limited space and expertise. The following recommendations attempt to redress this omission.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

History and further reading 59
 The history of quantum mechanics has been told in many places. We recommend es- pecially the outstanding works of Pais[Pai82, Pai86, Pai91]. Of these three, [Pai86] is most di- rectly concerned with the development of quantum mechanics; however, Pais’ biographies of Einstein[Pai82] and of Bohr[Pai91] also contain much material of interest, at a less intense level. The rise of technologies based upon quantum mechanics has been described by Mil- burn[Mil97, Mil98]. Turing’s marvelous paper on the foundations of computer science[Tur36] is well worth reading. It can be found in the valuable historical collection of Davis[Dav65]. Hofstadter[Hof79] and Penrose[Pen89] contain entertaining and informative discussions of the foundations of computer science. Shasha and Lazere’s biography of fifteen leading computer scientists[SL98] gives considerable insight into many different facets of the his- tory of computer science. Finally, Knuth’s awesome series of books[Knu97, Knu98a, Knu98b] contain an amazing amount of historical information. Shannon’s brilliant papers founding information theory make excellent reading[Sha48] (also reprinted in [SW49]). MacWilliams and Sloane[MS77] is not only an excellent text on error-correcting codes, but also contains an enormous amount of useful historical information. Similarly, Cover and Thomas[CT91] is an excellent text on information theory, with extensive historical information. Shan- non’s collected works, together with many useful historical items have been collected in a large volume[SW93] edited by Sloane and Wyner. Slepian has also collected a useful set of reprints on information theory[Sle74]. Cryptography is an ancient art with an intricate and often interesting history. Kahn[Kah96] is a huge history of cryptography contain- ing a wealth of information. For more recent developments we recommend the books by Menezes, van Oorschot, and Vanstone[MvOV96], Schneier[Sch96a], and by Diffie and Landau[DL98].
Quantum teleportation was discovered by Bennett, Brassard, Cre ́peau, Jozsa, Peres, and Wootters[BBC+93], and later experimentally realized in various different forms by Boschi, Branca, De Martini, Hardy and Popescu[BBM+98] using optical techniques, by Bouwmeester, Pan, Mattle, Eibl, Weinfurter, and Zeilinger[BPM+97] using photon polar- ization, by Furusawa, Sørensen, Braunstein, Fuchs, Kimble, and Polzik using ‘squeezed’ states of light[FSB+98], and by Nielsen, Knill, and Laflamme using NMR[NKL98].
Deutsch’s problem was posed by Deutsch[Deu85], and a one-bit solution was given in the same paper. The extension to the general n-bit case was given by Deutsch and Jozsa[DJ92]. The algorithms in these early papers have been substantially improved subsequently by Cleve, Ekert, Macchiavello, and Mosca[CEMM98], and independently in unpublished work by Tapp. In this chapter we have given the improved version of the algorithm, which fits very nicely into the hidden subgroup problem framework that will later be discussed in Chapter 5. The original algorithm of Deutsch only worked probabilistically; Deutsch and Jozsa improved this to obtain a deterministic algorithm, but their method required two function evaluations, in contrast to the improved algorithms presented in this chapter. Nevertheless, it is still conventional to refer to these algorithms as Deutsch’s algorithm and the Deutsch–Jozsa algorithm in honor of two huge leaps forward: the concrete demonstration by Deutsch that a quantum computer could do something faster than a classical computer; and the extension by Deutsch and Jozsa which demonstrated for the first time a similar gap for the scaling of the time required to solve a problem.
Excellent discussions of the Stern–Gerlach experiment can be found in standard quan- tum mechanics textbooks such as the texts by Sakurai[Sak95], Volume III of Feynman, Leighton and Sands[FLS65a], and Cohen-Tannoudji, Diu and Laloe ̈[CTDL77a, CTDL77b].
Problem 1.1 was suggested by the lovely article of Rahim[Rah99].
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

2 Introduction to quantum mechanics
I ain’t no physicist but I know what matters.
– Popeye the Sailor
Quantum mechanics: Real Black Magic Calculus
– Albert Einstein
Quantum mechanics is the most accurate and complete description of the world known. It is also the basis for an understanding of quantum computation and quantum information. This chapter provides all the necessary background knowledge of quantum mechanics needed for a thorough grasp of quantum computation and quantum information. No prior knowledge of quantum mechanics is assumed.
Quantum mechanics is easy to learn, despite its reputation as a difficult subject. The reputation comes from the difficulty of some applications, like understanding the struc- ture of complicated molecules, which aren’t fundamental to a grasp of the subject; we won’t be discussing such applications. The only prerequisite for understanding is some familiarity with elementary linear algebra. Provided you have this background you can begin working out simple problems in a few hours, even with no prior knowledge of the subject.
Readers already familiar with quantum mechanics can quickly skim through this chap- ter, to become familiar with our (mostly standard) notational conventions, and to assure themselves of familiarity with all the material. Readers with little or no prior knowledge should work through the chapter in detail, pausing to attempt the exercises. If you have difficulty with an exercise, move on, and return later to make another attempt.
The chapter begins with a review of some material from linear algebra in Section 2.1. This section assumes familiarity with elementary linear algebra, but introduces the nota- tion used by physicists to describe quantum mechanics, which is different to that used in most introductions to linear algebra. Section 2.2 describes the basic postulates of quan- tum mechanics. Upon completion of the section, you will have understood all of the fundamental principles of quantum mechanics. This section contains numerous simple exercises designed to help consolidate your grasp of this material. The remaining sections of the chapter, and of this book, elucidate upon this material, without introducing fun- damentally new physical principles. Section 2.3 explains superdense coding, a surprising and illuminating example of quantum information processing which combines many of the postulates of quantum mechanics in a simple setting. Sections 2.4 and 2.5 develop powerful mathematical tools – the density operator, purifications, and the Schmidt de- composition – which are especially useful in the study of quantum computation and quantum information. Understanding these tools will also help you consolidate your un- derstanding of elementary quantum mechanics. Finally, Section 2.6 examines the question of how quantum mechanics goes beyond the usual ‘classical’ understanding of the way the world works.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

2.1 Linear algebra
This book is written as much to disturb and annoy as to instruct. – The first line of About Vectors, by Banesh Hoffmann.
Life is complex – it has both real and imaginary parts.
– Anonymous
Linear algebra is the study of vector spaces and of linear operations on those vector spaces. A good understanding of quantum mechanics is based upon a solid grasp of elementary linear algebra. In this section we review some basic concepts from linear algebra, and describe the standard notations which are used for these concepts in the study of quantum mechanics. These notations are summarized in Figure 2.1 on page 62, with the quantum notation in the left column, and the linear-algebraic description in the right column. You may like to glance at the table, and see how many of the concepts in the right column you recognize.
In our opinion the chief obstacle to assimilation of the postulates of quantum mechan- ics is not the postulates themselves, but rather the large body of linear algebraic notions required to understand them. Coupled with the unusual Dirac notation adopted by physi- cists for quantum mechanics, it can appear (falsely) quite fearsome. For these reasons, we advise the reader not familiar with quantum mechanics to quickly read through the material which follows, pausing mainly to concentrate on understanding the absolute ba- sics of the notation being used. Then proceed to a careful study of the main topic of the chapter – the postulates of quantum mechanics – returning to study the necessary linear algebraic notions and notations in more depth, as required.
The basic objects of linear algebra are vector spaces. The vector space of most interest to us is Cn, the space of all n-tuples of complex numbers, (z1, . . . , zn). The elements of a vector space are called vectors, and we will sometimes use the column matrix notation
⎡z⎤ 1
⎢⎣ . ⎥⎦ (2.1) zn
to indicate a vector. There is an addition operation defined which takes pairs of vectors to other vectors. In Cn the addition operation for vectors is defined by
⎡ z ⎤ ⎡ z ⎤ ⎡ z +z ⎤ 1111
⎢⎣ . . . ⎥⎦ + ⎢⎣ . . . ⎥⎦ ≡ ⎢⎣ . . . ⎥⎦ , ( 2 . 2 ) z n z n z n + z n
where the addition operations on the right are just ordinary additions of complex numbers. Furthermore, in a vector space there is a multiplication by a scalar operation. In Cn this operation is defined by
⎡ z ⎤ ⎡ zz ⎤ 11
z ⎢⎣ . . . ⎥⎦ ≡ ⎢⎣ . . . ⎥⎦ , ( 2 . 3 ) zn zzn
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Linear algebra 61
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

62 Introduction to quantum mechanics
 where z is a scalar, that is, a complex number, and the multiplications on the right are ordinary multiplication of complex numbers. Physicists sometimes refer to complex numbers as c-numbers.
Quantum mechanics is our main motivation for studying linear algebra, so we will use the standard notation of quantum mechanics for linear algebraic concepts. The standard quantum mechanical notation for a vector in a vector space is the following:
|ψ⟩. (2.4)
ψ is a label for the vector (any label is valid, although we prefer to use simple labels like ψ and φ). The |·⟩ notation is used to indicate that the object is a vector. The entire object |ψ⟩ is sometimes called a ket, although we won’t use that terminology often.
A vector space also contains a special zero vector, which we denote by 0. It satisfies the property that for any other vector |v⟩, |v⟩ + 0 = |v⟩. Note that we do not use the ket notation for the zero vector – it is the only exception we shall make. The reason for making the exception is because it is conventional to use the ‘obvious’ notation for the zero vector, |0⟩, to mean something else entirely. The scalar multiplication operation is such that z0 = 0 for any complex number z. For convenience, we use the notation (z1, . . . , zn) to denote a column matrix with entries z1, . . . , zn. In Cn the zero element is (0,0,...,0). A vector subspace of a vector space V is a subset W of V such that W is also a vector space, that is, W must be closed under scalar multiplication and addition.
Notation   Description
   z∗
|ψ⟩
⟨ψ| ⟨φ|ψ⟩
Complex conjugate of the complex number z. (1+i)∗ =1−i
Vector. Also known as a ket.
Vector dual to |ψ⟩. Also known as a bra.
Inner product between the vectors |φ⟩ and |ψ⟩.
     |φ⟩ ⊗ |ψ⟩   Tensor product of |φ⟩ and |ψ⟩.
 |φ⟩|ψ⟩ A∗ AT A†
Abbreviated notation for tensor product of |φ⟩ and |ψ⟩. Complex conjugate of the A matrix.
Transpose of the A matrix.
Hermitian conjugate or adjoint of the A matrix, A† = (AT )∗. 􏰒ab􏰓† 􏰒a∗ c∗􏰓
    c d = b∗ d∗ .
Inner product between |φ⟩ and A|ψ⟩.
Equivalently, inner product between A†|φ⟩ and |ψ⟩.
 ⟨φ|A|ψ⟩
Figure 2.1. Summary of some standard quantum mechanical notation for notions from linear algebra. This style of
   notation is known as the Dirac notation.
2.1.1 Bases and linear independence
A spanning set for a vector space is a set of vectors |v1⟩,...,|vn⟩ such that any vector |v⟩ in the vector space can be written as a linear combination |v⟩ = 􏰶 ai|vi⟩ of vectors
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
i
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

in that set. For example, a spanning set for the vector space C2 is the set 􏰒􏰓 􏰒􏰓
since any vector
| v 1 ⟩ ≡
10 ; | v 2 ⟩ ≡ 01 􏰒a􏰓
|v⟩ = 1 a2
,
( 2 . 5 )
(2.6)
in C2 can be written as a linear combination |v⟩ = a1|v1⟩ + a2|v2⟩ of the vectors |v1⟩ and |v2⟩. We say that the vectors |v1⟩ and |v2⟩ span the vector space C2.
Generally, a vector space may have many different spanning sets. A second spanning set for the vector space C2 is the set
1􏰒1􏰓 1􏰒 1􏰓
|v1⟩≡√2 1 ; |v2⟩≡√2 −1 , (2.7)
since an arbitrary vector |v⟩ = (a1, a2) can be written as a linear combination of |v1⟩ and |v2 ⟩,
Linear algebra
63
     a1 + a2 a1 − a2 |v⟩ = √ |v1⟩ + √
|v2⟩. (2.8) A set of non-zero vectors |v1⟩,...,|vn⟩ are linearly dependent if there exists a set of
complex numbers a1, . . . , an with ai ̸= 0 for at least one value of i, such that
a1|v1⟩ + a2|v2⟩ + · · · + an|vn⟩ = 0. (2.9)
A set of vectors is linearly independent if it is not linearly dependent. It can be shown that any two sets of linearly independent vectors which span a vector space V contain the same number of elements. We call such a set a basis for V . Furthermore, such a basis set always exists. The number of elements in the basis is defined to be the dimension of V . In this book we will only be interested in finite dimensional vector spaces. There are many interesting and often difficult questions associated with infinite dimensional vector spaces. We won’t need to worry about these questions.
Exercise 2.1: (Linear dependence: example) Show that (1, −1), (1, 2) and (2, 1) are linearly dependent.
2.1.2 Linear operators and matrices
A linear operator between vector spaces V and W is defined to be any function A : V → W which is linear in its inputs,
􏰔􏰸 􏰕 􏰸 􏰇 􏰈
A ai|vi⟩ = aiA |vi⟩ . (2.10) ii
Usually we just write A|v⟩ to denote A(|v⟩). When we say that a linear operator A is defined on a vector space, V , we mean that A is a linear operator from V to V . An important linear operator on any vector space V is the identity operator, IV , defined by the equation IV |v⟩ ≡ |v⟩ for all vectors |v⟩. Where no chance of confusion arises we drop the subscript V and just write I to denote the identity operator. Another important linear operator is the zero operator, which we denote 0. The zero operator maps all vectors to
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
    22
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

64 Introduction to quantum mechanics
 the zero vector, 0|v⟩ ≡ 0. It is clear from (2.10) that once the action of a linear operator A on a basis is specified, the action of A is completely determined on all inputs.
Suppose V,W, and X are vector spaces, and A : V → W and B : W → X are linear operators. Then we use the notation BA to denote the composition of B with A, defined by (BA)(|v⟩) ≡ B(A(|v⟩)). Once again, we write BA|v⟩ as an abbreviation for (BA)(|v⟩).
The most convenient way to understand linear operators is in terms of their matrix representations. In fact, the linear operator and matrix viewpoints turn out to be com- pletely equivalent. The matrix viewpoint may be more familiar to you, however. To see the connection, it helps to first understand that an m by n complex matrix A with entries Aij is in fact a linear operator sending vectors in the vector space Cn to the vector space Cm, under matrix multiplication of the matrix A by a vector in Cn. More precisely, the claim that the matrix A is a linear operator just means that
􏰔􏰸 􏰕􏰸
A ai|vi⟩ = aiA|vi⟩ (2.11) ii
is true as an equation where the operation is matrix multiplication of A by column vectors. Clearly, this is true!
We’ve seen that matrices can be regarded as linear operators. Can linear operators be given a matrix representation? In fact they can, as we now explain. This equivalence between the two viewpoints justifies our interchanging terms from matrix theory and operator theory throughout the book. Suppose A : V → W is a linear operator between vector spaces V and W. Suppose |v1⟩,...,|vm⟩ is a basis for V and |w1⟩,...,|wn⟩ is a basis for W . Then for each j in the range 1, . . . , m, there exist complex numbers A1j through Anj such that
􏰸
i
The matrix whose entries are the values Aij is said to form a matrix representation of the operator A. This matrix representation of A is completely equivalent to the operator A, and we will use the matrix representation and abstract operator viewpoints interchange- ably. Note that to make the connection between matrices and linear operators we must specify a set of input and output basis states for the input and output vector spaces of the linear operator.
Exercise 2.2: (Matrix representations: example) Suppose V is a vector space with basis vectors |0⟩ and |1⟩, and A is a linear operator from V to V such that A|0⟩ = |1⟩ and A|1⟩ = |0⟩. Give a matrix representation for A, with respect to the input basis |0⟩, |1⟩, and the output basis |0⟩, |1⟩. Find input and output bases which give rise to a different matrix representation of A.
Exercise 2.3: (Matrix representation for operator products) Suppose A is a linear operator from vector space V to vector space W , and B is a linear operator from vector space W to vector space X. Let |vi⟩,|wj⟩, and |xk⟩ be bases for the vector spaces V,W, and X, respectively. Show that the matrix representation for the linear transformation BA is the matrix product of the matrix representations for B and A, with respect to the appropriate bases.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
A|vj⟩ =
Aij|wi⟩. (2.12)
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Exercise 2.4: (Matrix representation for identity) Show that the identity operator on a vector space V has a matrix representation which is one along the diagonal and zero everywhere else, if the matrix representation is taken with respect to the same input and output bases. This matrix is known as the identity matrix.
2.1.3 The Pauli matrices
Four extremely useful matrices which we shall often have occasion to use are the Pauli matrices. These are 2 by 2 matrices, which go by a variety of notations. The matrices, and their corresponding notations, are depicted in Figure 2.2. The Pauli matrices are so useful in the study of quantum computation and quantum information that we encourage you to memorize them by working through in detail the many examples and exercises based upon them in subsequent sections.
􏰒􏰓 􏰒􏰓
σ0 ≡ I ≡ 1 0 σ1 ≡ σx ≡ X ≡ 0 1 01 10
􏰒0−i􏰓 􏰒1 0􏰓 σ2≡σy≡Y≡ i 0 σ3≡σz≡Z≡ 0 −1
Figure 2.2. The Pauli matrices. Sometimes I is omitted from the list with just X, Y and Z known as the Pauli matrices.
2.1.4 Inner products
An inner product is a function which takes as input two vectors |v⟩ and |w⟩ from a vector space and produces a complex number as output. For the time being, it will be convenient to write the inner product of |v⟩ and |w⟩ as (|v⟩, |w⟩). This is not the standard quantum mechanical notation; for pedagogical clarity the (·, ·) notation will be useful occasionally in this chapter. The standard quantum mechanical notation for the inner product (|v⟩, |w⟩) is ⟨v|w⟩, where |v⟩ and |w⟩ are vectors in the inner product space, and the notation ⟨v| is used for the dual vector to the vector |v⟩; the dual is a linear operator from the inner product space V to the complex numbers C, defined by ⟨v|(|w⟩) ≡ ⟨v|w⟩ ≡ (|v⟩, |w⟩). We will see shortly that the matrix representation of dual vectors is just a row vector.
A function (·, ·) from V × V to C is an inner product if it satisfies the requirements that:
(1) (·, ·) is linear in the second argument, 􏰔􏰸􏰕􏰸􏰇􏰈
|v⟩, λi|wi⟩ = λi |v⟩,|wi⟩ . ii
(2.13)
(2.14)
(2) (|v⟩,|w⟩)=(|w⟩,|v⟩)∗.
(3) (|v⟩, |v⟩) ≥ 0 with equality if and only if |v⟩ = 0.
For example, Cn has an inner product defined by
((y1,...,yn),(z1,...,zn)) ≡
􏰉 ∗
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
􏰸 ∗
yi zi = y1 ...yn ⎣ . ⎦.
i
zn
Linear algebra 65
 ⎡z⎤ ∗􏰊⎢ .1 ⎥
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

66 Introduction to quantum mechanics
We call a vector space equipped with an inner product an inner product space.
Exercise 2.5: Verify that (·,·) just defined is an inner product on Cn. Exercise 2.6: Show that any inner product (·, ·) is conjugate-linear in the first
 argument,
􏰔􏰸 􏰕􏰸∗
λi|wi⟩, |v⟩ = λi (|wi⟩, |v⟩). (2.15)
ii
Discussions of quantum mechanics often refer to Hilbert space. In the finite dimen- sional complex vector spaces that come up in quantum computation and quantum infor- mation, a Hilbert space is exactly the same thing as an inner product space. From now on we use the two terms interchangeably, preferring the term Hilbert space. In infinite dimensions Hilbert spaces satisfy additional technical restrictions above and beyond inner product spaces, which we will not need to worry about.
Vectors |w⟩ and |v⟩ are orthogonal if their inner product is zero. For example, |w⟩ ≡ (1, 0) and |v⟩ ≡ (0, 1) are orthogonal with respect to the inner product defined by (2.14). We define the norm of a vector |v⟩ by
􏰡
∥|v⟩∥ ≡ ⟨v|v⟩ . (2.16)
A unit vector is a vector |v⟩ such that ∥|v⟩∥ = 1. We also say that |v⟩ is normalized if ∥|v⟩∥ = 1. It is convenient to talk of normalizing a vector by dividing by its norm; thus |v⟩/∥|v⟩∥ is the normalized form of |v⟩, for any non-zero vector |v⟩. A set |i⟩ of vectors with index i is orthonormal if each vector is a unit vector, and distinct vectors in the set are orthogonal, that is, ⟨i|j⟩ = δij, where i and j are both chosen from the index set.
Exercise 2.7: Verify that |w⟩ ≡ (1, 1) and |v⟩ ≡ (1, −1) are orthogonal. What are the normalized forms of these vectors?
Suppose |w1⟩,...,|wd⟩ is a basis set for some vector space V with an inner product. There is a useful method, the Gram–Schmidt procedure, which can be used to produce an orthonormal basis set |v1⟩, . . . , |vd⟩ for the vector space V . Define |v1⟩ ≡ |w1⟩/∥ |w1⟩ ∥, and for 1 ≤ k ≤ d − 1 define |vk+1⟩ inductively by
|v ⟩ ≡ |wk+1⟩ − 􏰶ki=1⟨vi|wk+1⟩|vi⟩ . (2.17) k+1 ∥|wk+1⟩ − 􏰶ki=1⟨vi|wk+1⟩|vi⟩∥
It is not difficult to verify that the vectors |v1⟩,...,|vd⟩ form an orthonormal set which is also a basis for V . Thus, any finite dimensional vector space of dimension d has an orthonormal basis, |v1⟩,...,|vd⟩.
Exercise 2.8: Prove that the Gram–Schmidt procedure produces an orthonormal basis for V .
From now on, when we speak of a matrix representation for a linear operator, we mean a matrix representation with respect to orthonormal input and output bases. We also use the convention that if the input and output spaces for a linear operator are the same, then the input and output bases are the same, unless noted otherwise.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
  Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Linear algebra 67 With these conventions, the inner product on a Hilbert space can be given a convenient
 matrix representation. Let |w⟩ = 􏰶 wi|i⟩ and |v⟩ = 􏰶 vj|j⟩ be representations of ij
vectors |w⟩ and |v⟩ with respect to some orthonormal basis |i⟩. Then, since ⟨i|j⟩ = δij , ⎛⎞
⟨v|w⟩ =
=
vi|i⟩, wj |j⟩ = vi wj δij =
i j ij i
vi wi
(2.18)
( 2 . 1 9 )
⎝􏰸􏰸⎠􏰸∗ 􏰸∗
⎡w⎤ 􏰉􏰊1
v 1∗ . . . v n∗ ⎢⎣ . . . ⎥⎦ . wn
That is, the inner product of two vectors is equal to the vector inner product between two matrix representations of those vectors, provided the representations are written with respect to the same orthonormal basis. We also see that the dual vector ⟨v| has a nice interpretation as the row vector whose components are complex conjugates of the corresponding components of the column vector representation of |v⟩.
There is a useful way of representing linear operators which makes use of the inner product, known as the outer product representation. Suppose |v⟩ is a vector in an inner product space V , and |w⟩ is a vector in an inner product space W . Define |w⟩⟨v| to be the linear operator from V to W whose action is defined by
􏰇|w⟩⟨v|􏰈 􏰇|v′⟩􏰈 ≡ |w⟩ ⟨v|v′⟩ = ⟨v|v′⟩|w⟩. (2.20)
This equation fits beautifully into our notational conventions, according to which the expression |w⟩⟨v|v′⟩ could potentially have one of two meanings: we will use it to denote the result when the operator |w⟩⟨v| acts on |v′⟩, and it has an existing interpretation as the result of multiplying |w⟩ by the complex number ⟨v|v′⟩. Our definitions are chosen so that these two potential meanings coincide. Indeed, we define the former in terms of the latter!
We can take linear combinations of outer product operators |w⟩⟨v| in the obvious way. By definition 􏰶 ai|wi⟩⟨vi| is the linear operator which, when acting on |v′⟩, produces
􏰶′i
i ai|wi⟩⟨vi|v ⟩ as output.
The usefulness of the outer product notation can be discerned from an important result
known as the completeness relation for orthonormal vectors. Let |i⟩ be any orthonormal
basis for the vector space V , so an arbitrary vector |v⟩ can be written |v⟩ = 􏰶 vi|i⟩ for i
some set of complex numbers vi. Note that ⟨i|v⟩ = vi and therefore
􏰔􏰸 􏰕 􏰸 􏰸
|i⟩⟨i| |v⟩ = |i⟩⟨i|v⟩ = iii
Since the last equation is true for all |v⟩ it follows that
􏰸
i
vi|i⟩ = |v⟩.
(2.21)
(2.22)
This equation is known as the completeness relation. One application of the completeness relation is to give a means for representing any operator in the outer product notation. Suppose A : V → W is a linear operator, |vi ⟩ is an orthonormal basis for V , and |wj ⟩ an orthonormal basis for W . Using the completeness relation twice we obtain
A = IW AIV (2.23)
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
|i⟩⟨i| = I.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

68 Introduction to quantum mechanics 􏰸
 =
=
ij
|wj ⟩⟨wj |A|vi ⟩⟨vi | ⟨wj |A|vi ⟩|wj ⟩⟨vi |,
(2.24)
(2.25)
􏰸
ij
which is the outer product representation for A. We also see from this equation that A has matrix element ⟨wj|A|vi⟩ in the ith column and jth row, with respect to the input basis |vi⟩ and output basis |wj⟩.
A second application illustrating the usefulness of the completeness relation is the Cauchy–Schwarz inequality. This important result is discussed in Box 2.1, on this page.
Exercise 2.9: (Pauli operators and the outer product) The Pauli matrices (Figure 2.2 on page 65) can be considered as operators with respect to an orthonormal basis |0⟩, |1⟩ for a two-dimensional Hilbert space. Express each of the Pauli operators in the outer product notation.
Exercise 2.10: Suppose |vi⟩ is an orthonormal basis for an inner product space V . What is the matrix representation for the operator |vj⟩⟨vk|, with respect to the |vi⟩ basis?
   Box 2.1: The Cauchy-Schwarz inequality
The Cauchy–Schwarz inequality is an important geometric fact about Hilbert
spaces. It states that for any two vectors |v⟩ and |w⟩, |⟨v|w⟩|2 ≤ ⟨v|v⟩⟨w|w⟩. To
see this, use the Gram–Schmidt procedure to construct an orthonormal basis |i⟩
􏰠
Using the completeness relation 􏰶 |i⟩⟨i| = I, and dropping some non-negative
 for the vector space such that the first member of the basis |i⟩ is |w⟩/ i
⟨w|w⟩.
terms gives
􏰸
i
⟨v|v⟩⟨w|w⟩ =
⟨v|i⟩⟨i|v⟩⟨w|w⟩
(2.26)
(2.27) (2.28)
≥ ⟨v|w⟩⟨w|v⟩⟨w|w⟩ ⟨w|w⟩
= ⟨v|w⟩⟨w|v⟩ = |⟨v|w⟩|2,
 as required. A little thought shows that equality occurs if and only if |v⟩ and |w⟩ are linearly related, |v⟩ = z|w⟩ or |w⟩ = z|v⟩, for some scalar z.
 2.1.5 Eigenvectors and eigenvalues
An eigenvector of a linear operator A on a vector space is a non-zero vector |v⟩ such that A|v⟩ = v|v⟩, where v is a complex number known as the eigenvalue of A corresponding to |v⟩. It will often be convenient to use the notation v both as a label for the eigenvector, and to represent the eigenvalue. We assume that you are familiar with the elementary properties of eigenvalues and eigenvectors – in particular, how to find them, via the characteristic equation. The characteristic function is defined to be c(λ) ≡ det |A − λI |,
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

where det is the determinant function for matrices; it can be shown that the characteristic function depends only upon the operator A, and not on the specific matrix representation used for A. The solutions of the characteristic equation c(λ) = 0 are the eigenvalues of the operator A. By the fundamental theorem of algebra, every polynomial has at least one complex root, so every operator A has at least one eigenvalue, and a corresponding eigenvector. The eigenspace corresponding to an eigenvalue v is the set of vectors which have eigenvalue v. It is a vector subspace of the vector space on which A acts.
A diagonal representation for an operator A on a vector space V is a representation A = 􏰶 λi|i⟩⟨i|, where the vectors |i⟩ form an orthonormal set of eigenvectors for A,
i
with corresponding eigenvalues λi. An operator is said to be diagonalizable if it has a
diagonal representation. In the next section we will find a simple set of necessary and
sufficient conditions for an operator on a Hilbert space to be diagonalizable. As an example
of a diagonal representation, note that the Pauli Z matrix may be written 􏰒􏰓
Z = 1 0 = |0⟩⟨0| − |1⟩⟨1|, (2.29) 0 −1
where the matrix representation is with respect to orthonormal vectors |0⟩ and |1⟩, re- spectively. Diagonal representations are sometimes also known as orthonormal decom- positions.
When an eigenspace is more than one dimensional we say that it is degenerate. For example, the matrix A defined by
⎡200⎤
A≡⎣0 2 0⎦ (2.30)
000
has a two-dimensional eigenspace corresponding to the eigenvalue 2. The eigenvectors (1,0,0) and (0,1,0) are said to be degenerate because they are linearly independent eigenvectors of A with the same eigenvalue.
Exercise 2.11: (Eigendecomposition of the Pauli matrices) Find the eigenvectors, eigenvalues, and diagonal representations of the Pauli matrices X,Y, and Z.
Exercise 2.12: Prove that the matrix
is not diagonalizable.
􏰒􏰓
10 11
(2.31)
2.1.6 Adjoints and Hermitian operators
Suppose A is any linear operator on a Hilbert space, V . It turns out that there exists a unique linear operator A† on V such that for all vectors |v⟩, |w⟩ ∈ V ,
(|v⟩, A|w⟩) = (A† |v⟩, |w⟩). (2.32)
This linear operator is known as the adjoint or Hermitian conjugate of the operator A. From the definition it is easy to see that (AB)† = B†A†. By convention, if |v⟩ is a vector, then we define |v⟩† ≡ ⟨v|. With this definition it is not difficult to see that (A|v⟩)† = ⟨v|A†.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Linear algebra 69
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

70 Introduction to quantum mechanics
Exercise 2.13: If |w⟩ and |v⟩ are any two vectors, show that (|w⟩⟨v|)† = |v⟩⟨w|.
Exercise 2.14: (Anti-linearity of the adjoint) Show that the adjoint operation is anti-linear,
􏰔􏰸 􏰕† 􏰸∗†
aiAi = ai Ai . (2.33)
ii
Exercise 2.15: Show that (A†)† = A.
In a matrix representation of an operator A, the action of the Hermitian conjugation operation is to take the matrix of A to the conjugate-transpose matrix, A† ≡ (A∗)T , where the ∗ indicates complex conjugation, and T indicates the transpose operation. For example, we have
􏰒 1+3i 2i 􏰓† 􏰒 1−3i 1−i 􏰓
1 + i 1 − 4i = −2i 1 + 4i . (2.34)
An operator A whose adjoint is A is known as a Hermitian or self-adjoint op- erator. An important class of Hermitian operators is the projectors. Suppose W is a k-dimensional vector subspace of the d-dimensional vector space V . Using the Gram– Schmidt procedure it is possible to construct an orthonormal basis |1⟩,...,|d⟩ for V such that |1⟩, . . . , |k⟩ is an orthonormal basis for W . By definition,
􏰸k i=1
is the projector onto the subspace W . It is easy to check that this definition is independent of the orthonormal basis |1⟩, . . . , |k⟩ used for W . From the definition it can be shown that |v⟩⟨v| is Hermitian for any vector |v⟩, so P is Hermitian, P† = P. We will often refer to the ‘vector space’ P, as shorthand for the vector space onto which P is a projector. The orthogonal complement of P is the operator Q ≡ I − P . It is easy to see that Q is a projector onto the vector space spanned by |k + 1⟩, . . . , |d⟩, which we also refer to as the orthogonal complement of P , and may denote by Q.
Exercise 2.16: Show that any projector P satisfies the equation P 2 = P .
An operator A is said to be normal if AA† = A†A. Clearly, an operator which is Hermitian is also normal. There is a remarkable representation theorem for normal operators known as the spectral decomposition, which states that an operator is a normal operator if and only if it is diagonalizable. This result is proved in Box 2.2 on page 72, which you should read closely.
Exercise 2.17: Show that a normal matrix is Hermitian if and only if it has real eigenvalues.
A matrix U is said to be unitary if U†U = I. Similarly an operator U is unitary if U†U = I. It is easily checked that an operator is unitary if and only if each of its matrix representations is unitary. A unitary operator also satisfies UU† = I, and therefore U is normal and has a spectral decomposition. Geometrically, unitary operators are important because they preserve inner products between vectors. To see this, let |v⟩ and |w⟩ be any
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 P ≡
|i⟩⟨i| (2.35)
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Linear algebra 71 two vectors. Then the inner product of U|v⟩ and U|w⟩ is the same as the inner product
of |v⟩ and |w⟩,
􏰇U|v⟩,U|w⟩􏰈 = ⟨v|U†U|w⟩ = ⟨v|I|w⟩ = ⟨v|w⟩. (2.36)
This result suggests the following elegant outer product representation of any unitary U .
 Let |vi⟩ be any orthonormal basis set. Define |wi⟩ ≡ U|vi⟩, so |wi⟩ is also an orthonormal
basis set, since unitary operators preserve inner products. Note that U = 􏰶 |wi⟩⟨vi|. i
Conversely, if |vi⟩ and |wi⟩ are any two orthonormal bases, then it is easily checked that the operator U defined by U ≡ 􏰶 |wi⟩⟨vi| is a unitary operator.
Exercise 2.18: Show that all eigenvalues of a unitary matrix have modulus 1, that is, can be written in the form eiθ for some real θ.
Exercise 2.19: (Pauli matrices: Hermitian and unitary) Show that the Pauli matrices are Hermitian and unitary.
Exercise 2.20: (Basis changes) Suppose A′ and A′′ are matrix representations of an operator A on a vector space V with respect to two different orthonormal bases, |vi⟩ and |wi⟩. Then the elements of A′ and A′′ are A′ij = ⟨vi|A|vj⟩ and
A′′ = ⟨w |A|w ⟩. Characterize the relationship between A′ and A′′.
A special subclass of Hermitian operators is extremely important. This is the positive
operators. A positive operator A is defined to be an operator such that for any vector |v⟩,
(|v⟩, A|v⟩) is a real, non-negative number. If (|v⟩, A|v⟩) is strictly greater than zero for
all |v⟩ ̸= 0 then we say that A is positive definite. In Exercise 2.24 on this page you will
ij i j
i
show that any positive operator is automatically Hermitian, and therefore by the spectral
decomposition has diagonal representation 􏰶 λi|i⟩⟨i|, with non-negative eigenvalues λi. i
Exercise 2.21: Repeat the proof of the spectral decomposition in Box 2.2 for the case when M is Hermitian, simplifying the proof wherever possible.
Exercise 2.22: Prove that two eigenvectors of a Hermitian operator with different eigenvalues are necessarily orthogonal.
Exercise 2.23: Show that the eigenvalues of a projector P are all either 0 or 1.
Exercise 2.24: (Hermiticity of positive operators) Show that a positive operator is necessarily Hermitian. (Hint: Show that an arbitrary operator A can be written A = B + iC where B and C are Hermitian.)
Exercise 2.25: Show that for any operator A, A†A is positive.
2.1.7 Tensor products
The tensor product is a way of putting vector spaces together to form larger vector spaces. This construction is crucial to understanding the quantum mechanics of multiparticle systems. The following discussion is a little abstract, and may be difficult to follow if you’re not already familiar with the tensor product, so feel free to skip ahead now and revisit later when you come to the discussion of tensor products in quantum mechanics.
Suppose V and W are vector spaces of dimension m and n respectively. For conve- nience we also suppose that V and W are Hilbert spaces. Then V ⊗ W (read ‘V tensor
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

72 Introduction to quantum mechanics
    Box 2.2: The spectral decomposition – important!
The spectral decomposition is an extremely useful representation theorem for nor- mal operators.
Theorem 2.1: (Spectral decomposition) Any normal operator M on a vector space V is diagonal with respect to some orthonormal basis for V . Conversely, any diagonalizable operator is normal.
Proof
The converse is a simple exercise, so we prove merely the forward implication, by induction on the dimension d of V . The case d = 1 is trivial. Let λ be an eigenvalue of M , P the projector onto the λ eigenspace, and Q the projector onto the orthogonal complement. Then M = (P + Q)M(P + Q) = PMP + QMP + PMQ + QMQ. Obviously PMP = λP. Furthermore, QMP = 0, as M takes the subspace P into itself. We claim that PMQ = 0 also. To see this, let |v⟩ be an element of the subspace P. Then MM†|v⟩ = M†M|v⟩ = λM†|v⟩. Thus, M†|v⟩ has eigenvalue λ and therefore is an element of the subspace P. It follows that QM†P = 0. Taking the adjoint of this equation gives PMQ = 0. Thus M = PMP +QMQ. Next, we prove that QMQ is normal. To see this, note that QM = QM(P + Q) = QMQ, and QM† = QM†(P + Q) = QM†Q. Therefore, by the normality of M , and the observation that Q2 = Q,
QMQQM†Q = QMQM†Q = QMM†Q = QM†MQ
= QM†QMQ
= QM†QQMQ,
(2.37) (2.38) (2.39) (2.40) (2.41)
so QMQ is normal. By induction, QMQ is diagonal with respect to some or- thonormal basis for the subspace Q, and PMP is already diagonal with respect to some orthonormal basis for P . It follows that M = P M P + QM Q is diagonal with respect to some orthonormal basis for the total vector space.
   In terms of the outer product representation, this means that M can be written as M = 􏰶 λi|i⟩⟨i|, where λi are the eigenvalues of M, |i⟩ is an orthonormal basis
i
for V , and each |i⟩ an eigenvector of M with eigenvalue λi. In terms of projectors,
M = 􏰶 λiPi, where λi are again the eigenvalues of M, and Pi is the projector i
onto the λi eigenspace of M. These projectors satisfy the completeness relation
􏰶 Pi = I, and the orthonormality relation PiPj = δijPi. i
 W ’) is an mn dimensional vector space. The elements of V ⊗ W are linear combinations of ‘tensor products’ |v⟩ ⊗ |w⟩ of elements |v⟩ of V and |w⟩ of W . In particular, if |i⟩ and |j⟩ are orthonormal bases for the spaces V and W then |i⟩⊗|j⟩ is a basis for V ⊗W. We often use the abbreviated notations |v⟩|w⟩, |v,w⟩ or even |vw⟩ for the tensor product
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

|v⟩ ⊗ |w⟩. For example, if V is a two-dimensional vector space with basis vectors |0⟩ and |1⟩ then |0⟩⊗|0⟩+|1⟩⊗|1⟩ is an element of V ⊗V.
By definition the tensor product satisfies the following basic properties: (1) For an arbitrary scalar z and elements |v⟩ of V and |w⟩ of W,
z􏰇|v⟩⊗|w⟩􏰈 = 􏰇z|v⟩􏰈⊗|w⟩ = |v⟩⊗􏰇z|w⟩􏰈. (2) For arbitrary |v1⟩ and |v2⟩ in V and |w⟩ in W,
􏰇|v1⟩+|v2⟩􏰈⊗|w⟩=|v1⟩⊗|w⟩+|v2⟩⊗|w⟩. (3) For arbitrary |v⟩ in V and |w1⟩ and |w2⟩ in W,
|v⟩⊗􏰇|w1⟩+|w2⟩􏰈=|v⟩⊗|w1⟩+|v⟩⊗|w2⟩.
(2.42)
(2.43)
(2.44)
What sorts of linear operators act on the space V ⊗ W ? Suppose |v⟩ and |w⟩ are vectors in V and W , and A and B are linear operators on V and W , respectively. Then we can define a linear operator A ⊗ B on V ⊗ W by the equation
(A ⊗ B)(|v⟩ ⊗ |w⟩) ≡ A|v⟩ ⊗ B|w⟩. (2.45) The definition of A ⊗ B is then extended to all elements of V ⊗ W in the natural way
to ensure linearity of A ⊗ B, that is,
􏰔􏰸 􏰕􏰸
(A ⊗ B) ai|vi⟩ ⊗ |wi⟩ ≡ aiA|vi⟩ ⊗ B|wi⟩. (2.46) ii
It can be shown that A ⊗ B defined in this way is a well-defined linear operator on V ⊗ W . This notion of the tensor product of two operators extends in the obvious way to the case where A : V → V′ and B : W → W′ map between different vector spaces. Indeed, an arbitrary linear operator C mapping V ⊗ W to V ′ ⊗ W ′ can be represented as a linear combination of tensor products of operators mapping V to V ′ and W to W ′ ,
where by definition
C =
􏰸
i
ciAi ⊗ Bi,
(2.47)
(2.48)
􏰔􏰸 􏰕 􏰸
ciAi ⊗ Bi |v⟩ ⊗ |w⟩ ≡ ciAi|v⟩ ⊗ Bi|w⟩. ii
The inner products on the spaces V and W can be used to define a natural inner product on V ⊗ W . Define
⎛⎞
⎝ 􏰸 a i | v i ⟩ ⊗ | w i ⟩ , 􏰸 b j | v j′ ⟩ ⊗ | w j′ ⟩ ⎠ ≡ 􏰸 a ∗i b j ⟨ v i | v j′ ⟩ ⟨ w i | w j′ ⟩ . ( 2 . 4 9 )
i j ij
It can be shown that the function so defined is a well-defined inner product. From this inner product, the inner product space V ⊗W inherits the other structure we are familiar with, such as notions of an adjoint, unitarity, normality, and Hermiticity.
All this discussion is rather abstract. It can be made much more concrete by moving
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Linear algebra 73
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

74 Introduction to quantum mechanics
 to a convenient matrix representation known as the Kronecker product. Suppose A is an m by n matrix, and B is a p by q matrix. Then we have the matrix representation:
nq
􏱄 􏱇􏱆 􏱅 ⎡ A11B A12B ... A1nB ⎤⎫⎪
⎢ A21B A22B ... A2nB ⎥⎬
A⊗B ≡ ⎢⎣ . . . . ⎥⎦⎪mp. (2.50)
A m 1 B A m 2 B . . . A m n B ⎪⎭
In this representation terms like A11B denote p by q submatrices whose entries are proportional to B, with overall proportionality constant A11. For example, the tensor product of the vectors (1, 2) and (2, 3) is the vector
(2.51)
(2.52)
Finally, we mention the useful notation |ψ⟩⊗k, which means |ψ⟩ tensored with itself k times. For example |ψ⟩⊗2 = |ψ⟩ ⊗ |ψ⟩. An analogous notation is also used for operators on tensor product spaces.
Exercise 2.26: Let |ψ⟩ = (|0⟩ + |1⟩)/√2. Write out |ψ⟩⊗2 and |ψ⟩⊗3 explicitly, both in terms of tensor products like |0⟩|1⟩, and using the Kronecker product.
Exercise 2.27: Calculate the matrix representation of the tensor products of the Pauli operators (a) X and Z; (b) I and X; (c) X and I. Is the tensor product commutative?
Exercise 2.28: Show that the transpose, complex conjugation, and adjoint operations distribute over the tensor product,
(A⊗B)∗ =A∗ ⊗B∗; (A⊗B)T =AT ⊗BT; (A⊗B)† =A† ⊗B†.(2.53)
  ⎡1×2⎤ ⎡2⎤ 􏰒1􏰓 􏰒2􏰓 ⎢1×3⎥ ⎢3⎥
2 ⊗ 3 =⎣2×2⎦=⎣4⎦. 2×3 6
The tensor product of the Pauli matrices X and Y is
Exercise 2.29: Exercise 2.30: Exercise 2.31: Exercise 2.32: Exercise 2.33:
Show that the tensor product of two unitary operators is unitary.
Show that the tensor product of two Hermitian operators is Hermitian.
Show that the tensor product of two positive operators is positive.
Show that the tensor product of two projectors is a projector.
The Hadamard operator on one qubit may be written as 1􏰜􏰝
H = √ (|0⟩ + |1⟩)⟨0| + (|0⟩ − |1⟩)⟨1| . (2.54) 2
⎡0 0 0 −i⎤ 􏰒0·Y 1·Y􏰓 ⎢0 0 i 0⎥
X⊗Y= 1·Y 0·Y =⎣0 −i 0 0 ⎦. i000
   Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Linear algebra 75 Show explicitly that the Hadamard transform on n qubits, H⊗n, may be written
 as
H = √2n
Write out an explicit matrix representation for H⊗2.
2.1.8 Operator functions
⊗n 1􏰸x·y
There are many important functions which can be defined for operators and matri-
ces. Generally speaking, given a function f from the complex numbers to the com-
plex numbers, it is possible to define a corresponding matrix function on normal ma-
trices (or some subclass, such as the Hermitian matrices) by the following construc-
tion. Let A = 􏰶 a|a⟩⟨a| be a spectral decomposition for a normal operator A. Define 􏰶a
f(A) ≡ a f(a)|a⟩⟨a|. A little thought shows that f(A) is uniquely defined. This pro- cedure can be used, for example, to define the square root of a positive operator, the logarithm of a positive-definite operator, or the exponential of a normal operator. As an example,
􏰒eθ 0􏰓 exp(θZ) = 0 e−θ ,
since Z has eigenvectors |0⟩ and |1⟩.
Exercise 2.34: Find the square root and logarithm of the matrix
􏰒􏰓
three-dimensional unit vector and θ a real number. Prove that exp(iθ⃗v · ⃗σ) = cos(θ)I + i sin(θ)⃗v · ⃗σ,
(2.56)
(2.57)
(2.58)
.
Exercise 2.35: (Exponential of the Pauli matrices) Let ⃗v be any real,
where ⃗v · ⃗σ ≡ 􏰶3i=1 vi σi . This exercise is generalized in Problem 2.1 on page 117.
Another important matrix function is the trace of a matrix. The trace of A is defined to be the sum of its diagonal elements,
􏰸
i
The trace is easily seen to be cyclic, tr(AB) = tr(BA), and linear, tr(A + B) = tr(A) + tr(B), tr(zA) = z tr(A), where A and B are arbitrary matrices, and z is a complex number. Furthermore, from the cyclic property it follows that the trace of a matrix is invariant under the unitary similarity transformation A → UAU†, as tr(UAU†) = tr(U†UA) = tr(A). In light of this result, it makes sense to define the trace of an operator A to be the trace of any matrix representation of A. The invariance of the trace under unitary similarity transformations ensures that the trace of an operator is well defined.
As an example of the trace, suppose |ψ⟩ is a unit vector and A is an arbitrary op- erator. To evaluate tr(A|ψ⟩⟨ψ|) use the Gram–Schmidt procedure to extend |ψ⟩ to an
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
tr(A) ≡
Aii. (2.59)
43 34
(−1) |x⟩⟨y|.
(2.55)
  x,y
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

76 Introduction to quantum mechanics
orthonormal basis |i⟩ which includes |ψ⟩ as the first element. Then we have
􏰸
⟨i|A|ψ⟩⟨ψ|i⟩ = ⟨ψ|A|ψ⟩.
 tr(A|ψ⟩⟨ψ|) =
(2.60) (2.61)
This result, that tr(A|ψ⟩⟨ψ|) = ⟨ψ|A|ψ⟩ is extremely useful in evaluating the trace of an operator.
Exercise 2.36: Show that the Pauli matrices except for I have trace zero.
Exercise 2.37: (Cyclic property of the trace) If A and B are two linear operators
show that
tr(AB) = tr(BA). (2.62) Exercise 2.38: (Linearity of the trace) If A and B are two linear operators, show
that
tr(A + B) = tr(A) + tr(B) and if z is an arbitrary complex number show that
tr(zA) = ztr(A).
(2.63)
(2.64)
The set LV
(2.65)
is an inner product function. This inner product is known as the
Hilbert–Schmidt or trace inner product.
(2) If V has d dimensions show that LV has dimension d2.
(3) Find an orthonormal basis of Hermitian matrices for the Hilbert space LV .
2.1.9 The commutator and anti-commutator
The commutator between two operators A and B is defined to be
[A, B] ≡ AB − BA. (2.66)
If [A,B] = 0, that is, AB = BA, then we say A commutes with B. Similarly, the anti-commutator of two operators A and B is defined by
{A, B} ≡ AB + BA; (2.67)
we say A anti-commutes with B if {A, B} = 0. It turns out that many important prop- erties of pairs of operators can be deduced from their commutator and anti-commutator. Perhaps the most useful relation is the following connection between the commutator and the property of being able to simultaneously diagonalize Hermitian operators A and B,
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Exercise 2.39: (The Hilbert–Schmidt inner product on operators)
of linear operators on a Hilbert space V is obviously a vector space – the sum of two linear operators is a linear operator, zA is a linear operator if A is a linear operator and z is a complex number, and there is a zero element 0. An important additional result is that the vector space LV can be given a natural inner product structure, turning it into a Hilbert space.
(1) Show that the function (·, ·) on LV × LV defined by (A, B) ≡ tr(A†B)
i
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Linear algebra 77 that is, write A = 􏰶 ai|i⟩⟨i|, B = 􏰶 bi|i⟩⟨i|, where |i⟩ is some common orthonormal
 ii
set of eigenvectors for A and B.
Theorem 2.2: (Simultaneous diagonalization theorem) Suppose A and B are Hermitian operators. Then [A, B] = 0 if and only if there exists an orthonormal basis such that both A and B are diagonal with respect to that basis. We say that A and B are simultaneously diagonalizable in this case.
This result connects the commutator of two operators, which is often easy to compute, to the property of being simultaneously diagonalizable, which is a priori rather difficult to determine. As an example, consider that
􏰒0 1􏰓􏰒0 −i􏰓 􏰒0 −i􏰓􏰒0 1􏰓
[X,Y]= 1 0 i 0 − i 0 􏰒􏰓
=2i 1 0 0 −1
= 2iZ ,
1 0
(2.68)
(2.69)
(2.70)
so X and Y do not commute. You have already shown, in Exercise 2.11, that X and Y do not have common eigenvectors, as we expect from the simultaneous diagonalization theorem.
Proof
You can (and should!) easily verify that if A and B are diagonal in the same orthonormal basis then [A,B] = 0. To show the converse, let |a,j⟩ be an orthonormal basis for the eigenspace Va of A with eigenvalue a; the index j is used to label possible degeneracies. Note that
AB|a, j⟩ = BA|a, j⟩ = aB|a, j⟩, (2.71)
and therefore B|a,j⟩ is an element of the eigenspace Va. Let Pa denote the projector onto the space Va and define Ba ≡ PaBPa. It is easy to see that the restriction of Ba to the space Va is Hermitian on Va, and therefore has a spectral decomposition in terms of an orthonormal set of eigenvectors which span the space Va. Let’s call these eigenvectors |a,b,k⟩, where the indices a and b label the eigenvalues of A and Ba, and k is an extra index to allow for the possibility of a degenerate Ba. Note that B|a,b,k⟩ is an element of Va, so B|a,b,k⟩ = PaB|a,b,k⟩. Moreover we have Pa|a,b,k⟩ = |a,b,k⟩, so
B|a, b, k⟩ = PaBPa|a, b, k⟩ = b|a, b, k⟩. (2.72)
It follows that |a, b, k⟩ is an eigenvector of B with eigenvalue b, and therefore |a, b, k⟩ is an orthonormal set of eigenvectors of both A and B, spanning the entire vector space on which A and B are defined. That is, A and B are simultaneously diagonalizable.
Exercise 2.40: (Commutation relations for the Pauli matrices) Verify the commutation relations
[X,Y ] = 2iZ; [Y,Z] = 2iX; [Z,X] = 2iY. (2.73) There is an elegant way of writing this using εjkl, the antisymmetric tensor on
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
   Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

78
Introduction to quantum mechanics
 three indices, for which εjkl = 0 except for ε123 = ε231 = ε312 = 1, and ε321 = ε213 = ε132 = −1:
{σi,σj} = 0 (2.75) where i̸=j are both chosen from the set 1,2,3. Also verify that (i = 0,1,2,3)
[σj,σk] = 2i
Exercise 2.41: (Anti-commutation relations for the Pauli matrices) Verify the
anti-commutation relations
Exercise 2.42:
Exercise 2.43:
Verify that
σ i2 = I .
AB = [A,B]+{A,B}.
( 2 . 7 6 )
(2.77)
(2.78)
Exercise 2.44:
Exercise 2.45: Exercise 2.46: Exercise 2.47:
Show that [A, B]† = [B†, A†].
Show that [A, B] = −[B, A].
Suppose A and B are Hermitian. Show that i[A, B] is Hermitian.
Show that for j,k = 1,2,3, σjσk = δjkI + i
􏰸3 l=1
εjklσl.
Suppose [A, B] = 0, {A, B} = 0, and A is invertible. Show that B must be 0.
2.1.10 The polar and singular value decompositions
The polar and singular value decompositions are useful ways of breaking linear operators up into simpler parts. In particular, these decompositions allow us to break general linear operators up into products of unitary operators and positive operators. While we don’t understand the structure of general linear operators terribly well, we do understand unitary operators and positive operators in quite some detail. The polar and singular value decompositions allow us to apply this understanding to better understand general linear operators.
Theorem 2.3: (Polar decomposition) Let A be a linear operator on a vector space V . Then there exists unitary U and positive operators J and K such that
A = UJ = KU, (2.79) where the unique positive operators J and K satisfying these equations are
√√
defined by J ≡ A†A and K ≡ AA†. Moreover, if A is invertible then U is
􏰸3 l=1
εjklσl. (2.74)
 2
  unique.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Consider for now only those i for which λi ̸= 0. For those i define |ei⟩ ≡ |ψi⟩/λi, so the |ei⟩ are normalized. Moreover, they are orthogonal, since if i ̸= j then ⟨ei|ej ⟩ = ⟨i|A†A|j⟩/λiλj = ⟨i|J2|j⟩/λiλj = 0.
We have been considering i such that λi ̸= 0. Now use the Gram–Schmidt procedure
to extend the orthonormal set |ei⟩ so it forms an orthonormal basis, which we also label
|ei⟩. Define a unitary operator U ≡ 􏰶 |ei⟩⟨i|. When λi ̸= 0 we have UJ|i⟩ = λi|ei⟩ = i
|ψi⟩ = A|i⟩. When λi = 0 we have UJ|i⟩ = 0 = |ψi⟩. We have proved that the action of A and UJ agree on the basis |i⟩, and thus that A = UJ.
J is unique, since multiplying A = UJ on the left by the adjoint equation A† = JU†
gives J2 = A†A, from which we see that J = √A†A, uniquely. A little thought shows that
Linear algebra 79
 We call the expression A = UJ the left polar decomposition of A, and A = KU the right polar decomposition of A. Most often, we’ll omit the ‘right’ or ‘left’ nomenclature, and use the term ‘polar decomposition’ for both expressions, with context indicating which is meant.
Proof√
 J ≡ A†A is a positive operator, so it can be given a spectral decomposition, J =
􏰶 λi|i⟩⟨i| (λi ≥ 0). Define |ψi⟩ ≡ A|i⟩. From the definition, we see that ⟨ψi|ψi⟩ = λ2i. i
 if A is invertible, then so is J, so U is uniquely determined by the equation U = AJ−1.
The proof of the right polar decomposition follows, since A = UJ = UJU†U = KU,
where K ≡ UJU† is a positive operator. Since AA† = KUU†K = K2 we must have
AA†, as claimed.
The singular value decomposition combines the polar decomposition and the spectral
√
 K = theorem.
   Corollary 2.4: (Singular value decomposition) Let A be a square matrix. Then there exist unitary matrices U and V , and a diagonal matrix D with non-negative entries such that
A = UDV . (2.80) The diagonal elements of D are called the singular values of A.
Proof
By the polar decomposition, A = SJ, for unitary S, and positive J. By the spectral theorem, J = TDT†, for unitary T and diagonal D with non-negative entries. Setting U ≡ ST and V ≡ T† completes the proof.
Exercise 2.48: What is the polar decomposition of a positive matrix P ? Of a unitary matrix U? Of a Hermitian matrix, H?
Exercise 2.49: Express the polar decomposition of a normal matrix in the outer product representation.
Exercise 2.50: Find the left and right polar decompositions of the matrix 􏰒􏰓
10 11
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
   . (2.81)
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

80 Introduction to quantum mechanics
2.2 The postulates of quantum mechanics
All understanding begins with our not accepting the world as it appears.
– Alan Kay
The most incomprehensible thing about the world is that it is comprehensible.
– Albert Einstein
Quantum mechanics is a mathematical framework for the development of physical theo- ries. On its own quantum mechanics doesn’t tell you what laws a physical system must obey, but it does provide a mathematical and conceptual framework for the development of such laws. In the next few sections we give a complete description of the basic postu- lates of quantum mechanics. These postulates provide a connection between the physical world and the mathematical formalism of quantum mechanics.
The postulates of quantum mechanics were derived after a long process of trial and (mostly) error, which involved a considerable amount of guessing and fumbling by the originators of the theory. Don’t be surprised if the motivation for the postulates is not always clear; even to experts the basic postulates of quantum mechanics appear surprising. What you should expect to gain in the next few sections is a good working grasp of the postulates – how to apply them, and when.
2.2.1 State space
The first postulate of quantum mechanics sets up the arena in which quantum mechanics takes place. The arena is our familiar friend from linear algebra, Hilbert space.
Postulate 1: Associated to any isolated physical system is a complex vector space with inner product (that is, a Hilbert space) known as the state space of the system. The system is completely described by its state vector, which is a unit vector in the system’s state space.
Quantum mechanics does not tell us, for a given physical system, what the state space of that system is, nor does it tell us what the state vector of the system is. Figuring that out for a specific system is a difficult problem for which physicists have developed many intricate and beautiful rules. For example, there is the wonderful theory of quantum electrodynamics (often known as QED), which describes how atoms and light interact. One aspect of QED is that it tells us what state spaces to use to give quantum descriptions of atoms and light. We won’t be much concerned with the intricacies of theories like QED (except in so far as they apply to physical realizations, in Chapter 7), as we are mostly interested in the general framework provided by quantum mechanics. For our purposes it will be sufficient to make some very simple (and reasonable) assumptions about the state spaces of the systems we are interested in, and stick with those assumptions.
The simplest quantum mechanical system, and the system which we will be most concerned with, is the qubit. A qubit has a two-dimensional state space. Suppose |0⟩ and |1⟩ form an orthonormal basis for that state space. Then an arbitrary state vector in the state space can be written
|ψ⟩ = a|0⟩ + b|1⟩, (2.82)
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

√
How does the state, |ψ⟩, of a quantum mechanical system change with time? The following postulate gives a prescription for the description of such state changes.
Postulate 2: The evolution of a closed quantum system is described by a unitary transformation. That is, the state |ψ⟩ of the system at time t1 is related to the state |ψ′⟩ of the system at time t2 by a unitary operator U which depends only on the times t1 and t2,
|ψ′⟩ = U|ψ⟩. (2.84)
Just as quantum mechanics does not tell us the state space or quantum state of a particular quantum system, it does not tell us which unitary operators U describe real- world quantum dynamics. Quantum mechanics merely assures us that the evolution of any closed quantum system may be described in such a way. An obvious question to ask is: what unitary operators are natural to consider? In the case of single qubits, it turns out that any unitary operator at all can be realized in realistic systems.
Let’s look at a few examples of unitary operators on a single qubit which are impor- tant in quantum computation and quantum information. We have already seen several examples of such unitary operators – the Pauli matrices, defined in Section 2.1.3, and the quantum gates described in Chapter 1. As remarked in Section 1.3.1, the X matrix is often known as the quantum       gate, by analogy to the classical       gate. The X and Z Pauli matrices are also sometimes referred to as the bit flip and phase flip matrices: the X matrix takes |0⟩ to |1⟩, and |1⟩ to |0⟩, thus earning the name bit flip; and the Z matrix leaves |0⟩ invariant, and takes |1⟩ to −|1⟩, with the extra factor of −1 added known as a phase factor, thus justifying the term phase flip. We will not use the term phase flip for
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
|0⟩ − |1⟩ √
The postulates of quantum mechanics 81
 where a and b are complex numbers. The condition that |ψ⟩ be a unit vector, ⟨ψ|ψ⟩ = 1, is therefore equivalent to |a|2 + |b|2 = 1. The condition ⟨ψ|ψ⟩ = 1 is often known as the normalization condition for state vectors.
We will take the qubit as our fundamental quantum mechanical system. Later, in Chapter 7, we will see that there are real physical systems which may be described in terms of qubits. For now, though, it is sufficient to think of qubits in abstract terms, without reference to a specific realization. Our discussions of qubits will always be referred to some orthonormal set of basis vectors, |0⟩ and |1⟩, which should be thought of as being fixed in advance. Intuitively, the states |0⟩ and |1⟩ are analogous to the two values 0 and 1 which a bit may take. The way a qubit differs from a bit is that superpositions of these two states, of the form a|0⟩ + b|1⟩, can also exist, in which it is not possible to say that the qubit is definitely in the state |0⟩, or definitely in the state |1⟩.
We conclude with some useful terminology which is often used in connection with the description of quantum states. We say that any linear combination 􏰶 αi|ψi⟩ is a
i superposition of the states |ψi⟩ with amplitude αi for the state |ψi⟩. So, for example,
the state
(2.83) is a superposition of the states |0⟩ and |1⟩ with amplitude 1/ 2 for the state |0⟩, and
  2
 √
amplitude −1/ 2 for the state |1⟩.
 2.2.2 Evolution
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

82 Introduction to quantum mechanics
 Z very often, since it is easily confused with the phase gate to be defined in Chapter 4. (Section 2.2.7 contains more discussion of the many uses of the term ‘phase’.)
Another interesting unitary operator is the Hadamard gate, which we denote H. This √√
has the action H |0⟩ ≡ (|0⟩ + |1⟩)/ 2, H |1⟩ ≡ (|0⟩ − |1⟩)/ 2, and corresponding matrix
  representation
Exercise 2.51: Exercise 2.52: Exercise 2.53:
1􏰒11􏰓 H=√2 1 −1 .
Verify that the Hadamard gate H is unitary. Verify that H2 = I.
What are the eigenvalues and eigenvectors of H?
(2.85)
  Postulate 2 requires that the system being described be closed. That is, it is not interacting in any way with other systems. In reality, of course, all systems (except the Universe as a whole) interact at least somewhat with other systems. Nevertheless, there are interesting systems which can be described to a good approximation as being closed, and which are described by unitary evolution to some good approximation. Furthermore, at least in principle every open system can be described as part of a larger closed system (the Universe) which is undergoing unitary evolution. Later, we’ll introduce more tools which allow us to describe systems which are not closed, but for now we’ll continue with the description of the evolution of closed systems.
Postulate 2 describes how the quantum states of a closed quantum system at two different times are related. A more refined version of this postulate can be given which describes the evolution of a quantum system in continuous time. From this more refined postulate we will recover Postulate 2. Before we state the revised postulate, it is worth pointing out two things. First, a notational remark. The operator H appearing in the following discussion is not the same as the Hadamard operator, which we just introduced. Second, the following postulate makes use of the apparatus of differential equations. Readers with little background in the study of differential equations should be reassured that they will not be necessary for much of the book, with the exception of parts of Chapter 7, on real physical implementations of quantum information processing.
Postulate 2′: The time evolution of the state of a closed quantum system is described by the Schro ̈dinger equation,
i􏱔d|ψ⟩ = H|ψ⟩. (2.86) dt
In this equation, 􏱔 is a physical constant known as Planck’s constant whose value must be experimentally determined. The exact value is not important to us. In practice, it is common to absorb the factor 􏱔 into H, effectively setting 􏱔 = 1. H is a fixed Hermitian operator known as the Hamiltonian of the closed system.
If we know the Hamiltonian of a system, then (together with a knowledge of 􏱔) we understand its dynamics completely, at least in principle. In general figuring out the Hamiltonian needed to describe a particular physical system is a very difficult problem – much of twentieth century physics has been concerned with this problem – which requires substantial input from experiment in order to be answered. From our point of
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

H =
E|E⟩⟨E|, (2.87)
The postulates of quantum mechanics 83
 view this is a problem of detail to be addressed by physical theories built within the framework of quantum mechanics – what Hamiltonian do we need to describe atoms in such-and-such a configuration – and is not a question that needs to be addressed by the theory of quantum mechanics itself. Most of the time in our discussion of quantum computation and quantum information we won’t need to discuss Hamiltonians, and when we do, we will usually just posit that some matrix is the Hamiltonian as a starting point, and proceed from there, without attempting to justify the use of that Hamiltonian.
Because the Hamiltonian is a Hermitian operator it has a spectral decomposition
􏰸
E
with eigenvalues E and corresponding normalized eigenvectors |E⟩. The states |E⟩ are conventionally referred to as energy eigenstates, or sometimes as stationary states, and E is the energy of the state |E⟩. The lowest energy is known as the ground state energy for the system, and the corresponding energy eigenstate (or eigenspace) is known as the ground state. The reason the states |E⟩ are sometimes known as stationary states is because their only change in time is to acquire an overall numerical factor,
|E⟩ → exp(−iEt/􏱔)|E⟩. (2.88) As an example, suppose a single qubit has Hamiltonian
H = 􏱔ωX. (2.89)
In this equation ω is a parameter that, in practice, needs to be experimentally determined.
We won’t worry about the parameter overly much here – the point is to give you a feel
for the sort of Hamiltonians that are sometimes written down in the study of quantum
computation and quantum information. The energy eigenstates of this Hamiltonian are
√√ obviously the same as the eigenstates of X, namely (|0⟩ + |1⟩)/ 2 and (|0⟩ − |1⟩)/√2,
   with corresponding energies 􏱔ω and −􏱔ω. The ground state is therefore (|0⟩ − |1⟩)/ 2, and the ground state energy is −􏱔ω.
What is the connection between the Hamiltonian picture of dynamics, Postulate 2′, and the unitary operator picture, Postulate 2? The answer is provided by writing down the solution to Schro ̈dinger’s equation, which is easily verified to be:
􏰒−iH(t2 − t1)􏰓
|ψ(t2)⟩ = exp 􏱔 |ψ(t1)⟩ = U(t1,t2)|ψ(t1)⟩,
(2.90)
(2.91)
 where we define
􏰒−iH(t2 − t1)􏰓 U(t1,t2) ≡ exp 􏱔 .
 You will show in the exercises that this operator is unitary, and furthermore, that any unitary operator U can be realized in the form U = exp(iK) for some Hermitian operator K. There is therefore a one-to-one correspondence between the discrete-time description of dynamics using unitary operators, and the continuous time description using Hamil- tonians. For most of the book we use the unitary formulation of quantum dynamics.
Exercise 2.54: Suppose A and B are commuting Hermitian operators. Prove that exp(A) exp(B) = exp(A + B). (Hint: Use the results of Section 2.1.9.)
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

84 Introduction to quantum mechanics
Exercise 2.55: Prove that U(t1,t2) defined in Equation (2.91) is unitary.
Exercise 2.56: Use the spectral decomposition to show that K ≡ −i log(U ) is Hermitian for any unitary U, and thus U = exp(iK) for some Hermitian K.
In quantum computation and quantum information we often speak of applying a unitary operator to a particular quantum system. For example, in the context of quantum circuits we may speak of applying the unitary gate X to a single qubit. Doesn’t this contradict what we said earlier, about unitary operators describing the evolution of a closed quantum system? After all, if we are ‘applying’ a unitary operator, then that implies that there is an external ‘we’ who is interacting with the quantum system, and the system is not closed.
An example of this occurs when a laser is focused on an atom. After a lot of thought and hard work it is possible to write down a Hamiltonian describing the total atom– laser system. The interesting thing is that when we write down the Hamiltonian for the atom–laser system and consider the effects on the atom alone, the behavior of the state vector of the atom turns out to be almost but not quite perfectly described by another Hamiltonian, the atomic Hamiltonian. The atomic Hamiltonian contains terms related to laser intensity, and other parameters of the laser, which we can vary at will. It is as if the evolution of the atom were being described by a Hamiltonian which we can vary at will, despite the atom not being a closed system.
More generally, for many systems like this it turns out to be possible to write down a time-varying Hamiltonian for a quantum system, in which the Hamiltonian for the system is not a constant, but varies according to some parameters which are under an experimentalist’s control, and which may be changed during the course of an experi- ment. The system is not, therefore, closed, but it does evolve according to Schro ̈dinger’s equation with a time-varying Hamiltonian, to some good approximation.
The upshot is that to begin we will often describe the evolution of quantum systems – even systems which aren’t closed – using unitary operators. The main exception to this, quantum measurement, will be described in the next section. Later on we will investigate in more detail possible deviations from unitary evolution due to the interaction with other systems, and understand more precisely the dynamics of realistic quantum systems.
2.2.3 Quantum measurement
We postulated that closed quantum systems evolve according to unitary evolution. The evolution of systems which don’t interact with the rest of the world is all very well, but there must also be times when the experimentalist and their experimental equipment – an external physical system in other words – observes the system to find out what is going on inside the system, an interaction which makes the system no longer closed, and thus not necessarily subject to unitary evolution. To explain what happens when this is done, we introduce Postulate 3, which provides a means for describing the effects of measurements on quantum systems.
Postulate 3: Quantum measurements are described by a collection {Mm} of measurement operators. These are operators acting on the state space of the system being measured. The index m refers to the measurement outcomes that may occur in the experiment. If the state of the quantum system is |ψ⟩ immediately before the measurement then the probability that result m occurs is
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The postulates of quantum mechanics
85
 given by
p(m) = ⟨ψ|Mm† Mm|ψ⟩ , and the state of the system after the measurement is
􏰡 Mm|ψ⟩ . ⟨ψ|Mm† Mm|ψ⟩
The measurement operators satisfy the completeness equation, 􏰸 M m† M m = I .
m
The completeness equation expresses the fact that probabilities sum to one:
􏰸􏰸†
1 = p(m) = ⟨ψ|MmMm|ψ⟩ .
mm
(2.92)
(2.93)
( 2 . 9 4 )
(2.95)
  This equation being satisfied for all |ψ⟩ is equivalent to the completeness equation. However, the completeness equation is much easier to check directly, so that’s why it appears in the statement of the postulate.
A simple but important example of a measurement is the measurement of a qubit in the computational basis. This is a measurement on a single qubit with two outcomes defined by the two measurement operators M0 = |0⟩⟨0|, M1 = |1⟩⟨1|. Observe that each measurement operator is Hermitian, and that M02 = M0 , M12 = M1 . Thus the completeness relation is obeyed, I = M0†M0 + M1†M1 = M0 + M1. Suppose the state being measured is |ψ⟩ = a|0⟩ + b|1⟩. Then the probability of obtaining measurement outcome 0 is
p(0) = ⟨ψ|M0†M0|ψ⟩ = ⟨ψ|M0|ψ⟩ = |a|2. (2.96) Similarly, the probability of obtaining the measurement outcome 1 is p(1) = |b|2. The
state after measurement in the two cases is therefore
M0|ψ⟩ = a |0⟩ (2.97)
  |a| |a|
M1|ψ⟩ = b |1⟩. (2.98)
  |b| |b|
We will see in Section 2.2.7 that multipliers like a/|a|, which have modulus one, can effectively be ignored, so the two post-measurement states are effectively |0⟩ and |1⟩, just as described in Chapter 1.
The status of Postulate 3 as a fundamental postulate intrigues many people. Measuring devices are quantum mechanical systems, so the quantum system being measured and the measuring device together are part of a larger, isolated, quantum mechanical system. (It may be necessary to include quantum systems other than the system being measured and the measuring device to obtain a completely isolated system, but the point is that this can be done.) According to Postulate 2, the evolution of this larger isolated system can be described by a unitary evolution. Might it be possible to derive Postulate 3 as a consequence of this picture? Despite considerable investigation along these lines there is still disagreement between physicists about whether or not this is possible. We, however, are going to take the very pragmatic approach that in practice it is clear when to apply
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

86 Introduction to quantum mechanics
 Postulate 2 and when to apply Postulate 3, and not worry about deriving one postulate from the other.
Over the next few sections we apply Postulate 3 to several elementary but important measurement scenarios. Section 2.2.4 examines the problem of distinguishing a set of quantum states. Section 2.2.5 explains a special case of Postulate 3, the projective or von Neumann measurements. Section 2.2.6 explains another special case of Postulate 3, known as POVM measurements. Many introductions to quantum mechanics only discuss projective measurements, omitting a full discussion of Postulate 3 or of POVM elements. For this reason we have included Box 2.5 on page 91 which comments on the relationship between the different classes of measurement we describe.
Exercise 2.57: (Cascaded measurements are single measurements) Suppose {Ll} and {Mm} are two sets of measurement operators. Show that a measurement defined by the measurement operators {Ll} followed by a measurement defined by the measurement operators {Mm} is physically equivalent to a single measurement defined by measurement operators {Nlm} with the representation Nlm ≡ MmLl.
2.2.4 Distinguishing quantum states
An important application of Postulate 3 is to the problem of distinguishing quantum states. In the classical world, distinct states of an object are usually distinguishable, at least in principle. For example, we can always identify whether a coin has landed heads or tails, at least in the ideal limit. Quantum mechanically, the situation is more complicated. In Section 1.6 we gave a plausible argument that non-orthogonal quantum states cannot be distinguished. With Postulate 3 as a firm foundation we can now give a much more convincing demonstration of this fact.
Distinguishability, like many ideas in quantum computation and quantum information, is most easily understood using the metaphor of a game involving two parties, Alice and Bob. Alice chooses a state |ψi⟩ (1 ≤ i ≤ n) from some fixed set of states known to both parties. She gives the state |ψi⟩ to Bob, whose task it is to identify the index i of the state Alice has given him.
Suppose the states |ψi⟩ are orthonormal. Then Bob can do a quantum measurement
to distinguish these states, using the following procedure. Define measurement operators
Mi ≡ |ψi⟩⟨ψi|, one for each possible index i, and an additional measurement operator
M defined as the positive square root of the positive operator I − 􏰶 |ψ ⟩⟨ψ |. 0 i̸=0 i i
These operators satisfy the completeness relation, and if the state |ψi⟩ is prepared then p(i) = ⟨ψi|Mi|ψi⟩ = 1, so the result i occurs with certainty. Thus, it is possible to reliably distinguish the orthonormal states |ψi⟩.
By contrast, if the states |ψi⟩ are not orthonormal then we can prove that there is no quantum measurement capable of distinguishing the states. The idea is that Bob will do a measurement described by measurement operators Mj, with outcome j. Depending on the outcome of the measurement Bob tries to guess what the index i was using some rule, i = f(j), where f(·) represents the rule he uses to make the guess. The key to why Bob can’t distinguish non-orthogonal states |ψ1⟩ and |ψ2⟩ is the observation that |ψ2⟩ can be decomposed into a (non-zero) component parallel to |ψ1⟩, and a component orthogonal to |ψ1⟩. Suppose j is a measurement outcome such that f(j) = 1, that is, Bob guesses that the state was |ψ1⟩ when he observes j. But because of the component of |ψ2⟩ parallel
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The postulates of quantum mechanics 87
 to |ψ1⟩, there is a non-zero probability of getting outcome j when |ψ2⟩ is prepared, so sometimes Bob will make an error identifying which state was prepared. A more rigorous argument that non-orthogonal states can’t be distinguished is given in Box 2.3, but this captures the essential idea.
   Box 2.3: Proof that non-orthogonal states can’t be reliably distinguished
Since 􏰶 Ei = I it follows that 􏰶 ⟨ψ1|Ei|ψ1⟩ = 1, and since ⟨ψ1|E1|ψ1⟩ = 1
A proof by contradiction shows that no measurement distinguishing the non- orthogonal states |ψ1⟩ and |ψ2⟩ is possible. Suppose such a measurement is possible. If the state |ψ1⟩ (|ψ2⟩) is prepared then the probability of measuring j such that
f(j) = 1 (f(j) = 2) must be 1. Defining Ei ≡ 􏰶 may be written as:
ii
Mj†Mj, these observations ⟨ψ1|E1|ψ1⟩ = 1; ⟨ψ2|E2|ψ2⟩ = 1. (2.99)
√
|ψ2⟩ = α|ψ1⟩+β|φ⟩, where |φ⟩ is orthonormal to |ψ1⟩, |α|2 +|β|2 = 1, and |β| &lt; 1
j:f(j)=i
 we must have ⟨ψ1|E2|ψ1⟩ = 0, and thus
since |ψ1⟩ and |ψ2⟩ are not orthogonal. Then √E2|ψ2⟩ = β√
a contradiction with (2.99), as
⟨ψ2|E2|ψ2⟩ = |β|2⟨φ|E2|φ⟩ ≤ |β|2 &lt; 1,
E2|ψ1⟩ = 0. Suppose we decompose
  where the second last inequality follows from the observation that
􏰸
i
⟨φ|E2|φ⟩ ≤
⟨φ|Ei|φ⟩ = ⟨φ|φ⟩ = 1.
(2.101)
E2|φ⟩, which implies (2.100)
 2.2.5 Projective measurements
In this section we explain an important special case of the general measurement postulate, Postulate 3. This special class of measurements is known as projective measurements. For many applications of quantum computation and quantum information we will be concerned primarily with projective measurements. Indeed, projective measurements ac- tually turn out to be equivalent to the general measurement postulate, when they are augmented with the ability to perform unitary transformations, as described in Postu- late 2. We will explain this equivalence in detail in Section 2.2.8, as the statement of the measurement postulate for projective measurements is superficially rather different from the general postulate, Postulate 3.
Projective measurements: A projective measurement is described by an
observable, M, a Hermitian operator on the state space of the system being
observed. The observable has a spectral decomposition,
􏰸
m
where Pm is the projector onto the eigenspace of M with eigenvalue m. The possible outcomes of the measurement correspond to the eigenvalues, m, of the observable. Upon measuring the state |ψ⟩, the probability of getting result m is
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
M =
mPm , (2.102)
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

88
Introduction to quantum mechanics
 given by
p(m) = ψ|Pm|ψ . (2.103) Given that outcome m occurred, the state of the quantum system immediately
after the measurement is
Pm|ψ
√p(m) . (2.104)
Projective measurements can be understood as a special case of Postulate 3. Suppose the
the Mm are Hermitian, and MmMm = δm,mMm. With these additional restrictions, Postulate 3 reduces to a projective measurement as just defined.
Projective measurements have many nice properties. In particular, it is very easy to calculate average values for projective measurements. By definition, the average (see Appendix 1 for elementary definitions and results in probability theory) value of the measurement is
  measurement operators in Postulate 3, in addition to satisfying the completeness relation
􏰶 M† M = I, also satisfy the conditions that M are orthogonal projectors, that is, mmm m
􏰸
E(M)= m p(m) m
= mψ|Pm|ψ m􏰔􏰸 􏰕
= ψ|
= ψ|M|ψ.
(2.110) (2.111)
(2.112)
(2.113)
􏰸
This is a useful formula, which simplifies many calculations. The average value of the observable M is often written M ≡ ψ|M|ψ. From this formula for the average follows a formula for the standard deviation associated to observations of M,
[Δ(M)]2 = (M − M)2 (2.114) = M2 − M2. (2.115)
The standard deviation is a measure of the typical spread of the observed values upon mea-
surement of M . In particular, if we perform a large number of experiments in which the
state |ψ is prepared and the observable M is measured, then the standard deviation Δ(M ) 􏰠
of the observed values is determined by the formula Δ(M ) = M 2 − M 2. This for- mulation of measurement and standard deviations in terms of observables gives rise in an elegant way to results such as the Heisenberg uncertainty principle (see Box 2.4).
Exercise 2.58: Suppose we prepare a quantum system in an eigenstate |ψ of some observable M , with corresponding eigenvalue m. What is the average observed value of M, and the standard deviation?
m
mPm
|ψ
 Two widely used nomenclatures for measurements deserve emphasis. Rather than giv- ing an observable to describe a projective measurement, often people simply list a com-
plete set of orthogonal projectors Pm satisfying the relations 􏰶 Pm = I and PmPm m
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.

=
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

δmm′Pm. The corresponding observable implicit in this usage is M = 􏰶
other widely used phrase, to ‘measure in a basis |m⟩’, where |m⟩ form an orthonormal ba- sis, simply means to perform the projective measurement with projectors Pm = |m⟩⟨m|.
Let’s look at an example of projective measurements on single qubits. First is the
measurement of the observable Z. This has eigenvalues +1 and −1 with corresponding
eigenvectors |0⟩ and |1⟩. Thus, for example, measurement of Z on the state |ψ⟩ = √
(|0⟩ + |1⟩)/ 2 gives the result +1 with probability ⟨ψ|0⟩⟨0|ψ⟩ = 1/2, and similarly the
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
The postulates of quantum mechanics 89
    Box 2.4: The Heisenberg uncertainty principle
Perhaps the best known result of quantum mechanics is the Heisenberg uncer- tainty principle. Suppose A and B are two Hermitian operators, and |ψ⟩ is a quantum state. Suppose ⟨ψ|AB|ψ⟩ = x + iy, where x and y are real. Note that ⟨ψ|[A, B]|ψ⟩ = 2iy and ⟨ψ|{A, B}|ψ⟩ = 2x. This implies that
|⟨ψ|[A, B]|ψ⟩|2 + |⟨ψ|{A, B}|ψ⟩|2 = 4 |⟨ψ|AB|ψ⟩|2 . (2.105) By the Cauchy–Schwarz inequality
|⟨ψ|AB|ψ⟩|2 ≤ ⟨ψ|A2|ψ⟩⟨ψ|B2|ψ⟩, (2.106) which combined with Equation (2.105) and dropping a non-negative term gives
|⟨ψ|[A,B]|ψ⟩|2 ≤4⟨ψ|A2|ψ⟩⟨ψ|B2|ψ⟩. (2.107)
Suppose C and D are two observables. Substituting A = C−⟨C⟩ and B = D−⟨D⟩ into the last equation, we obtain Heisenberg’s uncertainty principle as it is usually stated:
Δ(C)Δ(D) ≥ |⟨ψ|[C, D]|ψ⟩| . (2.108) 2
You should be wary of a common misconception about the uncertainty principle, that measuring an observable C to some ‘accuracy’ Δ(C) causes the value of D to be ‘disturbed’ by an amount Δ(D) in such a way that some sort of inequality similar to (2.108) is satisfied. While it is true that measurements in quantum mechanics cause disturbance to the system being measured, this is most emphatically not the content of the uncertainty principle.
The correct interpretation of the uncertainty principle is that if we prepare a large number of quantum systems in identical states, |ψ⟩, and then perform measurements of C on some of those systems, and of D in others, then the standard deviation Δ(C) of the C results times the standard deviation Δ(D) of the results for D will satisfy the inequality (2.108).
As an example of the uncertainty principle, consider the observables X and Y when measured for the quantum state |0⟩. In Equation (2.70) we showed that [X, Y ] = 2iZ , so the uncertainty principle tells us that
Δ(X)Δ(Y ) ≥ ⟨0|Z|0⟩ = 1 . (2.109)
One elementary consequence of this is that Δ(X) and Δ(Y ) must both be strictly greater than 0, as can be verified by direct calculation.
  m
mPm. An-
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

90 Introduction to quantum mechanics
result −1 with probability 1/2. More generally, suppose ⃗v is any real three-dimensional
unit vector. Then we can define an observable:
⃗v · ⃗σ ≡ v1σ1 + v2σ2 + v3σ3. (2.116)
Measurement of this observable is sometimes referred to as a ‘measurement of spin along the ⃗v axis’, for historical reasons. The following two exercises encourage you to work out some elementary but important properties of such a measurement.
Exercise 2.59: Suppose we have qubit in the state |0⟩, and we measure the observable X. What is the average value of X? What is the standard deviation of X?
Exercise 2.60: Show that ⃗v · ⃗σ has eigenvalues ±1, and that the projectors onto the corresponding eigenspaces are given by P± = (I ± ⃗v · ⃗σ)/2.
Exercise 2.61: Calculate the probability of obtaining the result +1 for a measurement of ⃗v · ⃗σ, given that the state prior to measurement is |0⟩. What is the state of the system after the measurement if +1 is obtained?
2.2.6 POVM measurements
The quantum measurement postulate, Postulate 3, involves two elements. First, it gives a rule describing the measurement statistics, that is, the respective probabilities of the different possible measurement outcomes. Second, it gives a rule describing the post- measurement state of the system. However, for some applications the post-measurement state of the system is of little interest, with the main item of interest being the probabilities of the respective measurement outcomes. This is the case, for example, in an experiment where the system is measured only once, upon conclusion of the experiment. In such instances there is a mathematical tool known as the POVM formalism which is especially well adapted to the analysis of the measurements. (The acronym POVM stands for ‘Positive Operator-Valued Measure’, a technical term whose historical origins we won’t worry about.) This formalism is a simple consequence of the general description of measurements introduced in Postulate 3, but the theory of POVMs is so elegant and widely used that it merits a separate discussion here.
Suppose a measurement described by measurement operators Mm is performed upon a quantum system in the state |ψ⟩. Then the probability of outcome m is given by p(m) = ⟨ψ|Mm† Mm|ψ⟩. Suppose we define
Em ≡ Mm† Mm. (2.117) Then from Postulate 3 and elementary linear algebra, Em is a positive operator such
 that 􏰶
As an example of a POVM, consider a projective measurement described by mea-
Em = I and p(m) = ⟨ψ|Em|ψ⟩. Thus the set of operators Em are sufficient to determine the probabilities of the different measurement outcomes. The operators Em are known as the POVM elements associated with the measurement. The complete set {Em} is known as a POVM.
m
surement operators Pm, where the Pm are projectors such that PmPm′ = δmm′ Pm and
􏰶 Pm = I. In this instance (and only this instance) all the POVM elements are the m
same as the measurement operators themselves, since Em ≡ Pm† Pm = Pm.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The postulates of quantum mechanics 91
    Box 2.5: General measurements, projective measurements, and POVMs
Most introductions to quantum mechanics describe only projective measurements, and consequently the general description of measurements given in Postulate 3 may be unfamiliar to many physicists, as may the POVM formalism described in Section 2.2.6. The reason most physicists don’t learn the general measurement formalism is because most physical systems can only be measured in a very coarse manner. In quantum computation and quantum information we aim for an exquisite level of control over the measurements that may be done, and consequently it helps to use a more comprehensive formalism for the description of measurements.
Of course, when the other axioms of quantum mechanics are taken into account, projective measurements augmented by unitary operations turn out to be completely equivalent to general measurements, as shown in Section 2.2.8. So a physicist trained in the use of projective measurements might ask to what end we start with the general formalism, Postulate 3? There are several reasons for doing so. First, mathematically general measurements are in some sense simpler than projective measurements, since they involve fewer restrictions on the measurement operators; there is, for example, no requirement for general measurements analogous to the condition Pi Pj = δij Pi for projective measurements. This simpler structure also gives rise to many useful properties for general measurements that are not possessed by projective measurements. Second, it turns out that there are important problems in quantum computation and quantum information – such as the optimal way to distinguish a set of quantum states – the answer to which involves a general measurement, rather than a projective measurement.
A third reason for preferring Postulate 3 as a starting point is related to a property
of projective measurements known as repeatability. Projective measurements are
repeatable in the sense that if we perform a projective measurement once, and
obtain the outcome m, repeating the measurement gives the outcome m again and
does not change the state. To see this, suppose |ψ⟩ was the initial state. After the 􏰎􏰏􏰠
first measurement the state is |ψm⟩ = Pm|ψ⟩ / ⟨ψ|Pm|ψ⟩. Applying Pm to
|ψm⟩ does not change it, so we have ⟨ψm|Pm|ψm⟩ = 1, and therefore repeated measurement gives the result m each time, without changing the state.
This repeatability of projective measurements tips us off to the fact that many important measurements in quantum mechanics are not projective measurements. For instance, if we use a silvered screen to measure the position of a photon we destroy the photon in the process. This certainly makes it impossible to repeat the measurement of the photon’s position! Many other quantum measurements are also not repeatable in the same sense as a projective measurement. For such measurements, the general measurement postulate, Postulate 3, must be employed. Where do POVMs fit in this picture? POVMs are best viewed as a special case of the general measurement formalism, providing the simplest means by which one can study general measurement statistics, without the necessity for knowing the post-measurement state. They are a mathematical convenience that sometimes gives extra insight into quantum measurements.
  Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

92 Introduction to quantum mechanics
Exercise 2.62: Show that any measurement where the measurement operators and the
 POVM elements coincide is a projective measurement.
Above we noticed that the POVM operators are positive and satisfy 􏰶 Em = I.
Suppose now that {Em} is some arbitrary set of positive operators such that 􏰶 Em = I. m
We will show that there exists a set of measurement operators Mm defining a measurement described by the POVM {Em}. Defining Mm ≡ √Em we see that 􏰶 Mm† Mm =
􏰶m
m Em = I, and therefore the set {Mm} describes a measurement with POVM {Em}.
For this reason it is convenient to define a POVM to be any set of operators {Em} such
that: (a) each operator Em is positive; and (b) the completeness relation 􏰶
obeyed, expressing the fact that probabilities sum to one. To complete the description of POVMs, we note again that given a POVM {Em}, the probability of outcome m is given by p(m) = ⟨ψ|Em|ψ⟩.
We’ve looked at projective measurements as an example of the use of POVMs, but
it wasn’t very exciting since we didn’t learn much that was new. The following more
sophisticated example illustrates the use of the POVM formalism as a guide for our
intuition in quantum computation and quantum information. Suppose Alice gives Bob a
Consider a POVM containing three elements,
√
2. As explained in Section 2.2.4 it is impossible for Bob to determine whether he has been given |ψ1⟩ or |ψ2⟩ with perfect reliability. However, it is possible for him to perform a measurement which distinguishes the states some of the time, but never makes an error of mis-identification.
m
Em = I is
m
  qubit prepared in one of two states, |ψ1 ⟩ = |0⟩ or |ψ2 ⟩ = (|0⟩ + |1⟩)/
√
E1 ≡ √ |1⟩⟨1|,
 2 1+2
(2.118)
  E2 ≡ 1 + √2
√2 􏰇|0⟩ − |1⟩􏰈 􏰇⟨0| − ⟨1|􏰈
 2 ,
It is straightforward to verify that these are positive operators which satisfy the com-
(2.119)
(2.120)
pleteness relation 􏰶
Suppose Bob is given the state |ψ1⟩ = |0⟩. He performs the measurement described
by the POVM {E1,E2,E3}. There is zero probability that he will observe the result E1, since E1 has been cleverly chosen to ensure that ⟨ψ1|E1|ψ1⟩ = 0. Therefore, if the result of his measurement is E1 then Bob can safely conclude that the state he received must have been |ψ2⟩. A similar line of reasoning shows that if the measurement outcome E2 occurs then it must have been the state |ψ1⟩ that Bob received. Some of the time, however, Bob will obtain the measurement outcome E3, and he can infer nothing about the identity of the state he was given. The key point, however, is that Bob never makes a mistake identifying the state he has been given. This infallibility comes at the price that sometimes Bob obtains no information about the identity of the state.
This simple example demonstrates the utility of the POVM formalism as a simple and intuitive way of gaining insight into quantum measurements in instances where only the measurement statistics matter. In many instances later in the book we will only be concerned with measurement statistics, and will therefore use the POVM formalism rather than the more general formalism for measurements described in Postulate 3.
Exercise 2.63: Suppose a measurement is described by measurement operators Mm.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
   m
Em = I, and therefore form a legitimate POVM.
E3 ≡ I − E1 − E2.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The postulates of quantum mechanics 93 Show that there exist unitary operators U such that M = U √E , where
  m mmm Em is the POVM associated to the measurement.
Exercise 2.64: Suppose Bob is given a quantum state chosen from a set |ψ1 ⟩, . . . , |ψm ⟩ of linearly independent states. Construct a POVM {E1,E2,...,Em+1} such that if outcome Ei occurs, 1 ≤ i ≤ m, then Bob knows with certainty that he was given the state |ψi⟩. (The POVM must be such that ⟨ψi|Ei|ψi⟩ &gt; 0 for each i.)
2.2.7 Phase
‘Phase’ is a commonly used term in quantum mechanics, with several different mean- ings dependent upon context. At this point it is convenient to review a couple of these meanings. Consider, for example, the state eiθ|ψ⟩, where |ψ⟩ is a state vector, and θ is a real number. We say that the state eiθ|ψ⟩ is equal to |ψ⟩, up to the global phase factor eiθ. It is interesting to note that the statistics of measurement predicted for these two states are the same. To see this, suppose Mm is a measurement operator associated to some quantum measurement, and note that the respective probabilities for outcome m occurring are ⟨ψ|Mm† Mm|ψ⟩ and ⟨ψ|e−iθMm† Mmeiθ|ψ⟩ = ⟨ψ|Mm† Mm|ψ⟩. Therefore, from an observational point of view these two states are identical. For this reason we may ignore global phase factors as being irrelevant to the observed properties of the physical system.
There is another kind of phase known as the relative phase, which has quite a different meaning. Consider the states
|0⟩ + |1⟩ |0⟩ − |1⟩ √ and √
. (2.121) In the first state the amplitude of |1⟩ is 1/ 2. For the second state the amplitude is
    22
√
sign. More generally, we say that two amplitudes, a and b, differ by a relative phase if there is a real θ such that a = exp(iθ)b. More generally still, two states are said to differ by a relative phase in some basis if each of the amplitudes in that basis is related by such a phase factor. For example, the two states displayed above are the same up to a relative phase shift because the |0⟩ amplitudes are identical (a relative phase factor of 1), and the |1⟩ amplitudes differ only by a relative phase factor of −1. The difference between relative phase factors and global phase factors is that for relative phase the phase factors may vary from amplitude to amplitude. This makes the relative phase a basis-dependent concept unlike global phase. As a result, states which differ only by relative phases in some basis give rise to physically observable differences in measurement statistics, and it is not possible to regard these states as physically equivalent, as we do with states differing by a global phase factor
√√
Exercise 2.65: Express the states (|0⟩ + |1⟩)/ 2 and (|0⟩ − |1⟩)/ 2 in a basis in
which they are not the same up to a relative phase shift.
2.2.8 Composite systems
Suppose we are interested in a composite quantum system made up of two (or more) distinct physical systems. How should we describe states of the composite system? The following postulate describes how the state space of a composite system is built up from the state spaces of the component systems.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 √
−1/ 2. In each case the magnitude of the amplitudes is the same, but they differ in
   Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

94
Introduction to quantum mechanics
 Postulate 4: The state space of a composite physical system is the tensor product of the state spaces of the component physical systems. Moreover, if we have systems numbered 1 through n, and system number i is prepared in the state |ψi⟩, then the joint state of the total system is |ψ1⟩ ⊗ |ψ2⟩ ⊗ · · · ⊗ |ψn⟩.
Why is the tensor product the mathematical structure used to describe the state space of a composite physical system? At one level, we can simply accept it as a basic postulate, not reducible to something more elementary, and move on. After all, we certainly expect that there be some canonical way of describing composite systems in quantum mechanics. Is there some other way we can arrive at this postulate? Here is one heuristic that is sometimes used. Physicists sometimes like to speak of the superposition principle of quantum mechanics, which states that if |x⟩ and |y⟩ are two states of a quantum system, then any superposition α|x⟩ + β|y⟩ should also be an allowed state of a quantum system, where |α|2 + |β|2 = 1. For composite systems, it seems natural that if |A⟩ is a state of system A, and |B⟩ is a state of system B, then there should be some corresponding state, which we might denote |A⟩|B⟩, of the joint system AB. Applying the superposition principle to product states of this form, we arrive at the tensor product postulate given above. This is not a derivation, since we are not taking the superposition principle as a fundamental part of our description of quantum mechanics, but it gives you the flavor of the various ways in which these ideas are sometimes reformulated.
A variety of different notations for composite systems appear in the literature. Part of the reason for this proliferation is that different notations are better adapted for different applications, and we will also find it convenient to introduce some specialized notations on occasion. At this point it suffices to mention a useful subscript notation to denote states and operators on different systems, when it is not clear from context. For example, in a system containing three qubits, X2 is the Pauli σx operator acting on the second qubit.
Exercise 2.66: Show that the average value of the observable X Z for a two qubit
√
system measured in the state (|00⟩ + |11⟩)/ 2 is zero.
12
 In Section 2.2.5 we claimed that projective measurements together with unitary dy- namics are sufficient to implement a general measurement. The proof of this statement makes use of composite quantum systems, and is a nice illustration of Postulate 4 in action. Suppose we have a quantum system with state space Q, and we want to per- form a measurement described by measurement operators Mm on the system Q. To do this, we introduce an ancilla system, with state space M, having an orthonormal basis |m⟩ in one-to-one correspondence with the possible outcomes of the measurement we wish to implement. This ancilla system can be regarded as merely a mathematical device appearing in the construction, or it can be interpreted physically as an extra quantum system introduced into the problem, which we assume has a state space with the required properties.
Letting |0⟩ be any fixed state of M, define an operator U on products |ψ⟩|0⟩ of states |ψ⟩ from Q with the state |0⟩ by
􏰸
Mm|ψ⟩|m⟩. (2.122) Using the orthonormality of the states |m⟩ and the completeness relation 􏰶 M † M =
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
U|ψ⟩|0⟩ ≡
m
mmm
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

p(m) = ⟨ψ|⟨0|U†PmU|ψ⟩|0⟩
=
= ⟨φ|ψ⟩.
m
The postulates of quantum mechanics
95
 I, we can see that U preserves inner products between states of the form |ψ⟩|0⟩, †􏰸†′
⟨φ|⟨0|U U|ψ⟩|0⟩ = ⟨φ|MmMm′|ψ⟩⟨m|m ⟩ m,m′
(2.123)
(2.124) (2.125)
By the results of Exercise 2.67 it follows that U can be extended to a unitary operator on the space Q ⊗ M, which we also denote by U.
Exercise 2.67: Suppose V is a Hilbert space with a subspace W . Suppose
U : W → V is a linear operator which preserves inner products, that is, for any |w1⟩ and |w2⟩ in W,
⟨w1|U†U|w2⟩ = ⟨w1|w2⟩. (2.126)
Prove that there exists a unitary operator U ′ : V → V which extends U . That is, U′|w⟩ = U|w⟩ for all |w⟩ in W, but U′ is defined on the entire space V . Usually we omit the prime symbol ′ and just write U to denote the extension.
Next, suppose we perform a projective measurement on the two systems described by projectors Pm ≡ IQ ⊗ |m⟩⟨m|. Outcome m occurs with probability
􏰸† ⟨φ|MmMm|ψ⟩
(2.127) (2.128)
conditional on result m occurring, is given by
􏰠 PmU|ψ⟩|0⟩ = 􏰡 Mm|ψ⟩|m⟩ . (2.130)
⟨ψ|U†PmU|ψ⟩ ⟨ψ|Mm† Mm|ψ⟩
It follows that the state of system M after the measurement is |m⟩, and the state of
system Q is
􏰡 Mm|ψ⟩ , (2.131) ⟨ψ|Mm† Mm|ψ⟩
just as prescribed by Postulate 3. Thus unitary dynamics, projective measurements, and the ability to introduce ancillary systems, together allow any measurement of the form described in Postulate 3 to be realized.
Postulate 4 also enables us to define one of the most interesting and puzzling ideas associated with composite quantum systems – entanglement. Consider the two qubit state
|00⟩ + |11⟩
􏰸†′ ′′ ⟨ψ|Mm′ ⟨m |(IQ ⊗ |m⟩⟨m|)Mm′′ |ψ⟩|m ⟩
=
= ⟨ψ|Mm† Mm|ψ⟩,
m′ ,m′′
(2.129) just as given in Postulate 3. The joint state of the system QM after measurement,
      |ψ⟩ = √
This state has the remarkable property that there are no single qubit states |a⟩ and |b⟩
. (2.132) such that |ψ⟩ = |a⟩|b⟩, a fact which you should now convince yourself of:
  Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
2
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

96 Introduction to quantum mechanics
Exercise 2.68: Prove that |ψ⟩ ̸= |a⟩|b⟩ for all single qubit states |a⟩ and |b⟩.
We say that a state of a composite system having this property (that it can’t be written as a product of states of its component systems) is an entangled state. For reasons which nobody fully understands, entangled states play a crucial role in quantum computation and quantum information, and arise repeatedly through the remainder of this book. We have already seen entanglement play a crucial role in quantum teleportation, as described in Section 1.3.7. In this chapter we give two examples of the strange effects enabled by entangled quantum states, superdense coding (Section 2.3), and the violation of Bell’s inequality (Section 2.6).
2.2.9 Quantum mechanics: a global view
We have now explained all the fundamental postulates of quantum mechanics. Most of the rest of the book is taken up with deriving consequences of these postulates. Let’s quickly review the postulates and try to place them in some kind of global perspective.
Postulate 1 sets the arena for quantum mechanics, by specifying how the state of an isolated quantum system is to be described. Postulate 2 tells us that the dynamics of closed quantum systems are described by the Schro ̈dinger equation, and thus by unitary evolution. Postulate 3 tells us how to extract information from our quantum systems by giving a prescription for the description of measurement. Postulate 4 tells us how the state spaces of different quantum systems may be combined to give a description of the composite system.
What’s odd about quantum mechanics, at least by our classical lights, is that we can’t directly observe the state vector. It’s a little bit like a game of chess where you can never find out exactly where each piece is, but only know the rank of the board they are on. Classical physics – and our intuition – tells us that the fundamental properties of an object, like energy, position, and velocity, are directly accessible to observation. In quantum mechanics these quantities no longer appear as fundamental, being replaced by the state vector, which can’t be directly observed. It is as though there is a hidden world in quantum mechanics, which we can only indirectly and imperfectly access. Moreover, merely observing a classical system does not necessarily change the state of the system. Imagine how difficult it would be to play tennis if each time you looked at the ball its position changed! But according to Postulate 3, observation in quantum mechanics is an invasive procedure that typically changes the state of the system.
What conclusions should we draw from these strange features of quantum mechanics? Might it be possible to reformulate quantum mechanics in a mathematically equivalent way so that it had a structure more like classical physics? In Section 2.6 we’ll prove Bell’s inequality, a surprising result that shows any attempt at such a reformulation is doomed to failure. We’re stuck with the counter-intuitive nature of quantum mechanics. Of course, the proper reaction to this is glee, not sorrow! It gives us an opportunity to develop tools of thought that make quantum mechanics intuitive. Moreover, we can exploit the hidden nature of the state vector to do information processing tasks beyond what is possible in the classical world. Without this counter-intuitive behavior, quantum computation and quantum information would be a lot less interesting.
We can also turn this discussion about, and ask ourselves: ‘If quantum mechanics is so different from classical physics, then how come the everyday world looks so classical?’ Why do we see no evidence of a hidden state vector in our everyday lives? It turns out
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

that the classical world we see can be derived from quantum mechanics as an approximate description of the world that will be valid on the sort of time, length and mass scales we commonly encounter in our everyday lives. Explaining the details of how quantum mechanics gives rise to classical physics is beyond the scope of this book, but the interested reader should check out the discussion of this topic in ‘History and further reading’at the end of Chapter 8.
2.3 Application: superdense coding
Superdense coding is a simple yet surprising application of elementary quantum mechan- ics. It combines in a concrete, non-trivial way all the basic ideas of elementary quantum mechanics, as covered in the previous sections, and is therefore an ideal example of the information processing tasks that can be accomplished using quantum mechanics.
Superdense coding involves two parties, conventionally known as ‘Alice’ and ‘Bob’, who are a long way away from one another. Their goal is to transmit some classical information from Alice to Bob. Suppose Alice is in possession of two classical bits of information which she wishes to send Bob, but is only allowed to send a single qubit to Bob. Can she achieve her goal?
Superdense coding tells us that the answer to this question is yes. Suppose Alice and Bob initially share a pair of qubits in the entangled state
|ψ⟩ = √
|00⟩ + |11⟩
. (2.133)
Alice is initially in possession of the first qubit, while Bob has possession of the second qubit, as illustrated in Figure 2.3. Note that |ψ⟩ is a fixed state; there is no need for Alice to have sent Bob any qubits in order to prepare this state. Instead, some third party may prepare the entangled state ahead of time, sending one of the qubits to Alice, and the other to Bob.
= 00 + 11 2
1 qubit
Application: superdense coding 97
   2
    Alice
00: I 01: Z 10:X 11:iY
Bob
 1 qubit
Figure 2.3. The initial setup for superdense coding, with Alice and Bob each in possession of one half of an entangled pair of qubits. Alice can use superdense coding to transmit two classical bits of information to Bob, using only a single qubit of communication and this preshared entanglement.
By sending the single qubit in her possession to Bob, it turns out that Alice can communicate two bits of classical information to Bob. Here is the procedure she uses. If she wishes to send the bit string ‘00’ to Bob then she does nothing at all to her qubit. If she wishes to send ‘01’ then she applies the phase flip Z to her qubit. If she wishes to send ‘10’ then she applies the quantum       gate, X, to her qubit. If she wishes to send ‘11’ then she applies the iY gate to her qubit. The four resulting states are easily seen
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

98 Introduction to quantum mechanics to be:
|00⟩ + |11⟩ 00 : |ψ⟩ → √
2
|00⟩ − |11⟩ 01 : |ψ⟩ → √
2
|10⟩ + |01⟩ 10 : |ψ⟩ → √
2
|01⟩ − |10⟩ 11 : |ψ⟩ → √
2
.
(2.134)
(2.135)
(2.136)
(2.137)
         As we noted in Section 1.3.6, these four states are known as the Bell basis, Bell states, or EPR pairs, in honor of several of the pioneers who first appreciated the novelty of entanglement. Notice that the Bell states form an orthonormal basis, and can therefore be distinguished by an appropriate quantum measurement. If Alice sends her qubit to Bob, giving Bob possession of both qubits, then by doing a measurement in the Bell basis Bob can determine which of the four possible bit strings Alice sent.
Summarizing, Alice, interacting with only a single qubit, is able to transmit two bits of information to Bob. Of course, two qubits are involved in the protocol, but Alice never need interact with the second qubit. Classically, the task Alice accomplishes would have been impossible had she only transmitted a single classical bit, as we will show in Chapter 12. Furthermore, this remarkable superdense coding protocol has received partial verification in the laboratory. (See ‘History and further reading’ for references to the experimental verification.) In later chapters we will see many other examples, some of them much more spectacular than superdense coding, of quantum mechanics being harnessed to perform information processing tasks. However, a key point can already be seen in this beautiful example: information is physical, and surprising physical theories such as quantum mechanics may predict surprising information processing abilities.
Exercise 2.69: Verify that the Bell basis forms an orthonormal basis for the two qubit state space.
Exercise 2.70: Suppose E is any positive operator acting on Alice’s qubit. Show that ⟨ψ|E ⊗ I|ψ⟩ takes the same value when |ψ⟩ is any of the four Bell states. Suppose some malevolent third party (‘Eve’) intercepts Alice’s qubit on the way to Bob in the superdense coding protocol. Can Eve infer anything about which of the four possible bit strings 00, 01, 10, 11 Alice is trying to send? If so, how, or if not, why not?
2.4 The density operator
We have formulated quantum mechanics using the language of state vectors. An alternate formulation is possible using a tool known as the density operator or density matrix. This alternate formulation is mathematically equivalent to the state vector approach, but it provides a much more convenient language for thinking about some commonly encountered scenarios in quantum mechanics. The next three sections describe the density operator formulation of quantum mechanics. Section 2.4.1 introduces the density operator using the concept of an ensemble of quantum states. Section 2.4.2 develops some general
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

properties of the density operator. Finally, Section 2.4.3 describes an application where the density operator really shines – as a tool for the description of individual subsystems of a composite quantum system.
2.4.1 Ensembles of quantum states
The density operator language provides a convenient means for describing quantum systems whose state is not completely known. More precisely, suppose a quantum system is in one of a number of states |ψi⟩, where i is an index, with respective probabilities pi. We shall call {pi,|ψi⟩} an ensemble of pure states. The density operator for the system is defined by the equation
􏰸
i
The density operator is often known as the density matrix; we will use the two terms interchangeably. It turns out that all the postulates of quantum mechanics can be re- formulated in terms of the density operator language. The purpose of this section and the next is to explain how to perform this reformulation, and explain when it is useful. Whether one uses the density operator language or the state vector language is a matter of taste, since both give the same results; however it is sometimes much easier to approach problems from one point of view rather than the other.
Suppose, for example, that the evolution of a closed quantum system is described by the unitary operator U . If the system was initially in the state |ψi ⟩ with probability pi then after the evolution has occurred the system will be in the state U|ψi⟩ with probability pi. Thus, the evolution of the density operator is described by the equation
􏰸U􏰸††
ρ = pi|ψi⟩⟨ψi| −→ piU|ψi⟩⟨ψi|U = UρU . (2.139)
ii
Measurements are also easily described in the density operator language. Suppose we perform a measurement described by measurement operators Mm. If the initial state was |ψi⟩, then the probability of getting result m is
p(m|i) = ⟨ψi|Mm† Mm|ψi⟩ = tr(Mm† Mm|ψi⟩⟨ψi|), (2.140)
where we have used Equation (2.61) to obtain the last equality. By the law of total probability (see Appendix 1 for an explanation of this and other elementary notions of probability theory) the probability of obtaining result m is
ρ ≡
pi|ψi⟩⟨ψi|. (2.138)
􏰸
p(m) = p(m|i)pi
i
􏰸†
= pitr(MmMm|ψi⟩⟨ψi|)
the initial state was |ψi⟩ then the state after obtaining the result m is
|ψim⟩ = 􏰡 Mm|ψi⟩ . (2.144)
⟨ψi|Mm† Mm|ψi⟩
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
(2.141)
(2.142)
(2.143) What is the density operator of the system after obtaining the measurement result m? If
i
= tr(Mm† Mmρ).
The density operator 99
   Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

100 Introduction to quantum mechanics
Thus, after a measurement which yields the result m we have an ensemble of states |ψim⟩
with respective probabilities p(i|m). The corresponding density operator ρm is therefore
􏰸 m m 􏰸 M m | ψ i ⟩ ⟨ ψ i | M m†
p(i|m)|ψi ⟩⟨ψi | = p(i|m)⟨ψi|Mm† Mm|ψi⟩. (2.145)
 ρm =
But by elementary probability theory, p(i|m) = p(m,i)/p(m) = p(m|i)pi/p(m). Substi-
 ii
tuting from (2.143) and (2.140) we obtain
What we have shown is that the basic postulates of quantum mechanics related to unitary evolution and measurement can be rephrased in the language of density operators. In the next section we complete this rephrasing by giving an intrinsic characterization of the density operator that does not rely on the idea of a state vector.
Before doing so, however, it is useful to introduce some more language, and one more fact about the density operator. First, the language. A quantum system whose state |ψ⟩ is known exactly is said to be in a pure state. In this case the density operator is simply ρ = |ψ⟩⟨ψ|. Otherwise, ρ is in a mixed state; it is said to be a mixture of the different pure states in the ensemble for ρ. In the exercises you will be asked to demonstrate a simple criterion for determining whether a state is pure or mixed: a pure state satisfies tr(ρ2) = 1, while a mixed state satisfies tr(ρ2) &lt; 1. A few words of warning about the nomenclature: sometimes people use the term ‘mixed state’ as a catch-all to include both pure and mixed quantum states. The origin for this usage seems to be that it implies that the writer is not necessarily assuming that a state is pure. Second, the term ‘pure state’ is often used in reference to a state vector |ψ⟩, to distinguish it from a density operator ρ.
Finally, imagine a quantum system is prepared in the state ρi with probability pi. It is
􏰸 M m | ψ i ⟩ ⟨ ψ i | M m†
pi tr(Mm† Mmρ) Mm ρMm†
ρm =
= tr(Mm† Mmρ).
(2.146)
(2.147)
 ρ = =
􏰸
pipij|ψij⟩⟨ψij| pi ρi ,
i
 not difficult to convince yourself that the system may be described by the density matrix
􏰶 piρi. A proof of this is to suppose that ρi arises from some ensemble {pij,|ψij⟩} i
(note that i is fixed) of pure states, so the probability for being in the state |ψij⟩ is pipij. The density matrix for the system is thus
ij
(2.148) (2.149)
􏰸
i
where we have used the definition ρi = 􏰶 pij|ψij⟩⟨ψij|. We say that ρ is a mixture j
of the states ρi with probabilities pi. This concept of a mixture comes up repeatedly in the analysis of problems like quantum noise, where the effect of the noise is to introduce ignorance into our knowledge of the quantum state. A simple example is provided by the measurement scenario described above. Imagine that, for some reason, our record of the result m of the measurement was lost. We would have a quantum system in the state ρm with probability p(m), but would no longer know the actual value of m. The state of
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

such a quantum system would therefore be described by the density operator
􏰸
ρ= p(m)ρm m
􏰸
(2.150)
(2.151)
(2.152)
a nice compact formula which may be used as the starting point for analysis of further operations on the system.
2.4.2 General properties of the density operator
The density operator was introduced as a means of describing ensembles of quantum states. In this section we move away from this description to develop an intrinsic char- acterization of density operators that does not rely on an ensemble interpretation. This allows us to complete the program of giving a description of quantum mechanics that does not take as its foundation the state vector. We also take the opportunity to develop numerous other elementary properties of the density operator.
The class of operators that are density operators are characterized by the following useful theorem:
Theorem 2.5: (Characterization of density operators) An operator ρ is the density operator associated to some ensemble {pi,|ψi⟩} if and only if it satisfies the conditions:
(1) (Trace condition) ρ has trace equal to one. (2) (Positivity condition) ρ is a positive operator.
Proof 􏰶 Suppose ρ =
i pi|ψi⟩⟨ψi| is a density operator. Then 􏰸􏰸
tr(ρ) = pitr(|ψi⟩⟨ψi|) = pi = 1, (2.153) ii
† MmρMm† tr(MmMmρ) tr(Mm† M ρ)
=
= MmρMm,
􏰸† m
so the trace condition tr(ρ) = 1 is satisfied. Suppose |φ⟩ is an arbitrary vector in state space. Then
⟨φ|ρ|φ⟩ = =
􏰸
􏰸
i
pi⟨φ|ψi⟩⟨ψi|φ⟩ pi |⟨φ|ψi ⟩|2
(2.154)
(2.155) (2.156)
≥ 0,
so the positivity condition is satisfied.
Conversely, suppose ρ is any operator satisfying the trace and positivity conditions.
Since ρ is positive, it must have a spectral decomposition
􏰸
ρ =
where the vectors |j⟩ are orthogonal, and λj are real, non-negative eigenvalues of ρ.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
j
i
The density operator
101
  mm
λj|j⟩⟨j|, (2.157)
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

102 Introduction to quantum mechanics
From the trace condition we see that 􏰶 λj = 1. Therefore, a system in state |j⟩ with
 j
probabilityλj willhavedensityoperatorρ.Thatis,theensemble{λj,|j⟩}isanensemble
of states giving rise to the density operator ρ.
This theorem provides a characterization of density operators that is intrinsic to the operator itself: we can define a density operator to be a positive operator ρ which has trace equal to one. Making this definition allows us to reformulate the postulates of quantum mechanics in the density operator picture. For ease of reference we state all the reformulated postulates here:
Postulate 1: Associated to any isolated physical system is a complex vector space with inner product (that is, a Hilbert space) known as the state space of the system. The system is completely described by its density operator, which is a positive operator ρ with trace one, acting on the state space of the system. If a quantum system is in the state ρi with probability pi, then the density operator for the system is 􏰶 piρi.
Postulate 2: The evolution of a closed quantum system is described by a unitary transformation. That is, the state ρ of the system at time t1 is related to the state ρ′ of the system at time t2 by a unitary operator U which depends only on the times t1 and t2,
ρ′ = UρU†. (2.158)
Postulate 3: Quantum measurements are described by a collection {Mm} of measurement operators. These are operators acting on the state space of the system being measured. The index m refers to the measurement outcomes that may occur in the experiment. If the state of the quantum system is ρ immediately before the measurement then the probability that result m occurs is given by
   i
p(m) = tr(Mm† Mmρ), and the state of the system after the measurement is
Mm ρMm† tr(Mm† Mmρ).
The measurement operators satisfy the completeness equation, 􏰸 M m† M m = I .
m
(2.159)
(2.160)
( 2 . 1 6 1 )
 Postulate 4: The state space of a composite physical system is the tensor product of the state spaces of the component physical systems. Moreover, if we have systems numbered 1 through n, and system number i is prepared in the state ρi, then the joint state of the total system is ρ1 ⊗ρ2 ⊗...ρn.
These reformulations of the fundamental postulates of quantum mechanics in terms of the density operator are, of course, mathematically equivalent to the description in terms of the state vector. Nevertheless, as a way of thinking about quantum mechanics, the density operator approach really shines for two applications: the description of quantum systems whose state is not known, and the description of subsystems of a composite
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The density operator 103 quantum system, as will be described in the next section. For the remainder of this
section we flesh out the properties of the density matrix in more detail.
Exercise 2.71: (Criterion to decide if a state is mixed or pure) Let ρ be a density operator. Show that tr(ρ2) ≤ 1, with equality if and only if ρ is a pure state.
It is a tempting (and surprisingly common) fallacy to suppose that the eigenvalues and eigenvectors of a density matrix have some special significance with regard to the ensemble of quantum states represented by that density matrix. For example, one might suppose that a quantum system with density matrix
ρ = 3 |0⟩⟨0| + 1 |1⟩⟨1| . (2.162) 44
must be in the state |0⟩ with probability 3/4 and in the state |1⟩ with probability 1/4. However, this is not necessarily the case. Suppose we define
   􏰢􏰢
  |a⟩ ≡ 3 |0⟩ + 􏰢4
1 |1⟩ 􏰢4
(2.163) (2.164)
and the quantum system is prepared in the state |a⟩ with probability 1/2 and in the state |b⟩ with probability 1/2. Then it is easily checked that the corresponding density matrix is
ρ = 1 |a⟩⟨a| + 1 |b⟩⟨b| = 3 |0⟩⟨0| + 1 |1⟩⟨1|. (2.165) 2244
That is, these two different ensembles of quantum states give rise to the same density matrix. In general, the eigenvectors and eigenvalues of a density matrix just indicate one of many possible ensembles that may give rise to a specific density matrix, and there is no reason to suppose it is an especially privileged ensemble.
A natural question to ask in the light of this discussion is what class of ensembles does
give rise to a particular density matrix? The solution to this problem, which we now give,
has surprisingly many applications in quantum computation and quantum information,
notably in the understanding of quantum noise and quantum error-correction (Chapters 8
    |b⟩ ≡ 3 |0⟩ −
1 |1⟩, 44
      and 10). For the solution it is convenient to make use of vectors |ψ ̃i⟩ which may not be
normalized to unit length. We say the set |ψ ̃i⟩ generates the operator ρ ≡ 􏰶 |ψ ̃i⟩⟨ψ ̃i|, i
and thus the connection to the usual ensemble picture of density operators is expressed
pi|ψi⟩. When do two sets of vectors, |ψ ̃i⟩ and |φ ̃j⟩ generate the by the equation |ψ ̃i⟩ = √
 same operator ρ? The solution to this problem will enable us to answer the question of what ensembles give rise to a given density matrix.
Theorem 2.6: (Unitary freedom in the ensemble for density matrices) The sets |ψ ̃i⟩ and |φ ̃j⟩ generate the same density matrix if and only if
| ψ ̃ i ⟩ = 􏰸 u i j | φ ̃ j ⟩ , ( 2 . 1 6 6 ) j
where uij is a unitary matrix of complex numbers, with indices i and j, and we
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

104 Introduction to quantum mechanics
‘pad’ whichever set of vectors |ψ ̃i⟩ or |φ ̃j⟩ is smaller with additional vectors 0 so
 that the two sets have the same number of elements.
As a consequence of the theorem, note that ρ = 􏰶 pi|ψi⟩⟨ψi| = 􏰶 qj|φj⟩⟨φj| for
ij normalized states |ψi⟩,|φj⟩ and probability distributions pi and qj if and only if
j
which shows that |ψ ̃i⟩ and |φ ̃j⟩ generate the same operator.
Conversely, suppose
p|ψ⟩=􏰸u √
√
for some unitary matrix uij , and we may pad the smaller ensemble with entries having probability zero in order to make the two ensembles the same size. Thus, Theorem 2.6 characterizes the freedom in ensembles {pi, |ψi⟩} giving rise to a given density matrix ρ. Indeed, it is easily checked that our earlier example of a density matrix with two different
q |φ ⟩, (2.167) ii ijjj
  decompositions, (2.162), arises as a special case of this general result. Let’s turn the proof of the theorem.
now to
(2.168)
(2.169) (2.170) (2.171)
Proof 􏰶 Suppose |ψ ̃i⟩ =
j uij|φ ̃j⟩ for some unitary uij. Then 􏰸 ̃ ̃􏰸∗
|ψi⟩⟨ψi| = uijuik|φ ̃j⟩⟨φ ̃k| i ijk􏰔􏰕
= = =
􏰸􏰸†
u k i u i j
| φ ̃ j ⟩ ⟨ φ ̃ k |
􏰸
δ k j | φ ̃ j ⟩ ⟨ φ ̃ k | | φ ̃ j ⟩ ⟨ φ ̃ j | ,
jk
􏰸
j
jk i
􏰸 ̃ ̃􏰸
A = |ψi⟩⟨ψi| = |φ ̃j⟩⟨φ ̃j|.
(2.172) LetA=􏰶 λk|k⟩⟨k|beadecompositionforAsuchthatthestates|k⟩areorthonormal,
ij
k
and the λk are strictly positive. Our strategy is to relate the states |ψ ̃i⟩ to the states
|k ̃⟩ ≡ √λk|k⟩, and similarly relate the states |φ ̃j⟩ to the states |k ̃⟩. Combining the two relations will give the result. Let |ψ⟩ be any vector orthonormal to the space spanned by the |k ̃⟩, so ⟨ψ|k ̃⟩⟨k ̃|ψ⟩ = 0 for all k, and thus we see that
 􏰸 ̃ ̃􏰸 ̃2
0 = ⟨ψ|A|ψ⟩ = ⟨ψ|ψi⟩⟨ψi|ψ⟩ = |⟨ψ|ψi⟩| . (2.173)
ii
Thus ⟨ψ|ψ ̃i⟩ = 0 for all i and all |ψ⟩ orthonormal to the space spanned by the |k ̃⟩.
It follows that each |ψ ̃i⟩ can be expressed as a linear combination of the |k ̃⟩, |ψ ̃i⟩ =
􏰶 c |k ̃⟩.SinceA=􏰶 |k ̃⟩⟨k ̃|=􏰶 |ψ ̃⟩⟨ψ ̃|weseethat kik k iii
􏰸 􏰸􏰔􏰸 􏰕
| k ̃ ⟩ ⟨ k ̃ | = c i k c ∗i l | k ̃ ⟩ ⟨ l  ̃ | . ( 2 . 1 7 4 ) k kli
The operators |k ̃⟩⟨l ̃| are easily seen to be linearly independent, and thus it must be that
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The density operator 105 􏰶 cikc∗il = δkl. This ensures that we may append extra columns to c to obtain a unitary
 i  ̃􏰶 ̃
matrix v such that |ψi = k vik|k, where we have appended zero vectors to the list
of |k ̃. Similarly, we can find a unitary matrix w such that |φ ̃j = 􏰶 wjk|k ̃. Thus  ̃􏰶†k
|ψi = j uij|φ ̃j, where u = vw is unitary.
  Exercise 2.72: (Bloch sphere for mixed states) The Bloch sphere picture for pure states of a single qubit was introduced in Section 1.2. This description has an important generalization to mixed states as follows.
(1) Show that an arbitrary density matrix for a mixed state qubit may be written as
ρ = I + ìr · ìσ , ( 2 . 1 7 5 ) 2
where ìr is a real three-dimensional vector such that ìr ≤ 1. This vector is
known as the Bloch vector for the state ρ.
(2) What is the Bloch vector representation for the state ρ = I/2?
(3) Showthatastateρispureifandonlyif ìr =1.
(4) Show that for pure states the description of the Bloch vector we have given
coincides with that in Section 1.2.
Exercise 2.73: Let ρ be a density operator. A minimal ensemble for ρ is an ensemble {pi, |ψi} containing a number of elements equal to the rank of ρ. Let |ψ be any state in the support of ρ. (The support of a Hermitian operator A is the vector space spanned by the eigenvectors of A with non-zero eigenvalues.) Show that there is a minimal ensemble for ρ that contains |ψ, and moreover that in any such ensemble |ψ must appear with probability
pi = 1 , (2.176) ψi |ρ−1 |ψi 
where ρ−1 is defined to be the inverse of ρ, when ρ is considered as an operator acting only on the support of ρ. (This definition removes the problem that ρ may not have an inverse.)
2.4.3 The reduced density operator
Perhaps the deepest application of the density operator is as a descriptive tool for sub- systems of a composite quantum system. Such a description is provided by the reduced density operator, which is the subject of this section. The reduced density operator is so useful as to be virtually indispensable in the analysis of composite quantum systems.
Suppose we have physical systems A and B, whose state is described by a density operator ρAB. The reduced density operator for system A is defined by
ρA ≡ trB(ρAB), (2.177) where trB is a map of operators known as the partial trace over system B. The partial
trace is defined by
tr 􏰇|a a |⊗|b b |􏰈≡|a a |tr(|b b |), (2.178) B1212 1212
where |a1 and |a2 are any two vectors in the state space of A, and |b1 and |b2 are any two vectors in the state space of B. The trace operation appearing on the right hand side
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
  Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

106 Introduction to quantum mechanics
 is the usual trace operation for system B, so tr(|b1b2|) = b2|b1. We have defined the partial trace operation only on a special subclass of operators on AB; the specification is completed by requiring in addition to Equation (2.178) that the partial trace be linear in its input.
It is not obvious that the reduced density operator for system A is in any sense a description for the state of system A. The physical justification for making this identifi- cation is that the reduced density operator provides the correct measurement statistics for measurements made on system A. This is explained in more detail in Box 2.6 on page 107. The following simple example calculations may also help understand the reduced density operator. First, suppose a quantum system is in the product state ρAB = ρ ⊗ σ, where ρ is a density operator for system A, and σ is a density operator for system B. Then
ρA =trB(ρ⊗σ)=ρtr(σ)=ρ, (2.184) which is the result we intuitively expect. Similarly, ρB = σ for this state. A less trivial
√
example is the Bell state (|00 + |11)/ 2. This has density operator
􏰐|00+|11􏰑􏰐00|+11|􏰑 ρ=√ √
22
= |0000| + |1100| + |0011| + |1111| .
(2.185)
     (2.186) Tracing out the second qubit, we find the reduced density operator of the first qubit,
 ρ1 = tr2(ρ)
= tr2(|0000|) + tr2(|1100|) + tr2(|0011|) + tr2(|1111|)
2
= |00|0|0 + |10|0|1 + |01|1|0 + |11|1|1
(2.187) (2.188)
(2.189)
(2.190)
(2.191)
2
  = |00| + |11| 2
= I. 2
2
  Notice that this state is a mixed state, since tr((I/2)2) = 1/2 &lt; 1. This is quite a remarkable result. The state of the joint system of two qubits is a pure state, that is, it is known exactly; however, the first qubit is in a mixed state, that is, a state about which we apparently do not have maximal knowledge. This strange property, that the joint state of a system can be completely known, yet a subsystem be in mixed states, is another hallmark of quantum entanglement.
Exercise 2.74: Suppose a composite of systems A and B is in the state |a|b, where |a is a pure state of system A, and |b is a pure state of system B. Show that the reduced density operator of system A alone is a pure state.
Exercise 2.75: For each of the four Bell states, find the reduced density operator for each qubit.
Quantum teleportation and the reduced density operator
A useful application of the reduced density operator is to the analysis of quantum telepor- tation. Recall from Section 1.3.7 that quantum teleportation is a procedure for sending
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The density operator 107
    Box 2.6: Why the partial trace?
Why is the partial trace used to describe part of a larger quantum system? The reason for doing this is because the partial trace operation is the unique operation which gives rise to the correct description of observable quantities for subsystems of a composite system, in the following sense.
Suppose M is any observable on system A, and we have some measuring device whichiscapableofrealizingmeasurementsofM.LetM ̃ denotethecorresponding observable for the same measurement, performed on the composite system AB. Our immediate goal is to argue that M ̃ is necessarily equal to M ⊗ IB . Note that if the system AB is prepared in the state |m⟩|ψ⟩, where |m⟩ is an eigenstate of M with eigenvalue m, and |ψ⟩ is any state of B, then the measuring device must yield the result m for the measurement, with probability one. Thus, if Pm is the projector onto the m eigenspace of the observable M, then the corresponding projector for M ̃ isPm⊗IB.Wethereforehave
M ̃ = 􏰸 m P m ⊗ I B = M ⊗ I B . ( 2 . 1 7 9 ) m
The next step is to show that the partial trace procedure gives the correct mea- surement statistics for observations on part of a system. Suppose we perform a measurement on system A described by the observable M. Physical consistency requires that any prescription for associating a ‘state’, ρA, to system A, must have the property that measurement averages be the same whether computed via ρA or ρAB ,
tr(M ρA ) = tr(M ̃ ρAB ) = tr((M ⊗ IB )ρAB ). (2.180)
This equation is certainly satisfied if we choose ρA ≡ trB (ρAB ). In fact, the partial trace turns out to be the unique function having this property. To see this unique- ness property, let f(·) be any map of density operators on AB to density operators on A such that
tr(M f (ρAB )) = tr((M ⊗ IB )ρAB ), (2.181)
for all observables M . Let Mi be an orthonormal basis of operators for the space of Hermitian operators with respect to the Hilbert–Schmidt inner product (X, Y ) ≡ tr(XY ) (compare Exercise 2.39 on page 76). Then expanding f(ρAB) in this basis gives
f(ρ
AB􏰸 AB
) = Mitr(Mif(ρ ))
=
(2.182)
(2.183)
i
􏰸 AB
i
Mitr((Mi ⊗ IB)ρ ).
It follows that f is uniquely determined by Equation (2.180). Moreover, the partial trace satisfies (2.180), so it is the unique function having this property.
 quantum information from Alice to Bob, given that Alice and Bob share an EPR pair, and have a classical communications channel.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

108 Introduction to quantum mechanics
 At first sight it appears as though teleportation can be used to do faster than light communication, a big no-no according to the theory of relativity. We surmised in Sec- tion 1.3.7 that what prevents faster than light communication is the need for Alice to communicate her measurement result to Bob. The reduced density operator allows us to make this rigorous.
Recall that immediately before Alice makes her measurement the quantum state of the three qubits is (Equation (1.32)):
1􏰜􏰇􏰈􏰇􏰈 |ψ2⟩=2 |00⟩ α|0⟩+β|1⟩ +|01⟩ α|1⟩+β|0⟩
􏰇 􏰈 􏰇 􏰈􏰝
+|10⟩ α|0⟩ − β|1⟩ + |11⟩ α|1⟩ − β|0⟩ . (2.192) Measuring in Alice’s computational basis, the state of the system after the measurement
 is:
􏰜􏰝1 |00⟩ α|0⟩ + β|1⟩ with probability 4
􏰜􏰝1 |01⟩ α|1⟩ + β|0⟩ with probability 4
􏰜􏰝1 |10⟩ α|0⟩ − β|1⟩ with probability 4
􏰜􏰝1 |11⟩ α|1⟩ − β|0⟩ with probability 4 .
(2.193) (2.194) (2.195) (2.196)
    The density operator of the system is thus 1􏰜∗∗∗∗
ρ = 4 |00⟩⟨00|(α|0⟩ + β|1⟩)(α ⟨0| + β ⟨1|) + |01⟩⟨01|(α|1⟩ + β|0⟩)(α ⟨1| + β ⟨0|) 􏰝
 +|10⟩⟨10|(α|0⟩−β|1⟩)(α∗⟨0|−β∗⟨1|)+|11⟩⟨11|(α|1⟩−β|0⟩)(α∗⟨1|−β∗⟨0|) . (2.197)
Tracing out Alice’s system, we see that the reduced density operator of Bob’s system is B1􏰜∗∗ ∗∗
ρ = 4 (α|0⟩+β|1⟩)(α ⟨0|+β ⟨1|)+(α|1⟩+β|0⟩)(α ⟨1|+β ⟨0|) 􏰝
+(α|0⟩ − β|1⟩)(α∗⟨0| − β∗⟨1|) + (α|1⟩ − β|0⟩)(α∗⟨1| − β∗⟨0|) = 2(|α|2 + |β|2)|0⟩⟨0| + 2(|α|2 + |β|2)|1⟩⟨1|
(2.198) (2.199) (2.200) (2.201)
  = |0⟩⟨0| + |1⟩⟨1|
= I,
4 2
  2
where we have used the completeness relation in the last line. Thus, the state of Bob’s system after Alice has performed the measurement but before Bob has learned the mea- surement result is I/2. This state has no dependence upon the state |ψ⟩ being teleported, and thus any measurements performed by Bob will contain no information about |ψ⟩, thus preventing Alice from using teleportation to transmit information to Bob faster than light.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The Schmidt decomposition and purifications 109 2.5 The Schmidt decomposition and purifications
Density operators and the partial trace are just the beginning of a wide array of tools useful for the study of composite quantum systems, which are at the heart of quan- tum computation and quantum information. Two additional tools of great value are the Schmidt decomposition and purifications. In this section we present both these tools, and try to give the flavor of their power.
Theorem 2.7: (Schmidt decomposition) Suppose |ψ⟩ is a pure state of a composite system, AB. Then there exist orthonormal states |iA⟩ for system A, and orthonormal states |iB ⟩ of system B such that
􏰸
 |ψ⟩ =
where λ are non-negative real numbers satisfying 􏰶 λ2 = 1 known as Schmidt
co-efficients.
λi|iA⟩|iB⟩, (2.202) iii
i
This result is very useful. As a taste of its power, consider the following consequence:
let |ψ⟩ be a pure state of a composite system, AB. Then by the Schmidt decomposition
ρA = 􏰶 λ2|i ⟩⟨i | and ρB = 􏰶 λ2|i ⟩⟨i |, so the eigenvalues of ρA and ρB are iiAA iiBB
identical, namely λ2i for both density operators. Many important properties of quantum
systems are completely determined by the eigenvalues of the reduced density operator of
the system, so for a pure state of a composite system such properties will be the same for
 both systems. As an example, consider the state of two qubits, (|00⟩ + |01⟩ + |11⟩)/ consequence of the Schmidt decomposition.
√
3. This has no obvious symmetry property, yet if you calculate tr􏰇(ρA)2􏰈 and tr􏰇(ρB)2􏰈 you will discover that they have the same value, 7/9 in each case. This is but one small
Proof
We give the proof for the case where systems A and B have state spaces of the same dimension, and leave the general case to Exercise 2.76. Let |j⟩ and |k⟩ be any fixed orthonormal bases for systems A and B, respectively. Then |ψ⟩ can be written
􏰸
jk
for some matrix a of complex numbers ajk . By the singular value decomposition, a = udv, where d is a diagonal matrix with non-negative elements, and u and v are unitary matrices. Thus
􏰸
ujidiivik|j⟩|k⟩. (2.204) Defining |iA⟩ ≡ 􏰶 uji|j⟩, |iB⟩ ≡ 􏰶 vik|k⟩, and λi ≡ dii, we see that this gives
|ψ⟩ = jk
|ψ⟩ =
ajk|j⟩|k⟩, (2.203)
ijk
λi|iA⟩|iB⟩. (2.205) It is easy to check that |iA⟩ forms an orthonormal set, from the unitarity of u and the
orthonormality of |j⟩, and similarly that the |iB⟩ form an orthonormal set.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
|ψ⟩ =
􏰸
i
   Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

110 Introduction to quantum mechanics
Exercise 2.76: Extend the proof of the Schmidt decomposition to the case where A
and B may have state spaces of different dimensionality.
Exercise 2.77: Suppose ABC is a three component quantum system. Show by example that there are quantum states |ψ⟩ of such systems which can not be
 written in the form
􏰸
|ψ⟩ =
where λi are real numbers, and |iA⟩,|iB⟩,|iC⟩ are orthonormal bases of the
respective systems.
The bases |iA⟩ and |iB⟩ are called the Schmidt bases for A and B, respectively, and
the number of non-zero values λi is called the Schmidt number for the state |ψ⟩. The
Schmidt number is an important property of a composite quantum system, which in
some sense quantifies the ‘amount’ of entanglement between systems A and B. To get
some idea of why this is the case, consider the following obvious but important property:
i
the Schmidt number is preserved under unitary transformations on system A or system
B alone. To see this, notice that if 􏰶 λi|iA⟩|iB⟩ is the Schmidt decomposition for |ψ⟩ 􏰶i
then i λi(U|iA⟩)|iB⟩ is the Schmidt decomposition for U|ψ⟩, where U is a unitary operator acting on system A alone. Algebraic invariance properties of this type make the Schmidt number a very useful tool.
Exercise 2.78: Prove that a state |ψ⟩ of a composite system AB is a product state if and only if it has Schmidt number 1. Prove that |ψ⟩ is a product state if and only if ρA (and thus ρB) are pure states.
A second, related technique for quantum computation and quantum information is purification. Suppose we are given a state ρA of a quantum system A. It is possible to introduce another system, which we denote R, and define a pure state |AR⟩ for the joint system AR such that ρA = trR(|AR⟩⟨AR|). That is, the pure state |AR⟩ reduces to ρA when we look at system A alone. This is a purely mathematical procedure, known as purification, which allows us to associate pure states with mixed states. For this reason we call system R a reference system: it is a fictitious system, without a direct physical significance.
To prove that purification can be done for any state, we explain how to construct
a system R and purification |AR⟩ for ρA. Suppose ρA has orthonormal decomposition
ρA = 􏰶 pi|iA⟩⟨iA|. To purify ρA we introduce a system R which has the same state i
space as system A, with orthonormal basis states |iR⟩, and define a pure state for the
combined system
|AR⟩ ≡ 􏰸 √pi|iA⟩|iR⟩. (2.207) i
λi|iA⟩|iB ⟩|iC ⟩, (2.206)
 We now calculate the reduced density operator for system A corresponding to the state |AR⟩:
(2.208) (2.209)
􏰸√AARR pipj|i ⟩⟨j |tr(|i ⟩⟨j |)
trR(|AR⟩⟨AR|) =
= 􏰸√pipj|iA⟩⟨jA|δij
 ij
 ij
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Thus |AR⟩ is a purification of ρA.
Notice the close relationship of the Schmidt decomposition to purification: the proce-
dure used to purify a mixed state of system A is to define a pure state whose Schmidt basis for system A is just the basis in which the mixed state is diagonal, with the Schmidt coefficients being the square root of the eigenvalues of the density operator being purified.
In this section we’ve explained two tools for studying composite quantum systems, the Schmidt decomposition and purifications. These tools will be indispensable to the study of quantum computation and quantum information, especially quantum information, which is the subject of Part III of this book.
Exercise 2.79: Consider a composite system consisting of two qubits. Find the Schmidt decompositions of the states
|00⟩+|11⟩ |00⟩+|01⟩+|10⟩+|11⟩ |00⟩+|01⟩+|10⟩
√2; 2 ;and√3.(2.212)
Exercise 2.80: Suppose |ψ⟩ and |φ⟩ are two pure states of a composite quantum system with components A and B, with identical Schmidt coefficients. Show that there are unitary transformations U on system A and V on system B such that |ψ⟩ = (U ⊗ V )|φ⟩.
Exercise 2.81: (Freedom in purifications) Let |AR1 ⟩ and |AR2 ⟩ be two purifications of a state ρA to a composite system AR. Prove that there exists a unitary transformation UR acting on system R such that
|AR1⟩ = (IA ⊗ UR)|AR2⟩.
Exercise 2.82: Suppose {pi, |ψi⟩} is an ensemble of states generating a density matrix ρ = 􏰶 pi|ψi⟩⟨ψi| for a quantum system A. Introduce a system R with
orthonormal basis |i⟩.
(1) Show that 􏰶 √pi|ψi⟩|i⟩ is a purification of ρ.
(2) Suppose we measure R in the basis |i⟩, obtaining outcome i. With what probability do we obtain the result i, and what is the corresponding state of system A?
(3) Let |AR⟩ be any purification of ρ to the system AR. Show that there exists an orthonormal basis |i⟩ in which R can be measured such that the corresponding post-measurement state for system A is |ψi⟩ with probability pi.
2.6 EPR and the Bell inequality
Anybody who is not shocked by quantum theory has not understood it.
– Niels Bohr
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
EPR and the Bell inequality
111
 􏰸AA = pi|i ⟩⟨i |
i = ρA.
(2.210) (2.211)
     i
 i
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

112 Introduction to quantum mechanics
 I recall that during one walk Einstein suddenly stopped, turned to me and asked whether I really believed that the moon exists only when I look at it. The rest of this walk was devoted to a discussion of what a physicist should mean by the term ‘to exist’.
– Abraham Pais
...quantum phenomena do not occur in a Hilbert space, they occur in a labora- tory.
– Asher Peres
...what is proved by impossibility proofs is lack of imagination.
– John Bell
This chapter has focused on introducing the tools and mathematics of quantum mechan- ics. As these techniques are applied in the following chapters of this book, an important recurring theme is the unusual, non-classical properties of quantum mechanics. But what exactly is the difference between quantum mechanics and the classical world? Un- derstanding this difference is vital in learning how to perform information processing tasks that are difficult or impossible with classical physics. This section concludes the chapter with a discussion of the Bell inequality, a compelling example of an essential difference between quantum and classical physics.
When we speak of an object such as a person or a book, we assume that the physical properties of that object have an existence independent of observation. That is, measure- ments merely act to reveal such physical properties. For example, a tennis ball has as one of its physical properties its position, which we typically measure using light scattered from the surface of the ball. As quantum mechanics was being developed in the 1920s and 1930s a strange point of view arose that differs markedly from the classical view. As described earlier in the chapter, according to quantum mechanics, an unobserved particle does not possess physical properties that exist independent of observation. Rather, such physical properties arise as a consequence of measurements performed upon the system. For example, according to quantum mechanics a qubit does not possess definite proper- ties of ‘spin in the z direction, σz’, and ‘spin in the x direction, σx’, each of which can be revealed by performing the appropriate measurement. Rather, quantum mechanics gives a set of rules which specify, given the state vector, the probabilities for the possible measurement outcomes when the observable σz is measured, or when the observable σx is measured.
Many physicists rejected this new view of Nature. The most prominent objector was Albert Einstein. In the famous ‘EPR paper’, co-authored with Nathan Rosen and Boris Podolsky, Einstein proposed a thought experiment which, he believed, demonstrated that quantum mechanics is not a complete theory of Nature.
The essence of the EPR argument is as follows. EPR were interested in what they termed ‘elements of reality’. Their belief was that any such element of reality must be represented in any complete physical theory. The goal of the argument was to show that quantum mechanics is not a complete physical theory, by identifying elements of reality that were not included in quantum mechanics. The way they attempted to do this was by introducing what they claimed was a sufficient condition for a physical property to
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

EPR and the Bell inequality 113 be an element of reality, namely, that it be possible to predict with certainty the value
that property will have, immediately before measurement.
    Box 2.7: Anti-correlations in the EPR experiment
Suppose we prepare the two qubit state
|01⟩ − |10⟩
a state sometimes known as the spin singlet for historical reasons. It is not difficult to show that this state is an entangled state of the two qubit system. Suppose we perform a measurement of spin along the ⃗v axis on both qubits, that is, we measure the observable ⃗v · ⃗σ (defined in Equation (2.116) on page 90) on each qubit, getting a result of +1 or −1 for each qubit. It turns out that no matter what choice of ⃗v we make, the results of the two measurements are always opposite to one another. That is, if the measurement on the first qubit yields +1, then the measurement on the second qubit will yield −1, and vice versa. It is as though the second qubit knows the result of the measurement on the first, no matter how the first qubit is measured. To see why this is true, suppose |a⟩ and |b⟩ are the eigenstates of ⃗v · ⃗σ. Then there exist complex numbers α, β, γ, δ such that
|ψ⟩ = √
2
, (2.213)
  Substituting we obtain
|0⟩ = α|a⟩ + β|b⟩ |1⟩ = γ|a⟩ + δ|b⟩.
(2.214) (2.215)
(2.216) , and thus is equal
(2.217)
|01⟩ − |10⟩ |ab⟩ − |ba⟩ √ = (αδ − βγ) √
.
􏰒α β􏰓
    22 But αδ − βγ is the determinant of the unitary matrix
γ
δ
to a phase factor eiθ for some real θ. Thus
|01⟩ − |10⟩ |ab⟩ − |ba⟩
√ = √ 22
,
    up to an unobservable global phase factor. As a result, if a measurement of ⃗v · ⃗σ is performed on both qubits, then we can see that a result of +1 (−1) on the first qubit implies a result of −1 (+1) on the second qubit.
 Consider, for example, an entangled pair of qubits belonging to Alice and Bob, re- spectively:
|01⟩ − |10⟩
√ . (2.218)
2
Suppose Alice and Bob are a long way away from one another. Alice performs a mea- surement of spin along the ⃗v axis, that is, she measures the observable ⃗v · ⃗σ (defined in Equation (2.116) on page 90). Suppose Alice receives the result +1. Then a simple quan- tum mechanical calculation, given in Box 2.7, shows that she can predict with certainty
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
  Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

114 Introduction to quantum mechanics
 that Bob will measure −1 on his qubit if he also measures spin along the ⃗v axis. Similarly, if Alice measured −1, then she can predict with certainty that Bob will measure +1 on his qubit. Because it is always possible for Alice to predict the value of the measurement result recorded when Bob’s qubit is measured in the ⃗v direction, that physical property must correspond to an element of reality, by the EPR criterion, and should be repre- sented in any complete physical theory. However, standard quantum mechanics, as we have presented it, merely tells one how to calculate the probabilities of the respective measurement outcomes if ⃗v · ⃗σ is measured. Standard quantum mechanics certainly does not include any fundamental element intended to represent the value of ⃗v · ⃗σ, for all unit vectors ⃗v.
The goal of EPR was to show that quantum mechanics is incomplete, by demonstrating that quantum mechanics lacked some essential ‘element of reality’, by their criterion. They hoped to force a return to a more classical view of the world, one in which systems could be ascribed properties which existed independently of measurements performed on those systems. Unfortunately for EPR, most physicists did not accept the above reasoning as convincing. The attempt to impose on Nature by fiat properties which she must obey seems a most peculiar way of studying her laws.
Indeed, Nature has had the last laugh on EPR. Nearly thirty years after the EPR paper was published, an experimental test was proposed that could be used to check whether or not the picture of the world which EPR were hoping to force a return to is valid or not. It turns out that Nature experimentally invalidates that point of view, while agreeing with quantum mechanics.
The key to this experimental invalidation is a result known as Bell’s inequality. Bell’s inequality is not a result about quantum mechanics, so the first thing we need to do is momentarily forget all our knowledge of quantum mechanics. To obtain Bell’s inequality, we’re going to do a thought experiment, which we will analyze using our common sense notions of how the world works – the sort of notions Einstein and his collaborators thought Nature ought to obey. After we have done the common sense analysis, we will perform a quantum mechanical analysis which we can show is not consistent with the common sense analysis. Nature can then be asked, by means of a real experiment, to decide between our common sense notions of how the world works, and quantum mechanics.
Imagine we perform the following experiment, illustrated in Figure 2.4. Charlie pre- pares two particles. It doesn’t matter how he prepares the particles, just that he is capable of repeating the experimental procedure which he uses. Once he has performed the prepa- ration, he sends one particle to Alice, and the second particle to Bob.
Once Alice receives her particle, she performs a measurement on it. Imagine that she has available two different measurement apparatuses, so she could choose to do one of two different measurements. These measurements are of physical properties which we shall label PQ and PR, respectively. Alice doesn’t know in advance which measurement she will choose to perform. Rather, when she receives the particle she flips a coin or uses some other random method to decide which measurement to perform. We suppose for simplicity that the measurements can each have one of two outcomes, +1 or −1. Suppose Alice’s particle has a value Q for the property PQ. Q is assumed to be an objective property of Alice’s particle, which is merely revealed by the measurement, much as we imagine the position of a tennis ball to be revealed by the particles of light being scattered off it. Similarly, let R denote the value revealed by a measurement of the property PR.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Similarly, suppose that Bob is capable of measuring one of two properties, PS or PT , once again revealing an objectively existing value S or T for the property, each taking value +1 or −1. Bob does not decide beforehand which property he will measure, but waits until he has received the particle and then chooses randomly. The timing of the experiment is arranged so that Alice and Bob do their measurements at the same time (or, to use the more precise language of relativity, in a causally disconnected manner). Therefore, the measurement which Alice performs cannot disturb the result of Bob’s measurement (or vice versa), since physical influences cannot propagate faster than light.
Figure 2.4. Schematic experimental setup for the Bell inequalities. Alice can choose to measure either Q or R, and Bob chooses to measure either S or T . They perform their measurements simultaneously. Alice and Bob are assumed to be far enough apart that performing a measurement on one system can not have any effect on the result of measurements on the other.
We are going to do some simple algebra with the quantity QS + RS + RT − QT . Notice that
QS+RS+RT−QT =(Q+R)S+(R−Q)T. (2.219)
Because R,Q = ±1 it follows that either (Q+R)S = 0 or (R−Q)T = 0. In either case, it is easy to see from (2.219) that QS + RS + RT − QT = ±2. Suppose next that p(q, r, s, t) is the probability that, before the measurements are performed, the system is in a state where Q = q,R = r,S = s, and T = t. These probabilities may depend on how Charlie performs his preparation, and on experimental noise. Letting E(·) denote the mean value of a quantity, we have
EPR and the Bell inequality 115
   Alice
Q = ±1 R = ±1
 Also,
􏰸
E(QS+RS+RT−QT)= p(q, r, s, t)(qs + rs + rt − qt) qrst
􏰸
≤ p(q, r, s, t) × 2 qrst
= 2.
􏰸􏰸
E(QS + RS + RT − QT ) = p(q, r, s, t)qs + p(q, r, s, t)rs qrst qrst
+ p(q,r,s,t)rt− p(q,r,s,t)qt qrst qrst
(2.220)
(2.221) (2.222)
(2.223) (2.224)
(2.225)
= E(QS) + E(RS) + E(RT) − E(QT). Comparing (2.222) and (2.224) we obtain the Bell inequality,
E(QS) + E(RS) + E(RT) − E(QT) ≤ 2.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
􏰸􏰸
Bob
S =±1 T =±1
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

116 Introduction to quantum mechanics
 This result is also often known as the CHSH inequality after the initials of its four discoverers. It is part of a larger set of inequalities known generically as Bell inequalities, since the first was found by John Bell.
By repeating the experiment many times, Alice and Bob can determine each quantity on the left hand side of the Bell inequality. For example, after finishing a set of experiments, Alice and Bob get together to analyze their data. They look at all the experiments where Alice measured PQ and Bob measured PS . By multiplying the results of their experiments together, they get a sample of values for QS. By averaging over this sample, they can estimate E(QS) to an accuracy only limited by the number of experiments which they perform. Similarly, they can estimate all the other quantities on the left hand side of the Bell inequality, and thus check to see whether it is obeyed in a real experiment.
It’s time to put some quantum mechanics back in the picture. Imagine we perform the following quantum mechanical experiment. Charlie prepares a quantum system of two qubits in the state
|01⟩ − |10⟩
−Z2 − X2
|ψ⟩ = √ ments of the following observables:
. (2.226) He passes the first qubit to Alice, and the second qubit to Bob. They perform measure-
  Q = Z1 R = X1
S = √ Z2 − X2
(2.227)
T = √
Simple calculations show that the average values for these observables, written in the
2
  2
. (2.228)
  2
1111 ⟨QS⟩= √ ; ⟨RS⟩= √ ; ⟨RT⟩= √ ; ⟨QT⟩=−√ .
2222
√
quantum mechanical ⟨·⟩ notation, are:
(2.229)
        Thus,
 2.
Hold on! We learned back in (2.225) that the average value of QS plus the average value
⟨QS⟩ + ⟨RS⟩ + ⟨RT⟩ − ⟨QT⟩ = 2
(2.230) of RS plus the average value of RT minus the average value of QT can never exceed
two. Yet here, quantum mechanics predicts that this sum of averages yields 2 2! Fortunately, we can ask Nature to resolve the apparent paradox for us. Clever experi- ments using photons – particles of light – have been done to check the prediction (2.230) of quantum mechanics versus the Bell inequality (2.225) which we were led to by our common sense reasoning. The details of the experiments are outside the scope of the book, but the results were resoundingly in favor of the quantum mechanical prediction.
The Bell inequality (2.225) is not obeyed by Nature.
What does this mean? It means that one or more of the assumptions that went into
the derivation of the Bell inequality must be incorrect. Vast tomes have been written analyzing the various forms in which this type of argument can be made, and analyzing the subtly different assumptions which must be made to reach Bell-like inequalities. Here we merely summarize the main points.
There are two assumptions made in the proof of (2.225) which are questionable:
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
√
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

(1) The assumption that the physical properties PQ , PR , PS , PT have definite values Q, R, S, T which exist independent of observation. This is sometimes known as the assumption of realism.
(2) The assumption that Alice performing her measurement does not influence the result of Bob’s measurement. This is sometimes known as the assumption of locality.
These two assumptions together are known as the assumptions of local realism. They are certainly intuitively plausible assumptions about how the world works, and they fit our everyday experience. Yet the Bell inequalities show that at least one of these assumptions is not correct.
What can we learn from Bell’s inequality? For physicists, the most important lesson is that their deeply held commonsense intuitions about how the world works are wrong. The world is not locally realistic. Most physicists take the point of view that it is the assumption of realism which needs to be dropped from our worldview in quantum me- chanics, although others have argued that the assumption of locality should be dropped instead. Regardless, Bell’s inequality together with substantial experimental evidence now points to the conclusion that either or both of locality and realism must be dropped from our view of the world if we are to develop a good intuitive understanding of quantum mechanics.
What lessons can the fields of quantum computation and quantum information learn from Bell’s inequality? Historically the most useful lesson has perhaps also been the most vague: there is something profoundly ‘up’ with entangled states like the EPR state. A lot of mileage in quantum computation and, especially, quantum information, has come from asking the simple question: ‘what would some entanglement buy me in this problem?’ As we saw in teleportation and superdense coding, and as we will see repeatedly later in the book, by throwing some entanglement into a problem we open up a new world of possibilities unimaginable with classical information. The bigger picture is that Bell’s inequality teaches us that entanglement is a fundamentally new resource in the world that goes essentially beyond classical resources; iron to the classical world’s bronze age. A major task of quantum computation and quantum information is to exploit this new resource to do information processing tasks impossible or much more difficult with classical resources.
Problem 2.1: (Functions of the Pauli matrices) Let f(·) be any function from complex numbers to complex numbers. Let ⃗n be a normalized vector in three dimensions, and let θ be real. Show that
f (θ⃗n · ⃗σ) = f(θ) + f(−θ)I + f(θ) − f(−θ)⃗n · ⃗σ. (2.231) 22
Problem 2.2: (Properties of the Schmidt number) Suppose |ψ⟩ is a pure state of a composite system with components A and B.
Chapter problems 117
   (1) Prove that the Schmidt number of |ψ⟩ is equal to the rank of the reduced density matrix ρA ≡ trB(|ψ⟩⟨ψ|). (Note that the rank of a Hermitian operator is equal to the dimension of its support.)
(2) Suppose |ψ⟩ = 􏰶 |αj ⟩|βj ⟩ is a representation for |ψ⟩, where |αj ⟩ and |βj ⟩ j
are (un-normalized) states for systems A and B, respectively. Prove that the
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

118 Introduction to quantum mechanics
 number of terms in such a decomposition is greater than or equal to the
Schmidt number of |ψ⟩, Sch(ψ).
(3) Suppose |ψ⟩ = α|φ⟩ + β|γ⟩. Prove that
Sch(ψ) ≥ |Sch(φ) − Sch(γ)| . (2.232)
Problem 2.3: (Tsirelson’s inequality) Suppose
Q=⃗q·⃗σ,R=⃗r·⃗σ,S=⃗s·⃗σ,T =⃗t·⃗σ,whereq⃗,⃗r,⃗sand⃗tarerealunitvectors in three dimensions. Show that
(Q⊗S+R⊗S+R⊗T−Q⊗T)2 =4I+[Q,R]⊗[S,T]. (2.233)
Use this result to prove that
⟨Q⊗S⟩+⟨R⊗S⟩+⟨R⊗T⟩−⟨Q⊗T⟩≤2 2, (2.234)
so the violation of the Bell inequality found in Equation (2.230) is the maximum possible in quantum mechanics.
History and further reading
There are an enormous number of books on linear algebra at levels ranging from High School through to Graduate School. Perhaps our favorites are the two volume set by Horn and Johnson[HJ85, HJ91], which cover an extensive range of topics in an accessible manner. Other useful references include Marcus and Minc[MM92], and Bhatia[Bha97]. Good introductions to linear algebra include Halmos[Hal58], Perlis[Per52], and Strang[Str76].
There are many excellent books on quantum mechanics. Unfortunately, most of these books focus on topics of tangential interest to quantum information and computa- tion. Perhaps the most relevant in the existing literature is Peres’ superb book[Per93]. Beside an extremely clear exposition of elementary quantum mechanics, Peres gives an extensive discussion of the Bell inequalities and related results. Good introductory level texts include Sakurai’s book[Sak95], Volume III of the superb series by Feynman, Leighton, and Sands[FLS65a], and the two volume work by Cohen-Tannoudji, Diu and Laloe ̈[CTDL77a, CTDL77b]. All three of these works are somewhat closer in spirit to quan- tum computation and quantum information than are most other quantum mechanics texts, although the great bulk of each is still taken up by applications far removed from quantum computation and quantum information. As a result, none of these texts need be read in detail by someone interested in learning about quantum computation and quantum information. However, any one of these texts may prove handy as a reference, especially when reading articles by physicists. References for the history of quantum mechanics may be found at the end of Chapter 1.
Many texts on quantum mechanics deal only with projective measurements. For ap- plications to quantum computing and quantum information it is more convenient – and, we believe, easier for novices – to start with the general description of measurements, of which projective measurements can be regarded as a special case. Of course, ulti- mately, as we have shown, the two approaches are equivalent. The theory of generalized measurements which we have employed was developed between the 1940s and 1970s. Much of the history can be distilled from the book of Kraus[Kra83]. Interesting discus- sion of quantum measurements may be found in Section 2.2 of Gardiner[Gar91], and in the book by Braginsky and Khahili[BK92]. The POVM measurement for distinguishing
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
√
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

non-orthogonal states described in Section 2.2.6 is due to Peres[Per88]. The extension described in Exercise 2.64 appeared in Duan and Guo[DG98].
Superdense coding was invented by Bennett and Wiesner[BW92]. An experiment im- plementing a variant of superdense coding using entangled photon pairs was performed by Mattle, Weinfurter, Kwiat, and Zeilinger[MWKZ96].
The density operator formalism was introduced independently by Landau[Lan27] and by von Neumann[von27]. The unitary freedom in the ensemble for density matrices, The- orem 2.6, was first pointed out by Schrod ̈inger[Sch36], and was later rediscovered and extended by Jaynes[Jay57] and by Hughston, Jozsa and Wootters[HJW93]. The result of Ex- ercise 2.73 is from the paper by Jaynes, and the results of Exercises 2.81 and 2.82 appear in the paper by Hughston, Jozsa and Wootters. The class of probability distributions which may appear in a density matrix decomposition for a given density matrix has been studied by Uhlmann[Uhl70] and by Nielsen[Nie99b]. Schmidt’s eponymous decomposition appeared in[Sch06]. The result of Exercise 2.77 was noted by Peres[Per95].
The EPR thought experiment is due to Einstein, Podolsky and Rosen[EPR35], and was recast in essentially the form we have given here by Bohm[Boh51]. It is sometimes misleadingly referred to as the EPR ‘paradox’. The Bell inequality is named in honour of Bell[Bel64], who first derived inequalities of this type. The form we have presented is due to Clauser, Horne, Shimony, and Holt[CHSH69], and is often known as the CHSH inequality. This inequality was derived independently by Bell, who did not publish the result.
Part 3 of Problem 2.2 is due to Thapliyal (private communication). Tsirelson’s in- equality is due to Tsirelson[Tsi80].
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
History and further reading 119
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

3 Introduction to computer science
In natural science, Nature has given us a world and we’re just to discover its laws. In computers, we can stuff laws into it and create a world.
– Alan Kay
Our field is still in its embryonic stage. It’s great that we haven’t been around for 2000 years. We are still at a stage where very, very important results occur in front of our eyes.
– Michael Rabin, on computer science
Algorithms are the key concept of computer science. An algorithm is a precise recipe for performing some task, such as the elementary algorithm for adding two numbers which we all learn as children. This chapter outlines the modern theory of algorithms developed by computer science. Our fundamental model for algorithms will be the Turing machine. This is an idealized computer, rather like a modern personal computer, but with a simpler set of basic instructions, and an idealized unbounded memory. The apparent simplicity of Turing machines is misleading; they are very powerful devices. We will see that they can be used to execute any algorithm whatsoever, even one running on an apparently much more powerful computer.
The fundamental question we are trying to address in the study of algorithms is: what resources are required to perform a given computational task? This question splits up naturally into two parts. First, we’d like to understand what computational tasks are pos- sible, preferably by giving explicit algorithms for solving specific problems. For example, we have many excellent examples of algorithms that can quickly sort a list of numbers into ascending order. The second aspect of this question is to demonstrate limitations on what computational tasks may be accomplished. For example, lower bounds can be given for the number of operations that must be performed by any algorithm which sorts a list of numbers into ascending order. Ideally, these two tasks – the finding of algorithms for solving computational problems, and proving limitations on our ability to solve computational problems – would dovetail perfectly. In practice, a significant gap often exists between the best techniques known for solving a computational problem, and the most stringent limitations known on the solution. The purpose of this chapter is to give a broad overview of the tools which have been developed to aid in the analysis of computational problems, and in the construction and analysis of algorithms to solve such problems.
Why should a person interested in quantum computation and quantum information spend time investigating classical computer science? There are three good reasons for this effort. First, classical computer science provides a vast body of concepts and techniques which may be reused to great effect in quantum computation and quantum informa- tion. Many of the triumphs of quantum computation and quantum information have come by combining existing ideas from computer science with novel ideas from quantum
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Introduction to computer science 121
 mechanics. For example, some of the fast algorithms for quantum computers are based upon the Fourier transform, a powerful tool utilized by many classical algorithms. Once it was realized that quantum computers could perform a type of Fourier transform much more quickly than classical computers this enabled the development of many important quantum algorithms.
Second, computer scientists have expended great effort understanding what resources are required to perform a given computational task on a classical computer. These results can be used as the basis for a comparison with quantum computation and quantum information. For example, much attention has been focused on the problem of finding the prime factors of a given number. On a classical computer this problem is believed to have no ‘efficient’ solution, where ‘efficient’ has a meaning we’ll explain later in the chapter. What is interesting is that an efficient solution to this problem is known for quantum computers. The lesson is that, for this task of finding prime factors, there appears to be a gap between what is possible on a classical computer and what is possible on a quantum computer. This is both intrinsically interesting, and also interesting in the broader sense that it suggests such a gap may exist for a wider class of computational problems than merely the finding of prime factors. By studying this specific problem further, it may be possible to discern features of the problem which make it more tractable on a quantum computer than on a classical computer, and then act on these insights to find interesting quantum algorithms for the solution of other problems.
Third, and most important, there is learning to think like a computer scientist. Com- puter scientists think in a rather different style than does a physicist or other natural scientist. Anybody wanting a deep understanding of quantum computation and quantum information must learn to think like a computer scientist at least some of the time; they must instinctively know what problems, what techniques, and most importantly what problems are of greatest interest to a computer scientist.
The structure of this chapter is as follows. In Section 3.1 we introduce two models for computation: the Turing machine model, and the circuit model. The Turing machine model will be used as our fundamental model for computation. In practice, however, we mostly make use of the circuit model of computation, and it is this model which is most useful in the study of quantum computation. With our models for computation in hand, the remainder of the chapter discusses resource requirements for computation. Section 3.2 begins by overviewing the computational tasks we are interested in as well as discusing some associated resource questions. It continues with a broad look at the key concepts of computational complexity, a field which examines the time and space requirements necessary to solve particular computational problems, and provides a broad classification of problems based upon their difficulty of solution. Finally, the section concludes with an examination of the energy resources required to perform computations. Surprisingly, it turns out that the energy required to perform a computation can be made vanishingly small, provided one can make the computation reversible. We explain how to construct reversible computers, and explain some of the reasons they are important both for computer science and for quantum computation and quantum information. Section 3.3 concludes the chapter with a broad look at the entire field of computer science, focusing on issues of particular relevance to quantum computation and quantum information.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

122 Introduction to computer science
3.1 Models for computation
...algorithms are concepts that have existence apart from any programming language.
– Donald Knuth
What does it mean to have an algorithm for performing some task? As children we all learn a procedure which enables us to add together any two numbers, no matter how large those numbers are. This is an example of an algorithm. Finding a mathematically precise formulation of the concept of an algorithm is the goal of this section.
Historically, the notion of an algorithm goes back centuries; undergraduates learn Euclid’s two thousand year old algorithm for finding the greatest common divisor of two positive integers. However, it wasn’t until the 1930s that the fundamental notions of the modern theory of algorithms, and thus of computation, were introduced, by Alonzo Church, Alan Turing, and other pioneers of the computer era. This work arose in response to a profound challenge laid down by the great mathematician David Hilbert in the early part of the twentieth century. Hilbert asked whether or not there existed some algorithm which could be used, in principle, to solve all the problems of mathematics. Hilbert expected that the answer to this question, sometimes known as the entscheidungsproblem, would be yes.
Amazingly, the answer to Hilbert’s challenge turned out to be no: there is no algorithm to solve all mathematical problems. To prove this, Church and Turing had to solve the deep problem of capturing in a mathematical definition what we mean when we use the intuitive concept of an algorithm. In so doing, they laid the foundations for the modern theory of algorithms, and consequently for the modern theory of computer science.
In this chapter, we use two ostensibly different approaches to the theory of computa- tion. The first approach is that proposed by Turing. Turing defined a class of machines, now known as Turing machines, in order to capture the notion of an algorithm to perform a computational task. In Section 3.1.1, we describe Turing machines, and then discuss some of the simpler variants of the Turing machine model. The second approach is via the circuit model of computation, an approach that is especially useful as preparation for our later study of quantum computers. The circuit model is described in Section 3.1.2. Although these models of computation appear different on the surface, it turns out that they are equivalent. Why introduce more than one model of computation, you may ask? We do so because different models of computation may yield different insights into the solution of specific problems. Two (or more) ways of thinking about a concept are better than one.
3.1.1 Turing machines
The basic elements of a Turing machine are illustrated in Figure 3.1. A Turing machine contains four main elements: (a) a program, rather like an ordinary computer; (b) a finite state control, which acts like a stripped-down microprocessor, co-ordinating the other operations of the machine; (c) a tape, which acts like a computer memory; and (d) a read- write tape-head, which points to the position on the tape which is currently readable or writable. We now describe each of these four elements in more detail.
The finite state control for a Turing machine consists of a finite set of internal states,
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Models for computation 123
  Program
   Finite State Control
  Read/Write Head
01110100110
Tape
     Figure 3.1. Main elements of a Turing machine. In the text, blanks on the tape are denoted by a ‘b’. Note the  marking the left hand end of the tape.
q1, . . . , qm. The number m is allowed to be varied; it turns out that for m sufficiently large this does not affect the power of the machine in any essential way, so without loss of generality we may suppose that m is some fixed constant. The best way to think of the finite state control is as a sort of microprocessor, co-ordinating the Turing machine’s operation. It provides temporary storage off-tape, and a central place where all processing for the machine may be done. In addition to the states q1 , . . . , qm , there are also two special internal states, labelled qs and qh. We call these the starting state and the halting state, respectively. The idea is that at the beginning of the computation, the Turing machine is in the starting state qs. The execution of the computation causes the Turing machine’s internal state to change. If the computation ever finishes, the Turing machine ends up in the state qh to indicate that the machine has completed its operation.
The Turing machine tape is a one-dimensional object, which stretches off to infinity in one direction. The tape consists of an infinite sequence of tape squares. We number the tape squares 0,1,2,3,.... The tape squares each contain one symbol drawn from some alphabet, Γ, which contains a finite number of distinct symbols. For now, it will be convenient to assume that the alphabet contains four symbols, which we denote by 0, 1, b (the ‘blank’ symbol), and ◃, to mark the left hand edge of the tape. Initially, the tape contains a ◃ at the left hand end, a finite number of 0s and 1s, and the rest of the tape contains blanks. The read-write tape-head identifies a single square on the Turing machine tape as the square that is currently being accessed by the machine.
Summarizing, the machine starts its operation with the finite state control in the state qs, and with the read-write head at the leftmost tape square, the square numbered 0. The computation then proceeds in a step by step manner according to the program, to be defined below. If the current state is qh, then the computation has halted, and the output of the computation is the current (non-blank) contents of the tape.
A program for a Turing machine is a finite ordered list of program lines of the form ⟨q, x, q′, x′, s⟩. The first item in the program line, q, is a state from the set of internal states of the machine. The second item, x, is taken from the alphabet of symbols which may appear on the tape, Γ. The way the program works is that on each machine cycle, the Turing machine looks through the list of program lines in order, searching for a line ⟨q, x, ·, ·, ·⟩, such that the current internal state of the machine is q, and the symbol
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

124 Introduction to computer science
 being read on the tape is x. If it doesn’t find such a program line, the internal state of the machine is changed to qh, and the machine halts operation. If such a line is found, then that program line is executed. Execution of a program line involves the following steps: the internal state of the machine is changed to q′; the symbol x on the tape is overwritten by the symbol x′, and the tape-head moves left, right, or stands still, depending on whether s is −1, +1, or 0, respectively. The only exception to this rule is if the tape-head is at the leftmost tape square, and s = −1, in which case the tape-head stays put.
Now that we know what a Turing machine is, let’s see how it may be used to compute a simple function. Consider the following example of a Turing machine. The machine starts with a binary number, x, on the tape, followed by blanks. The machine has three internal states, q1, q2, and q3, in addition to the starting state qs and halting state qh. The program contains the following program lines (the numbers on the left hand side are for convenience in referring to the program lines in later discussion, and do not form part of the program):
1 : ⟨qs,◃,q1,◃,+1⟩ 2 : ⟨q1,0,q1,b,+1⟩ 3 : ⟨q1,1,q1,b,+1⟩ 4 : ⟨q1,b,q2,b,−1⟩ 5 : ⟨q2,b,q2,b,−1⟩ 6 : ⟨q2,◃,q3,◃,+1⟩ 7 : ⟨q3,b,qh,1,0⟩.
What function does this program compute? Initially the machine is in the state qs and at the left-most tape position so line 1, ⟨qs , ◃, q1 , ◃, +1⟩, is executed, which causes the tape-head to move right without changing what is written on the tape, but changing the internal state of the machine to q1. The next three lines of the program ensure that while the machine is in the state q1 the tape-head will continue moving right while it reads either 0s (line 2) or 1s (line 3) on the tape, over-writing the tape contents with blanks as it goes and remaining in the state q1, until it reaches a tape square that is already blank, at which point the tape-head is moved one position to the left, and the internal state is changed to q2 (line 4). Line 5 then ensures that the tape-head keeps moving left while blanks are being read by the tape-head, without changing the contents of the tape. This keeps up until the tape-head returns to its starting point, at which point it reads a ◃ on the tape, changes the internal state to q3, and moves one step to the right (line 6). Line 7 completes the program, simply printing the number 1 onto the tape, and then halting.
The preceding analysis shows that this program computes the constant function f (x) = 1. That is, regardless of what number is input on the tape the number 1 is output. More generally, a Turing machine can be thought of as computing functions from the non- negative integers to the non-negative integers; the initial state of the tape is used to represent the input to the function, and the final state of the tape is used to represent the output of the function.
It seems as though we have gone to a very great deal of trouble to compute this simple function using our Turing machines. Is it possible to build up more complicated functions using Turing machines? For example, could we construct a machine such that when two numbers, x and y, are input on the tape with a blank to demarcate them, it will
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Models for computation 125
 output the sum x + y on the tape? More generally, what class of functions is it possible to compute using a Turing machine?
It turns out that the Turing machine model of computation can be used to compute an enormous variety of functions. For example, it can be used to do all the basic arithmetical operations, to search through text represented as strings of bits on the tape, and many other interesting operations. Surprisingly, it turns out that a Turing machine can be used to simulate all the operations performed on a modern computer! Indeed, according to a thesis put forward independently by Church and by Turing, the Turing machine model of computation completely captures the notion of computing a function using an algorithm. This is known as the Church–Turing thesis:
The class of functions computable by a Turing machine corresponds exactly to the class of functions which we would naturally regard as being computable by an algorithm.
The Church–Turing thesis asserts an equivalence between a rigorous mathematical concept – function computable by a Turing machine – and the intuitive concept of what it means for a function to be computable by an algorithm. The thesis derives its importance from the fact that it makes the study of real-world algorithms, prior to 1936 a rather vague concept, amenable to rigorous mathematical study. To understand the significance of this point it may be helpful to consider the definition of a continuous function from real analysis. Every child can tell you what it means for a line to be continuous on a piece of paper, but it is far from obvious how to capture that intuition in a rigorous definition. Mathematicians in the nineteenth century spent a great deal of time arguing about the merits of various definitions of continuity before the modern definition of continuity came to be accepted. When making fundamental definitions like that of continuity or of computability it is important that good definitions be chosen, ensuring that one’s intuitive notions closely match the precise mathematical definition. From this point of view the Church–Turing thesis is simply the assertion that the Turing machine model of computation provides a good foundation for computer science, capturing the intuitive notion of an algorithm in a rigorous definition.
A priori it is not obvious that every function which we would intuitively regard as computable by an algorithm can be computed using a Turing machine. Church, Tur- ing and many other people have spent a great deal of time gathering evidence for the Church–Turing thesis, and in sixty years no evidence to the contrary has been found. Nevertheless, it is possible that in the future we will discover in Nature a process which computes a function not computable on a Turing machine. It would be wonderful if that ever happened, because we could then harness that process to help us perform new computations which could not be performed before. Of course, we would also need to overhaul the definition of computability, and with it, computer science.
Exercise 3.1: (Non-computable processes in Nature) How might we recognize that a process in Nature computes a function not computable by a Turing machine?
Exercise 3.2: (Turing numbers) Show that single-tape Turing machines can each be given a number from the list 1,2,3,... in such a way that the number uniquely specifies the corresponding machine. We call this number the Turing number of the corresponding Turing machine. (Hint: Every positive integer has
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

126 Introduction to computer science
a unique prime factorization pa1 pa2 . . . pak , where p are distinct prime numbers,
 12ki anda1,...,ak arenon-negativeintegers.)
In later chapters, we will see that quantum computers also obey the Church–Turing thesis. That is, quantum computers can compute the same class of functions as is com- putable by a Turing machine. The difference between quantum computers and Turing machines turns out to lie in the efficiency with which the computation of the function may be performed – there are functions which can be computed much more efficiently on a quantum computer than is believed to be possible with a classical computing device such as a Turing machine.
Demonstrating in complete detail that the Turing machine model of computation can be used to build up all the usual concepts used in computer programming languages is beyond the scope of this book (see ‘History and further reading’ at the end of the chapter for more information). When specifying algorithms, instead of explicitly specifying the Turing machine used to compute the algorithm, we shall usually use a much higher level pseudocode, trusting in the Church–Turing thesis that this pseudocode can be translated into the Turing machine model of computation. We won’t give any sort of rigorous definition for pseudocode. Think of it as a slightly more formal version of English or, if you like, a sloppy version of a high-level programming language such as C++ or BASIC. Pseudocode provides a convenient way of expressing algorithms, without going into the extreme level of detail required by a Turing machine. An example use of pseudocode may be found in Box 3.2 on page 130; it is also used later in the book to describe quantum algorithms.
There are many variants on the basic Turing machine model. We might imagine Turing machines with different kinds of tapes. For example, one could consider two-way infinite tapes, or perhaps computation with tapes of more than one dimension. So far as is presently known, it is not possible to change any aspect of the Turing model in a way that is physically reasonable, and which manages to extend the class of functions computable by the model.
As an example consider a Turing machine equipped with multiple tapes. For simplicity we consider the two-tape case, as the generalization to more than two tapes is clear from this example. Like the basic Turing machine, a two-tape Turing machine has a finite number of internal states q1, . . . , qm, a start state qs, and a halt state qh. It has two tapes, each of which contain symbols from some finite alphabet of symbols, Γ. As before we find it convenient to assume that the alphabet contains four symbols, 0, 1, b and ◃, where ◃ marks the left hand edge of each tape. The machine has two tape-heads, one for each tape. The main difference between the two-tape Turing machine and the basic Turing machine is in the program. Program lines are of the form ⟨q,x1,x2,q′,x′1,x′2,s1,s2⟩, meaning that if the internal state of the machine is q, tape one is reading x1 at its current position, and tape two is reading x2 at its current position, then the internal state of the machine should be changed to q′, x1 overwritten with x′1, x2 overwritten with x′2, and the tape-heads for tape one and tape two moved according to whether s1 or s2 are equal to +1, −1 or 0, respectively.
In what sense are the basic Turing machine and the two-tape Turing machine equiv- alent models of computation? They are equivalent in the sense that each computational model is able to simulate the other. Suppose we have a two-tape Turing machine which takes as input a bit string x on the first tape and blanks on the remainder of both tapes,
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Models for computation 127
 except the endpoint marker ◃. This machine computes a function f(x), where f(x) is defined to be the contents of the first tape after the Turing machine has halted. Rather remarkably, it turns out that given a two-tape Turing machine to compute f, there exists an equivalent single-tape Turing machine that is also able to compute f. We won’t ex- plain how to do this explicitly, but the basic idea is that the single-tape Turing machine simulates the two-tape Turing machine, using its single tape to store the contents of both tapes of the two-tape Turing machine. There is some computational overhead required to do this simulation, but the important point is that in principle it can always be done. In fact, there exists a Universal Turing machine (see Box 3.1) which can simulate any other Turing machine!
Another interesting variant of the Turing machine model is to introduce randomness into the model. For example, imagine that the Turing machine can execute a program line whose effect is the following: if the internal state is q and the tape-head reads x, then flip an unbiased coin. If the coin lands heads, change the internal state to qiH , and if it lands tails, change the internal state to qiT , where qiH and qiT are two internal states of the Turing machine. Such a program line can be represented as ⟨q, x, qiH , qiT ⟩. However, even this variant doesn’t change the essential power of the Turing machine model of computation. It is not difficult to see that we can simulate the effect of the above algorithm on a deterministic Turing machine by explicitly ‘searching out’ all the possible computational paths corresponding to different values of the coin tosses. Of course, this deterministic simulation may be far less efficient than the random model, but the key point for the present discussion is that the class of functions computable is not changed by introducing randomness into the underlying model.
Exercise 3.3: (Turing machine to reverse a bit string) Describe a Turing machine which takes a binary number x as input, and outputs the bits of x in reverse order. (Hint: In this exercise and the next it may help to use a multi-tape Turing machine and/or symbols other than ◃, 0, 1 and the blank.)
Exercise 3.4: (Turing machine to add modulo 2) Describe a Turing machine to add two binary numbers x and y modulo 2. The numbers are input on the Turing machine tape in binary, in the form x, followed by a single blank, followed by a y. If one number is not as long as the other then you may assume that it has been padded with leading 0s to make the two numbers the same length.
Let us return to Hilbert’s entscheidungsproblem, the original inspiration for the founders of computer science. Is there an algorithm to decide all the problems of math- ematics? The answer to this question was shown by Church and Turing to be no. In Box 3.2, we explain Turing’s proof of this remarkable fact. This phenomenon of unde- cidability is now known to extend far beyond the examples which Church and Turing constructed. For example, it is known that the problem of deciding whether two topo- logical spaces are topologically equivalent (‘homeomorphic’) is undecidable. There are simple problems related to the behavior of dynamical systems which are undecidable, as you will show in Problem 3.4. References for these and other examples are given in the end of chapter ‘History and further reading’.
Besides its intrinsic interest, undecidability foreshadows a topic of great concern in computer science, and also to quantum computation and quantum information: the dis-
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

128 Introduction to computer science
    Box 3.1: The Universal Turing Machine
We’ve described Turing machines as containing three elements which may vary from machine to machine – the initial configuration of the tape, the internal states of the finite state control, and the program for the machine. A clever idea known as the Universal Turing Machine (UTM) allows us to fix the program and finite state control once and for all, leaving the initial contents of the tape as the only part of the machine which needs to be varied.
The Universal Turing Machine (see the figure below) has the following property. Let M be any Turing machine, and let TM be the Turing number associated to machineM.ThenoninputofthebinaryrepresentationforTM followedbyablank, followed by any string of symbols x on the remainder of the tape, the Universal Turing Machine gives as output whatever machine M would have on input of x. Thus, the Universal Turing Machine is capable of simulating any other Turing machine!
UTM Compute UTM
TM b x M(x)
The Universal Turing Machine is similar in spirit to a modern programmable computer, in which the action to be taken by the computer – the ‘program’ – is stored in memory, analogous to the bit string TM stored at the beginning of the tape by the Universal Turing Machine. The data to be processed by the program is stored in a separate part of memory, analogous to the role of x in the Universal Turing Machine. Then some fixed hardware is used to run the program, producing the output. This fixed hardware is analogous to the internal states and the (fixed) program being executed by the Universal Turing Machine.
Describing the detailed construction of a Universal Turing Machine is beyond the scope of this book. (Though industrious readers may like to attempt the construc- tion.) The key point is the existence of such a machine, showing that a single fixed machine can be used to run any algorithm whatsoever. The existence of a Univer- sal Turing Machine also explains our earlier statement that the number of internal states in a Turing machine does not matter much, for provided that number m exceeds the number needed for a Universal Turing Machine, such a machine can be used to simulate a Turing machine with any number of internal states.
           tinction between problems which are easy to solve, and problems which are hard to solve. Undecidability provides the ultimate example of problems which are hard to solve – so hard that they are in fact impossible to solve.
Exercise 3.5: (Halting problem with no inputs) Show that given a Turing
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Models for computation 129 machine M there is no algorithm to determine whether M halts when the input
to the machine is a blank tape.
Exercise 3.6: (Probabilistic halting problem) Suppose we number the probabilistic Turing machines using a scheme similar to that found in Exercise 3.2 and define the probabilistic halting function hp(x) to be 1 if machine x halts on input of x with probability at least 1/2 and 0 if machine x halts on input of x with probability less than 1/2. Show that there is no probabilistic Turing machine which can output hp(x) with probability of correctness strictly greater than 1/2 for all x.
Exercise 3.7: (Halting oracle) Suppose a black box is made available to us which takes a non-negative integer x as input, and then outputs the value of h(x), where h(·) is the halting function defined in Box 3.2 on page 130. This type of black box is sometimes known as an oracle for the halting problem. Suppose we have a regular Turing machine which is augmented by the power to call the oracle. One way of accomplishing this is to use a two-tape Turing machine, and add an extra program instruction to the Turing machine which results in the oracle being called, and the value of h(x) being printed on the second tape, where x is the current contents of the second tape. It is clear that this model for computation is more powerful than the conventional Turing machine model, since it can be used to compute the halting function. Is the halting problem for this model of computation undecidable? That is, can a Turing machine aided by an oracle for the halting problem decide whether a program for the Turing machine with oracle will halt on a particular input?
3.1.2 Circuits
Turing machines are rather idealized models of computing devices. Real computers are finite in size, whereas for Turing machines we assumed a computer of unbounded size. In this section we investigate an alternative model of computation, the circuit model, that is equivalent to the Turing machine in terms of computational power, but is more conve- nient and realistic for many applications. In particular the circuit model of computation is especially important as preparation for our investigation of quantum computers.
A circuit is made up of wires and gates, which carry information around, and perform simple computational tasks, respectively. For example, Figure 3.2 shows a simple circuit which takes as input a single bit, a. This bit is passed through a       gate, which flips the bit, taking 1 to 0 and 0 to 1. The wires before and after the       gate serve merely to carry the bit to and from the       gate; they can represent movement of the bit through space, or perhaps just through time.
More generally, a circuit may involve many input and output bits, many wires, and many logical gates. A logic gate is a function f : {0,1}k → {0,1}l from some fixed number k of input bits to some fixed number l of output bits. For example, the       gate is a gate with one input bit and one output bit which computes the function f(a) = 1⊕a, where a is a single bit, and ⊕ is modulo 2 addition. It is also usual to make the convention that no loops are allowed in the circuit, to avoid possible instabilities, as illustrated in Figure 3.3. We say such a circuit is acyclic, and we adhere to the convention that circuits in the circuit model of computation be acyclic.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

130 Introduction to computer science
    Box 3.2: The halting problem
In Exercise 3.2 you showed that each Turing machine can be uniquely associated with a number from the list 1, 2, 3, . . .. To solve Hilbert’s problem, Turing used this numbering to pose the halting problem: does the machine with Turing number x halt upon input of the number y? This is a well posed and interesting mathematical problem. After all, it is a matter of some considerable interest to us whether our algorithms halt or not. Yet it turns out that there is no algorithm which is capable of solving the halting problem. To see this, Turing asked whether there is an algorithm to solve an even more specialized problem: does the machine with Turing number x halt upon input of the same number x? Turing defined the halting function,
􏰵 0 if machine number x does not halt upon input of x h(x) ≡ 1 if machine number x halts upon input of x.
If there is an algorithm to solve the halting problem, then there surely is an al- gorithm to evaluate h(x). We will try to reach a contradiction by supposing such an algorithm exists, denoted by HALT(x). Consider an algorithm computing the function TURING(x), with pseudocode
TURING(x)
y = HALT(x) if y = 0 then
halt else
loop forever
end if
Since HALT is a valid program, TURING must also be a valid program, with some Turing number, t. By definition of the halting function, h(t) = 1 if and only if TURING halts on input of t. But by inspection of the program for TURING, we see that TURING halts on input of t if and only if h(t) = 0. Thus h(t) = 1 if and only if h(t) = 0, a contradiction. Therefore, our initial assumption that there is an algorithm to evaluate h(x) must have been wrong. We conclude that there is no algorithm allowing us to solve the halting problem.
  aa
Figure 3.2. Elementary circuit performing a single gate on a single input bit.
There are many other elementary logic gates which are useful for computation. A partial list includes the       gate, the     gate, the       gate, the         gate, and the gate. Each of these gates takes two bits as input, and produces a single bit as output. The gate outputs 1 if and only if both of its inputs are 1. The     gate outputs 1 if
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
         Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

 Figure 3.3. Circuits containing cycles can be unstable, and are not usually permitted in the circuit model of computation.
and only if at least one of its inputs is 1. The       gate outputs the sum, modulo 2, of its inputs. The         and       gates take the       and     , respectively, of their inputs, and then apply a       to whatever is output. The action of these gates is illustrated in Figure 3.4.
a NOTa ab aANDb (a) (b)
ab aORb ab aXORb
Models for computation 131
     (c) (e) ab
(d)
  aNANDb=
(f) ab
Figure 3.4. Elementary circuits performing the       ,     ,       ,         , and       gates.
There are two important ‘gates’ missing from Figure 3.4, namely the             gate and the                   gate. In circuits we often allow bits to ‘divide’, replacing a bit with two copies of itself, an operation referred to as             . We also allow bits to                   , that is, the value of two bits are interchanged. A third operation missing from Figure 3.4, not really a logic gate at all, is to allow the preparation of extra ancilla or work bits, to allow extra working space during the computation.
These simple circuit elements can be put together to perform an enormous variety of computations. Below we’ll show that these elements can be used to compute any function whatsoever. In the meantime, let’s look at a simple example of a circuit which adds two n bit integers, using essentially the same algorithm taught to school-children around the
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
  aNORb
=
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

132 Introduction to computer science
 world. The basic element in this circuit is a smaller circuit known as a half-adder, shown in Figure 3.5. A half-adder takes two bits, x and y, as input, and outputs the sum of the bits x ⊕ y modulo 2, together with a carry bit set to 1 if x and y are both 1, or 0 otherwise.
x
y
c xÅy
    Figure 3.5. Half-adder circuit. The carry bit c is set to 1 when x and y are both 1, otherwise it is 0.
Two cascaded half-adders may be used to build a full-adder, as shown in Figure 3.6. A full-adder takes as input three bits, x, y, and c. The bits x and y should be thought of as data to be added, while c is a carry bit from an earlier computation. The circuit outputs two bits. One output bit is the modulo 2 sum, x ⊕ y ⊕ c of all three input bits. The second output bit, c′, is a carry bit, which is set to 1 if two or more of the inputs is 1, and is 0 otherwise.
x y c
c' xÅyÅc
    HA
   HA
   Figure 3.6. Full-adder circuit.
By cascading many of these full-adders together we obtain a circuit to add two n-bit
integers, as illustrated in Figure 3.7 for the case n = 3. x2
y2 x1 y1 x0 y0
Figure 3.7. Addition circuit for two three-bit integers, x = x2x1x0 and y = y2y1y0, using the elementary algorithm taught to school-children.
We claimed earlier that just a few fixed gates can be used to compute any function f : {0, 1}n → {0, 1}m whatsoever. We will now prove this for the simplified case of a function f : {0, 1}n → {0, 1} with n input bits and a single output bit. Such a function
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
   FA
      FA
     HA
  Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Models for computation 133
 is known as a Boolean function, and the corresponding circuit is a Boolean circuit. The general universality proof follows immediately from the special case of Boolean functions. The proof is by induction on n. For n = 1 there are four possible functions: the identity, which has a circuit consisting of a single wire; the bit flip, which is implemented using a single       gate; the function which replaces the input bit with a 0, which can be obtained by       ing the input with a work bit initially in the 0 state; and the function which replaces the input with a 1, which can be obtained by     ing the input with a work bit initially in the 1 state.
To complete the induction, suppose that any function on n bits may be computed by a circuit, and let f be a function on n + 1 bits. Define n-bit functions f0 and f1 by f0(x1,...,xn) ≡ f(0,x1,...,xn) and f1(x1,...,xn) ≡ f(1,x1,...,xn). These are both n-bit functions, so by the inductive hypothesis there are circuits to compute these functions.
It is now an easy matter to design a circuit which computes f. The circuit computes both f0 and f1 on the last n bits of the input. Then, depending on whether the first bit of the input was a 0 or a 1 it outputs the appropriate answer. A circuit to do this is shown in Figure 3.8. This completes the induction.
      NOT
        . . .
. . .
              AND
AND
XOR
             . . .
               Figure 3.8. Circuit to compute an arbitrary function f on n + 1 bits, assuming by induction that there are circuits to compute the n-bit functions f0 and f1.
Five elements may be identified in the universal circuit construction: (1) wires, which preserve the states of the bits; (2) ancilla bits prepared in standard states, used in the n = 1 case of the proof; (3) the             operation, which takes a single bit as input and outputs two copies of that bit; (4) the                   operation, which interchanges the value of two bits; and (5) the       ,       , and       gates. In Chapter 4 we’ll define the quantum circuit model of computation in a manner analogous to classical circuits. It is interesting to note that many of these five elements pose some interesting challenges when extending to the quantum case: it is not necessarily obvious that good quantum wires for the preservation of qubits can be constructed, even in principle, the
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
      Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

134 Introduction to computer science
 operation cannot be performed in a straightforward manner in quantum mechanics, due to the no-cloning theorem (as explained in Section 1.3.5), and the       and       gates are not invertible, and thus can’t be implemented in a straightforward manner as unitary quantum gates. There is certainly plenty to think about in defining a quantum circuit model of computation!
Exercise 3.8: (Universality of         ) Show that the         gate can be used to simulate the       ,       and       gates, provided wires, ancilla bits and
are available.
Let’s return from our brief quantum digression, to the properties of classical circuits. We claimed earlier that the Turing machine model is equivalent to the circuit model of computation. In what sense do we mean the two models are equivalent? On the face of it, the two models appear quite different. The unbounded nature of a Turing machine makes them more useful for abstractly specifying what it is we mean by an algorithm, while circuits more closely capture what an actual physical computer does.
The two models are connected by introducing the notion of a uniform circuit family. A circuit family consists of a collection of circuits, {Cn}, indexed by a positive integer n. The circuit Cn has n input bits, and may have any finite number of extra work bits, and output bits. The output of the circuit Cn, upon input of a number x of at most n bits in length, is denoted by Cn(x). We require that the circuits be consistent, that is, if m &lt; n and x is at most m bits in length, then Cm(x) = Cn(x). The function computed by the circuit family {Cn} is the function C(·) such that if x is n bits in length then C(x) = Cn(x). For example, consider a circuit Cn that squares an n-bit number. This defines a family of circuits {Cn} that computes the function, C(x) = x2, where x is any positive integer.
It’s not enough to consider unrestricted families of circuits, however. In practice, we need an algorithm to build the circuit. Indeed, if we don’t place any restrictions on the circuit family then it becomes possible to compute all sorts of functions which we do not expect to be able to compute in a reasonable model of computation. For example, let hn(x) denote the halting function, restricted to values of x which are n bits in length. Thus hn is a function from n bits to 1 bit, and we have proved there exists a circuit Cn to compute hn(·). Therefore the circuit family {Cn} computes the halting function! However, what prevents us from using this circuit family to solve the halting problem is that we haven’t specified an algorithm which will allow us to build the circuit Cn for all values of n. Adding this requirement results in the notion of a uniform circuit family.
That is, a family of circuits {Cn} is said to be a uniform circuit family if there is some algorithm running on a Turing machine which, upon input of n, generates a description of Cn. That is, the algorithm outputs a description of what gates are in the circuit Cn, how those gates are connected together to form a circuit, any ancilla bits needed by the circuit,             and                   operations, and where the output from the circuit should be read out. For example, the family of circuits we described earlier for squaring n-bit numbers is certainly a uniform circuit family, since there is an algorithm which, given n, outputs a description of the circuit needed to square an n-bit number. You can think of this algorithm as the means by which an engineer is able to generate a description of (and thus build) the circuit for any n whatsoever. By contrast, a circuit family that is not uniform is said to be a non-uniform circuit family. There is no algorithm to construct
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
      Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The analysis of computational problems 135
 the circuit for arbitrary n, which prevents our engineer from building circuits to compute functions like the halting function.
Intuitively, a uniform circuit family is a family of circuits that can be generated by some reasonable algorithm. It can be shown that the class of functions computable by uniform circuit families is exactly the same as the class of functions which can be computed on a Turing machine. With this uniformity restriction, results in the Turing machine model of computation can usually be given a straightforward translation into the circuit model of computation, and vice versa. Later we give similar attention to issues of uniformity in the quantum circuit model of computation.
3.2 The analysis of computational problems
The analysis of computational problems depends upon the answer to three fundamental questions:
(1) What is a computational problem? Multiplying two numbers together is a computational problem; so is programming a computer to exceed human abilities in the writing of poetry. In order to make progress developing a general theory for the analysis of computational problems we are going to isolate a special class of problems known as decision problems, and concentrate our analysis on those. Restricting ourselves in this way enables the development of a theory which is both elegant and rich in structure. Most important, it is a theory whose principles have application far beyond decision problems.
(2) How may we design algorithms to solve a given computational problem? Once a problem has been specified, what algorithms can be used to solve the problem? Are there general techniques which can be used to solve wide classes of problems? How can we be sure an algorithm behaves as claimed?
(3) What are the minimal resources required to solve a given computational problem? Running an algorithm requires the consumption of resources, such as time, space, and energy. In different situations it may be desirable to minimize consumption of one or more resource. Can we classify problems according to the resource requirements needed to solve them?
In the next few sections we investigate these three questions, especially questions 1 and 3. Although question 1, ‘what is a computational problem?’, is perhaps the most fundamental of the questions, we shall defer answering it until Section 3.2.3, pausing first to establish some background notions related to resource quantification in Section 3.2.1, and then reviewing the key ideas of computational complexity in Section 3.2.2.
Question 2, how to design good algorithms, is the subject of an enormous amount of ingenious work by many researchers. So much so that in this brief introduction we cannot even begin to describe the main ideas employed in the design of good algorithms. If you are interested in this beautiful subject, we refer you to the end of chapter ‘History and further reading’. Our closest direct contact with this subject will occur later in the book, when we study quantum algorithms. The techniques involved in the creation of quantum algorithms have typically involved a blend of deep existing ideas in algorithm design for classical computers, and the creation of new, wholly quantum mechanical techniques for algorithm design. For this reason, and because the spirit of quantum algorithm design
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

136 Introduction to computer science
 is so similar in many ways to classical algorithm design, we encourage you to become familiar with at least the basic ideas of algorithm design.
Question 3, what are the minimal resources required to solve a given computational problem, is the main focus of the next few sections. For example, suppose we are given two numbers, each n bits in length, which we wish to multiply. If the multiplication is performed on a single-tape Turing machine, how many computational steps must be executed by the Turing machine in order to complete the task? How much space is used on the Turing machine while completing the task?
These are examples of the type of resource questions we may ask. Generally speak- ing, computers make use of many different kinds of resources, however we will focus most of our attention on time, space, and energy. Traditionally in computer science, time and space have been the two major resource concerns in the study of algorithms, and we study these issues in Sections 3.2.2 through 3.2.4. Energy has been a less impor- tant consideration; however, the study of energy requirements motivates the subject of reversible classical computation, which in turn is a prerequisite for quantum computa- tion, so we examine energy requirements for computation in some considerable detail in Section 3.2.5.
3.2.1 How to quantify computational resources
Different models of computation lead to different resource requirements for computa- tion. Even something as simple as changing from a single-tape to a two-tape Turing machine may change the resources required to solve a given computational problem. For a computational task which is extremely well understood, like addition of integers, for example, such differences between computational models may be of interest. However, for a first pass at understanding a problem, we would like a way of quantifying resource requirements that is independent of relatively trivial changes in the computational model. One of the tools which has been developed to do this is the asymptotic notation, which can be used to summarize the essential behavior of a function. This asymptotic notation can be used, for example, to summarize the essence of how many time steps it takes a given algorithm to run, without worrying too much about the exact time count. In this section we describe this notation in detail, and apply it to a simple problem illustrating the quantification of computational resources – the analysis of algorithms for sorting a list of names into alphabetical order.
Suppose, for example, that we are interested in the number of gates necessary to add together two n-bit numbers. Exact counts of the number of gates required obscure the big picture: perhaps a specific algorithm requires 24n + 2⌈log n⌉ + 16 gates to perform this task. However, in the limit of large problem size the only term which matters is the 24n term. Furthermore, we disregard constant factors as being of secondary importance to the analysis of the algorithm. The essential behavior of the algorithm is summed up by saying that the number of operations required scales like n, where n is the number of bits in the numbers being added. The asymptotic notation consists of three tools which make this notion precise.
The O (‘big O’) notation is used to set upper bounds on the behavior of a function. Suppose f(n) and g(n) are two functions on the non-negative integers. We say ‘f(n) is in the class of functions O(g(n))’, or just ‘f(n) is O(g(n))’, if there are constants c and n0 such that for all values of n greater than n0, f(n) ≤ cg(n). That is, for sufficiently large n, the function g(n) is an upper bound on f(n), up to an unimportant constant
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

factor. The big O notation is particularly useful for studying the worst-case behavior of specific algorithms, where we are often satisfied with an upper bound on the resources consumed by an algorithm.
When studying the behaviors of a class of algorithms – say the entire class of algorithms which can be used to multiply two numbers – it is interesting to set lower bounds on the resources required. For this the Ω (‘big Omega’) notation is used. A function f(n) is said to be Ω(g(n)) if there exist constants c and n0 such that for all n greater than n0, cg(n) ≤ f(n). That is, for sufficiently large n, g(n) is a lower bound on f(n), up to an unimportant constant factor.
Finally, the Θ (‘big Theta’) notation is used to indicate that f(n) behaves the same as g(n) asymptotically, up to unimportant constant factors. That is, we say f(n) is Θ(g(n)) if it is both O(g(n)) and Ω(g(n)).
Asymptotic notation: examples
Let’s consider a few simple examples of the asymptotic notation. The function 2n is in the class O(n2), since 2n ≤ 2n2 for all positive n. The function 2n is Ω(n3), since n3 ≤ 2n for sufficiently large n. Finally, the function 7n2 + √n log(n) is Θ(n2 ), since 7n2 ≤ 7n2 + √n log(n) ≤ 8n2 for all sufficiently large values of n. In the following few exercises you will work through some of the elementary properties of the asymptotic notation that make it a useful tool in the analysis of algorithms.
Exercise 3.9: Prove that f(n) is O(g(n)) if and only if g(n) is Ω(f(n)). Deduce that f(n) is Θ(g(n)) if and only if g(n) is Θ(f(n)).
Exercise 3.10: Suppose g(n) is a polynomial of degree k. Show that g(n) is O(nl) for any l ≥ k.
Exercise 3.11: Show that log n is O(nk ) for any k &gt; 0.
Exercise 3.12: (nlog n is super-polynomial) Show that nk is O(nlog n) for any k, but
that nlog n is never O(nk ).
Exercise 3.13: (nlog n is sub-exponential) Show that cn is Ω(nlog n) for any c &gt; 1,
but that nlog n is never Ω(cn).
Exercise 3.14: Suppose e(n) is O(f(n)) and g(n) is O(h(n)). Show that e(n)g(n) is
O(f (n)h(n)).
An example of the use of the asymptotic notation in quantifying resources is the following simple application to the problem of sorting an n element list of names into alphabetical order. Many sorting algorithms are based upon the ‘compare-and-swap’ operation: two elements of an n element list are compared, and swapped if they are in the wrong order. If this compare-and-swap operation is the only means by which we can access the list, how many such operations are required in order to ensure that the list has been correctly sorted?
A simple compare-and-swap algorithm for solving the sorting problem is as follows: (note that compare-and-swap(j,k) compares the list entries numbered j and k, and swaps them if they are out of order)
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
The analysis of computational problems 137
   Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

138 Introduction to computer science
         for j = 1 to n-1
            for k = j+1 to n
                compare-and-swap(j,k)
            end k
end j
It is clear that this algorithm correctly sorts a list of n names into alphabetical order. Note that the number of compare-and-swap operations executed by the algorithm is (n − 1) + (n − 2) + ··· + 1 = n(n − 1)/2. Thus the number of compare-and-swap operations used by the algorithm is Θ(n2). Can we do better than this? It turns out that we can. Algorithms such as ‘heapsort’ are known which run using O(n log n) compare-and- swap operations. Furthermore, in Exercise 3.15 you’ll work through a simple counting argument that shows any algorithm based upon the compare-and-swap operation requires Ω(n log n) such operations. Thus, the sorting problem requires Θ(n log n) compare-and- swap operations, in general.
Exercise 3.15: (Lower bound for compare-and-swap based sorts) Suppose an n element list is sorted by applying some sequence of compare-and-swap operations to the list. There are n! possible initial orderings of the list. Show that after k of the compare-and-swap operations have been applied, at most 2k of the possible initial orderings will have been sorted into the correct order. Conclude that Ω(n log n) compare-and-swap operations are required to sort all possible initial orderings into the correct order.
3.2.2 Computational complexity
The idea that there won’t be an algorithm to solve it – this is something fun- damental that won’t ever change – that idea appeals to me.
– Stephen Cook
Sometimes it is good that some things are impossible. I am happy there are many things that nobody can do to me.
– Leonid Levin
It should not come as a surprise that our choice of polynomial algorithms as the mathematical concept that is supposed to capture the informal notion of ‘practically efficient computation’ is open to criticism from all sides. [. . . ] Ul- timately, our argument for our choice must be this: Adopting polynomial worst-case performance as our criterion of efficiency results in an elegant and useful theory that says something meaningful about practical computation, and would be impossible without this sim- plification.
– Christos Papadimitriou
What time and space resources are required to perform a computation? In many cases these are the most important questions we can ask about a computational problem. Prob- lems like addition and multiplication of numbers are regarded as efficiently solvable because we have fast algorithms to perform addition and multiplication, which consume
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The analysis of computational problems 139
 little space when running. Many other problems have no known fast algorithm, and are effectively impossible to solve, not because we can’t find an algorithm to solve the prob- lem, but because all known algorithms consume such vast quantities of space or time as to render them practically useless.
Computational complexity is the study of the time and space resources required to solve computational problems. The task of computational complexity is to prove lower bounds on the resources required by the best possible algorithm for solving a problem, even if that algorithm is not explicitly known. In this and the next two sections, we give an overview of computational complexity, its major concepts, and some of the more important results of the field. Note that computational complexity is in a sense comple- mentary to the field of algorithm design; ideally, the most efficient algorithms we could design would match perfectly with the lower bounds proved by computational complex- ity. Unfortunately, this is often not the case. As already noted, in this book we won’t examine classical algorithm design in any depth.
One difficulty in formulating a theory of computational complexity is that different computational models may require different resources to solve the same problem. For in- stance, multiple-tape Turing machines can solve many problems substantially faster than single-tape Turing machines. This difficulty is resolved in a rather coarse way. Suppose a problem is specified by giving n bits as input. For instance, we might be interested in whether a particular n-bit number is prime or not. The chief distinction made in com- putational complexity is between problems which can be solved using resources which are bounded by a polynomial in n, or which require resources which grow faster than any polynomial in n. In the latter case we usually say that the resources required are exponential in the problem size, abusing the term exponential, since there are functions like nlog n which grow faster than any polynomial (and thus are ‘exponential’ accord- ing to this convention), yet which grow slower than any true exponential. A problem is regarded as easy, tractable or feasible if an algorithm for solving the problem using polynomial resources exists, and as hard, intractable or infeasible if the best possible algorithm requires exponential resources.
As a simple example, suppose we have two numbers with binary expansions x1 . . . xm1 and y1 . . . ym2 , and we wish to determine the sum of the two numbers. The total size of the input is n ≡ m1 + m2. It’s easy to see that the two numbers can be added using a number of elementary operations that scales as Θ(n); this algorithm uses a polynomial (indeed, linear) number of operations to perform its tasks. By contrast, it is believed (though it has never been proved!) that the problem of factoring an integer into its prime factors is intractable. That is, the belief is that there is no algorithm which can factor an arbitrary n-bit integer using O(p(n)) operations, where p is some fixed polynomial function of n. We will later give many other examples of problems which are believed to be intractable in this sense.
The polynomial versus exponential classification is rather coarse. In practice, an algo- rithm that solves a problem using 2n/1000 operations is probably more useful than one which runs in n1000 operations. Only for very large input sizes (n ≈ 108) will the ‘effi- cient’ polynomial algorithm be preferable to the ‘inefficient’ exponential algorithm, and for many purposes it may be more practical to prefer the ‘inefficient’ algorithm.
Nevertheless, there are many reasons to base computational complexity primarily on the polynomial versus exponential classification. First, historically, with few exceptions, polynomial resource algorithms have been much faster than exponential algorithms. We
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

140 Introduction to computer science
 might speculate that the reason for this is lack of imagination: coming up with algorithms requiring n, n2 or some other low degree polynomial number of operations is often much easier than finding a natural algorithm which requires n1000 operations, although examples like the latter do exist. Thus, the predisposition for the human mind to come up with relatively simple algorithms has meant that in practice polynomial algorithms usually do perform much more efficiently than their exponential cousins.
A second and more fundamental reason for emphasizing the polynomial versus expo- nential classification is derived from the strong Church–Turing thesis. As discussed in Section 1.1, it was observed in the 1960s and 1970s that probabilistic Turing machines appear to be the strongest ‘reasonable’ model of computation. More precisely, researchers consistently found that if it was possible to compute a function using k elementary opera- tions in some model that was not the probabilistic Turing machine model of computation, then it was always possible to compute the same function in the probabilistic Turing ma- chine model, using at most p(k) elementary operations, where p(·) is some polynomial function. This statement is known as the strong Church–Turing thesis:
Strong Church–Turing thesis: Any model of computation can be simulated on a probabilistic Turing machine with at most a polynomial increase in the number of elementary operations required.
The strong Church–Turing thesis is great news for the theory of computational complex- ity, for it implies that attention may be restricted to the probabilistic Turing machine model of computation. After all, if a problem has no polynomial resource solution on a probabilistic Turing machine, then the strong Church–Turing thesis implies that it has no efficient solution on any computing device. Thus, the strong Church–Turing thesis implies that the entire theory of computational complexity will take on an ele- gant, model-independent form if the notion of efficiency is identified with polynomial resource algorithms, and this elegance has provided a strong impetus towards acceptance of the identification of ‘solvable with polynomial resources’ and ‘efficiently solvable’. Of course, one of the prime reasons for interest in quantum computers is that they cast into doubt the strong Church–Turing thesis, by enabling the efficient solution of a prob- lem which is believed to be intractable on all classical computers, including probabilistic Turing machines! Nevertheless, it is useful to understand and appreciate the role the strong Church–Turing thesis has played in the search for a model-independent theory of computational complexity.
Finally, we note that, in practice, computer scientists are not only interested in the polynomial versus exponential classification of problems. This is merely the first and coarsest way of understanding how difficult a computational problem is. However, it is an exceptionally important distinction, and illustrates many broader points about the nature of resource questions in computer science. For most of this book, it will be our central concern in evaluating the efficiency of a given algorithm.
Having examined the merits of the polynomial versus exponential classification, we now have to confess that the theory of computational complexity has one remarkable outstanding failure: it seems very hard to prove that there are interesting classes of prob- lems which require exponential resources to solve. It is quite easy to give non-constructive proofs that most problems require exponential resources (see Exercise 3.16, below), and furthermore many interesting problems are conjectured to require exponential resources for their solution, but rigorous proofs seem very hard to come by, at least with the present
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The analysis of computational problems 141
 state of knowledge. This failure of computational complexity has important implications for quantum computation, because it turns out that the computational power of quantum computers can be related to some major open problems in classical computational com- plexity theory. Until these problems are resolved, it cannot be stated with certainty how computationally powerful a quantum computer is, or even whether it is more powerful than a classical computer!
Exercise 3.16: (Hard-to-compute functions exist) Show that there exist Boolean functions on n inputs which require at least 2n/ log n logic gates to compute.
3.2.3 Decision problems and the complexity classes P and NP
Many computational problems are most cleanly formulated as decision problems – prob- lems with a yes or no answer. For example, is a given number m a prime number or not? This is the primality decision problem. The main ideas of computational complexity are most easily and most often formulated in terms of decision problems, for two reasons: the theory takes its simplest and most elegant form in this form, while still generalizing in a natural way to more complex scenarios; and historically computational complexity arose primarily from the study of decision problems.
Although most decision problems can easily be stated in simple, familiar language, discussion of the general properties of decision problems is greatly helped by the termi- nology of formal languages. In this terminology, a language L over the alphabet Σ is a subset of the set Σ∗ of all (finite) strings of symbols from Σ. For example, if Σ = {0, 1}, then the set of binary representations of even numbers, L = {0,10,100,110,...} is a language over Σ.
Decision problems may be encoded in an obvious way as problems about languages. For instance, the primality decision problem can be encoded using the binary alphabet Σ = {0, 1}. Strings from Σ∗ can be interpreted in a natural way as non-negative integers. For example, 0010 can be interpreted as the number 2. The language L is defined to consist of all binary strings such that the corresponding number is prime.
To solve the primality decision problem, what we would like is a Turing machine which, when started with a given number n on its input tape, eventually outputs some equivalent of ‘yes’ if n is prime, and outputs ‘no’ if n is not prime. To make this idea precise, it is convenient to modify our old Turing machine definition (of Section 3.1.1) slightly, replacing the halting state qh with two states qY and qN to represent the answers ‘yes’ and ‘no’ respectively. In all other ways the machine behaves in the same way, and it still halts when it enters the state qY or qN. More generally, a language L is decided by a Turing machine if the machine is able to decide whether an input x on its tape is a member of the language of L or not, eventually halting in the state qY if x ∈ L, and eventually halting in the state qN if x ̸∈ L. We say that the machine has accepted or rejected x depending on which of these two cases comes about.
How quickly can we determine whether or not a number is prime? That is, what is the fastest Turing machine which decides the language representing the primality decision problem? We say that a problem is in TIME(f(n)) if there exists a Turing machine which decides whether a candidate x is in the language in time O(f(n)), where n is the length of x. A problem is said to be solvable in polynomial time if it is in TIME(nk) for some finite k. The collection of all languages which are in TIME(nk), for some k, is denoted P. P is our first example of a complexity class. More generally, a complexity
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

142 Introduction to computer science
 class is defined to be a collection of languages. Much of computational complexity theory is concerned with the definition of various complexity classes, and understanding the relationship between different complexity classes.
Not surprisingly, there are problems which cannot be solved in polynomial time. Unfortunately, proving that any given problem can’t be solved in polynomial time seems to be very difficult, although conjectures abound! A simple example of an interesting decision problem which is believed not to be in P is the factoring decision problem:
: Given a composite integer m and l &lt; m, does m have a non-trivial factor less than l?
An interesting property of factoring is that if somebody claims that the answer is ‘yes, m does have a non-trivial factor less than l’ then they can establish this by exhibiting such a factor, which can then be efficiently checked by other parties, simply by doing long-division. We call such a factor a witness to the fact that m has a factor less than l. This idea of an easily checkable witness is the key idea in the definition of the complexity class NP, below. We have phrased factoring as a decision problem, but you can easily verify that the decision problem is equivalent to finding the factors of a number:
Exercise 3.17: Prove that a polynomial-time algorithm for finding the factors of a number m exists if and only if the factoring decision problem is in P.
Factoring is an example of a problem in an important complexity class known as NP. What distinguishes problems in NP is that ‘yes’ instances of a problem can easily be verified with the aid of an appropriate witness. More rigorously, a language L is in NP if there is a Turing machine M with the following properties:
(1) If x ∈ L then there exists a witness string w such that M halts in the state qY after a time polynomial in |x| when the machine is started in the state x-blank-w.
(2) If x ̸∈ L then for all strings w which attempt to play the role of a witness, the machine halts in state qN after a time polynomial in |x| when M is started in the state x-blank-w.
There is an interesting asymmetry in the definition of NP. While we have to be able to quickly decide whether a possible witness to x ∈ L is truly a witness, there is no such need to produce a witness to x ̸∈ L. For instance, in the factoring problem, we have an easy way of proving that a given number has a factor less than m, but exhibiting a witness to prove that a number has no factors less than m is more daunting. This suggests defining coNP, the class of languages which have witnesses to ‘no’ instances; obviously the languages in coNP are just the complements of languages in NP.
How are P and NP related? It is clear that P is a subset of NP. The most famous open problem in computer science is whether or not there are problems in NP which are not in P, often abbreviated as the P ̸= NP problem. Most computer scientists believe that P ̸= NP, but despite decades of work nobody has been able to prove this, and the possibility remains that P = NP.
Exercise 3.18: Prove that if coNP ̸= NP then P ̸= NP.
Upon first acquaintance it’s tempting to conclude that the conjecture P ̸= NP ought
to be pretty easy to resolve. To see why it’s actually rather subtle it helps to see couple of
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
         Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The analysis of computational problems 143
 examples of problems that are in P and NP. We’ll draw the examples from graph theory, a rich source of decision problems with surprisingly many practical applications. A graph is a finite collection of vertices {v1,...,vn} connected by edges, which are pairs (vi,vj) of vertices. For now, we are only concerned with undirected graphs, in which the order of the vertices (in each edge pair) does not matter; similar ideas can be investigated for directed graphs in which the order of vertices does matter. A typical graph is illustrated in Figure 3.9.
UHTI SP QR    HUIT SP QR  
  
  
       
HUIT SP RQ     HUIT PS QR
HUTI SP RQ ccccccccccccccUHTI SP QR
    Figure 3.9. A graph.
A cycle in a graph is a sequence v1,...,vm of vertices such that each pair (vj,vj+1) is an edge, as is (v1,vm). A simple cycle is a cycle in which none of the vertices is repeated, except for the first and last vertices. A Hamiltonian cycle is a simple cycle which visits every vertex in the graph. Examples of graphs with and without Hamiltonian cycles are shown in Figure 3.10.
 UHIT PS QR    HUTI PS RQ
HUTI PS RQ    HUIT SP QR  
        

 
UHIT PS QR
     tt tt 
       ?? ??      

  
      ?? ??
HUIT PS QR     􏱕􏱕􏱕􏱕
  
c c c c c c c 􏱖􏱖 c􏱖􏱖 c c c c c c
  
 
HUTI SP RQ
      
             

  
UHTI SP RQ

OOOO HUIT SP QR
UHIT PS RQ    
UHIT SP QR
    UHTI SP RQ
    Figure 3.10. The graph on the left contains a Hamiltonian cycle, 0, 1, 2, 3, 4, 5, 0. The graph on the right contains no Hamiltonian cycle, as can be verified by inspection.
The Hamiltonian cycle problem (     ) is to determine whether a given graph contains a Hamiltonian cycle or not.     is a decision problem in NP, since if a given graph has a Hamiltonian cycle, then that cycle can be used as an easily checkable witness. Moreover,
has no known polynomial time algorithm. Indeed,     is a problem in the class of so-called NP-complete problems, which can be thought of as the ‘hardest’ problems in NP, in the sense that solving     in time t allows any other problem in NP to be solved in time O(poly(t)). This also means that if any NP-complete problem has a polynomial time solution then it will follow that P = NP.
There is a problem, the Euler cycle decision problem, which is superficially similar to
, but which has astonishingly different properties. An Euler cycle is an ordering of the edges of a graph G so that every edge in the graph is visited exactly once. The Euler
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
    Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

144 Introduction to computer science
 cycle decision problem (     ) is to determine, given a graph G on n vertices, whether that graph contains an Euler cycle or not.     is, in fact, exactly the same problem as     , only the path visits edges, rather than vertices. Consider the following remarkable theorem, to be proven in Exercise 3.20:
Theorem 3.1: (Euler’s theorem) A connected graph contains an Euler cycle if and only if every vertex has an even number of edges incident upon it.
Euler’s theorem gives us a method for efficiently solving     . First, check to see whether the graph is connected; this is easily done with O(n2) operations, as shown in Exer- cise 3.19. If the graph is not connected, then obviously no Euler cycle exists. If the graph is connected then for each vertex check whether there is an even number of edges incident upon the vertex. If a vertex is found for which this is not the case, then there is no Euler cycle, otherwise an Euler cycle exists. Since there are n vertices, and at most n(n − 1)/2 edges, this algorithm requires O(n3) elementary operations. Thus     is in P! Somehow, there is a structure present in the problem of visiting each edge that can be exploited to provide an efficient algorithm for     , yet which does not seem to be reflected in the problem of visiting each vertex; it is not at all obvious why such a structure should be present in one case, but not in the other, if indeed it is absent for the     problem.
Exercise 3.19: The                         problem is to determine whether there is a path between two specified vertices in a graph. Show that                         can be solved using O(n) operations if the graph has n vertices. Use the solution to
to show that it is possible to decide whether a graph is connected in O(n2) operations.
Exercise 3.20: (Euler’s theorem) Prove Euler’s theorem. In particular, if each vertex has an even number of incident edges, give a constructive procedure for finding an Euler cycle.
The equivalence between the factoring decision problem and the factoring problem proper is a special instance of one of the most important ideas in computer science, an idea known as reduction. Intuitively, we know that some problems can be viewed as special instances of other problems. A less trivial example of reduction is the reduction of     to the traveling salesman decision problem (       ). The traveling salesman decision problem is as follows: we are given n cities 1, 2, . . . , n and a non-negative integer distance dij between each pair of cities. Given a distance d the problem is to determine if there is a tour of all the cities of distance less than d.
The reduction of     to       goes as follows. Suppose we have a graph containing n vertices. We turn this into an instance of       by thinking of each vertex of the graph as a ‘city’ and defining the distance dij between cities i and j to be one if vertices i and j are connected, and the distance to be two if the vertices are unconnected. Then a tour of the cities of distance less than n + 1 must be of distance n, and be a Hamiltonian cycle for the graph. Conversely, if a Hamiltonian cycle exists then a tour of the cities of distance less than n + 1 must exist. In this way, given an algorithm for solving       , we can convert it into an algorithm for solving     without much overhead. Two consequences can be inferred from this. First, if       is a tractable problem, then     is also tractable. Second, if
is hard then       must also be hard. This is an example of a general technique known
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
              Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

as reduction: we’ve reduced the problem to the problem       . This is a technique we will use repeatedly throughout this book.
A more general notion of reduction is illustrated in Figure 3.11. A language B is said to be reducible to another language A if there exists a Turing machine operating in polynomial time such that given as input x it outputs R(x), and x ∈ B if and only if R(x) ∈ A. Thus, if we have an algorithm for deciding A, then with a little extra overhead we can decide the language B. In this sense, the language B is essentially no more difficult to decide than the language A.
Is x ∈ B
 Compute R(x) in polynomial time

Is R(x) ∈ A?

‘‘Yes’’ or ‘‘No’’
Figure 3.11. Reduction of B to A.
Exercise 3.21: (Transitive property of reduction) Show that if a language L1 is reducible to the language L2 and the language L2 is reducible to L3 then the language L1 is reducible to the language L3.
Some complexity classes have problems which are complete with respect to that com- plexity class, meaning there is a language L in the complexity class which is the ‘most difficult’ to decide, in the sense that every other language in the complexity class can be reduced to L. Not all complexity classes have complete problems, but many of the complexity classes we are concerned with do have complete problems. A trivial example is provided by P. Let L be any language in P which is not empty or equal to the set of all words. That is, there exists a string x1 such that x1 ̸∈ L and a string x2 such that x2 ∈ L. Then any other language L′ in P can be reduced to L using the following reduction: given an input x, use the polynomial time decision procedure to determine whether x ∈ L′ or not. If it is not, then set R(x) = x1, otherwise set R(x) = x2.
Exercise 3.22: Suppose L is complete for a complexity class, and L′ is another language in the complexity class such that L reduces to L′. Show that L′ is complete for the complexity class.
Less trivially, NP also contains complete problems. An important example of such a problem and the prototype for all other NP-complete problems is the circuit satisfiability problem or       : given a Boolean circuit composed of     ,     and       gates, is there an assignment of values to the inputs to the circuit that results in the circuit outputting 1, that is, is the circuit satisfiable for some input? The NP-completeness of       is known as the Cook–Levin theorem, for which we now outline a proof.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
The analysis of computational problems 145
                    Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

146 Introduction to computer science
Theorem 3.2: (Cook–Levin)         is NP-complete.
Proof
The proof has two parts. The first part of the proof is to show that         is in NP, and the second part is to show that any language in NP can be reduced to         . Both parts of the proof are based on simulation techniques: the first part of the proof is essentially showing that a Turing machine can efficiently simulate a circuit, while the second part of the proof is essentially showing that a circuit can efficiently simulate a Turing machine. Both parts of the proof are quite straightforward; for the purposes of illustration we give the second part in some detail.
The first part of the proof is to show that         is in NP. Given a circuit containing n circuit elements, and a potential witness w, it is obviously easy to check in polynomial time on a Turing machine whether or not w satisfies the circuit, which establishes that
is in NP.
The second part of the proof is to show that any language L ∈ NP can be reduced to
. That is, we aim to show that there is a polynomial time computable reduction R such that x ∈ L if and only if R(x) is a satisfiable circuit. The idea of the reduction is to find a circuit which simulates the action of the machine M which is used to check instance-witness pairs, (x, w), for the language L. The input variables for the circuit will represent the witness; the idea is that finding a witness which satisfies the circuit is equivalent to M accepting (x, w) for some specific witness w. Without loss of generality we may make the following assumptions about M to simplify the construction:
(1) M’s tape alphabet is ◃,0,1 and the blank symbol.
(2) M runs using time at most t(n) and total space at most s(n) where t(n) and s(n)
are polynomials in n.
(3) Machine M can actually be assumed to run using time exactly t(n) for all inputs of
size n. This is done by adding the lines ⟨qY, x, qY, x, 0⟩, and ⟨qN, x, qN, x, 0⟩ for each of x = ◃, 0, 1 and the blank, artificially halting the machine after exactly t(n) steps.
The basic idea of the construction to simulate M is outlined in Figure 3.12. Each internal state of the Turing machine is represented by a single bit in the circuit. We name the corresponding bits q ̃s,q ̃1,...,q ̃m,q ̃Y,q ̃N. Initially, q ̃s is set to one, and all the other bits representing internal states are set to zero. Each square on the Turing machine tape is represented by three bits: two bits to represent the letter of the alphabet (◃, 0, 1 or blank) currently residing on the tape, and a single ‘flag’ bit which is set to one if the read-write head is pointing to the square, and set to zero otherwise. We denote the bits representing the tape contents by (u1,v1),...,(us(n),vs(n)) and the corresponding flag bits by f1, . . . , fs(n). Initially the uj and vj bits are set to represent the inputs x and w, as appropriate, while f1 = 1 and all other fj = 0. There is also a lone extra ‘global flag’ bit, F , whose function will be explained later. F is initially set to zero. We regard all the bits input to the circuit as fixed, except for those representing the witness w, which are the variable bits for the circuit.
The action of M is obtained by repeating t(n) times a ‘simulation step’ which simulates the execution of a single program line for the Turing machine. Each simulation step may be broken up into a sequence of steps corresponding in turn to the respective program lines, with a final step which resets the global flag F to zero, as
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
         Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

⎧
⎪ q ̃s
The analysis of computational problems
147
         m+3 fixed input bits
3n+6 fixed input bits
3w(n) variable
input bits
3s(n) fixed input bits
1 fixed input bit
⎪ ⎪⎨ . /m+3 ⎪
···
output bit q ̃Y
⎪ ⎪q ⎪  ̃1
  Simulation Step
    ⎪ q ̃m ⎪ q ̃Y ⎪⎩ q ̃N
⎧
⎪ 􏱗
⎪⎨
⎪ x
/3n+6     ···
/3w(n)     ···
 Simulation Step
 ⎪⎩ b ⎧
⎪⎨
⎪ w ⎪⎩
Simulation Step
⎧
⎪ b
⎨ . ⎪ .
/3s(n)
···
···
  ⎪⎩ b ⎧⎨
⎩F
   􏱆 􏱅􏱄 􏱇
  t(n) simulationsteps
Figure 3.12. Outline of the procedure used to simulate a Turing machine using a circuit.
illustrated in Figure 3.13. To complete the simulation, we only need to simulate a program line of the form ⟨qi,x,qj,x′,s⟩. For convenience, we assume qi ̸=qj, but a similar construction works in the case when qi = qj . The procedure is as follows:
(1) Check to see that q ̃i = 1, indicating that the current state of the machine is qi. (2) For each tape square:
(a) Check to see that the global flag bit is set to zero, indicating that no action has yet been taken by the Turing machine.
(b) Check that the flag bit is set to one, indicating that the tape head is at this tape square.
(c) Check that the simulated tape contents at this point are x.
(d) If all conditions check out, then perform the following steps:
1. Setq ̃i =0andq ̃j =1.
2. Update the simulated tape contents at this tape square to x′.
3. Update the flag bit of this and adjacent ‘squares’ as appropriate, depending
on whether s = +1, 0, −1, and whether we are at the left hand end of the
tape.
4. Set the global flag bit to one, indicating that this round of computation has
been completed.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

148 Introduction to computer science
 This is a fixed procedure which involves a constant number of bits, and by the universality result of Section 3.1.2 can be performed using a circuit containing a constant number of gates.
Figure 3.13. Outline of the simulation step used to simulate a Turing machine using a circuit.
The total number of gates in the entire circuit is easily seen to be O(t(n)(s(n) + n)), whichispolynomialinsize.Attheendofthecircuit,itisclearthatq ̃Y =1ifandonly if the machine M accepts (x, w). Thus, the circuit is satisfiable if and only if there exists w such that machine M accepts (x, w), and we have found the desired reduction from Lto .
gives us a foot in the door which enables us to easily prove that many other problems are NP-complete. Instead of directly proving that a problem is NP-complete, we can instead prove that it is in NP and that         reduces to it, so by Exercise 3.22 the problem must be NP-complete. A small sample of NP-complete problems is discussed in Box 3.3. An example of another NP-complete problem is the satisfiability problem (       ), which is phrased in terms of a Boolean formula. Recall that a Boolean formula φ is composed of the following elements: a set of Boolean variables, x1 , x2 , . . .; Boolean connectives, that is, a Boolean function with one or two inputs and one output, such as ∧ (AND), ∨ (OR), and ¬ (NOT); and parentheses. The truth or falsity of a Boolean formula for a given set of Boolean variables is decided according to the usual laws of Boolean algebra. For example, the formula φ = x1 ∨ ¬x2 has the satisfying assignment x1 =0andx2 =0,whilex1 =0andx2 =1isnotasatisfyingassignment.The satisfiability problem is to determine, given a Boolean formula φ, whether or not it is satisfiable by any set of possible inputs.
Exercise 3.23: Show that       is NP-complete by first showing that       is in NP, and then showing that         reduces to       . (Hint: for the reduction it may help to represent each distinct wire in an instance of         by different variables in a Boolean formula.)
An important restricted case of       is also NP-complete, the 3-satisfiability problem (         ), which is concerned with formulae in 3-conjunctive normal form. A formula is said to be in conjunctive normal form if it is the AND of a collection of clauses, each of which is the OR of one or more literals, where a literal is an expression is of the form x or ¬x. For example, the formula (x1 ∨ ¬x2) ∧ (x2 ∨ x3 ∨ ¬x4) is in conjunctive normal form. A formula is in 3-conjunctive normal form or 3-CNF if each clause has exactly three literals. For example, the formula (¬x1 ∨x2 ∨¬x2)∧(¬x1 ∨x3 ∨¬x4)∧(x2 ∨x3 ∨x4) is in 3-conjunctive normal form. The 3-satisfiability problem is to determine whether a formula in 3-conjunctive normal form is satisfiable or not.
The proof that         is NP-complete is straightforward, but is a little too lengthy to justify inclusion in this overview. Even more than         and       ,         is in some sense
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
                                                                                                               Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The analysis of computational problems 149
 the NP-complete problem, and it is the basis for countless proofs that other problems are NP-complete. We conclude our discussion of NP-completeness with the surprising fact that         , the analogue of         in which every clause has two literals, can be solved in polynomial time:
Exercise 3.24: (         has an efficient solution) Suppose φ is a Boolean formula in conjunctive normal form, in which each clause contains only two literals.
(1) Construct a (directed) graph G(φ) with directed edges in the following way: the vertices of G correspond to variables xj and their negations ¬xj in φ. There is a (directed) edge (α, β) in G if and only if the clause (¬α ∨ β) or the clause (β ∨ ¬α) is present in φ. Show that φ is not satisfiable if and only if there exists a variable x such that there are paths from x to ¬x and from ¬x to x in G(φ).
(2) Show that given a directed graph G containing n vertices it is possible to determine whether two vertices v1 and v2 are connected in polynomial time.
(3) Find an efficient algorithm to solve         .
   Box 3.3: A zoo of NP-complete problems
The importance of the class NP derives, in part, from the enormous number of computational problems that are known to be NP-complete. We can’t possibly hope to survey this topic here (see ‘History and further reading’), but the following ex- amples, taken from many distinct areas of mathematics, give an idea of the delicious melange of problems known to be NP-complete.
•
• •
•
(graph theory): A clique in an undirected graph G is a subset of vertices, each pair of which is connected by an edge. The size of a clique is the number of vertices it contains. Given an integer m and a graph G, does G have a clique of size m?
(arithmetic): Given a finite collection S of positive integers and a target t, is there any subset of S which sums to t?
(linear programming): Given an integer m × n matrix A and an m-dimensional vector y with integer values, does there exist
an n-dimensional vector x with entries in the set {0, 1} such that Ax ≤ y? (graph theory): A vertex cover for an undirected graph G is a
set of vertices V ′ such that every edge in the graph has one or both vertices contained in V ′. Given an integer m and a graph G, does G have a vertex cover V ′ containing m vertices?
                                                 Assuming that P ̸= NP it is possible to prove that there is a non-empty class of problems NPI (NP intermediate) which are neither solvable with polynomial resources, nor are NP-complete. Obviously, there are no problems known to be in NPI (otherwise we would know that P ̸= NP) but there are several problems which are regarded as being likely candidates. Two of the strongest candidates are the factoring and graph isomorphism problems:
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

150 Introduction to computer science
 : Suppose G and G′ are two undirected graphs over the vertices V ≡ {v1, . . . , vn}. Are G and G′ isomorphic? That is, does there exist a one-to-one function φ : V → V such that the edge (vi,vj) is contained in G if
and only if (φ(vi),φ(vj)) is contained in G?
Problems in NPI are interesting to researchers in quantum computation and quantum information for two reasons. First, it is desirable to find fast quantum algorithms to solve problems which are not in P. Second, many suspect that quantum computers will not be able to efficiently solve all problems in NP, ruling out NP-complete problems. Thus, it is natural to focus on the class NPI. Indeed, a fast quantum algorithm for factoring has been discovered (Chapter 5), and this has motivated the search for fast quantum algorithms for other problems suspected to be in NPI.
3.2.4 A plethora of complexity classes
We have investigated some of the elementary properties of some important complexity classes. A veritable pantheon of complexity classes exists, and there are many non-trivial relationships known or suspected between these classes. For quantum computation and quantum information, it is not necessary to understand all the different complexity classes that have been defined. However, it is useful to have some appreciation for the more important of the complexity classes, many of which have natural analogues in the study of quantum computation and quantum information. Furthermore, if we are to understand how powerful quantum computers are, then it behooves us to understand how the class of problems solvable on a quantum computer fits into the zoo of complexity classes which may be defined for classical computers.
There are essentially three properties that may be varied in the definition of a complex- ity class: the resource of interest (time, space, . . . ), the type of problem being considered (decision problem, optimization problem, . . . ), and the underlying computational model (deterministic Turing machine, probabilistic Turing machine, quantum computer, . . . ). Not surprisingly, this gives us an enormous range to define complexity classes. In this section, we briefly review a few of the more important complexity classes and some of their elementary properties. We begin with a complexity class defined by changing the resource of interest from time to space.
The most natural space-bounded complexity class is the class PSPACE of decision problems which may be solved on a Turing machine using a polynomial number of working bits, with no limitation on the amount of time that may be used by the machine (see Exercise 3.25). Obviously, P is included in PSPACE, since a Turing machine that halts after polynomial time can only traverse polynomially many squares, but it is also true that NP is a subset of PSPACE. To see this, suppose L is any language in NP. Suppose problems of size n have witnesses of size at most p(n), where p(n) is some polynomial in n. To determine whether or not the problem has a solution, we may sequentially test all 2p(n) possible witnesses. Each test can be run in polynomial time, and therefore polynomial space. If we erase all the intermediate working between tests then we can test all the possibilities using polynomial space.
Unfortunately, at present it is not even known whether PSPACE contains problems which are not in P! This is a pretty remarkable situation – it seems fairly obvious that having unlimited time and polynomial spatial resources must be more powerful than having only a polynomial amount of time. However, despite considerable effort and in-
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
                Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

genuity, this has never been shown. We will see later that the class of problems solvable on a quantum computer in polynomial time is a subset of PSPACE, so proving that a problem efficiently solvable on a quantum computer is not efficiently solvable on a clas- sical computer would establish that P ̸= PSPACE, and thus solve a major outstanding problem of computer science. An optimistic way of looking at this result is that ideas from quantum computation might be useful in proving that P ̸= PSPACE. Pessimisti- cally, one might conclude that it will be a long time before anyone rigorously proves that quantum computers can be used to efficiently solve problems that are intractable on a classical computer. Even more pessimistically, it is possible that P = PSPACE, in which case quantum computers offer no advantage over classical computers! However, very few (if any) computational complexity theorists believe that P = PSPACE.
Exercise 3.25: (PSPACE ⊆ EXP) The complexity class EXP (for exponential time) contains all decision problems which may be decided by a Turing machine running in exponential time, that is time O(2nk ), where k is any constant. Prove that PSPACE ⊆ EXP. (Hint: If a Turing machine has l internal states, an m letter alphabet, and uses space p(n), argue that the machine can exist in one of at most lmp(n) different states, and that if the Turing machine is to avoid infinite loops then it must halt before revisiting a state.)
Exercise 3.26: (L ⊆ P) The complexity class L (for logarithmic space) contains all decision problems which may be decided by a Turing machine running in logarithmic space, that is, in space O(log(n)). More precisely, the class L is defined using a two-tape Turing machine. The first tape contains the problem instance, of size n, and is a read-only tape, in the sense that only program lines which don’t change the contents of the first tape are allowed. The second tape is a working tape which initially contains only blanks. The logarithmic space requirement is imposed on the second, working tape only. Show that L ⊆ P.
Does allowing more time or space give greater computational power? The answer to this question is yes in both cases. Roughly speaking, the time hierarchy theorem states that TIME(f(n)) is a proper subset of TIME(f(n) log2(f(n))). Similarly, the space hierarchy theorem states that SPACE(f (n)) is a proper subset of SPACE(f (n) log(f (n))), where SPACE(f(n)) is, of course, the complexity class consisting of all languages that can be decided with spatial resources O(f(n)). The hierarchy theorems have interesting implications with respect to the equality of complexity classes. We know that
L ⊆ P ⊆ NP ⊆ PSPACE ⊆ EXP. (3.1)
Unfortunately, although each of these inclusions is widely believed to be strict, none of them has ever been proved to be strict. However, the time hierarchy theorem implies that P is a strict subset of EXP, and the space hierarchy theorem implies that L is a strict subset of PSPACE! So we can conclude that at least one of the inclusions in (3.1) must be strict, although we do not know which one.
What should we do with a problem once we know that it is NP-complete, or that some other hardness criterion holds? It turns out that this is far from being the end of the story in problem analysis. One possible line of attack is to identify special cases of the problem which may be amenable to attack. For example, in Exercise 3.24 we saw that the         problem has an efficient solution, despite the NP-completeness of       .
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
The analysis of computational problems 151
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

152 Introduction to computer science
 Another approach is to change the type of problem which is being considered, a tactic which typically results in the definition of new complexity classes. For example, instead of finding exact solutions to an NP-complete problem, we can instead try to find good algorithms for finding approximate solutions to a problem. For example, the
problem is an NP-complete problem, yet in Exercise 3.27 we show that it is possible to efficiently find an approximation to the minimal vertex cover which is correct to within a factor two! On the other hand, in Problem 3.6 we show that it is not possible to find approximations to solutions of       correct to within any factor, unless P = NP!
Exercise 3.27: (Approximation algorithm for                       ) Let G = (V, E) be an undirected graph. Prove that the following algorithm finds a vertex cover for G that is within a factor two of being a minimal vertex cover:
VC=∅
E′ = E
do until E′ = ∅
let (α,β) be any edge of E′
V C = V C ∪ {α, β}
remove from E′ every edge incident on α or β
return V C.
Why is it possible to approximate the solution of one NP-complete problem, but not another? After all, isn’t it possible to efficiently transform from one problem to another? This is certainly true, however it is not necessarily true that this transformation preserves the notion of a ‘good approximation’ to a solution. As a result, the computational complexity theory of approximation algorithms for problems in NP has a structure that goes beyond the structure of NP proper. An entire complexity theory of approximation algorithms exists, which unfortunately is beyond the scope of this book. The basic idea, however, is to define a notion of reduction that corresponds to being able to efficiently reduce one approximation problem to another, in such a way that the notion of good approximation is preserved. With such a notion, it is possible to define complexity classes such as MAXSNP by analogy to the class NP, as the set of problems for which it is possible to efficiently verify approximate solutions to the problem. Complete problems exist for MAXSNP, just as for NP, and it is an interesting open problem to determine how the class MAXSNP compares to the class of approximation problems which are efficiently solvable.
We conclude our discussion with a complexity class that results when the underlying model of computation itself is changed. Suppose a Turing machine is endowed with the ability to flip coins, using the results of the coin tosses to decide what actions to take during the computation. Such a Turing machine may only accept or reject inputs with a certain probability. The complexity class BPP (for bounded-error probabilistic time) contains all languages L with the property that there exists a probabilistic Turing machine M such that if x ∈ L then M accepts x with probability at least 3/4, and if x ̸∈ L, then M rejects x with probability at least 3/4. The following exercise shows that the choice of the constant 3/4 is essentially arbitrary:
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
           Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Exercise 3.28: (Arbitrariness of the constant in the definition of BPP) Suppose k is a fixed constant, 1/2 &lt; k ≤ 1. Suppose L is a language such that there exists a Turing machine M with the property that whenever x ∈ L, M accepts x with probability at least k, and whenever x ̸∈ L, M rejects x with probability at least k. Show that L ∈ BPP.
Indeed, the Chernoff bound, discussed in Box 3.4, implies that with just a few repetitions of an algorithm deciding a language in BPP the probability of success can be amplified to the point where it is essentially equal to one, for all intents and purposes. For this reason, BPP even more than P is the class of decision problems which is usually regarded as being efficiently solvable on a classical computer, and it is the quantum analogue of BPP, known as BQP, that is most interesting in our study of quantum algorithms.
3.2.5 Energy and computation
Computational complexity studies the amount of time and space required to solve a computational problem. Another important computational resource is energy. In this section, we study the energy requirements for computation. Surprisingly, it turns out that computation, both classical and quantum, can in principle be done without expending any energy! Energy consumption in computation turns out to be deeply linked to the reversibility of the computation. Consider a gate like the         gate, which takes as input two bits, and produces a single bit as output. This gate is intrinsically irreversible because, given the output of the gate, the input is not uniquely determined. For example, if the output of the         gate is 1, then the input could have been any one of 00, 01, or 10. On the other hand, the       gate is an example of a reversible logic gate because, given the output of the       gate, it is possible to infer what the input must have been.
Another way of understanding irreversibility is to think of it in terms of information erasure. If a logic gate is irreversible, then some of the information input to the gate is lost irretrievably when the gate operates – that is, some of the information has been erased by the gate. Conversely, in a reversible computation, no information is ever erased, because the input can always be recovered from the output. Thus, saying that a computation is reversible is equivalent to saying that no information is erased during the computation.
What is the connection between energy consumption and irreversibility in compu- tation? Landauer’s principle provides the connection, stating that, in order to erase information, it is necessary to dissipate energy. More precisely, Landauer’s principle may be stated as follows:
Landauer’s principle (first form): Suppose a computer erases a single bit of information. The amount of energy dissipated into the environment is at least kBT ln2, where kB is a universal constant known as Boltzmann’s constant, and T is the temperature of the environment of the computer.
According to the laws of thermodynamics, Landauer’s principle can be given an alterna- tive form stated not in terms of energy dissipation, but rather in terms of entropy:
Landauer’s principle (second form): Suppose a computer erases a single bit of information. The entropy of the environment increases by at least kB ln 2, where kB is Boltzmann’s constant.
Justifying Landauer’s principle is a problem of physics that lies beyond the scope of this
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
The analysis of computational problems 153
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

154 Introduction to computer science
    Box 3.4: BPP and the Chernoff bound
Suppose we have an algorithm for a decision problem which gives the correct answer with probability 1/2 + ε, and the wrong answer with probability 1/2 − ε. If we run the algorithm n times, then it seems reasonable to guess that the correct answer is whichever appeared most frequently. How reliably does this procedure work? The Chernoff bound is a simple result from elementary probability which answers this question.
Theorem 3.3: (The Chernoff bound) Suppose X1 , . . . , Xn are independent and identically distributed random variables, each taking the value 1 with probability 1/2 + ε, and the value 0 with probability 1/2 − ε. Then
Proof
p
􏰔􏰸n 􏰕 Xi≤n/2 ≤e−2ε2n.
i=1
(3.2)
Consider any sequence (x1 , . . . , xn ) containing at most n/2 ones. The probability of such a sequence occurring is maximized when it contains ⌊n/2⌋ ones, so
􏰐1 􏰑n 􏰐1 􏰑n 22
  p(X1 =x1,...,Xn =xn)≤
= 2n .
There can be at most 2n such sequences, so
􏰔􏰸 􏰕 2n n (1−4ε)2
􏰔􏰸 􏰕
Xi ≤ n/2 ≤ e−4ε2n/2 = e−2ε2n.
2−ε
(1 − 4ε2)n
2+ε
(3.3) (3.4)
(3.5)
(3.6)
   p
Finally, by calculus, 1 − x ≤ exp(−x), so
i
p
2n Xi≤n/2 ≤2× 2n =(1−4ε)2.
i
2
       What this tells us is that for fixed ε, the probability of making an error decreases exponentially quickly in the number of repetitions of the algorithm. In the case of BPP we have ε = 1/4, so it takes only a few hundred repetitions of the algorithm to reduce the probability of error below 10−20, at which point an error in one of the computer’s components becomes much more likely than an error due to the probabilistic nature of the algorithm.
 book – see the end of chapter ‘History and further reading’ if you wish to understand why Landauer’s principle holds. However, if we accept Landauer’s principle as given, then it raises a number of interesting questions. First of all, Landauer’s principle only provides a lower bound on the amount of energy that must be dissipated to erase information.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

How close are existing computers to this lower bound? Not very, turns out to be the answer – computers circa the year 2000 dissipate roughly 500kB T ln 2 in energy for each elementary logical operation.
Although existing computers are far from the limit set by Landauer’s principle, it is still an interesting problem of principle to understand how much the energy consumption can be reduced. Aside from the intrinsic interest of the problem, a practical reason for the interest follows from Moore’s law: if computer power keeps increasing then the amount of energy dissipated must also increase, unless the energy dissipated per operation drops at least as fast as the rate of increase in computing power.
If all computations could be done reversibly, then Landauer’s principle would imply no lower bound on the amount of energy dissipated by the computer, since no bits at all are erased during a reversible computation. Of course, it is possible that some other physical principle might require that energy be dissipated during the computation; fortunately, this turns out not to be the case. But is it possible to perform universal computation without erasing any information? Physicists can cheat on this problem to see in advance that the answer to this question must be yes, because our present understanding of the laws of physics is that they are fundamentally reversible. That is, if we know the final state of a closed physical system, then the laws of physics allow us to work out the initial state of the system. If we believe that those laws are correct, then we must conclude that hidden in the irreversible logic gates like       and     , there must be some underlying reversible computation. But where is this hidden reversibility, and can we use it to construct manifestly reversible computers?
We will use two different techniques to give reversible circuit-based models capable of universal computation. The first model, a computer built entirely of billiard balls and mirrors, gives a beautiful concrete realization of the principles of reversible computation. The second model, based on a reversible logic gate known as the Toffoli gate (which we first encountered in Section 1.4.1), is a more abstract view of reversible computation that will later be of great use in our discussion of quantum computation. It is also possible to build reversible Turing machines that are universal for computation; however, we won’t study these here, since the reversible circuit models turn out to be much more useful for quantum computation.
The basic idea of the billiard ball computer is illustrated in Figure 3.14. Billiard ball ‘inputs’ enter the computer from the left hand side, bouncing off mirrors and each other, before exiting as ‘outputs’ on the right hand side. The presence or absence of a billiard ball at a possible input site is used to indicate a logical 1 or a logical 0, respectively. The fascinating thing about this model is that it is manifestly reversible, insofar as its operation is based on the laws of classical mechanics. Furthermore, this model of computation turns out to be universal in the sense that it can be used to simulate an arbitrary computation in the standard circuit model of computation.
Of course, if a billiard ball computer were ever built it would be highly unstable. As any billiards player can attest, a billiard ball rolling frictionlessly over a smooth surface is easily knocked off course by small perturbations. The billiard ball model of computation depends on perfect operation, and the absence of external perturbations such as those caused by thermal noise. Periodic corrections can be performed, but information gained by doing this would have to be erased, requiring work to be performed. Expenditure of energy thus serves the purpose of reducing this susceptibility to noise, which is necessary for a practical, real-world computational machine. For the purposes of this introduction,
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
The analysis of computational problems 155
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

156 Introduction to computer science
        `
c c'
b b'
a a'
Figure 3.14. A simple billiard ball computer, with three input bits and three output bits, shown entering on the left and leaving on the right, respectively. The presence or absence of a billiard ball indicates a 1 or a 0, respectively. Empty circles illustrate potential paths due to collisions. This particular computer implements the Fredkin classical reversible logic gate, discussed in the text.
we will ignore the effects of noise on the billiard ball computer, and concentrate on understanding the essential elements of reversible computation.
The billiard ball computer provides an elegant means for implementing a reversible universal logic gate known as the Fredkin gate. Indeed, the properties of the Fredkin gate provide an informative overview of the general principles of reversible logic gates and circuits. The Fredkin gate has three input bits and three output bits, which we refer to as a, b, c and a′ , b′ , c′ , respectively. The bit c is a control bit, whose value is not changed by the action of the Fredkin gate, that is, c′ = c. The reason c is called the control bit is because it controls what happens to the other two bits, a and b. If c is set to 0 then a andbareleftalone,a′ =a,b′ =b.Ifcissetto1,aandbareswapped,a′ =b,b′ =a. The explicit truth table for the Fredkin gate is shown in Figure 3.15. It is easy to see that the Fredkin gate is reversible, because given the output a′,b′,c′, we can determine the inputs a, b, c. In fact, to recover the original inputs a, b and c we need only apply another Fredkin gate to a′, b′, c′:
Exercise 3.29: (Fredkin gate is self-inverse) Show that applying two consecutive Fredkin gates gives the same outputs as inputs.
Examining the paths of the billiard balls in Figure 3.14, it is not difficult to verify that this billiard ball computer implements the Fredkin gate:
Exercise 3.30: Verify that the billiard ball computer in Figure 3.14 computes the Fredkin gate.
In addition to reversibility, the Fredkin gate also has the interesting property that the number of 1s is conserved between the input and output. In terms of the billiard ball computer, this corresponds to the number of billiard balls going into the Fredkin gate being equal to the number coming out. Thus, it is sometimes referred to as being a conservative reversible logic gate. Such reversibility and conservative properties are interesting to a physicist because they can be motivated by fundamental physical princi-
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
                                                                Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

The analysis of computational problems 157
    Inputs Outputs
a b c a′ b′ c′ 000000 001001 010010 011101 100100 101011 110110 111111
Figure 3.15. Fredkin gate truth table and circuit representation. The bits a and b are swapped if the control bit c is set, and otherwise are left alone.
ples. The laws of Nature are reversible, with the possible exception of the measurement postulate of quantum mechanics, discussed in Section 2.2.3 on page 84. The conservative property can be thought of as analogous to properties such as conservation of mass, or conservation of energy. Indeed, in the billiard ball model of computation the conservative property corresponds exactly to conservation of mass.
                                                                                                         Figure 3.16. Fredkin gate configured to perform the elementary gates       (left), (middle), and a primitive routing function, the                   (right). The middle gate also serves to perform the operation, since it produces two copies of x at the output. Note that each of these configurations requires the use of extra ‘ancilla’ bits prepared in standard states – for example, the 0 input on the first line of the       gate – and in general the output contains ‘garbage’ not needed for the remainder of the computation.
The Fredkin gate is not only reversible and conservative, it’s a universal logic gate as well! As illustrated in Figure 3.16, the Fredkin gate can be configured to simulate ,       ,                   and             functions, and thus can be cascaded to simulate any
classical circuit whatsoever.
To simulate irreversible gates such as       using the Fredkin gate, we made use of two
ideas. First, we allowed the input of ‘ancilla’ bits to the Fredkin gate, in specially prepared states, either 0 or 1. Second, the output of the Fredkin gate contained extraneous ‘garbage’ not needed for the remainder of the computation. These ancilla and garbage bits are not directly important to the computation. Their importance lies in the fact that they make the computation reversible. Indeed the irreversibility of gates like the       and     may be viewed as a consequence of the ancilla and garbage bits being ‘hidden’. Summarizing, given any classical circuit computing a function f(x), we can build a reversible circuit made entirely of Fredkin gates, which on input of x, together with some ancilla bits
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
            Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

158 Introduction to computer science
 in a standard state a, computes f(x), together with some extra ‘garbage’ output, g(x). Therefore, we represent the action of the computation as (x, a) → (f (x), g(x)).
We now know how to compute functions reversibly. Unfortunately, this computation produces unwanted garbage bits. With some modifications it turns out to be possible to perform the computation so that any garbage bits produced are in a standard state. This construction is crucial for quantum computation, because garbage bits whose value depends upon x will in general destroy the interference properties crucial to quantum computation. To understand how this works it is convenient to assume that the       gate is available in our repertoire of reversible gates, so we may as well assume that the ancilla bits a all start out as 0s, with       gates being added where necessary to turn the ancilla 0s into 1s. It will also be convenient to assume that the classical controlled-       gate is available, defined in a manner analogous to the quantum definition of Section 1.3.2, that is, the inputs (c, t) are taken to (c, t ⊕ c), where ⊕ denotes addition modulo 2. Notice that t = 0 gives (c, 0) → (c, c), so the controlled-       can be thought of as a reversible copying gate or             , which leaves no garbage bits at the output.
With the additional       gates appended at the beginning of the circuit, the action of the computation may be written as (x,0) → (f(x),g(x)). We could also have added gates to the beginning of the circuit, in order to create a copy of x which is not changed during the subsequent computation. With this modification, the action of the
circuit may be written
(x, 0, 0) → (x, f (x), g(x)) . (3.7)
Equation (3.7) is a very useful way of writing the action of the reversible circuit, because it allows an idea known as uncomputation to be used to get rid of the garbage bits, for a small cost in the running time of the computation. The idea is the following. Suppose we start with a four register computer in the state (x, 0, 0, y). The second register is used to store the result of the computation, and the third register is used to provide workspace for the computation, that is, the garbage bits g(x). The use of the fourth register is described shortly, and we assume it starts in an arbitrary state y.
We begin as before, by applying a reversible circuit to compute f , resulting in the state (x, f (x), g(x), y). Next, we use         s to add the result f (x) bitwise to the fourth register, leaving the machine in the state (x, f (x), g(x), y ⊕ f (x)). However, all the steps used to compute f(x) were reversible and did not affect the fourth register, so by applying the reverse of the circuit used to compute f we come to the state (x, 0, 0, y ⊕ f (x)). Typically, we omit the ancilla 0s from the description of the function evaluation, and just write the action of the circuit as
(x, y) → (x, y ⊕ f (x)) . (3.8)
In general we refer to this modified circuit computing f as the reversible circuit computing f, even though in principle there are many other reversible circuits which could be used to compute f.
What resource overhead is involved in doing reversible computation? To analyze this question, we need to count the number of extra ancilla bits needed in a reversible circuit, and compare the gate counts with classical models. It ought to be clear that the number of gates in a reversible circuit is the same as in an irreversible circuit to within the constant factor which represents the number of Fredkin gates needed to simulate a single element of the irreversible circuit, and an additional factor of two for uncomputation, with an
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
    Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

overhead for the extra         operations used in reversible computation which is linear in the number of bits involved in the circuit. Similarly, the number of ancilla bits required scales at most linearly with the number of gates in the irreversible circuit, since each element in the irreversible circuit can be simulated using a constant number of ancilla bits. As a result, natural complexity classes such as P and NP are the same no matter whether a reversible or irreversible model of computation is used. For more elaborate complexity classes like PSPACE the situation is not so immediately clear; see Problem 3.9 and ‘History and further reading’ for a discussion of some such subtleties.
Exercise 3.31: (Reversible half-adder) Construct a reversible circuit which, when two bits x and y are input, outputs (x, y, c, x ⊕ y), where c is the carry bit when x and y are added.
The Fredkin gate and its implementation using the billiard ball computer offers a beautiful paradigm for reversible computation. There is another reversible logic gate, the Toffoli gate, which is also universal for classical computation. While the Toffoli gate does not have quite the same elegant physical simplicity as the billiard ball implementation of the Fredkin gate, it will be more useful in the study of quantum computation. We have already met the Toffoli gate in Section 1.4.1, but for convenience we review its properties here.
The Toffoli gate has three input bits, a, b and c. a and b are known as the first and second control bits, while c is the target bit. The gate leaves both control bits unchanged, flips the target bit if both control bits are set, and otherwise leaves the target bit alone. The truth table and circuit representation for the Toffoli gate are shown in Figure 3.17.
Inputs Outputs
a b c a′ b′ c′ 000000 001001 010010 011011 100100 101101 110111 111110
Figure 3.17. Truth table and circuit representation of the Toffoli gate.
How can the Toffoli gate be used to do universal computation? Suppose we wish to the bits a and b. To do this using the Toffoli gate, we input a and b as control bits, and send in an ancilla bit set to 1 as the target bit, as shown in Figure 3.18. The of a and b is output as the target bit. As expected from our study of the Fredkin gate, the Toffoli gate simulation of a         requires the use of a special ancilla input,
and some of the outputs from the simulation are garbage bits.
The Toffoli gate can also be used to implement the             operation by inputting
an ancilla 1 to the first control bit, and a to the second control bit, producing the output 1, a, a. This is illustrated in Figure 3.19. Recalling that         and are together
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
The analysis of computational problems 159
                                                     Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

160 Introduction to computer science
                              Figure 3.18. Implementing a         gate using a Toffoli gate. The top two bits represent the input to the         , while the third bit is prepared in the standard state 1, sometimes known as an ancilla state. The output from the
is on the third bit.
universal for computation, we see that an arbitrary circuit can be efficiently simulated using a reversible circuit consisting only of Toffoli gates and ancilla bits, and that useful additional techniques such as uncomputation may be achieved using the same methods as were employed with the Fredkin gate.
Figure 3.19.             with the Toffoli gate, with the second bit being the input to the             , and the other two bits standard ancilla states. The output from             appears on the second and third bits.
Our interest in reversible computation was motivated by our desire to understand the energy requirements for computation. It is clear that the noise-free billiard ball model of computation requires no energy for its operation; what about models based upon the Toffoli gate? This can only be determined by examining specific models for the computation of the Toffoli gate. In Chapter 7, we examine several such implementations, and it turns out that, indeed, the Toffoli gate can be implemented in a manner which does not require the expenditure of energy.
There is a significant caveat attached to the idea that computation can be done without the expenditure of energy. As we noted earlier, the billiard ball model of computation is highly sensitive to noise, and this is true of many other models of reversible computation. To nullify the effects of noise, some form of error-correction needs to be done. Such error-correction typically involves the performance of measurements on the system to determine whether the system is behaving as expected, or if an error has occurred. Because the computer’s memory is finite, the bits used to store the measurement results utilized in error-correction must eventually be erased to make way for new measurement results. According to Landauer’s principle, this erasure carries an associated energy cost
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
                        Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Perspectives on computer science 161
 that must be accounted for when tallying the total energy cost of the computation. We analyze the energy cost associated with error-correction in more detail in Section 12.4.4. What can we conclude from our study of reversible computation? There are three key ideas. First, reversibility stems from keeping track of every bit of information; irre- versibility occurs only when information is lost or erased. Second, by doing computation reversibly, we obviate the need for energy expenditure during computation. All computa- tions can be done, in principle, for zero cost in energy. Third, reversible computation can be done efficiently, without the production of garbage bits whose value depends upon the input to the computation. That is, if there is an irreversible circuit computing a function f, then there is an efficient simulation of this circuit by a reversible circuit with action
(x, y) → (x, y ⊕ f (x)).
What are the implications of these results for physics, computer science, and for
quantum computation and quantum information? From the point of view of a physicist or hardware engineer worried about heat dissipation, the good news is that, in principle, it is possible to make computation dissipation-free by making it reversible, although in practice energy dissipation is required for system stability and immunity from noise. At an even more fundamental level, the ideas leading to reversible computation also lead to the resolution of a century-old problem in the foundations of physics, the famous problem of Maxwell’s demon. The story of this problem and its resolution is outlined in Box 3.5 on page 162. From the point of view of a computer scientist, reversible computation validates the use of irreversible elements in models of computation such as the Turing machine (since using them or not gives polynomially equivalent models). Moreover, since the physical world is fundamentally reversible, one can argue that complexity classes based upon reversible models of computation are more natural than complexity classes based upon irreversible models, a point revisited in Problem 3.9 and ‘History and further reading’. From the point of view of quantum computation and quantum information, reversible computation is enormously important. To harness the full power of quantum computation, any classical subroutines in a quantum computation must be performed reversibly and without the production of garbage bits depending on the classical input.
Exercise 3.32: (From Fredkin to Toffoli and back again) What is the smallest number of Fredkin gates needed to simulate a Toffoli gate? What is the smallest number of Toffoli gates needed to simulate a Fredkin gate?
3.3 Perspectives on computer science
In a short introduction such as this chapter, it is not remotely possible to cover in detail all the great ideas of a field as rich as computer science. We hope to have conveyed to you something of what it means to think like a computer scientist, and provided a basic vocabulary and overview of some of the fundamental concepts important in the understanding of computation. To conclude this chapter, we briefly touch on some more general issues, in order to provide some perspective on how quantum computation and quantum information fits into the overall picture of computer science.
Our discussion has revolved around the Turing machine model of computation. How does the computational power of unconventional models of computation such as massively parallel computers, DNA computers and analog computers compare with the standard
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

162 Introduction to computer science
    Box 3.5: Maxwell’s demon
The laws of thermodynamics govern the amount of work that can be performed by a physical system at thermodynamic equilibrium. One of these laws, the second law of thermodynamics, states that the entropy in a closed system can never decrease. In 1871, James Clerk Maxwell proposed the existence of a machine that apparently violated this law. He envisioned a miniature little ‘demon’, like that shown in the figure below, which could reduce the entropy of a gas cylinder initially at equilibrium by individually separating the fast and slow molecules into the two halves of the cylinder. This demon would sit at a little door at the middle partition. When a fast molecule approaches from the left side the demon opens a door between the partitions, allowing the molecule through, and then closes the door. By doing this many times the total entropy of the cylinder can be decreased, in apparent violation of the second law of thermodynamics.
                   The resolution to the Maxwell’s demon paradox lies in the fact that the demon must perform measurements on the molecules moving between the partitions, in order to determine their velocities. The result of this measurement must be stored in the demon’s memory. Because any memory is finite, the demon must eventually begin erasing information from its memory, in order to have space for new measurement results. By Landauer’s principle, this act of erasing information increases the total entropy of the combined system – demon, gas cylinder, and their environments. In fact, a complete analysis shows that Landauer’s principle implies that the entropy of the combined system is increased at least as much by this act of erasing information as the entropy of the combined system is decreased by the actions of the demon, thus ensuring that the second law of thermodynamics is obeyed.
 Turing machine model of computation and, implicitly, with quantum computation? Let’s begin with parallel computing architectures. The vast majority of computers in existence are serial computers, processing instructions one at a time in some central processing unit. By contrast, parallel computers can process more than one instruction at a time, leading to a substantial savings in time and money for some applications. Nevertheless, parallel processing does not offer any fundamental advantage over the standard Turing machine model when issues of efficiency are concerned, because a Turing machine can simulate a parallel computer with polynomially equivalent total physical resources – the total space and time used by the computation. What a parallel computer gains in time,
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Perspectives on computer science 163
 it loses in the total spatial resources required to perform the computation, resulting in a net of no essential change in the power of the computing model.
An interesting specific example of massively parallel computing is the technique of DNA computing. A strand of DNA, deoxyribonucleic acid, is a molecule composed of a sequence (a polymer) of four kinds of nucleotides distinguished by the bases they carry, denoted by the letter A (adenine), C (cytosine), G (guanine) and T (thymine). Two strands, under certain circumstances, can anneal to form a double strand, if the respective base pairs form complements of each other (A matches T and G matches C). The ends are also distinct and must match appropriately. Chemical techniques can be used to amplify the number of strands beginning or ending with specific sequences (polymerase chain reaction), separate the strands by length (gel electrophoresis), dissolve double strands into single strands (changing temperature and pH), read the sequence on a strand, cut strands at a specific position (restriction enzymes), and detect if a certain sequence of DNA is in a test tube. The procedure for using these mechanisms in a robust manner is rather involved, but the basic idea can be appreciated from an example.
The directed Hamiltonian path problem is a simple and equivalently hard variant of the Hamiltonian cycle problem of Section 3.2.2, in which the goal is to determine if a path exists or not between two specified vertices j1 and jN in a directed graph G of N vertices, entering each vertex exactly once, and following only allowed edge directions. This problem can be solved with a DNA computer using the following five steps, in which xj are chosen to be unique sequences of bases (and x ̄j their complements), DNA strands xjxk encode edges, and strands x ̄jx ̄j encode vertices. (1) Generate random paths through G, by combining a mixture of all possible vertex and edge DNA strands, and waiting for the strands to anneal. (2) Keep only the paths beginning with j1 and ending with jN, by amplifying only the double strands beginning with x ̄j1 and ending with x ̄jN . (3) Select only paths of length N , by separating the strands according to their length. (4) Select only paths which enter each vertex at least once, by dissolving the DNA into single strands, and annealing with all possible vertex strands one at a time and filtering out only those strands which anneal. And (5) detect if any strands have survived the selection steps; if so, then a path exists, and otherwise, it does not. To ensure the answer is correct with sufficiently high probability, xj may be chosen to contain many (≈ 30) bases, and a large number (≈ 1014 or more are feasible) of strands are used in the reaction.
Heuristic methods are available to improve upon this basic idea. Of course, exhaustive search methods such as this only work as long as all possible paths can be generated efficiently, and thus the number of molecules used must grow exponentially as the size of the problem (the number of vertices in the example above). DNA molecules are relatively small and readily synthesized, and the huge number of DNA combinations one can fit into a test tube can stave off the exponential complexity cost increase for a while – up to a few dozen vertices – but eventually the exponential cost limits the applicability of this method. Thus, while DNA computing offers an attractive and physically realizable model of computation for the solution of certain problems, it is a classical computing technique and offers no essential improvement in principle over a Turing machine.
Analog computers offer a yet another paradigm for performing computation. A com- puter is analog when the physical representation of information it uses for computation is based on continuous degrees of freedom, instead of zeroes and ones. For example, a thermometer is an analog computer. Analog circuitry, using resistors, capacitors, and amplifiers, is also said to perform analog computation. Such machines have an infinite
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

164 Introduction to computer science
 resource to draw upon in the ideal limit, since continuous variables like position and voltage can store an unlimited amount of information. But this is only true in the absence of noise. The presence of a finite amount of noise reduces the number of distinguishable states of a continuous variable to a finite number – and thus restricts analog computers to the representation of a finite amount of information. In practice, noise reduces analog computers to being no more powerful than conventional digital computers, and through them Turing machines. One might suspect that quantum computers are just analog com- puters, because of the use of continuous parameters in describing qubit states; however, it turns out that the effects of noise on a quantum computer can effectively be digitized. As a result, their computational advantages remain even in the presence of a finite amount of noise, as we shall see in Chapter 10.
What of the effects of noise on digital computers? In the early days of computation, noise was a very real problem for computers. In some of the original computers a vacuum tube would malfunction every few minutes. Even today, noise is a problem for compu- tational devices such as modems and hard drives. Considerable effort was devoted to the problem of understanding how to construct reliable computers from unreliable compo- nents. It was proven by von Neumann that this is possible with only a polynomial increase in the resources required for computation. Ironically, however, modern computers use none of those results, because the components of modern computers are fantastically reliable. Failure rates of 10−17 and even less are common in modern electronic compo- nents. For this reason, failures happen so rarely that the extra effort required to protect against them is not regarded as being worth making. On the other hand, we shall find that quantum computers are very delicate machines, and will likely require substantial application of error-correction techniques.
Different architectures may change the effects of noise. For example, if the effect of noise is ignored, then changing to a computer architecture in which many operations are performed in parallel may not change the number of operations which need to be done. However, a parallel system may be substantially more resistant to noise, because the effects of noise have less time to accumulate. Therefore, in a realistic analysis, the parallel version of an algorithm may have some substantial advantages over a serial implementation. Architecture design is a well developed field of study for classical computers. Hardly anything similar has been developed along the same lines for quantum computers, but the study of noise already suggests some desirable traits for future quantum computer architectures, such as a high level of parallelism.
A fourth model of computation is distributed computation, in which two or more spatially separated computational units are available to solve a computational problem. Obviously, such a model of computation is no more powerful than the Turing machine model in the sense that it can be efficiently simulated on a Turing machine. However, distributed computation gives rise to an intriguing new resource challenge: how best to utilize multiple computational units when the cost of communication between the units is high. This problem of distributed computation becomes especially interesting as comput- ers are connected through high speed networks; although the total computational capacity of all the computers on a network might be extremely large, utilization of that potential is difficult. Most interesting problems do not divide easily into independent chunks that can be solved separately, and may frequently require global communication between dif- ferent computational subsystems to exchange intermediate results or synchronize status. The field of communication complexity has been developed to address such issues, by
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

//
Chapter problems 165
 quantifying the cost of communication requirements in solving problems. When quan- tum resources are available and can be exchanged between distributed computers, the communication costs can sometimes be greatly reduced.
A recurring theme through these concluding thoughts and through the entire book is that despite the traditional independence of computer science from physical constraints, ultimately physical laws have tremendous impact not only upon how computers are realized, but also the class of problems they are capable of solving. The success of quantum computation and quantum information as a physically reasonable alternative model of computation questions closely held tenets of computer science, and thrusts notions of computer science into the forefront of physics. The task of the remainder of this book is to stir together ideas from these disparate fields, and to delight in what results!
Problem 3.1: (Minsky machines) A Minsky machine consists of a finite set of registers, r1,r2,...,rk, each capable of holding an arbitrary non-negative integer, and a program, made up of orders of one of two types. The first type has the form:
yrxs wt vu     //
The interpretation is that at point m in the program register rj is incremented by one, and execution proceeds to point n in the program. The second type of order has the form:
rysx tw uv66       (( ((     
The interpretation is that at point m in the program, register rj is decremented if it contains a positive integer, and execution proceeds to point n in the program. If register rj is zero then execution simply proceeds to point p in the program. The program for the Minsky machine consists of a collection of such orders, of a form like:
          //
          //
//
rysx tw vupppp
􏱕􏱕􏱕􏱕 ppppp
         ppp ppbbpp pp p
􏱕􏱕
     ry sx     tw
uv
  The starting and all possible halting points for the program are conventionally labeled zero. This program takes the contents of register r1 and adds them to register r2, while decrementing r1 to zero.
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

166
(1)
(2)
Introduction to computer science
Prove that all (Turing) computable functions can be computed on a Minsky machine, in the sense that given a computable function f(·) there is a Minsky machine program that when the registers start in the state (n,0,...,0) gives as output (f(n),0,...,0).
Sketch a proof that any function which can be computed on a Minsky machine, in the sense just defined, can also be computed on a Turing machine.
 Problem 3.2: (Vector games) A vector game is specified by a finite list of vectors, all of the same dimension, and with integer co-ordinates. The game is to start with a vector x of non-negative integer co-ordinates and to add to x the first vector from the list which preserves the non-negativity of all the components, and to repeat this process until it is no longer possible. Prove that for any computable function f(·) there is a vector game which when started with the vector (n,0,...,0) reaches (f(n),0,...,0). (Hint: Show that a vector game in k + 2 dimensions can simulate a Minsky machine containing k registers.)
Problem 3.3: (Fractran) A Fractran program is defined by a list of positive rational numbers q1, . . . , qn. It acts on a positive integer m by replacing it by qim, where i is the least number such that qim is an integer. If there is ever a time when there is no i such that qim is an integer, then execution stops. Prove that for any computable function f(·) there is a Fractran program which when started with 2n reaches 2f(n) without going through any intermediate powers of 2. (Hint: use the previous problem.)
Problem 3.4: (Undecidability of dynamical systems) A Fractran program is essentially just a very simple dynamical system taking positive integers to positive integers. Prove that there is no algorithm to decide whether such a dynamical system ever reaches 1.
Problem 3.5: (Non-universality of two bit reversible logic) Suppose we are trying to build circuits using only one and two bit reversible logic gates, and ancilla bits. Prove that there are Boolean functions which cannot be computed in this fashion. Deduce that the Toffoli gate cannot be simulated using one and two bit reversible gates, even with the aid of ancilla bits.
Problem 3.6: (Hardness of approximation of       ) Let r ≥ 1 and suppose that there is an approximation algorithm for       which is guaranteed to find the shortest tour among n cities to within a factor r. Let G = (V, E) be any graph on n vertices. Define an instance of       by identifying cities with vertices in V , and defining the distance between cities i and j to be 1 if (i, j) is an edge of G, and to be ⌈r⌉|V | + 1 otherwise. Show that if the approximation algorithm is applied to this instance of       then it returns a Hamiltonian cycle for G if one exists, and otherwise returns a tour of length more than ⌈r⌉|V |. From the NP-completeness of     it follows that no such approximation algorithm can exist unless P = NP.
Problem 3.7: (Reversible Turing machines)
(1) Explain how to construct a reversible Turing machine that can compute the same class of functions as is computable on an ordinary Turing machine. (Hint: It may be helpful to use a multi-tape construction.)
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

(2) Give general space and time bounds for the operation of your reversible Turing machine, in terms of the time t(x) and space s(x) required on an ordinary single-tape Turing machine to compute a function f(x).
Problem 3.8: (Find a hard-to-compute class of functions (Research)) Find a natural class of functions on n inputs which requires a super-polynomial number of Boolean gates to compute.
Problem 3.9: (Reversible PSPACE = PSPACE) It can be shown that the problem ‘quantified satisfiability’, or         , is PSPACE-complete. That is, every other language in PSPACE can be reduced to         in polynomial time. The language
is defined to consist of all Boolean formulae φ in n variables x1 , . . . , xn , and in conjunctive normal form, such that:
∃x1∀x2∃x3 ...∀xn φ if n is even; (3.9) ∃x1∀x2∃x3 ...∃xn φ if n is odd. (3.10)
Prove that a reversible Turing machine operating in polynomial space can be used to solve         . Thus, the class of languages decidable by a computer operating reversibly in polynomial space is equal to PSPACE.
Problem 3.10: (Ancilla bits and efficiency of reversible computation) Let pm be the mth prime number. Outline the construction of a reversible circuit which, upon input of m and n such that n &gt; m, outputs the product pmpn, that is
(m, n) → (pmpn, g(m, n)), where g(m, n) is the final state of the ancilla bits used by the circuit. Estimate the number of ancilla qubits your circuit requires. Prove that if a polynomial (in log n) size reversible circuit can be found that uses O(log(log n)) ancilla bits then the problem of factoring a product of two prime numbers is in P.
History and further reading
Computer science is a huge subject with many interesting subfields. We cannot hope for any sort of completeness in this brief space, but instead take the opportunity to recommend a few titles of general interest, and some works on subjects of specific interest in relation to topics covered in this book, with the hope that they may prove stimulating.
Modern computer science dates to the wonderful 1936 paper of Turing[Tur36]. The Church–Turing thesis was first stated by Church[Chu36] in 1936, and was then given a more complete discussion from a different point of view by Turing. Several other researchers found their way to similar conclusions at about the same time. Many of these contributions and a discussion of the history may be found in a volume edited by Davis[Dav65]. Provocative discussions of the Church–Turing thesis and undecidability may be found in Hofstadter[Hof79] and Penrose[Pen89].
There are many excellent books on algorithm design. We mention only three. First, there is the classic series by Knuth[Knu97, Knu98a, Knu98b] which covers an enormous portion of computer science. Second, there is the marvelous book by Cormen, Leiserson, and Rivest[CLR90]. This huge book contains a plethora of well-written material on many areas
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
History and further reading 167
     Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

168 Introduction to computer science
of algorithm design. Finally, the book of Motwani and Raghavan[MR95] is an excellent
survey of the field of randomized algorithms.
The modern theory of computational complexity was especially influenced by the papers of Cook[Coo71] and Karp[Kar72]. Many similar ideas were arrived at independently in Russia by Levin[Lev73], but unfortunately took time to propagate to the West. The classic book by Garey and Johnson[GJ79] has also had an enormous influence on the field. More recently, Papadimitriou[Pap94] has written a beautiful book that surveys many of the main ideas of computational complexity theory. Much of the material in this chapter is based upon Papadimitriou’s book. In this chapter we considered only one type of reducibility between languages, polynomial time reducibility. There are many other notions of reductions between languages. An early survey of these notions was given by Ladner, Lynch and Selman[LLS75]. The study of different notions of reducibility later blossomed into a subfield of research known as structural complexity, which has been reviewed by Balca ́zar, Diaz, and Gabarro ́[BDG88a, BDG88b].
The connection between information, energy dissipation, and computation has a long history. The modern understanding is due to a 1961 paper by Landauer[Lan61], in which Landauer’s principle was first formulated. A paper by Szilard[Szi29] and a 1949 lecture by von Neumann[von66] (page 66) arrive at conclusions close to Landauer’s principle, but do not fully grasp the essential point that it is the erasure of information that requires dissipation.
Reversible Turing machines were invented by Lecerf[Lec63] and later, but indepen- dently, in an influential paper by Bennett[Ben73]. Fredkin and Toffoli[FT82] introduced reversible circuit models of computation. Two interesting historical documents are Bar- ton’s May, 1978 MIT 6.895 term paper[Bar78], and Ressler’s 1981 Master’s thesis[Res81], which contain designs for a reversible PDP-10! Today, reversible logic is potentially important in implementations of low-power CMOS circuitry[YK95].
Maxwell’s demon is a fascinating subject, with a long and intricate history. Maxwell proposed his demon in 1871[Max71]. Szilard published a key paper in 1929[Szi29] which an- ticipated many of the details of the final resolution of the problem of Maxwell’s demon. In 1965 Feynman[FLS65b] resolved a special case of Maxwell’s demon. Bennett, build- ing on Landauer’s work[Lan61], wrote two beautiful papers on the subject[BBBW82, Ben87] which completed the resolution of the problem. An interesting book about the history of Maxwell’s demon and its exorcism is the collection of papers by Leff and Rex[LR90].
DNA computing was invented by Adleman, and the solution of the directed Hamil- tonian path problem we describe is his[Adl94]. Lipton has also shown how         and circuit satisfiability can be solved in this model[Lip95]. A good general article is Adleman’s Scientific American article[Adl98]; for an insightful look into the universality of DNA operations, see Winfree[Win98]. An interesting place to read about performing reliable computation in the presence of noise is the book by Winograd and Cowan[WC67]. This topic will be addressed again in Chapter 10. A good textbook on computer architecture is by Hennessey, Goldberg, and Patterson.[HGP96].
Problems 3.1 through 3.4 explore a line of thought originated by Minsky (in his beautiful book on computational machines[Min67]) and developed by Conway[Con72, Con86]. The Fractran programming language is certainly one of the most beautiful and elegant universal computational models known, as demonstrated by the following example, known
Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
 Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

History and further reading 169 as PRIMEGAME[Con86]. PRIMEGAME is defined by the list of rational numbers:
17; 78; 19; 23; 29; 77; 95; 77; 1 ; 11; 13; 15; 1; 55. (3.11)
9185513833292319171311 2 7 1
Amazingly, when PRIMEGAME is started at 2, the other powers of 2 that appear, namely, 22, 23, 25, 27, 211, 213, . . . , are precisely the prime powers of 2, with the powers stepping through the prime numbers, in order. Problem 3.9 is a special case of the more general subject of the spatial requirements for reversible computation. See the papers by Bennett[Ben89], and by Li, Tromp and Vitanyi[LV96, LTV98].
               Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.

Nielsen, Michael. Quantum Computation Quantum Infomation, Cambridge University Press Textbooks, 1900. ProQuest Ebook Central, http://ebookcentral.proquest.com/lib/uci/detail.action?docID=5120014.
Created from uci on 2020-09-25 15:38:48.
Copyright © 1900. Cambridge University Press Textbooks. All rights reserved.
</Text>
        </Document>
        <Document ID="196BB4A1-6202-4B07-A85E-804B8C05BFF3">
            <Title>Deutsch-Jozsa Algorithm</Title>
            <Text>  
Learn Quantum Computation using Qiskit
What is Quantum?
0. Prerequisites
0.1 Setting Up Your Environment
0.2 Python and Jupyter Notebooks
1. Quantum States and Qubits
1.1 Introduction
1.2 The Atoms of Computation
1.3 Representing Qubit States
1.4 Single Qubit Gates
1.5 The Case for Quantum
2. Multiple Qubits and Entanglement
2.1 Introduction
2.2 Multiple Qubits and Entangled States
2.3 Phase Kickback
2.4 More Circuit Identities
2.5 Proving Universality
2.6 Classical Computation on a Quantum Computer
3. Quantum Protocols and Quantum Algorithms
3.1 Defining Quantum Circuits
3.2 Quantum Teleportation
3.3 Superdense Coding
3.4 Deutsch-Jozsa Algorithm
3.5 Bernstein-Vazirani Algorithm
3.6 Simon's Algorithm
3.7 Quantum Fourier Transform
3.8 Quantum Phase Estimation
3.9 Shor's Algorithm
3.10 Grover's Algorithm
3.11 Quantum Counting
3.12 Quantum Key Distribution
4. Quantum Algorithms for Applications
4.1 Applied Quantum Algorithms
4.1.1 Solving Linear Systems of Equations using HHL
4.1.2 Simulating Molecules using VQE
4.1.3 Solving combinatorial optimization problems using QAOA
4.1.4 Solving Satisfiability Problems using Grover's Algorithm
4.1.5 Hybrid quantum-classical Neural Networks with PyTorch and Qiskit
4.2 Implementations of Recent Quantum Algorithms
4.2.1 Variational Quantum Linear Solver
5. Investigating Quantum Hardware Using Quantum Circuits
5.1 Introduction to Quantum Error Correction using Repetition Codes
5.2 Measurement Error Mitigation
5.3 Randomized Benchmarking
5.4 Measuring Quantum Volume
6. Investigating Quantum Hardware Using Microwave Pulses
6.1 Calibrating Qubits with Qiskit Pulse
6.2 Accessing Higher Energy States
6.3 Introduction to Transmon Physics
6.4 Circuit Quantum Electrodynamics
7. Problem Sets &amp; Exercises
Set 1. Classical Logic Gates with Quantum Circuits
Set 2. Basic Synthesis of Single-Qubit Gates
Set 3. Building the Best AND Gate
8. Appendix
8.1 Linear Algebra
8.2 Qiskit
9. Games &amp; Demos
Hello Qiskit Game
Estimating Pi Using Quantum Phase Estimation Algorithm
Interactivity Index
Powered by Jupyter Book


Deutsch-Jozsa Algorithm
In this section, we first introduce the Deutsch-Jozsa problem, and classical and quantum algorithms to solve it. We then implement the quantum algorithm using Qiskit, and run it on a simulator and device.

Contents

Introduction
1.1 Deutsch-Jozsa Problem
1.2 Deutsch-Jozsa Algorithm
1.3 The Quantum Solution
1.4 Why Does This Work?
Worked Example
Creating Quantum Oracles
Qiskit Implementation
4.1 Constant Oracle
4.2 Balanced Oracle
4.3 The Full Algorithm
4.4 Generalised Circuit
Running on Real Devices
Problems
References
1. Introduction

The Deutsch-Jozsa algorithm, first introduced in Reference [1], was the first example of a quantum algorithm that performs better than the best classical algorithm. It showed that there can be advantages to using a quantum computer as a computational tool for a specific problem.

1.1 Deutsch-Jozsa Problem 

We are given a hidden Boolean function f, which takes as input a string of bits, and returns either 0 or 1, that is:

f({x0,x1,x2,...})→0 or 1 , where xn is 0 or 1
The property of the given Boolean function is that it is guaranteed to either be balanced or constant. A constant function returns all 0's or all 1's for any input, while a balanced function returns 0's for exactly half of all inputs and 1's for the other half. Our task is to determine whether the given function is balanced or constant.

Note that the Deutsch-Jozsa problem is an n-bit extension of the single bit Deutsch problem.

1.2 The Classical Solution 

Classically, in the best case, two queries to the oracle can determine if the hidden Boolean function, f(x), is balanced: e.g. if we get both f(0,0,0,...)→0 and f(1,0,0,...)→1, then we know the function is balanced as we have obtained the two different outputs.

In the worst case, if we continue to see the same output for each input we try, we will have to check exactly half of all possible inputs plus one in order to be certain that f(x) is constant. Since the total number of possible inputs is 2n, this implies that we need 2n−1+1 trial inputs to be certain that f(x) is constant in the worst case. For example, for a 4-bit string, if we checked 8 out of the 16 possible combinations, getting all 0's, it is still possible that the 9th input returns a 1 and f(x) is balanced. Probabilistically, this is a very unlikely event. In fact, if we get the same result continually in succession, we can express the probability that the function is constant as a function of k inputs as:

Pconstant(k)=1−
1
2k−1
 
for k≤2n−1
Realistically, we could opt to truncate our classical algorithm early, say if we were over x% confident. But if we want to be 100% confident, we would need to check 2n−1+1 inputs.

1.3 Quantum Solution 

Using a quantum computer, we can solve this problem with 100% confidence after only one call to the function f(x), provided we have the function f implemented as a quantum oracle, which maps the state |x⟩|y⟩ to |x⟩|y⊕f(x)⟩, where ⊕ is addition modulo 2. Below is the generic circuit for the Deutsh-Jozsa algorithm.



Now, let's go through the steps of the algorithm:

Prepare two quantum registers. The first is an n-qubit register initialised to |0⟩, and the second is a one-qubit register initialised to |1⟩:
|ψ0⟩=|0⟩⊗n|1⟩
Apply a Hadamard gate to each qubit:
|ψ1⟩=
1
√
2n+1
 
2n−1
∑
x=0 |x⟩(|0⟩−|1⟩)
Apply the quantum oracle |x⟩|y⟩ to |x⟩|y⊕f(x)⟩:
|ψ2⟩	=
1
√
2n+1
 
2n−1
∑
x=0 |x⟩(|f(x)⟩−|1⊕f(x)⟩)		=
1
√
2n+1
 
2n−1
∑
x=0 (−1)f(x)|x⟩(|0⟩−|1⟩) 
since for each x,f(x) is either 0 or 1.
At this point the second single qubit register may be ignored. Apply a Hadamard gate to each qubit in the first register:
|ψ3⟩	=
1
2n
 
2n−1
∑
x=0 (−1)f(x)[ 
2n−1
∑
y=0 (−1)x⋅y|y⟩]		=
1
2n
 
2n−1
∑
y=0 [ 
2n−1
∑
x=0 (−1)f(x)(−1)x⋅y]|y⟩ 
where x⋅y=x0y0⊕x1y1⊕…⊕xn−1yn−1 is the sum of the bitwise product.
Measure the first register. Notice that the probability of measuring |0⟩⊗n=|
1
2n
 
∑
2n−1
x=0
(−1)f(x)|2, which evaluates to 1 if f(x) is constant and 0 if f(x) is balanced.
1.4 Why Does This Work? 

Constant Oracle
When the oracle is constant, it has no effect (up to a global phase) on the input qubits, and the quantum states before and after querying the oracle are the same. Since the H-gate is its own inverse, in Step 4 we reverse Step 2 to obtain the initial quantum state of |00…0⟩ in the first register.

H⊗n[ 1	0	0	⋮	0 ]=
1
√
2n
 
[ 1	1	1	⋮	1 ] 
after Uf
→
 H⊗n
1
√
2n
 
[ 1	1	1	⋮	1 ]=[ 1	0	0	⋮	0 ]
Balanced Oracle
After step 2, our input register is an equal superposition of all the states in the computational basis. When the oracle is balanced, phase kickback adds a negative phase to exactly half these states:

Uf
1
√
2n
 
[ 1	1	1	⋮	1 ]=
1
√
2n
 
[ −1	1	−1	⋮	1 ]
The quantum state after querying the oracle is orthogonal to the quantum state before querying the oracle. Thus, in Step 4, when applying the H-gates, we must end up with a quantum state that is orthogonal to |00…0⟩. This means we should never measure the all-zero state.

2. Worked Example

Let's go through a specific example for a two bit balanced function:

The first register of two qubits is initialized to |00⟩ and the second register qubit to |1⟩ (Note that we are using subscripts 1, 2, and 3 to index the qubits. A subscript of "12" indicates the state of the register containing qubits 1 and 2)
|ψ0⟩=|00⟩12⊗|1⟩3
Apply Hadamard on all qubits
|ψ1⟩=
1
2
 
(|00⟩+|01⟩+|10⟩+|11⟩)12⊗
1
√
2
 
(|0⟩−|1⟩)3
The oracle function can be implemented as Qf=CX13CX23,
|ψ2⟩=
1
2
√
2
 
[|00⟩12⊗(|0⊕0⊕0⟩−|1⊕0⊕0⟩)3+|01⟩12⊗(|0⊕0⊕1⟩−|1⊕0⊕1⟩)3+|10⟩12⊗(|0⊕1⊕0⟩−|1⊕1⊕0⟩)3+|11⟩12⊗(|0⊕1⊕1⟩−|1⊕1⊕1⟩)3] 
Simplifying this, we get the following:
|ψ2⟩	=
1
2
√
2
 
[|00⟩12⊗(|0⟩−|1⟩)3−|01⟩12⊗(|0⟩−|1⟩)3−|10⟩12⊗(|0⟩−|1⟩)3+|11⟩12⊗(|0⟩−|1⟩)3]		=
1
2
 
(|00⟩−|01⟩−|10⟩+|11⟩)12⊗
1
√
2
 
(|0⟩−|1⟩)3		=
1
√
2
 
(|0⟩−|1⟩)1⊗
1
√
2
 
(|0⟩−|1⟩)2⊗
1
√
2
 
(|0⟩−|1⟩)3 
Apply Hadamard on the first register
|ψ3⟩=|1⟩1⊗|1⟩2⊗(|0⟩−|1⟩)3
Measuring the first two qubits will give the non-zero 11, indicating a balanced function.
You can try out similar examples using the widget below. Press the buttons to add H-gates and oracles, re-run the cell and/or set case="constant" to try out different oracles.

from qiskit_textbook.widgets import dj_widget
dj_widget(size="small", case="balanced")
 try
3. Creating Quantum Oracles 

Let's see some different ways we can create a quantum oracle.

For a constant function, it is simple:

 1. if f(x) = 0, then apply the I gate to the qubit in register 2.
 2. if f(x) = 1, then apply the X gate to the qubit in register 2.

For a balanced function, there are many different circuits we can create. One of the ways we can guarantee our circuit is balanced is by performing a CNOT for each qubit in register 1, with the qubit in register 2 as the target. For example:



In the image above, the top three qubits form the input register, and the bottom qubit is the output register. We can see which input states give which output in the table below:

Input states that output 0	Input States that output 1
000	001
011	100
101	010
110	111
We can change the results while keeping them balanced by wrapping selected controls in X-gates. For example, see the circuit and its results table below:



Input states that output 0	Input states that output 1
001	000
010	011
100	101
111	110
4. Qiskit Implementation

We now implement the Deutsch-Jozsa algorithm for the example of a three-bit function, with both constant and balanced oracles. First let's do our imports:

# initialization
import numpy as np

# importing Qiskit
from qiskit import IBMQ, BasicAer
from qiskit.providers.ibmq import least_busy
from qiskit import QuantumCircuit, execute

# import basic plot tools
from qiskit.visualization import plot_histogram
 try
Next, we set the size of the input register for our oracle:

# set the length of the n-bit input string. 
n = 3
 try
4.1 Constant Oracle 

Let's start by creating a constant oracle, in this case the input has no effect on the ouput so we just randomly set the output qubit to be 0 or 1:

# set the length of the n-bit input string. 
n = 3

const_oracle = QuantumCircuit(n+1)

output = np.random.randint(2)
if output == 1:
    const_oracle.x(n)

const_oracle.draw()
 try
4.2 Balanced Oracle 

balanced_oracle = QuantumCircuit(n+1)
 try
Next, we create a balanced oracle. As we saw in section 1b, we can create a balanced oracle by performing CNOTs with each input qubit as a control and the output bit as the target. We can vary the input states that give 0 or 1 by wrapping some of the controls in X-gates. Let's first choose a binary string of length n that dictates which controls to wrap:

b_str = "101"
 try
Now we have this string, we can use it as a key to place our X-gates. For each qubit in our circuit, we place an X-gate if the corresponding digit in b_str is 1, or do nothing if the digit is 0.

balanced_oracle = QuantumCircuit(n+1)
b_str = "101"

# Place X-gates
for qubit in range(len(b_str)):
    if b_str[qubit] == '1':
        balanced_oracle.x(qubit)
balanced_oracle.draw()
 try
Next, we do our controlled-NOT gates, using each input qubit as a control, and the output qubit as a target:

balanced_oracle = QuantumCircuit(n+1)
b_str = "101"

# Place X-gates
for qubit in range(len(b_str)):
    if b_str[qubit] == '1':
        balanced_oracle.x(qubit)

# Use barrier as divider
balanced_oracle.barrier()

# Controlled-NOT gates
for qubit in range(n):
    balanced_oracle.cx(qubit, n)

balanced_oracle.barrier()
balanced_oracle.draw()
 try
Finally, we repeat the code from two cells up to finish wrapping the controls in X-gates:

balanced_oracle = QuantumCircuit(n+1)
b_str = "101"

# Place X-gates
for qubit in range(len(b_str)):
    if b_str[qubit] == '1':
        balanced_oracle.x(qubit)

# Use barrier as divider
balanced_oracle.barrier()

# Controlled-NOT gates
for qubit in range(n):
    balanced_oracle.cx(qubit, n)

balanced_oracle.barrier()

# Place X-gates
for qubit in range(len(b_str)):
    if b_str[qubit] == '1':
        balanced_oracle.x(qubit)

# Show oracle
balanced_oracle.draw()
 try
We have just created a balanced oracle! All that's left to do is see if the Deutsch-Joza algorithm can solve it.

4.3 The Full Algorithm 

Let's now put everything together. This first step in the algorithm is to initialise the input qubits in the state |+⟩ and the output qubit in the state |−⟩:

dj_circuit = QuantumCircuit(n+1, n)

# Apply H-gates
for qubit in range(n):
    dj_circuit.h(qubit)

# Put qubit in state |-&gt;
dj_circuit.x(n)
dj_circuit.h(n)
dj_circuit.draw()
 try
Next, let's apply the oracle. Here we apply the balanced_oracle we created above:

dj_circuit = QuantumCircuit(n+1, n)

# Apply H-gates
for qubit in range(n):
    dj_circuit.h(qubit)

# Put qubit in state |-&gt;
dj_circuit.x(n)
dj_circuit.h(n)

# Add oracle
dj_circuit += balanced_oracle
dj_circuit.draw()
 try
Finally, we perform H-gates on the n-input qubits, and measure our input register:

dj_circuit = QuantumCircuit(n+1, n)

# Apply H-gates
for qubit in range(n):
    dj_circuit.h(qubit)

# Put qubit in state |-&gt;
dj_circuit.x(n)
dj_circuit.h(n)

# Add oracle
dj_circuit += balanced_oracle

# Repeat H-gates
for qubit in range(n):
    dj_circuit.h(qubit)
dj_circuit.barrier()

# Measure
for i in range(n):
    dj_circuit.measure(i, i)

# Display circuit
dj_circuit.draw()
 try
Let's see the output:

# use local simulator
backend = BasicAer.get_backend('qasm_simulator')
shots = 1024
results = execute(dj_circuit, backend=backend, shots=shots).result()
answer = results.get_counts()

plot_histogram(answer)
 try
We can see from the results above that we have a 0% chance of measuring 000. This correctly predicts the function is balanced.

4.4 Generalised Circuits 

Below, we provide a generalised function that creates Deutsch-Joza oracles and turns them into quantum gates. It takes the case, (either 'balanced' or 'constant', and n, the size of the input register:

def dj_oracle(case, n):
    # We need to make a QuantumCircuit object to return
    # This circuit has n+1 qubits: the size of the input,
    # plus one output qubit
    oracle_qc = QuantumCircuit(n+1)
    
    # First, let's deal with the case in which oracle is balanced
    if case == "balanced":
        # First generate a random number that tells us which CNOTs to
        # wrap in X-gates:
        b = np.random.randint(1,2**n)
        # Next, format 'b' as a binary string of length 'n', padded with zeros:
        b_str = format(b, '0'+str(n)+'b')
        # Next, we place the first X-gates. Each digit in our binary string 
        # corresponds to a qubit, if the digit is 0, we do nothing, if it's 1
        # we apply an X-gate to that qubit:
        for qubit in range(len(b_str)):
            if b_str[qubit] == '1':
                oracle_qc.x(qubit)
        # Do the controlled-NOT gates for each qubit, using the output qubit 
        # as the target:
        for qubit in range(n):
            oracle_qc.cx(qubit, n)
        # Next, place the final X-gates
        for qubit in range(len(b_str)):
            if b_str[qubit] == '1':
                oracle_qc.x(qubit)

    # Case in which oracle is constant
    if case == "constant":
        # First decide what the fixed output of the oracle will be
        # (either always 0 or always 1)
        output = np.random.randint(2)
        if output == 1:
            oracle_qc.x(n)
    
    oracle_gate = oracle_qc.to_gate()
    oracle_gate.name = "Oracle" # To show when we display the circuit
    return oracle_gate
 try
Let's also create a function that takes this oracle gate and performs the Deutsch-Joza algorithm on it:

def dj_algorithm(oracle, n):
    dj_circuit = QuantumCircuit(n+1, n)
    # Set up the output qubit:
    dj_circuit.x(n)
    dj_circuit.h(n)
    # And set up the input register:
    for qubit in range(n):
        dj_circuit.h(qubit)
    # Let's append the oracle gate to our circuit:
    dj_circuit.append(oracle, range(n+1))
    # Finally, perform the H-gates again and measure:
    for qubit in range(n):
        dj_circuit.h(qubit)
    
    for i in range(n):
        dj_circuit.measure(i, i)
    
    return dj_circuit
 try
Finally, let's use these functions to play around with the algorithm:

n = 4
oracle_gate = dj_oracle('balanced', n)
dj_circuit = dj_algorithm(oracle_gate, n)
dj_circuit.draw()
 try
And see the results of running this circuit:

results = execute(dj_circuit, backend=backend, shots=1024).result()
answer = results.get_counts()
plot_histogram(answer)
 try
5. Experiment with Real Devices 

We can run the circuit on the real device as shown below. We first look for the least-busy device that can handle our circuit.

# Load our saved IBMQ accounts and get the least busy backend device with greater than or equal to (n+1) qubits
IBMQ.load_account()
provider = IBMQ.get_provider(hub='ibm-q')
backend = least_busy(provider.backends(filters=lambda x: x.configuration().n_qubits &gt;= (n+1) and
                                   not x.configuration().simulator and x.status().operational==True))
print("least busy backend: ", backend)
 try
least busy backend:  ibmq_burlington
# Run our circuit on the least busy backend. Monitor the execution of the job in the queue
from qiskit.tools.monitor import job_monitor

shots = 1024
job = execute(dj_circuit, backend=backend, shots=shots, optimization_level=3)

job_monitor(job, interval = 2)
 try
Job Status: job has successfully run
# Get the results of the computation
results = job.result()
answer = results.get_counts()

plot_histogram(answer)
 try
As we can see, the most likely result is 1111. The other results are due to errors in the quantum computation.

6. Problems

Are you able to create a balanced or constant oracle of a different form?
from qiskit_textbook.problems import dj_problem_oracle
oracle = dj_problem_oracle(1)
 try
The function dj_problem_oracle (shown above) returns a Deutsch-Joza oracle for n = 4 in the form of a gate. The gate takes 5 qubits as input where the final qubit (q_4) is the output qubit (as with the example oracles above). You can get different oracles by giving dj_problem_oracle different integers between 1 and 5. Use the Deutsch-Joza algorithm to decide whether each oracle is balanced or constant (Note: It is highly recommended you try this example using the qasm_simulator instead of a real device).
7. References

David Deutsch and Richard Jozsa (1992). "Rapid solutions of problems by quantum computation". Proceedings of the Royal Society of London A. 439: 553–558. doi:10.1098/rspa.1992.0167.
R. Cleve; A. Ekert; C. Macchiavello; M. Mosca (1998). "Quantum algorithms revisited". Proceedings of the Royal Society of London A. 454: 339–354. doi:10.1098/rspa.1998.0164.
import qiskit
qiskit.__qiskit_version__
 try
{'qiskit-terra': '0.14.2',
 'qiskit-aer': '0.5.2',
 'qiskit-ignis': '0.3.3',
 'qiskit-ibmq-provider': '0.7.2',
 'qiskit-aqua': '0.7.3',
 'qiskit': '0.19.6'}
〈 Superdense Coding
Bernstein-Vazirani Algorithm 〉
This page was created by The Jupyter Book Community
Cookie Preferences and Do Not Sell My Info</Text>
        </Document>
        <Document ID="299E2AEA-17DA-4227-A68C-A743AB82E86D">
            <Title>Goldilocks and the Three Bears</Title>
            <Text>GOLDILOCKS AND THE THREE BEARS
There was once a little girl whose hair was so bright and yellow that it glittered in the sun like spun-gold. For this reason she was called Goldilocks.
One day Goldilocks went out into the meadows to gather flowers. She wandered on and on, and after a while she came to a forest, where she had never been before. She went on into the forest, and it was very cool and shady.
Presently she came to a little house, standing all alone in the forest, and as she was tired and thirsty she knocked at the door. She hoped the good people inside would give her a drink, and let her rest a little while.
Now, though Goldilocks did not know it, this house belonged to three bears. There was a GREAT BIG FATHER BEAR, and a middling-sized mother bear, and a dear little baby bear, no bigger than Goldilocks herself. But the three bears had gone out to take a walk in the forest while their supper was cooling, so when Goldilocks knocked at the door no one answered her.
She waited awhile and then she knocked again, and as still nobody answered her she pushed the door open and stepped inside. There in a row stood three chairs. One was a GREAT BIG CHAIR, and it belonged to the father bear. And one was a middling-sized chair, and it belonged to the mother bear, and one was a dear little chair, and it belonged to the baby bear. And on the table stood three bowls of smoking hot porridge. “And so,” thought Goldilocks, “the people must be coming back soon to eat it.”
She thought she would sit down and rest until they came, so first she sat down in the GREAT BIG CHAIR, but the cushion was too soft. It seemed as though it would swallow her up. Then she sat down in the middle-sized chair, and the cushion was too hard, and it was not comfortable. Then she sat down in the dear little chair, and it was just right, and fitted her as though it had been made for her. So there she sat, and she rocked and she rocked, and she sat and she sat, until with her rocking and her sitting she sat the bottom right out of it.
And still nobody had come, and there stood the bowls of porridge on the table. “They can’t be very hungry people,” thought Goldilocks to herself, “or they would come home to eat their suppers.” And she went over to the table just to see whether the bowls were full.
The first bowl was a GREAT BIG BOWL with a GREAT BIG WOODEN SPOON in it, and that was the father bear’s bowl. The second bowl was a middle-sized bowl, with a middle-sized wooden spoon in it, and that was the mother bear’s bowl. And the third bowl was a dear little bowl, with a dear little silver spoon in it, and that was the baby bear’s bowl.
The porridge that was in the bowls smelled so very good that Goldilocks thought she would just taste it.
She took up the GREAT BIG SPOON, and tasted the porridge in the GREAT BIG BOWL, but it was too hot. Then she took up the middle-sized spoon and tasted the porridge in the middle-sized bowl, and it was too cold. Then she took up the little silver spoon and tasted the porridge in the dear little bowl, and it was just right, and it tasted so good that she tasted and tasted, and tasted and tasted until she tasted it all up.
After that she felt very sleepy, so she went upstairs and looked about her, and there were three beds all in a row. The first bed was the GREAT BIG BED that belonged to the father bear. And the second bed was a middling-sized bed that belonged to the mother bear, and the third bed was a dear little bed that belonged to the dear little baby bear.
Goldilocks lay down on the GREAT BIG BED to try it, but the pillow was too high, and she wasn’t comfortable at all.
Then she lay down on the middle-sized bed, and the pillow was too low, and that wasn’t comfortable either.
Then she lay down on the little baby bear’s bed and it was exactly right, and so very comfortable that she lay there and lay there until she went fast asleep.
Now while Goldilocks was still asleep in the little bed the three bears came home again, and as soon as they stepped inside the door and looked about them they knew that somebody had been there.
“SOMEBODY’S BEEN SITTING IN MY CHAIR,” growled the father bear in his great big voice, “AND LEFT THE CUSHION CROOKED.”
“And somebody’s been sitting in my chair,” said the mother bear, “and left it standing crooked.”
“And somebody’s been sitting in my chair,” squeaked the baby bear, in his shrill little voice, “and they’ve sat and sat till they’ve sat the bottom out”; and he felt very sad about it.
Then the three bears went over to the table to get their porridge.
“WHAT’S THIS!” growled the father bear, in his great big voice, “SOMEBODY’S BEEN TASTING MY PORRIDGE, AND LEFT THE SPOON ON THE TABLE.”
“And somebody’s been taking my porridge,” said the mother bear in her middle-sized voice, “and they’ve splashed it over the side.”
“And somebody’s been tasting my porridge,” squealed the baby bear, “and they’ve tasted and tasted until they’ve tasted it all up.” And when he said so the baby bear looked as if he were about to cry.
“If somebody’s been here they must be here still,” said the mother bear; so the three bears went upstairs to look.
First the father bear looked at his bed. “SOMEBODY’S BEEN LYING ON MY BED AND PULLED THE COVERS DOWN,” he growled in his great big voice.
Then the mother bear looked at her bed. “Somebody’s been lying on my bed and pulled the pillow off,” said she in her middle-sized voice.
Then the baby bear looked at his bed, and there lay little Goldilocks with her cheeks as pink as roses, and her golden hair all spread over the pillow.
“Somebody’s been lying in my bed,” squeaked the baby bear joyfully, “and here she is still!”
Now when Goldilocks in her dreams heard the great big father bear’s voice she dreamed it was the thunder rolling through the heavens.
And when she heard the mother bear’s middle-sized voice she dreamed it was the wind blowing through the trees.
But when she heard the baby bear’s voice it was so shrill and sharp that it woke her right up. She sat up in bed and there were the three bears standing around and looking at her.
“Oh, my goodness me!” cried Goldilocks. She tumbled out of bed and ran to the window. It was open, and out she jumped before the bears could stop her. Then home she ran as fast as she could, and she never went near the forest again. But the little baby bear cried and cried because he had wanted the pretty little girl to play with.

http://gutenberg.org/files/49001/49001-h/49001-h.htm</Text>
        </Document>
        <Document ID="EDBD6EB2-F631-4F75-B56A-314E5AB21CD9">
            <Title>Teleportation Algorithm</Title>
            <Text>Processing math: 100%
  
Learn Quantum Computation using Qiskit
What is Quantum?
0. Prerequisites
0.1 Setting Up Your Environment
0.2 Python and Jupyter Notebooks
1. Quantum States and Qubits
1.1 Introduction
1.2 The Atoms of Computation
1.3 Representing Qubit States
1.4 Single Qubit Gates
1.5 The Case for Quantum
2. Multiple Qubits and Entanglement
2.1 Introduction
2.2 Multiple Qubits and Entangled States
2.3 Phase Kickback
2.4 More Circuit Identities
2.5 Proving Universality
2.6 Classical Computation on a Quantum Computer
3. Quantum Protocols and Quantum Algorithms
3.1 Defining Quantum Circuits
3.2 Quantum Teleportation
3.3 Superdense Coding
3.4 Deutsch-Jozsa Algorithm
3.5 Bernstein-Vazirani Algorithm
3.6 Simon's Algorithm
3.7 Quantum Fourier Transform
3.8 Quantum Phase Estimation
3.9 Shor's Algorithm
3.10 Grover's Algorithm
3.11 Quantum Counting
3.12 Quantum Key Distribution
4. Quantum Algorithms for Applications
4.1 Applied Quantum Algorithms
4.1.1 Solving Linear Systems of Equations using HHL
4.1.2 Simulating Molecules using VQE
4.1.3 Solving combinatorial optimization problems using QAOA
4.1.4 Solving Satisfiability Problems using Grover's Algorithm
4.1.5 Hybrid quantum-classical Neural Networks with PyTorch and Qiskit
4.2 Implementations of Recent Quantum Algorithms
4.2.1 Variational Quantum Linear Solver
5. Investigating Quantum Hardware Using Quantum Circuits
5.1 Introduction to Quantum Error Correction using Repetition Codes
5.2 Measurement Error Mitigation
5.3 Randomized Benchmarking
5.4 Measuring Quantum Volume
6. Investigating Quantum Hardware Using Microwave Pulses
6.1 Calibrating Qubits with Qiskit Pulse
6.2 Accessing Higher Energy States
6.3 Introduction to Transmon Physics
6.4 Circuit Quantum Electrodynamics
7. Problem Sets &amp; Exercises
Set 1. Classical Logic Gates with Quantum Circuits
Set 2. Basic Synthesis of Single-Qubit Gates
Set 3. Building the Best AND Gate
8. Appendix
8.1 Linear Algebra
8.2 Qiskit
9. Games &amp; Demos
Hello Qiskit Game
Estimating Pi Using Quantum Phase Estimation Algorithm
Interactivity Index
Powered by Jupyter Book


Quantum Teleportation
This notebook demonstrates quantum teleportation. We first use Qiskit's built-in simulators to test our quantum circuit, and then try it out on a real quantum computer.

Contents

Overview
The Quantum Teleportation Protocol
Simulating the Teleportation Protocol
3.1 How will we Test this Result on a Real Quantum Computer?
3.2 Using the Statevector Simulator
3.3 Using the QASM Simulator
Understanding Quantum Teleportation
Teleportation on a Real Quantum Computer
5.1 IBM hardware and Deferred Measurement
5.2 Executing
References
1. Overview

Alice wants to send quantum information to Bob. Specifically, suppose she wants to send the qubit state |ψ⟩=α|0⟩+β|1⟩. This entails passing on information about α and β to Bob.

There exists a theorem in quantum mechanics which states that you cannot simply make an exact copy of an unknown quantum state. This is known as the no-cloning theorem. As a result of this we can see that Alice can't simply generate a copy of |ψ⟩ and give the copy to Bob. We can only copy classical states (not superpositions).

However, by taking advantage of two classical bits and an entangled qubit pair, Alice can transfer her state |ψ⟩ to Bob. We call this teleportation because, at the end, Bob will have |ψ⟩ and Alice won't anymore.

2. The Quantum Teleportation Protocol

To transfer a quantum bit, Alice and Bob must use a third party (Telamon) to send them an entangled qubit pair. Alice then performs some operations on her qubit, sends the results to Bob over a classical communication channel, and Bob then performs some operations on his end to receive Alice’s qubit.



We will describe the steps on a quantum circuit below. Here, no qubits are actually ‘sent’, you’ll just have to imagine that part!

First we set up our session:

# Do the necessary imports
import numpy as np
from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, BasicAer, IBMQ
from qiskit.visualization import plot_histogram, plot_bloch_multivector
from qiskit.extensions import Initialize
from qiskit_textbook.tools import random_state, array_to_latex
 try
and create our quantum circuit:

## SETUP
# Protocol uses 3 qubits and 2 classical bits in 2 different registers

qr = QuantumRegister(3, name="q")    # Protocol uses 3 qubits
crz = ClassicalRegister(1, name="crz") # and 2 classical bits
crx = ClassicalRegister(1, name="crx") # in 2 different registers
teleportation_circuit = QuantumCircuit(qr, crz, crx)
 try
Step 1 

A third party, Telamon, creates an entangled pair of qubits and gives one to Bob and one to Alice.

The pair Telamon creates is a special pair called a Bell pair. In quantum circuit language, the way to create a Bell pair between two qubits is to first transfer one of them to the X-basis (|+⟩ and |−⟩) using a Hadamard gate, and then to apply a CNOT gate onto the other qubit controlled by the one in the X-basis.

def create_bell_pair(qc, a, b):
    """Creates a bell pair in qc using qubits a &amp; b"""
    qc.h(a) # Put qubit a into state |+&gt;
    qc.cx(a,b) # CNOT with a as control and b as target
 try
## SETUP
# Protocol uses 3 qubits and 2 classical bits in 2 different registers
qr = QuantumRegister(3, name="q")
crz, crx = ClassicalRegister(1, name="crz"), ClassicalRegister(1, name="crx")
teleportation_circuit = QuantumCircuit(qr, crz, crx)

## STEP 1
# In our case, Telamon entangles qubits q1 and q2
# Let's apply this to our circuit:
create_bell_pair(teleportation_circuit, 1, 2)
# And view the circuit so far:
teleportation_circuit.draw()
 try
Let's say Alice owns q1 and Bob owns q2 after they part ways.

Step 2 

Alice applies a CNOT gate to q1, controlled by |ψ⟩ (the qubit she is trying to send Bob). Then Alice applies a Hadamard gate to |ψ⟩. In our quantum circuit, the qubit (|ψ⟩) Alice is trying to send is q0:

def alice_gates(qc, psi, a):
    qc.cx(psi, a)
    qc.h(psi)
 try
## SETUP
# Protocol uses 3 qubits and 2 classical bits in 2 different registers
qr = QuantumRegister(3, name="q")
crz, crx = ClassicalRegister(1, name="crz"), ClassicalRegister(1, name="crx")
teleportation_circuit = QuantumCircuit(qr, crz, crx)

## STEP 1
create_bell_pair(teleportation_circuit, 1, 2)

## STEP 2
teleportation_circuit.barrier() # Use barrier to separate steps
alice_gates(teleportation_circuit, 0, 1)
teleportation_circuit.draw()
 try
Step 3 

Next, Alice applies a measurement to both qubits that she owns, q1 and |ψ⟩, and stores this result in two classical bits. She then sends these two bits to Bob.

def measure_and_send(qc, a, b):
    """Measures qubits a &amp; b and 'sends' the results to Bob"""
    qc.barrier()
    qc.measure(a,0)
    qc.measure(b,1)
 try
## SETUP
# Protocol uses 3 qubits and 2 classical bits in 2 different registers
qr = QuantumRegister(3, name="q")
crz, crx = ClassicalRegister(1, name="crz"), ClassicalRegister(1, name="crx")
teleportation_circuit = QuantumCircuit(qr, crz, crx)

## STEP 1
create_bell_pair(teleportation_circuit, 1, 2)

## STEP 2
teleportation_circuit.barrier() # Use barrier to separate steps
alice_gates(teleportation_circuit, 0, 1)

## STEP 3
measure_and_send(teleportation_circuit, 0 ,1)
teleportation_circuit.draw()
 try
Step 4 

Bob, who already has the qubit q2, then applies the following gates depending on the state of the classical bits:

00 → Do nothing

01 → Apply X gate

10 → Apply Z gate

11 → Apply ZX gate

(Note that this transfer of information is purely classical.)

# This function takes a QuantumCircuit (qc), integer (qubit)
# and ClassicalRegisters (crz &amp; crx) to decide which gates to apply
def bob_gates(qc, qubit, crz, crx):
    # Here we use c_if to control our gates with a classical
    # bit instead of a qubit
    qc.x(qubit).c_if(crx, 1) # Apply gates if the registers 
    qc.z(qubit).c_if(crz, 1) # are in the state '1'
 try
## SETUP
# Protocol uses 3 qubits and 2 classical bits in 2 different registers
qr = QuantumRegister(3, name="q")
crz, crx = ClassicalRegister(1, name="crz"), ClassicalRegister(1, name="crx")
teleportation_circuit = QuantumCircuit(qr, crz, crx)

## STEP 1
create_bell_pair(teleportation_circuit, 1, 2)

## STEP 2
teleportation_circuit.barrier() # Use barrier to separate steps
alice_gates(teleportation_circuit, 0, 1)

## STEP 3
measure_and_send(teleportation_circuit, 0, 1)

## STEP 4
teleportation_circuit.barrier() # Use barrier to separate steps
bob_gates(teleportation_circuit, 2, crz, crx)
teleportation_circuit.draw()
 try
And voila! At the end of this protocol, Alice's qubit has now teleported to Bob.

3. Simulating the Teleportation Protocol

3.1 How Will We Test the Protocol on a Quantum Computer?

In this notebook, we will initialize Alice's qubit in a random state |ψ⟩ (psi). This state will be created using an Initialize gate on |q0⟩. In this chapter we use the function random_state to choose psi for us, but feel free to set psi to any qubit state you want.

# Create random 1-qubit state
psi = random_state(1)

# Display it nicely
array_to_latex(psi, pretext="|\\psi\\rangle =")
# Show it on a Bloch sphere
plot_bloch_multivector(psi)
 try
|ψ⟩=[ 0.16706−0.42866i	0.70336+0.54187i ]
Let's create our initialization gate to create |ψ⟩ from the state |0⟩:

init_gate = Initialize(psi)
init_gate.label = "init"
 try
If the quantum teleportation circuit works, then at the end of the circuit the qubit |q2⟩ will be in this state. We will check this using the statevector simulator.

3.2 Using the Statevector Simulator 

We can use the statevector simulator to verify our qubit has been teleported.

## SETUP
qr = QuantumRegister(3, name="q")   # Protocol uses 3 qubits
crz = ClassicalRegister(1, name="crz") # and 2 classical registers
crx = ClassicalRegister(1, name="crx")
qc = QuantumCircuit(qr, crz, crx)

## STEP 0
# First, let's initialize Alice's q0
qc.append(init_gate, [0])
qc.barrier()

## STEP 1
# Now begins the teleportation protocol
create_bell_pair(qc, 1, 2)
qc.barrier()

## STEP 2
# Send q1 to Alice and q2 to Bob
alice_gates(qc, 0, 1)

## STEP 3
# Alice then sends her classical bits to Bob
measure_and_send(qc, 0, 1)

## STEP 4
# Bob decodes qubits
bob_gates(qc, 2, crz, crx)

# Display the circuit
qc.draw()
 try
At the time of writing, there is a rendering issue with the Initialize gate in the image above, but the circuit operates just fine. We can see below, using our statevector simulator, that the state of |q2⟩ is the same as the state |ψ⟩ we created above, while the states of |q0⟩ and |q1⟩ have been collapsed to either |0⟩ or |1⟩. The state |ψ⟩ has been teleported from qubit 0 to qubit 2.

backend = BasicAer.get_backend('statevector_simulator')
out_vector = execute(qc, backend).result().get_statevector()
plot_bloch_multivector(out_vector)
 try
You can run this cell a few times to make sure. You may notice that the qubits 0 &amp; 1 change states, but qubit 2 is always in the state |ψ⟩.

3.3 Using the QASM Simulator 

Quantum teleportation is designed to send qubits between two parties. We do not have the hardware to demonstrate this, but we can demonstrate that the gates perform the correct transformations on a single quantum chip. Here we use the QASM simulator to simulate how we might test our protocol.

On a real quantum computer, we would not be able to sample the statevector, so if we wanted to check our teleportation circuit is working, we need to do things slightly differently. You will remember that we used Initialize to turn our |0⟩ qubit into the state |ψ⟩:

|0⟩ 
Initialize
→
 |ψ⟩
Since all quantum gates are reversible, we can find the inverse of Initialize using:

inverse_init_gate = init_gate.gates_to_uncompute()
 try
This operation has the property:

|ψ⟩ 
Inverse Initialize
→
 |0⟩
To prove the qubit |q0⟩ has been teleported to |q2⟩, if we do this inverse initialization on |q2⟩, we expect to measure |0⟩ with certainty. We do this in the circuit below:

## SETUP
qr = QuantumRegister(3, name="q")   # Protocol uses 3 qubits
crz = ClassicalRegister(1, name="crz") # and 2 classical registers
crx = ClassicalRegister(1, name="crx")
qc = QuantumCircuit(qr, crz, crx)

## STEP 0
# First, let's initialize Alice's q0
qc.append(init_gate, [0])
qc.barrier()

## STEP 1
# Now begins the teleportation protocol
create_bell_pair(qc, 1, 2)
qc.barrier()

## STEP 2
# Send q1 to Alice and q2 to Bob
alice_gates(qc, 0, 1)

## STEP 3
# Alice then sends her classical bits to Bob
measure_and_send(qc, 0, 1)

## STEP 4
# Bob decodes qubits
bob_gates(qc, 2, crz, crx)

## STEP 5
# reverse the initialization process
qc.append(inverse_init_gate, [2])

# Display the circuit
qc.draw()
 try
Again, there is a rendering issue with the inverse_init_gate (called 'disentangler' on the circuit diagram), but we can clearly see the gate appearing in the image. Finally, we measure the third qubit and store the result in the third classical bit:

# Need to add a new ClassicalRegister
# to see the result
cr_result = ClassicalRegister(1)
qc.add_register(cr_result)
qc.measure(2,2)
qc.draw()
 try
and we run our experiment:

backend = BasicAer.get_backend('qasm_simulator')
counts = execute(qc, backend, shots=1024).result().get_counts()
plot_histogram(counts)
 try
We can see we have a 100% chance of measuring q2 (the leftmost bit in the string) in the state |0⟩. This is the expected result, and indicates the teleportation protocol has worked properly.

4. Understanding Quantum Teleportation

As you have worked with the Quantum Teleportation's implementation, it is time to understand the mathematics behind the protocol.

Step 1 

Quantum Teleportation begins with the fact that Alice needs to transmit |q⟩=a|0⟩+b|1⟩ (a random qubit) to Bob. She doesn't know the state of the qubit. For this, Alice and Bob take the help of a third party (Telamon). Telamon prepares a pair of entangled qubits for Alice and Bob. The entangled qubits could be written in Dirac Notation as:

|ψ⟩=
1
√
2
 
(|00⟩+|11⟩)
Alice and Bob each possess one qubit of the entangled pair (denoted as A and B respectively),

|ψ⟩=
1
√
2
 
(|0⟩A|0⟩B+|1⟩A|1⟩B)
This creates a three qubit quantum system where Alice has the first two qubits and Bob the last one.

|q⟩⊗|ψ⟩	=
1
√
2
 
(a|0⟩⊗(|00⟩+|11⟩)+b|1⟩⊗(|00⟩+|11⟩))		=
1
√
2
 
(a|000⟩+a|011⟩+b|100⟩+b|111⟩) 
Step 2 

Now according to the protocol Alice applies CNOT gate on her two qubits followed by Hadamard gate on the first qubit. This results in the state:

(H⊗I⊗I)(CNOT⊗I)(|q⟩⊗|ψ⟩)	=(H⊗I⊗I)(CNOT⊗I)
1
√
2
 
(a|000⟩+a|011⟩+b|100⟩+b|111⟩)		=(H⊗I⊗I)
1
√
2
 
(a|000⟩+a|011⟩+b|110⟩+b|101⟩)		=
1
2
 
(a(|000⟩+|011⟩+|100⟩+|111⟩)+b(|010⟩+|001⟩−|110⟩−|101⟩)) 
Which can then be separated and written as:

=
1
2
 
(	|00⟩(a|0⟩+b|1⟩)
+|01⟩(a|1⟩+b|0⟩)
+|10⟩(a|0⟩−b|1⟩)
+|11⟩(a|1⟩−b|0⟩)) 
Step 3 

Alice measures the first two qubit (which she owns) and sends them as two classical bits to Bob. The result she obtains is always one of the four standard basis states |00⟩,|01⟩,|10⟩, and |11⟩ with equal probability.

On the basis of her measurement, Bob's state will be projected to,
|00⟩→(a|0⟩+b|1⟩)|01⟩→(a|1⟩+b|0⟩)|10⟩→(a|0⟩−b|1⟩)|11⟩→(a|1⟩−b|0⟩)
.

Step 4 

Bob, on receiving the bits from Alice, knows he can obtain the original state |q⟩ by applying appropriate transformations on his qubit that was once part of the entangled pair.

The transformations he needs to apply are:



After this step Bob will have successfully reconstructed Alice's state.

5. Teleportation on a Real Quantum Computer

5.1 IBM hardware and Deferred Measurement

The IBM quantum computers currently do not support instructions after measurements, meaning we cannot run the quantum teleportation in its current form on real hardware. Fortunately, this does not limit our ability to perform any computations due to the deferred measurement principle discussed in chapter 4.4 of [1]. The principle states that any measurement can be postponed until the end of the circuit, i.e. we can move all the measurements to the end, and we should see the same results.



Any benefits of measuring early are hardware related: If we can measure early, we may be able to reuse qubits, or reduce the amount of time our qubits are in their fragile superposition. In this example, the early measurement in quantum teleportation would have allowed us to transmit a qubit state without a direct quantum communication channel.

While moving the gates allows us to demonstrate the "teleportation" circuit on real hardware, it should be noted that the benefit of the teleportation process (transferring quantum states via classical channels) is lost.

Let us re-write the bob_gates function to new_bob_gates:

def new_bob_gates(qc, a, b, c):
    qc.cz(a, c)
    qc.cx(b, c)
 try
And create our new circuit:

qc = QuantumCircuit(3,1)

# First, let's initialize Alice's q0
qc.append(init_gate, [0])
qc.barrier()

# Now begins the teleportation protocol
create_bell_pair(qc, 1, 2)
qc.barrier()
# Send q1 to Alice and q2 to Bob
alice_gates(qc, 0, 1)
qc.barrier()
# Alice sends classical bits to Bob
new_bob_gates(qc, 0, 1, 2)

# We undo the initialization process
qc.append(inverse_init_gate, [2])

# See the results, we only care about the state of qubit 2
qc.measure(2,0)

# View the results:
qc.draw()
 try
5.2 Executing 

# First, see what devices we are allowed to use by loading our saved accounts
IBMQ.load_account()
provider = IBMQ.get_provider(hub='ibm-q')
provider.backends()
 try
[&lt;IBMQSimulator('ibmq_qasm_simulator') from IBMQ(hub='ibm-q', group='open', project='main')&gt;,
 &lt;IBMQBackend('ibmqx2') from IBMQ(hub='ibm-q', group='open', project='main')&gt;,
 &lt;IBMQBackend('ibmq_16_melbourne') from IBMQ(hub='ibm-q', group='open', project='main')&gt;,
 &lt;IBMQBackend('ibmq_vigo') from IBMQ(hub='ibm-q', group='open', project='main')&gt;,
 &lt;IBMQBackend('ibmq_ourense') from IBMQ(hub='ibm-q', group='open', project='main')&gt;,
 &lt;IBMQBackend('ibmq_london') from IBMQ(hub='ibm-q', group='open', project='main')&gt;,
 &lt;IBMQBackend('ibmq_burlington') from IBMQ(hub='ibm-q', group='open', project='main')&gt;,
 &lt;IBMQBackend('ibmq_essex') from IBMQ(hub='ibm-q', group='open', project='main')&gt;,
 &lt;IBMQBackend('ibmq_armonk') from IBMQ(hub='ibm-q', group='open', project='main')&gt;]
# get the least-busy backend at IBM and run the quantum circuit there
from qiskit.providers.ibmq import least_busy
backend = least_busy(provider.backends(filters=lambda b: b.configuration().n_qubits &gt;= 3 and
                                   not b.configuration().simulator and b.status().operational==True))
job_exp = execute(qc, backend=backend, shots=8192)
 try
# Get the results and display them
exp_result = job_exp.result()
exp_measurement_result = exp_result.get_counts(qc)
print(exp_measurement_result)
plot_histogram(exp_measurement_result)
 try
{'1': 2428, '0': 5764}
As we see here, there are a few results in which we measured |1⟩. These arise due to errors in the gates and the qubits. In contrast, our simulator in the earlier part of the notebook had zero errors in its gates, and allowed error-free teleportation.

error_rate_percent = sum([exp_measurement_result[result] for result in exp_measurement_result.keys() if result[0]=='1']) \
                    * 100./ sum(list(exp_measurement_result.values()))
print("The experimental error rate : ", error_rate_percent, "%")
 try
The experimental error rate :  29.638671875 %
6. References

[1] M. Nielsen and I. Chuang, Quantum Computation and Quantum Information, Cambridge Series on Information and the Natural Sciences (Cambridge University Press, Cambridge, 2000).

[2] Eleanor Rieffel and Wolfgang Polak, Quantum Computing: a Gentle Introduction (The MIT Press Cambridge England, Massachusetts, 2011).

import qiskit
qiskit.__qiskit_version__
 try
{'qiskit-terra': '0.14.2',
 'qiskit-aer': '0.5.2',
 'qiskit-ignis': '0.3.3',
 'qiskit-ibmq-provider': '0.7.2',
 'qiskit-aqua': '0.7.3',
 'qiskit': '0.19.6'}
〈 Defining Quantum Circuits
Superdense Coding 〉
This page was created by The Jupyter Book Community</Text>
        </Document>
        <Document ID="B389321B-423A-450A-80A8-6C97796177FA">
            <Title>The Cowherd and the Weaver Girl
</Title>
            <Text>The Cowherd and the Weaver Girl
In late summer, the stars Altair and Vega are high in the night sky, and the Chinese tell the following love story, of which there are many variations:
#
A young cowherd named Niú Láng (牛郎), came across seven fairy sisters bathing in a lake. Encouraged by his mischievous companion the ox, he stole their clothes and waited to see what would happen. The fairy sisters elected the youngest and most beautiful sister Zhī Nǚ (织女) to retrieve their clothing. She agreed to do so, but since Niú Láng had seen her naked, she agreed to his request for marriage. She proved to be a wonderful wife, and Niú Láng to be a good husband. They lived happily and had two children. But the Goddess of Heaven (or in some versions, Zhī Nǚ’s mother) found out that Zhī Nǚ, a fairy girl, had married a mere mortal. The Goddess was furious and ordered Zhī Nǚ to return to heaven. (Alternatively, the Goddess forced the fairy back to her former duty of weaving colorful clouds, a task she neglected while living on earth with a mortal.) On Earth, Niú Láng was very upset that his wife had disappeared. Suddenly, his ox began to talk, telling him that if he killed it and put on its hide, he would be able to go up to Heaven to find his wife. Crying bitterly, he killed the ox, put on the skin, and carried his two beloved children off to Heaven to find Zhī Nǚ. The Goddess discovered this and was very angry. Taking out her hairpin, the Goddess scratched a wide river in the sky to separate the two lovers forever, thus forming the Milky Way between Altair and Vega.
Zhī Nǚ must sit forever on one side of the river, sadly weaving on her loom, while Niú Láng watches her from afar and takes care of their two children (his flanking stars β and γ Aquilae or by their Chinese names Hè Gu 1 and Hè Gu 3).
But once a year all the magpies in the world would take pity on them and fly up into heaven to form a bridge (鵲橋, "the bridge of magpies", Que Qiao) over the star Deneb in the Cygnus constellation so the lovers may be together for a single night, which is the seventh night of the seventh moon.</Text>
        </Document>
        <Document ID="8A486C95-748E-441D-BC1F-B2D97E794246">
            <Title>rspa.1998.0164</Title>
            <Text>  Quantum algorithms revisited
By R. Cleve1, A. Ekert2, C. Macchiavello2,3 and M. Mosca2,4
1Department of Computer Science, University of Calgary, Calgary, Alberta, Canada T2N 1N4
2Clarendon Laboratory, Department of Physics, University of Oxford, Parks Road, Oxford OX1 3PU, UK
3I.S.I. Foundation, Villa Gualino, Viale Settimio Severo 65, 1033 Torino, Italy
4Mathematical Institute, University of Oxford, 24–29 St. Giles’, Oxford OX1 3LB, UK
Quantum computers use the quantum interference of different computational paths to enhance correct outcomes and suppress erroneous outcomes of computations. A common pattern underpinning quantum algorithms can be identified when quantum computation is viewed as multiparticle interference. We use this approach to review (and improve) some of the existing quantum algorithms and to show how they are related to different instances of quantum phase estimation. We provide an explic- it algorithm for generating any prescribed interference pattern with an arbitrary precision.
Keywords: quantum computation; quantum factoring; quantum networks; quantum algorithms; quantum phase estimation
1. Introduction
Quantum computation is based on two quantum phenomena: quantum interference and quantum entanglement. Entanglement allows one to encode data into non-trivial multiparticle superpositions of some preselected basis states, and quantum inter- ference, which is a dynamical process, allows one to evolve initial quantum states (inputs) into final states (outputs) modifying intermediate multiparticle superpo- sitions in some prescribed way. Multiparticle quantum interference, unlike single- particle interference, does not have any classical analogue and can be viewed as an inherently quantum process.
It is natural to think of quantum computations as multiparticle processes (just as classical computations are processes involving several ‘particles’ or bits). It turns out that viewing quantum computation as multiparticle interferometry leads to a simple and a unifying picture of known quantum algorithms. In this language, quantum computers are basically multiparticle interferometers with phase shifts that result from operations of some quantum logic gates. To illustrate this point, consider, for example, a Mach–Zehnder interferometer (figure 1a).
A particle, say a photon, impinges on a half-silvered mirror, and, with some prob- ability amplitudes, propagates via two different paths to another half-silvered mirror which directs the particle to one of the two detectors. Along each path between the two half-silvered mirrors is a phase shifter. If the lower path is labelled as state |0⟩
Proc. R. Soc. Lond. A (1998) 454, 339–354 ⃝c 1998 The Royal Society Printed in Great Britain 339 TEX Paper
 
340 R. Cleve, A. Ekert, C. Macchiavello and M. Mosca
(a)
(b)
   φ
φ
φφφ
                     Figure 1. (a) Scheme of a Mach–Zehnder interferometer with two phase shifters. The interference pattern depends on the difference between the phase shifts in different arms of the interferometer. (b) The corresponding quantum network representation.
and the upper one as state |1⟩, then the state of the particle in between the half- silvered mirrors and after passing through the phase shifters is a superposition of the type 1/√2(|0⟩ + ei(φ1−φ0)|1⟩), where φ0 and φ1 are the settings of the two phase shifters. This is illustrated in figure 1a. The phase shifters in the two paths can be tuned to effect any prescribed relative phase shift φ = φ1 − φ0 and to direct the particle with probabilities 12 (1 + cos φ) and 12 (1 − cos φ), respectively, to detectors ‘0’ and ‘1’. The second half-silvered mirror effectively erases all information about the path taken by the particle (path |0⟩ or path |1⟩) which is essential for observing quantum interference in the experiment.
Let us now rephrase the experiment in terms of quantum logic gates. We identify the half-silvered mirrors with the single-qubit Hadamard transform (H), defined as
H√ H√
|0⟩ −→ 1/ 2(|0⟩ + |1⟩), |1⟩ −→ 1/ 2(|0⟩ − |1⟩). (1.1)
The Hadamard transform is a special case of the more general Fourier transform, which we shall consider in §4.
We view the phase shifter as a single-qubit gate. The resulting network correspond- ing to the Mach–Zehnder interferometer is shown in figure 1b. The phase shift can be ‘computed’ with the help of an auxiliary qubit (or a set of qubits) in a prescribed state |u⟩ and some controlled-U transformation where U|u⟩ = eiφ|u⟩ (see figure 2). Here, the controlled U means that the form of U depends on the logical value of the control qubit; for example, we can apply the identity transformation to the auxiliary qubits (i.e. do nothing) when the control qubit is in state |0⟩ and apply a prescribed U when the control qubit is in state |1⟩. The controlled-U operation must be followed by a transformation which brings all computational paths together, like the second half-silvered mirror in the Mach–Zehnder interferometer. This last step is essential to enable the interference of different computational paths to occur—for example, by applying a Hadamard transform. In our example, we can obtain the following sequence of transformations on the two qubits:
H√ c−U√iφ
|0⟩|u⟩ −→ 1/ 2(|0⟩ + |1⟩)|u⟩ −→ 1/ 2(|0⟩ + e |1⟩)|u⟩
H 1 1 iφ/2 −→ (cos( 2 φ)|0⟩ − i sin( 2 φ)|1⟩)e |u⟩.
(1.2)
We note that the state of the auxiliary register |u⟩, being an eigenstate of U, is not altered along this network, but its eigenvalue eiφ is ‘kicked back’ in front of the |1⟩ component in the first qubit. The sequence (1.2) is the exact simulation of the
Proc. R. Soc. Lond. A (1998)

Quantum algorithms revisited 341
φx Uf x
Figure 2. Network representation for the phase shift transformation of equation (1.2). Here, x is a label for the state of the first qubit.
Mach–Zehnder interferometer and, as we will illustrate in the following sections, the kernel of quantum algorithms.
The rest of the paper is organized as follows. In the next section, we discuss Deutsch’s problem (1985) which shows how differentiation between interference pat- terns (different phase shifts) can lead to the formulation of computational problems. Then, in § 3, we review, in a unified way, generalizations of Deutsch’s problem, and propose further ones. In §4, we discuss an alternative and convenient way to view the quantum Fourier transform. In §5, we propose an efficient method for phase estimation based on the quantum Fourier transform. In order to illustrate how some of the existing algorithms can be reformulated in terms of the multiparticle inter- ferometry and the phase estimation problem, in § 6 we rephrase Shor’s order-finding algorithm (used to factor) using the phase estimation approach. Finally, in §7, we present a universal construction which generates any desired interference pattern with arbitrary accuracy. We summarize the conclusions in § 8.
2. Deutsch’s problem
Since quantum phases in the interferometers can be introduced by some controlled- U operations, it is natural to ask whether effecting these operations can be described as an interesting computational problem. In this section, we illustrate how inter- ference patterns lead to computational problems that are well suited to quantum computations, by presenting the first such problem that was proposed by Deutsch (1985).
To begin with, suppose that the phase shifter in the Mach–Zehnder interferometer is set either to φ = 0 or to φ = π. Can we tell the difference? Of course we can. In fact, a single instance of the experiment determines the difference: for φ = 0 the particle always ends up in the detector ‘0’ and for φ = π always in the detector ‘1’. Deutsch’s problem is related to this effect.
Consider the Boolean functions f that map {0, 1} to {0, 1}. There are exactly four such functions: two constant functions (f(0) = f(1) = 0 and f(0) = f(1) = 1) and two ‘balanced’ functions (f(0) = 0, f(1) = 1 and f(0) = 1, f(1) = 0). Informally, in Deutsch’s problem, one is allowed to evaluate the function f only once and required to deduce from the result whether f is constant or balanced (in other words, whether the binary numbers f(0) and f(1) are the same or different). Note that we are not asked for the particular values f(0) and f(1) but for a global property of f. Classical intuition tells us that to determine this global property of f, we have to evaluate both f(0) and f(1) anyway, which involves evaluating f twice. We shall see that
Proc. R. Soc. Lond. A (1998)
        Uf
           
342 R. Cleve, A. Ekert, C. Macchiavello and M. Mosca
 (a)
(b)
        π
      this is not so in the setting of quantum information, where we can solve Deutsch’s problem with a single function evaluation, by employing an algorithm that has the same mathematical structure as the Mach–Zehnder interferometer.
Let us formally define the operation of ‘evaluating’ f in terms of the f-controlled- NOT operation on two bits: the first contains the input value and the second contains the output value. If the second bit is initialized to 0, the f -controlled-NOT maps (x, 0) to (x,f(x)). This is clearly just a formalization of the operation of computing f. In order to make the operation reversible, the mapping is defined for all initial settings of the two bits, taking (x, y) to (x, y ⊕ f (x)). Note that this operation is similar to the controlled-NOT (see, for example, Barenco et al. 1995), except that the second bit is negated when f(x) = 1, rather than when x = 1.
If one is only allowed to perform classically the f-controlled-NOT operation once, on any input from {0,1}2, then it is impossible to distinguish between balanced and constant functions in the following sense. Whatever the outcome, both possibilities (balanced and constant) remain for f. However, if quantum mechanical superposi- tions are allowed, then a single evaluation of the f-controlled-NOT suffices to classify f. Our quantum algorithm that accomplishes this is best represented as the quan- tum network shown in figure 3b, where the middle operation is the f-controlled-NOT, whose semantics in quantum mechanical notation are
f −c−N
|x⟩|y⟩ −→ |x⟩|y ⊕ f (x)⟩. (2.1)
The initial state of the qubits in the quantum network is |0⟩(|0⟩ − |1⟩) (apart from a normalization factor, which will be omitted in the following). After the first Hadamard transform, the state of the two qubits has the form (|0⟩ + |1⟩)(|0⟩ − |1⟩). To determine the effect of the f-controlled-NOT on this state, first note that, for each x ∈ {0, 1},
f −c−N f (x)
|x⟩(|0⟩ − |1⟩) −→ |x⟩(|0 ⊕ f (x)⟩ − |1 ⊕ f (x)⟩) = (−1) |x⟩(|0⟩ − |1⟩).
Therefore, the state after the f-controlled-NOT is ((−1)f(0)|0⟩ + (−1)f(1)|1⟩)(|0⟩ − |1⟩).
(2.2) (2.3)
That is, for each x, the |x⟩ term acquires a phase factor of (−1)f(x), which corresponds to the eigenvalue of the state of the auxiliary qubit under the action of the operator that sends |y⟩ to |y ⊕ f (x)⟩.
This state can also be written as
(−1)f(0)(|0⟩ + (−1)f(0)⊕f(1)|1⟩),
which, after applying the second Hadamard transform, becomes (−1)f(0)|f(0) ⊕ f(1)⟩.
Proc. R. Soc. Lond. A (1998)
(2.4) (2.5)
Uf
 Figure 3. Network representation of Deutsch’s algorithm.

Quantum algorithms revisited 343
Therefore, the first qubit is finally in state |0⟩ if the function f is constant, and in state |1⟩ if the function is balanced, and a measurement of this qubit distinguishes these cases with certainty.
This algorithm is an improved version of the first quantum algorithm for this prob- lem proposed by Deutsch (1985), which accomplishes the following. There are three possible outcomes: ‘balanced’, ‘constant’ and ‘inconclusive’. For any f, the algorithm has the property that, with probability 12 , it outputs ‘balanced’ or ‘constant’ (correct- ly corresponding to f), and, with probability 12, it outputs ‘inconclusive’ (in which case, no information is determined about f). This is a task that no classical com- putation can accomplish (with a single evaluation of the f-controlled-NOT gate). In comparison, our algorithm can be described as always producing the output ‘bal- anced’ or ‘constant’ (correctly). Tapp (1997, personal communication) independently discovered an algorithm for Deutsch’s problem that is similar to ours.
Deutsch’s result laid the foundation for the new field of quantum computation, and was followed by several other quantum algorithms for various problems, which all seem to rest on the same generic sequence: a Fourier transform, followed by an f- controlled-U , followed by another Fourier transform. (In some cases, such as Grover’s ‘database search’ algorithm (1996), this sequence is a critical component to a larger algorithm (see Appendix B)). We illustrate this point by reviewing several of these other algorithms in the sections that follow.
3. Generalizations of Deutsch’s problem
Deutsch’s original problem was subsequently generalized by Deutsch &amp; Jozsa (1992) for Boolean functions f : {0,1}n → {0,1} in the following way. Assume that, for one of these functions, it is ‘promised’ that it is either constant or balanced (i.e. has an equal number of 0 outputs as 1s), and consider the goal of determining which of the two properties the function actually has.
How many evaluations of f are required to do this? Any classical algorithm for this problem would, in the worst case, require 2n−1 +1 evaluations of f before determining the answer with certainty. There is a quantum algorithm that solves this problem with a single evaluation of f . The algorithm is presented in figure 4, where the control register is now composed of n qubits, all initially in state |0⟩, denoted as |00···0⟩, and, as in the quantum algorithm for Deutsch’s simple problem, an auxiliary qubit is employed, which is initially set to the state |0⟩ − |1⟩ and is not altered during the computation. Also, the n-qubit Hadamard transform H is defined as
for all x ∈ {0,1}n, where
y∈{0,1}n
x·y=(x1 ∧y1)⊕···⊕(xn ∧yn)
|x⟩ −→
(−1) |y⟩,
H 􏰸 x·y
(3.1)
(3.2)
(i.e. the scalar product modulo two). This is equivalent to performing a one-qubit Hadamard transform on each of the n qubits individually. The actual computation of the function f is by means of an f-controlled-NOT gate (the middle gate in figure 4), which acts as
f −c−N
|x⟩|y⟩ −→ |x⟩|y ⊕ f (x)⟩. (3.3)
This is similar to equation (2.1), except that now x ∈ {0, 1}n . Proc. R. Soc. Lond. A (1998)

344 R. Cleve, A. Ekert, C. Macchiavello and M. Mosca
Uf
Figure 4. Network representation of Deutsch–Jozsa’s and Bernstein–Vazirani’s algorithms.
Stepping through the execution of the network, the state after the first n-qubit Hadamard transform is applied is
                    |x⟩(|0⟩ − |1⟩), which, after the f-controlled-NOT gate, is
􏰸 (−1)f(x)|x⟩(|0⟩ − |1⟩). x∈{0,1}n
Finally, after the last Hadamard transform, the state is
􏰸
(3.4)
(3.5)
􏰸
x∈{0,1}n
(−1)f(x)⊕(x·y)|y⟩(|0⟩ − |1⟩).
Note that the amplitude of |00···0⟩ is 􏰶 ((−1)f(x))/2n, so if f is constant
simple form
Proc. R. Soc. Lond. A (1998)
􏰸 (−1)(a·x)⊕b|x⟩(|0⟩ − |1⟩), (3.8) x∈{0,1}n
x,y∈{0,1}n
x∈{0,1}n
then this state is (−1)f(00···0)|00···0⟩(|0⟩ − |1⟩); whereas, if f is balanced then,
for the state of the first n qubits, the amplitude of |00···0⟩ is zero. Therefore, by measuring the first n qubits, it can be determined with certainty whether f is constant or balanced. Note that, as in Deutsch’s simple example, this entails a single f-controlled-NOT operation. (This is a slight improvement of Deutsch &amp; Jozsa’s original algorithm, which involves two f-controlled-NOT operations.)
Following Deutsch &amp; Jozsa, Bernstein &amp; Vazirani (1993) formulated a variation of the above problem that can be solved with the same network. Suppose that f : {0,1}n → {0,1} is of the form
f(x)=(a1 ∧x1)⊕···⊕(an ∧xn)⊕b=(a·x)⊕b, (3.7)
where a ∈ {0,1}n and b ∈ {0,1}, and consider the goal of determining a. Note that such a function is constant if a = 00···0 and balanced otherwise (though a balanced function need not be of this form). Furthermore, the classical determination of a requires at least n f-controlled-NOT operations (since a contains n bits of information and each classical evaluation of f yields a single bit of information). Nevertheless, by running the quantum network given in figure 4, it is possible to determine a with a single f-controlled-NOT operation.
The initial conditions are the same as above. In this case, equation (3.5) takes the
(3.6)

Quantum algorithms revisited 345 which, after the final Hadamard transform, becomes
(−1)b 􏰸 (−1)x·(a⊕y)|y⟩(|0⟩ − |1⟩), (3.9) x,y∈{0,1}n
which is equivalent to (−1)b|a⟩(|0⟩−|1⟩). Thus, a measurement of the control register yields the value of a. (Bernstein &amp; Vazirani’s algorithm is similar to the above, except that it employs two f-controlled-NOT operations instead of one. Also, this problem, and its solution, is very similar to the search problems considered by Terhal &amp; Smolin (1997).)
The network construction presented in this section (figure 4) can be generalized to the case of a Boolean function f : {0,1}n → {0,1}m (with m 􏱁 n), with the promise that the parity of the elements in the range of f is either constant or evenly balanced (i.e. its output values all have the same parity, or half of them have parity 0 and half have parity 1). In this case, by choosing an auxiliary register composed of m qubits, and setting all of them in the initial state (|0⟩ − |1⟩), it is possible to solve the problem with certainty in one run of the network. As in the above case, the function is constant when the n qubits of the first register are detected in state |00 · · · 0⟩, and evenly balanced otherwise.
A particular subclass of the above functions consists of those that are of the form f(x) = (A·x)⊕b, where A is an m×n binary matrix, b is a binary m-tuple and ⊕ is applied bitwise (this can be thought of as an affine linear function in modulo-two arithmetic). The output string of f has constant parity if (11 · · · 1) · A = (00 · · · 0) and has balanced parity otherwise. It is possible to determine all the entries of A by evaluating the function f only m times, via a suitable multiqubit f-controlled-NOT gate of the form
f −c−N
|x⟩|y⟩ −→ |x⟩|y ⊕ f (x)⟩, (3.10)
where x ∈ {0, 1}n and y ∈ {0, 1}m. The network described below is a generalization of that in figure 4, and determines the n-tuple c · A, where c is any binary m-tuple. The auxiliary register is composed of m qubits, which are initialized to the state
(|0⟩ + (−1)c1 |1⟩)(|0⟩ + (−1)c2 |1⟩) · · · (|0⟩ + (−1)cm |1⟩). (3.11)
(This state can be ‘computed’ by first setting the auxiliary register to the state |c1 c2 · · · cm ⟩ and then applying a Hadamard transform to it.) The n-qubit control register is initialized in state |00 · · · 0⟩, and then a Hadamard transform is applied to it. Then the f-controlled-NOT operation is performed, and is followed by another Hadamard transform to the control register. It is straightforward to show that the control register will then reside in the state |c · A⟩. By running the network m times with suitable choices for c, all the entries of A can be determined. Høyer (1997) independently solved a problem that is similar to the above, except that f is an Abelian group homomorphism, rather than an affine linear function.
4. Another look at the quantum Fourier transform
The quantum Fourier transform (QFT) on the additive group of integers modulo 2m is the mapping
Proc. R. Soc. Lond. A (1998)
2m −1
F2m 􏰸 (2πiay)/2m
y=0
(4.1)
|a⟩ −→
e |y⟩,

346 R. Cleve, A. Ekert, C. Macchiavello and M. Mosca
Figure 5. A network for F2m shown acting on the basis state |a1a2 ···am⟩. At the end, the order of the output qubits is reversed (not shown in diagram).
where a ∈ {0, . . . , 2m − 1} (Coppersmith 1994). Let a be represented in binary as a1 ···am ∈ {0,1}m, where a = 2m−1a1 +2m−2a2 +···+21am−1 +20am (and similarly for y).
It is interesting to note that the state (4.1) is unentangled, and can in fact be factorized as
(|0⟩+e2πi(0.am)|1⟩)(|0⟩+e2πi(0.am−1am)|1⟩)···(|0⟩+e2πi(0.a1a2...am)|1⟩). (4.2)
This follows from the fact that
e2πiay/2m |y1 · · · ym⟩ = e2πi(0.am)y1 |y1⟩e2πi(0.am−1am)y2 |y2⟩ · · · e2πi(0.a1a2...am)ym |ym⟩,
 so the coefficient of |y1y2 · · · ym⟩ in (4.1) matches that in (4.2). A network for computing F2n is shown in figure 5.
In the above network, Rk denotes the unitary transformation
􏰔􏰕
R=10. (4.4) k 0 e2πi/2k
We now show that the network shown in figure 5 produces the state (4.1). The initial state is |a⟩ = |a1a2 · · · am⟩ (and a/2m = 0.a1a2 . . . am in binary). Applying H to the first qubit in |a1 · · · am⟩ produces the state
(|0⟩+e2πi(0.a1)|1⟩)|a2 ···am⟩. Then applying the controlled R2 changes the state to
(|0⟩+e2πi(0.a1a2)|1⟩)|a2 ···am⟩. Next, the controlled R3 produces
(|0⟩+e2πi(0.a1a2a3)|1⟩)|a2 ···am⟩, and so on, until the state is
(|0⟩+e2πi(0.a1...am)|1⟩)|a2 ···am⟩.
The next H yields
(|0⟩+e2πi(0.a1···am)|1⟩)(|0⟩+e2πi(0.a2)|1⟩)|a3 ···am⟩
and the controlled R2 to Rm−1 yield (|0⟩+e2πi(0.a1···am)|1⟩)(|0⟩+e2πi(0.a2···am)|1⟩)|a3 ···am⟩.
Proc. R. Soc. Lond. A (1998)
(4.5)
(4.3)

Quantum algorithms revisited 347 Continuing in this manner, the state eventually becomes
(|0⟩+e2πi(0.a1···am)|1⟩)(|0⟩+e2πi(0.a2···am)|1⟩)···(|0⟩+e2πi(0.am)|1⟩),
which, when the order of the qubits is reversed, is state (4.2).
Note that, if we do not know a1 · · · am, but are given a state of the form (4.2), then
a1 · · · am can be easily extracted by applying the inverse of the QFT to the state, which will yield the state |a1 · · · am ⟩.
5. A scenario for estimating arbitrary phases
In § 1, we noted that differences in phase shifts by π can, in principle, be detected exactly by interferometry, and by quantum computations. In §§ 2 and 3, we reviewed powerful computational tasks that can be performed by quantum computers, based on the mathematical structure of detecting these phase differences. In this section, we consider the case of arbitrary phase differences, and show in simple terms how to obtain good estimators for them, via the quantum Fourier transform. This phase estimation plays a central role in the fast quantum algorithms for factoring and for finding discrete logarithms discovered by Shor (1994). This point has been nicely emphasized by the quantum algorithms presented by Kitaev (1995) for the Abelian stabilizer problem.
Suppose that U is any unitary transformation on n qubits and |ψ⟩ is an eigenvector of U with eigenvalue e2πiφ, where 0 􏱁 φ &lt; 1. Consider the following scenario. We do not explicitly know U or |ψ⟩ or e2πiφ, but instead are given devices that perform controlled-U, controlled-U21, controlled-U22 (and so on) operations. Also, assume that we are given a single preparation of the state |ψ⟩. From this, our goal is to obtain an m-bit estimator of φ.
This can be solved as follows. First, apply the network of figure 6. This network produces the state
2m −1 (|0⟩+e2πi2m−1φ|1⟩)(|0⟩+e2πi2m−2φ|1⟩)···(|0⟩+e2πiφ|1⟩)= 􏰸 e2πiφy|y⟩. (5.1)
y=0
As noted in the last section, in the special case where φ = 0.a1 · · · am, the state |a1 · · · am⟩ (and hence φ) can be obtained by just applying the inverse of the QFT (which is the network of figure 5 in the backwards direction). This will produce the state |a1 · · · am ⟩ exactly (and hence φ).
However, φ is not in general a fraction of a power of two (and may not even be a rational number). For such a φ, it turns out that applying the inverse of the QFT produces the best m-bit approximation of φ with probability at least 4/π2 = 0.405.... To see why this is so, let a/2m = 0.a1 ···am be the best m-bit estimate of φ. Then φ = a/2m + δ, where 0 &lt; |δ| 􏱁 1/2m+1. Applying the inverse QFT to state (5.1) yields the state
1
2m
m
1 2m
2m
x=0 y=0
mm
2m−1 2m−1
􏰸 􏰸 e(−2πixy)/2
x=0 y=0
2m−1 2m−1
􏰸 􏰸 e(−2πixy)/2 e2πi(a/2 +δ)y |x⟩
Proc. R. Soc. Lond. A (1998)
e2πiφy |x⟩ =
= 1 􏰸 􏰸 e(2πi(a−x)y)/2 e2πiδy|x⟩ (5.2)
x=0 y=0 2m−1 2m−1
m

348 R. Cleve, A. Ekert, C. Macchiavello and M. Mosca
Figure 6. A network illustrating estimation of phase φ with m-bit precision. The same network forms the kernel of the order-finding algorithm discussed in § 6.
(for clarity, we are now including the normalization factors) and the coefficient of |a1 · · · am⟩ in the above is the geometric series
 􏰑
Since |δ| 􏱁 1/2m+1, it follows that |2πδ2m| 􏱁 π, and thus |1 − e2πiδ2m | 􏱂 |2πδ2m|/12 π = |4δ2m|. Also, |1 − e2πiδ| 􏱁 |2πδ|. Therefore, the probability of observ- ing a1 · · · am when measuring the state is
􏰴􏰴 1 􏰐1 − (e2πiδ)2m 􏰑􏰴􏰴2 􏰐 1 􏰐4δ2m 􏰑􏰑2 4
􏰴􏰴2m 1−e2πiδ 􏰴􏰴􏱂 2m 2πδ =π2. (5.4)
Note that the above algorithm (described by networks in figures 5 and 6) consists of m controlled-U2k operations, and O(m2) other operations.
In many contexts (such as that of the factoring algorithm of Shor), the above positive probability of success is sufficient to be useful; however, in other contexts, a higher probability of success may be desirable. The success probability can be amplified to 1−ε for any ε &gt; 0 by inflating m to m′ = m+O(log(1/ε)), and rounding off the resulting m′-bit string to its most significant m bits. The details of the analysis are in Appendix C.
The above approach was motivated by the method proposed by Kitaev (1995), which involves a sequence of repetitions for each unit U2j. The estimation of φ can also be obtained by other methods, such as the techniques studied for optimal state estimation by Massar &amp; Popescu (1995), Derka et al. (1997) and the techniques studied for use in frequency standards by Huelga et al. (1997). Also, it should be noted that the QFT, and its inverse, can be implemented in the fault tolerant ‘semiclassical’ way (see Griffiths &amp; Niu 1996).
6. The order-finding problem
In this section, we show how the scheme from the previous section can be applied to solve the order-finding problem, where one is given positive integers a and N which are relatively prime and such that a &lt; N, and the goal is to find the minimum positive integer r such that ar mod N = 1. There is no known classical procedure for doing this in time polynomial in n, where n is the number of bits of N. Shor (1994) presented a polynomial–time quantum algorithm for this problem, and noted that,
Proc. R. Soc. Lond. A (1998)
􏰐
1 􏰸 2πiδ y 1 1−(e2πiδ)2
 2m
(e ) =2m 1−e2πiδ
. (5.3)
2m −1 y=0
m
 
Quantum algorithms revisited 349
since there is an efficient classical randomized reduction from the factoring problem to order-finding, there is a polynomial–time quantum algorithm for factoring. Also, the quantum order-finding algorithm can be used directly to break the RSA cryptosystem (see Appendix A).
Let us begin by assuming that we are also supplied with a prepared state of the form
r−1
|ψ1⟩ = 􏰸 e(−2πij)/r|aj mod N⟩. (6.1)
j=0
Such a state is not at all trivial to fabricate; we shall see how this difficulty is circum-
vented later. Consider the unitary transformation U that maps |x⟩ to |axmodN⟩. Note that |ψ1⟩ is an eigenvector of U with eigenvalue e2πi(1/r). Also, for any j, it is possible to implement a controlled-U2j gate in terms of O(n2) elementary gates. Thus, using the state |ψ1⟩ and the implementation of controlled-U2j gates, we can directly apply the method of §5 to efficiently obtain an estimator of 1/r that has 2n bits of precision with high probability. This is sufficient precision to extract r.
The problem with the above method is that we are aware of no straightforward efficient method to prepare state |ψ1⟩. Let us now suppose that we have a device for the following kind of state preparation. When executed, the device produces a state of the form
r−1
|ψk⟩ = 􏰸 e(−2πikj)/r|aj mod N⟩, (6.2)
j=0
where k is randomly chosen (according to the uniform distribution) from {1, . . . , r}. We shall first show that this is also sufficient to efficiently compute r, and then later address the issue of preparing such states. For each k ∈ {1,...,r}, the eigenvalue of state |ψk⟩ is e2πi(k/r), and we can again use the technique from §5 to efficiently determine k/r with 2n bits of precision. From this, we can extract the quantity k/r exactly by the method of continued fractions. If k and r happen to be coprime then this yields r; otherwise, we might only obtain a divisor of r. Note that we can efficient- ly verify whether or not we happen to have obtained r by checking if ar mod N = 1. If verification fails then the device can be used again to produce another |ψk⟩. The expected number of random trials until k is coprime to r is O(log log(N )) = O(log n).
In fact, the expected number of trials for the above procedure can be improved to a constant. This is because, given any two independent trials which yield k1/r and k2/r, it suffices for k1 and k2 to be coprime to extract r (which is then the least common denominator of the two quotients). The probability that k1 and k2 are coprime is bounded below by
1− 􏰸 Pr[pdividesk1]Pr[pdividesk2]􏱂1− 􏰸 1/p2 &gt;0.54. (6.3) p prime p prime
This was also noted by Knill (1995) and Shor (1995).
Now, returning to our actual setting, where we have no special devices that produce
random eigenvectors, the important observation is that
􏰸r
|1⟩ =
|ψk⟩, (6.4)
k=1
and |1⟩ is an easy state to prepare. Consider what happens if we use the previous
Proc. R. Soc. Lond. A (1998)

350 R. Cleve, A. Ekert, C. Macchiavello and M. Mosca
quantum algorithm, but with state |1⟩ substituted in place of a random |ψk⟩. In order to understand the resulting behaviour, imagine if, initially, the control register were measured with respect to the orthonormal basis consisting of |ψ1⟩,...,|ψr⟩. This would yield a uniform sampling of these r eigenvectors, so the algorithm would behave exactly as the previous one. Also, since this imagined measurement operation is with respect to an orthonormal set of eigenvectors of U, it commutes with all the controlled-U2j operations, and hence will have the same effect if it is performed at the end rather than at the beginning of the computation. Now, if the measurement were performed at the end of the computation, then it would have no effect on the outcome of the measurement of the control register. This implies that state |1⟩ can in fact be used in place of a random |ψk⟩, because the relevant information that the resulting algorithm yields is equivalent. This completes the description of the algorithm for the order-finding problem.
It is interesting to note that the algorithm that we have described for the order- finding problem, which follows Kitaev’s methodology, results in a network (figure 6 followed by figure 5 backwards) that is identical to the network for Shor’s algorithm, although the latter algorithm was derived by an apparently different methodology. The sequence of controlled-U2j operations is equivalent to the implementation (via repeated squarings) of the modular exponentiation function in Shor’s algorithm. This demonstrates that Shor’s algorithm, in effect, estimates the eigenvalue corresponding to an eigenstate of the operation U that maps |x⟩ to |axmodN⟩.
7. Generating arbitrary interference patterns
We will show in this section how to generate specific interference patterns with arbitrary precision via some function evaluations. We require two registers. The first we call the control register; it contains the states we wish to interfere. The second we call the auxiliary register and it is used solely to induce relative phase changes in the first register.
Suppose the first register contains n bits. For each n-bit string |x⟩, we require a unitary operator Ux. All of these operators Ux should share an eigenvector |Ψ⟩ which will be the state of the auxiliary register. Suppose the eigenvalue of |Ψ⟩ for x is denoted by e2πiφ(x). By applying a unitary operator to the auxiliary register conditioned upon the value of the first register we will get the following interference pattern:
2n−1 2n−1 2n−1
􏰸 |x⟩|Ψ⟩ → 􏰸 |x⟩Ux(|Ψ⟩) = 􏰸 e2πiφ(x)|x⟩|Ψ⟩. (7.1) x=0 x=0 x=0
Thecontrolled-Uf gatethatwasdescribedin§2canbeviewedinthisway.Namely,
the operator Uf (0) which maps |y⟩ to |y ⊕ f (0)⟩ and the operator Uf (1) which maps
|y⟩ to |y⊕f(1)⟩ have common eigenstate |0⟩−|1⟩. The operator Uf(j) has eigenvalue e2πi(f(j)/2) for j = 0,1.
In general, the family of unitary operators on m qubits which simply add a constant integer k mod 2m share the eigenstates
2m −1
􏰸 e−2πi(ly/2m)|y⟩,
y=0
and kickback a phase change of e2πi(kl/2m).
Proc. R. Soc. Lond. A (1998)
l∈{1,1,...,2m −1}
(7.2)

Quantum algorithms revisited 351
For example, suppose we wish to create the state |0⟩ + e2πiφ|1⟩, where φ = 0.a1a2a3 · · · am.
We could set up an auxiliary register with m qubits and set it to the state 2m −1
􏰸 e−2πiφy|y⟩. (7.3) y=0
By applying the identity operator when the control bit is |0⟩ and the ‘add 1 mod 2m’ operator, U1, when the control bit is |1⟩, we see that
gets mapped to itself and
goes to
2m −1
|0⟩ 􏰸 e−2πiφy|y⟩
y=0
2m −1
|1⟩ 􏰸 e−2πiφy|y⟩
y=0
2m −1 y=0 y=0
2m −1
= e2πiφ|1⟩ 􏰸 e−2πiφy|y⟩.
y=0
An alternative is to set the m-bit auxiliary register to the eigenstate
2m −1
􏰸 e−(2πi/2m)y|y⟩
2m −1
|1⟩ 􏰸 e−2πiφy|y+1mod2m⟩=e2πiφ|1⟩ 􏰸 e−2πiφ(y+1)|y+1mod2m⟩
y=0
and conditionally apply Uφ which adds a = a1 a2 · · · am to the auxiliary register.
Similarly, the state
goes to
2m −1
|1⟩ 􏰸 e−(2πi/2m)y|y⟩
y=0
2m −1 y=0 y=0
2m −1
= e2πiφ|1⟩ 􏰸 e−(2πi/2m)y|y⟩. (7.6)
y=0
Similarly, if φ = ab/2m for some integers a and b, we could also obtain the same
2m −1
|1⟩ 􏰸 e−(2πi/2m)y|y+amod2m⟩=e2πiφ|1⟩ 􏰸 e−(2πi/2m)(y+a)|y+amod2m⟩
phase ‘kickback’ by starting with state
2m −1
􏰸 e−2πi(a/2m)y|y⟩
y=0
and conditionally adding b to the second register.
Proc. R. Soc. Lond. A (1998)
(7.7)
(7.4)
(7.5)

352 R. Cleve, A. Ekert, C. Macchiavello and M. Mosca The method using eigenstate
2m −1
􏰸 e−(2πi/2m)y|y⟩ (7.8)
y=0
has the advantage that we can use the same eigenstate in the auxiliary register for any φ. So in the case of an n-qubit control register where we want phase change e2πiφ(x) for state |x⟩, and if we have a reversible network for adding φ(x) to the auxiliary register when we have |x⟩ in the first register, we can use it on a superposition of control inputs to produce the desired phase ‘kickback’ e2πiφ(x) in front of |x⟩. Which functions φ(x) will produce a useful result, and how to compute them, depends on the problems we seek to solve.
8. Conclusions
Various quantum algorithms, which may appear different, exhibit remarkably simi- lar structures when they are cast within the paradigm of multiparticle interferometry. They start with a Fourier transform to prepare superpositions of classically different inputs, followed by function evaluations (i.e. f-controlled unitary transformations) which induce interference patterns (phase shifts), and are followed by another Fourier transform that brings together different computational paths with different phases. The last Fourier transform is essential to guarantee the interference of different paths.
We believe that the paradigm of estimating (or determining exactly) the eigen- values of operators on eigenstates gives helpful insight into the nature of quantum algorithms and may prove useful in constructing new and improving existing algo- rithms. Other problems whose algorithms can be deconstructed in a similar manner are Simon’s algorithm (1993), Shor’s discrete logarithm algorithm (1994), Boneh &amp; Lipton’s algorithm (1995) and Kitaev’s more general algorithm for the Abelian stabilizer problem (1995), which first highlighted this approach.
We have also shown that the evaluation of classical functions on quantum super- positions can generate arbitrary interference patterns with any prescribed precision, and have provided an explicit example of a universal construction which can accom- plish this task.
We thank David Deutsch, David DiVincenzo, Ignacio Cirac and Peter Høyer for helpful discus- sions and comments.
This work was supported in part by the European TMR Research Network ERP-4061PL95- 1412, CESG, Hewlett-Packard, The Royal Society London, the US National Science Foundation under grant no. PHY94-07194 and Canada’s NSERC. Part of this work was completed during the 1997 Elsag–Bailey–I.S.I. Foundation research meeting on quantum computation.
Appendix A. Cracking RSA
What we seek is a way to compute MmodN given Me, e and N; that is, a method for finding eth roots in the multiplicative group of integers modulo N (this group is often denoted by ZN∗ and contains the integers coprime to N). It is still an open question whether a solution to this problem necessarily gives us a polynomial time randomized algorithm for factoring. However, factoring does give a polynomial time algorithm for finding eth roots for any e relatively prime to φ(N) and thus
for cracking RSA. Knowing the prime factorization of N, say 􏰷pa1pa2 ···pak, we 12k
Proc. R. Soc. Lond. A (1998)

Quantum algorithms revisited 353
Figure 7. Network representation of Grover’s algorithms. By repeating the basic sequence 2n/2 times, value k is obtained at the output with probability greater than 0.5.
can easily compute φ(N) = N 􏰷ni=1(1 − 1/pi). Then we can compute d such that ed ≡ 1modφ(N), which implies Med ≡ M modN.
However, to crack a particular instance of RSA, it suffices to find an integer d such that ed ≡ 1 mod r where r is the order of M modulo N (i.e. the least positive integer such that Mr ≡ 1modN); so ed = rk + 1 for some integer k. We would then have Cd ≡Med ≡Mrk+1 ≡MmodN.
Since e is relatively prime to φ(N), it is easy to see that the order od M is equal to the order of C ≡ Me. So given C ≡ Me, we can compute r using Shor’s algorithm and then compute d satisfying de ≡ 1modord(P) using the extended Euclidean algorithm. Thus, we do not need several repetitions of Shor’s algorithm to find the order of a for various random a; we just find the order of C and solve for M regardless of whether or not this permits us to factor N.
Appendix B. Concatenated interference
The generic sequence: a Hadamard/Fourier transform, followed by an f -controlled- U, followed by another Hadamard/Fourier transform, can be repeated several times. This can be illustrated, for example, with Grover’s database search algorithm (1996). Suppose we are given (as an oracle) a function fk which maps {0, 1}n to {0, 1} such that fk(x) = δxk for some k. Our task is to find k. Thus in a set of numbers from 0 to 2n − 1 one element has been ‘tagged’ and by evaluating fk we have to find which one. To find k with a probability of 50%, any classical algorithm, be it deterministic or randomized, will need to evaluate fk a minimum of 2n−1 times. In contrast, a quantum algorithm needs only O(2n/2) evaluations. Grover’s algorithm can be best presented as a network shown in figure 7.
Appendix C. Amplifying success probability when estimating phases
Let φ be a real number satisfying 0 􏱁 φ &lt; 1 which is not a fraction with denomi- nator 2m, and let a/2m = 0. a1a2 · · · am be the closest m-bit approximation to φ so that φ = q/2m + δ, where 0 &lt; |δ| 􏱁 1/2m+1. For such a φ, we have already shown that applying the inverse of the QFT to (5.1) and then measuring yields the state |a⟩ with probability at least 4/π2 = 0.405 . . . .
Without loss of generality, assume 0 &lt; δ 􏱁 1/(2m + 1). For t satisfying −2m−1 􏱁 t &lt; 2m−1, let αt denote the amplitude of |a − t mod 2m⟩. It follows from (5.2) that
1 􏰐1 − (e2πi(δ+t/2m))2m 􏰑
αt = 2m 1−e2πi(δ+t/2m) . (C1)
Since
|1 − e2πi(δ+t/2m)| 􏱁 2π(δ + t/2m)/12π = 4(δ + t/2m) (C2) Proc. R. Soc. Lond. A (1998)
  
354 R. Cleve, A. Ekert, C. Macchiavello and M. Mosca
then
􏰴􏰴􏰴 2 􏰴􏰴􏰴 1
|αt| 􏱁 􏰴2m4(δ + t/2m)􏰴 􏱁 2m+1(δ + t/2m). (C3)
  The probability of getting an error greater than k/2m is
2m−1 −1 −(k+1) 􏰸|αt|2+􏰸|αt|2􏱁􏰸 1+􏰸 1
  k􏱁t&lt;2m−1
−2m−1 􏱁t&lt;−k
4(t + 2mδ)2
t=k t=−2m−1
2m−1 −1 2m−1 􏱁􏰸1+􏰸1
4(t + 2mδ)2
 4t2 4(t − 12 )2 t=k+1
t=k
2m−1 􏰻m
􏰸1 2−11 1
􏱁 4(1t)2 &lt; t2 &lt;2k−1. (C4)
t=2k 2 2k−1
So, for example, if we wish to have an estimate that is within 1/2n+1 of the value φ with probability at least 1 − ε, it suffices to use this technique with m = n + ⌈log2 (1/2ε + 12 )⌉ bits.
References
Barenco, A., Bennett, C. H., Cleve, R., DiVincenzo, D. P., Margolus, N., Shor, P., Sleater, T., Smolin, J. &amp; Weinfurter, H. 1995 Phys. Rev. A 52, 3457.
Barenco, A., Deutsch, D., Ekert, A. &amp; Jozsa, R. 1995 Phys. Rev. Lett. 74, 4083.
Bernstein, E. &amp; Vazirani, U. 1993 Proc. 25th Ann. ACM Symp. on the Theory of Computing,
pp. 11–20. New York: ACM Press.
Boneh, D. &amp; Lipton, R. J. 1995 Advances in cryptology. In Proc. Crypto ’95, Lecture Notes in
Computer Science, pp. 424–437. Berlin: Springer.
Coppersmith, D. 1994 An approximate Fourier transform useful in quantum factoring. IBM
research report no. RC19642.
Derka, R., Buˇzek, V. &amp; Ekert, A. 1997 e-print quant-ph/9707028.
Deutsch, D. 1985 Proc. R. Soc. Lond. A 400, 97.
Deutsch, D. &amp; Jozsa, R. 1992 Proc. R. Soc. Lond. A 439, 553.
Ekert, A. &amp; Jozsa, R. 1996 Rev. Mod. Phys. 68, 733.
Griffiths, R. B. &amp; Niu, C.-S. 1996 Phys. Rev. Lett. 76, 3228.
Grover, L. 1996 Proc. 28th Ann. ACM Symp. on the Theory of Computing, p. 212. New York: ACM Press.
Høyer, P. 1997 Quantum Algorithms. Paper for qualifying exam at Odense University, Denmark.
Huelga, S. F., Macchiavello, C., Pellizzari, T., Ekert, A., Plenio, M. B. &amp; Cirac J. I. 1997 e-print quant-ph/9707014.
Kitaev, A. 1995 Quantum measurements and the Abelian stabilizer problem. e-print quant- ph/9511026.
Knill, E. 1995 Los Alamos National Laboratory Report LAUR-95-2225 (also available at http://www.c3.lanl.gov/ knill).
Massar, S. &amp; Popescu, S. 1995 Phys. Rev. Lett. 74, 1259.
Shor, P. 1994 Proc. 35th Ann. Symp. on the Foundation of Computer Science, p. 124. Los
Alamitos, CA: IEEE Computer Society.
Shor, P. 1995 e-print quant-ph/9508027.
Terhal, B. &amp; Smolin, J. 1997 e-print quant-ph/9705041.
Proc. R. Soc. Lond. A (1998)
</Text>
        </Document>
        <Document ID="B7929AD4-ADBC-4ED3-BA29-670977119F09">
            <Title>The Hare &amp; the Tortoise
</Title>
            <Text>The Hare &amp; the Tortoise
#
A Hare was making fun of the Tortoise one day for being so slow.
"Do you ever get anywhere?" he asked with a mocking laugh.
"Yes," replied the Tortoise, "and I get there sooner than you think. I'll run you a race and prove it."
The Hare was much amused at the idea of running a race with the Tortoise, but for the fun of the thing he agreed. So the Fox, who had consented to act as judge, marked the distance and started the runners off.
The Hare was soon far out of sight, and to make the Tortoise feel very deeply how ridiculous it was for him to try a race with a Hare, he lay down beside the course to take a nap until the Tortoise should catch up.
#
The Tortoise meanwhile kept going slowly but steadily, and, after a time, passed the place where the Hare was sleeping. But the Hare slept on very peacefully; and when at last he did wake up, the Tortoise was near the goal. The Hare now ran his swiftest, but he could not overtake the Tortoise in time.
The race is not always to the swift.

http://read.gov/aesop/025.html</Text>
        </Document>
        <Document ID="35E77B97-AF07-4517-9C8B-425D1113FB8F">
            <Title>Ali Baba and Forty Thieves
</Title>
            <Text>Ali Baba and Forty Thieves
The story takes place in Baghdad during the Abbasid era. Ali Baba and his elder brother Cassim are the sons of Ali Baba and forty thievesa merchant. After the death of their father, the greedy Cassim marries a wealthy woman and becomes well-to-do, building on their father's business - but Ali Baba marries a poor woman and settles into the trade of a woodcutter.
#
One day Ali Baba is at work collecting and cutting firewood in the forest, and he happens to overhear a group of forty thieves visiting their treasure store. The treasure is in a cave, the mouth of which is sealed by magic. It opens on the words "Open, Simsim", and seals itself on the words "Close, Simsim". When the thieves are gone, Ali Baba enters the cave himself, and takes some of the treasure home.
Ali Baba borrows his sister-in-law's scales to weigh this new wealth of gold coins. Unbeknownst to Ali, she puts a blob of wax in the scales to find out what Ali is using them for, as she is curious to know what kind of grain her impoverished brother-in-law needs to measure. To her shock, she finds a gold coin sticking to the scales and tells her husband, Ali Baba's rich and greedy brother, Cassim. Under pressure from his brother, Ali Baba is forced to reveal the secret of the cave. Cassim goes to the cave and enters with the magic words, but in his greed and excitement over the treasures forgets the magic words to get back out again. The thieves find him there, and kill him. When his brother does not come back, Ali Baba goes to the cave to look for him, and finds the body, quartered and with each piece displayed just inside the entrance of the cave to discourage any similar attempts in the future.
Ali Baba brings the body home, where he entrusts Morgiana, a clever slave-girl in Cassim's household, with the task of making others believe that Cassim has died a natural death. First, Morgiana purchases medicines from an apothecary, telling him that Cassim is gravely ill. Then, she finds an old tailor known as Baba Mustafa whom she pays, blindfolds, and leads to Cassim's house. There, overnight, the tailor stitches the pieces of Cassims' body back together, so that no one will be suspicious. Ali and his family are able to give Cassim a proper burial without anyone asking awkward questions.
The thieves, finding the body gone, realize that yet another person must know their secret, and set out to track him down. One of the thieves goes down to the town and comes across Baba Mustafa, who mentions that he has just sewn a dead man's body back together. Realizing that the dead man must have been the thieves' victim, the thief asks Baba Mustafa to lead the way to the house where the deed was performed. The tailor is blindfolded again, and in this state he is able to retrace his steps and find the house. The thief marksforty thieves the door with a symbol. The plan is for the other thieves to come back that night and kill everyone in the house. However, the thief has been seen by Morgiana and she, loyal to her master, foils his plan by marking all the houses in the neighborhood with a similar marking. When the 40 thieves return that night, they cannot identify the correct house and the head thief kills the lesser thief. The next day, another thief revisits Baba Mustafa and tries again, only this time, a chunk is chipped out of the stone step at Ali Baba's front door. Again Morgiana foils the plan by making similar chips in all the other doorsteps. The second thief is killed for his stupidity as well. At last, the head thief goes and looks for himself. This time, he memorizes every detail he can of the exterior of Ali Baba's house.
#
The chief of the thieves pretends to be an oil merchant in need of Ali Baba's hospitality, bringing with him Forty thieves hiding in oil jarsmules loaded with thirty-eight oil jars, one filled with oil, the other thirty-seven hiding the other remaining thieves. Once Ali Baba is asleep, the thieves plan to kill him. Again, Morgiana discovers and foils the plan, killing the thirty-seven thieves in their oil jars by pouring boiling oil on them. When their leader comes to rouse his men, he discovers that they are dead, and escapes.
To exact revenge, after some time the thief establishes himself as a merchant, befriends Ali Baba's son (who is now in charge of the late Cassim's business), and is invited to dinner at Ali Baba's house. The thief is recognized by Morgiana, who performs a dance with a dagger for the diners and plunges it into the heart of the thief when he is off his guard. Ali Baba is at first angry with Morgiana, but when he finds out the thief tried to kill him, he gives Morgiana her freedom and marries her to his son. Ali Baba is then left as the only one knowing the secret of the treasure in the cave and how to access it. Thus, the story ends happily for everyone except the forty thieves and Cassim.

https://www.kidsgen.com/stories/arabian_tales/ali_baba_and_forty_thieves.htm</Text>
        </Document>
        <Document ID="2E9399D3-9647-45AA-900E-B6E4CE772E5F">
            <Title>shor</Title>
            <Text>Circuit for Shor’s algorithm using 2n+3 qubits
St ́ephane Beauregard∗
Abstract
We try to minimize the number of qubits needed to factor an integer of n bits using Shor’s algorithm on a quantum computer. We introduce a circuit which uses 2n+3 qubits and O(n3lg(n)) elementary quantum gates in a depth of O(n3) to implement the factorization algorithm. The circuit is computable in polynomial time on a classical computer and is completely general as it does not rely on any property of the number to be factored.
1 Introduction
Since Shor discovered a polynomial time algorithm for factorization on a quantum computer [1], a lot of effort has been directed towards building a working quantum computer. Despite all these efforts, it is still extremely difficult to control even a few qubits. It is thus of great interest to study exactly how few qubits are needed to factor an n-bit number.
Quantum factorization consists of classical preprocessing, a quantum algorithm for order-finding and classical postprocessing [1, 2, 3] (fig. 1). We will concentrate on the quantum part of factorization and consider classical parts as being free as long as they are computable in polynomial time. The only use of quantum computation in Shor’s algorithm is to find the order of a modulo N, where N is an n-bit integer that we want to factor. The order r of a modulo N is the least positive integer such that ar ≡ 1(mod N).
For completeness, we now give the full algorithm for factoring N as given in [3]:
1. If N is even, return the factor 2.
∗ D  ́e p a r t e m e n t d e P h y s i q u e e t D  ́e p a r t e m e n t d ’ I n f o r m a t i q u e e t Op ́erationnelle, Universit ́e de Montr ́eal, beaurest@iro.umontreal.ca. NSERC.
1
d e R e c h e r c h e Supported by
 arXiv:quant-ph/0205095v3 21 Feb 2003

     2n qubits
n qubits
0Hm
0Hm 0Hm 0Hm
1 Ua20 Ua21 Ua22 Ua22n-1
              Figure 1: The order-finding circuit for quantum factorization. Ua implements |x⟩ → |(ax)mod N⟩ and the measurements followed by classical postprocessing yields the order r of a modulo N with good probability.
2. ClassicallydetermineifN=pq forp≥1andq≥2andifsoreturn the factor p (this can be done in polynomial time).
3. Choose a random number a such that 1 &lt; a ≤ N −1. Using Eu- clid’s algorithm, determine if gcd(a, N )&gt; 1 and if so, return the factor gcd(a, N ).
4. Use the order-finding quantum algorithm to find the order r of a mod- ulo N.
5. Ifrisoddorrisevenbutar/2 =−1(modN),thengotostep(iii). Otherwise, compute gcd(ar/2 − 1, N ) and gcd(ar/2 + 1, N ). Test to see if one of these is a non-trivial factor of N, and return the factor if so.
It can be shown that with probability at least one half, r will be even and ar/2 ̸= −1(mod N) [1, 3]. The quantum part of the algorithm (step 4) is known to be computable in polynomial time on a quantum computer. Using classical techniques, it is straigthforward to build the order-finding circuit (fig. 1) using a polynomial number of elementary gates and a linear number of qubits [1]. Because the depth of the circuit is related to its running time, it is desirable to minimize this depth, and much progress has been made in that direction [4]. We propose to take the problem from the other side: by how much can the number of qubits be reduced for factorization in polynomial time? Answering this question would give insights on the size of a quantum computer useful for factorization. We thus introduce a new order-finding circuit focused on reducing the number of qubits while still using only a polynomial number of elementary quantum gates. We also somewhat try to
2
-1
QFT

minimize the depth of the circuit, but very little parallelization is available since we avoid using any unnecessary qubit.
Conditional Phase Shift
  k
100 0
010 0
 ==
001 0 k 2πi
 an−1 an−2
a1 a0
φ (b) 1 n−1
φn−2(b) φ1(b)
φ0 (b)
2
an−1 an−2
a1 a0
φ (a+b) n−1
φn−2(a+b) 1 2 φ1(a+b)
0 0 0 e2k Addition Transform
n−1 n
                      1
n−2 n−1
      1 φ0(a+b) Figure 2: The quantum addition as described by Draper [6].
    2 The Circuit
The circuit for factorization that will be discussed here was inspired in part by a circuit from Vedral, Barenco and Ekert [5]. To reduce the number of qubits, we use a variant of a quantum addition algorithm described by Draper [6] (fig. 2). Other techniques used to reduce the number of qubits are the hardwiring of classical values and the sequential computation of the Fourier transform.
The quantum addition of figure 2 takes as input n qubits representing a number a, and n more qubits containing the quantum Fourier transform of an other number b, denoted by φ(b). After the addition, the first register
3

keeps the same value a but the bottom register now contains the quantum Fourier transform of (a + b)mod 2n, denoted by φ(a + b).
A1
A2
Φ(a+b) = Φ(b)
   Φ
A D D (a)
 Φ(b)
Φ(a+b)
An-1
An
  Figure 3: The circuit for addition of a classical value a to the quantum value b in the Fourier space. The gates Ai are classically computed combinations of phase shifts.
2.1 The adder gate
Adding together two quantum registers is, however, more than we ask for. We are trying to find the period of the function (ax)mod N where a is a classical random number smaller than N. Since a is classical, we only need to be able to add a classical value to a quantum register. We can thus change the qubits representing a in figure 2 to classical bits. The controlled gates are then classically controlled, and since we know what a is beforehand, we might as well precompute the product of all gates on each single qubit and apply only one gate for every single qubit. These are one-qubit gates, which also makes them easier to implement.
Since the addition takes place in the Fourier space, we will call this circuit the φADD(a) gate where a is the classical value added to the quantum register (fig. 3). Notice the thick black bar on the right, used to distinguish the gate from its unitary inverse. In order to prevent overflow, we need n+1 qubits for the quantum register instead of n, so that φ(b) is effectively the QFT of an (n + 1)-qubit register containing a n-bit number (thus the most significant qubit before the QFT preceding the addition is always |0⟩).
If we apply the unitary inverse of the φADD(a) gate with input φ(b), we get either φ(b−a) if b ≥ a, or φ(2n+1−(a−b)) if b &lt; a. Thus if b &lt; a, the most significant qubit of the result is always |1⟩, whereas it is always |0⟩ if b ≤ a. This reverse φADD(a) gate can be useful for subtraction and comparison purposes (fig. 4) and we use a black bar on the left to distinguish it from the regular gate. The unitary inverse of a circuit is obtained by applying the unitary inverse of each elementary gate in reverse order.
4

  −1 b QFT QFT
b−a if b&gt;a n+1
2 −(a−b) ifb&lt;a
Φ
A D D (a)
  Figure 4: The effect of the reverse φADD(a) gate on |φ(b)⟩.
2.2 The modular adder gate
Now that we have a φADD(a) gate, we can use it to build a modular adder gate (fig. 5). For future use, two control qubits are included in the circuit. For the modular adder gate, we need to compute a + b and subtract N if a + b ≥ N. However, it is not so easy to implement this operation in a reversible way. The input to the φADD(a)MOD(N) gate is φ(b) with b &lt; N, and the classical number a that we add is also smaller than N.
cc 11
c2 c2
Φ(b) QFT-1 QFT QFT-1   QFT Φ((a+b)mod N) 00
= Φ(b) Φ((a+b)mod N)
Figure 5: The doubly controlled φADD(a)MOD(N) gate with c1 = c2 = 1. If either of the control qubits is in state |0⟩, the output of the gate is |φ(b)⟩ since b &lt; N.
We begin by applying a φADD(a) gate to the register φ(b). The quantum register now contains φ(a + b) with no overflow because we were careful enough to put an extra qubit in state |0⟩ along with the value b before
5
           Φ
A D D (a)
Φ
A D D (N)
Φ
A D D (N)
Φ
A D D (a)
   Φ
A D D (a) mod N
Φ
A D D (a)
  
applying the QFT. We next run a reverse φADD(N ) to get φ(a + b − N ). If a+b &lt; N, we did not have to subtract N but now we can determine if a+b &lt; N by checking the most significant bit of a+b−N. However, to access this most significant bit we need to inverse the QFT on the whole register containing φ(a+b−N). We can then use this qubit as the controlling qubit of a controlled-not gate acting on an ancillary qubit. It is then possible to reapply the QFT and use this ancilla as a control qubit for a φADD(N) controlled gate, so that if a + b &lt; N we add back the value N that we subtracted earlier. We now have φ((a + b)mod N) in the register, and we are done except for the ancilla which is now a junk bit. We have to restore it to |0⟩ somehow, otherwise the computation will not be clean and the algorithm will not worka.
Restoring the ancilla to |0⟩ is no easy task if we do not want to waste qubits. We can still do it by using the identity:
(a + b)mod N ≥ a ⇔ a + b &lt; N. (1)
Hence, we only have to compare (a + b)mod N with the value a using essentially the same trick as before. We run an inverse φADD(a) followed by an inverse QFT to get the most significant qubit of (a + b)mod N − a. This qubit is |0⟩ if (a+b)mod N ≥a. We apply a NOT gate on this qubit and use it as the controlling qubit of a controlled-not gate targeting the ancilla. The ancilla is thus restored to |0⟩ and we can apply a NOT gate again on the control wire, followed by a QFT and a φADD(a) gate on the quantum register. After this, we have a clean computation of (a + b)mod N in the Fourier space.
Again, what we need exactly is a doubly controlled version of the φADD(a)M OD(N ) gate. In order to reduce the complexity of the cir- cuit, we will doubly control only the φADD(a) gates instead of all the gates (fig. 5). If the φADD(a) gates are not performed, it is easy to verify that the rest of the circuit implements the identity on all qubits because b &lt; N.
2.3 The controlled multiplier gate
The next step is to use the doubly controlled φADD(a)MOD(N) gate to build a controlled multiplier gate that we will call CMULT(a)MOD(N) (fig. 6). This gate takes three inputs, |c⟩|x⟩|b⟩, and its output depends on the qubit |c⟩. If |c⟩ = |1⟩, the output is |c⟩|x⟩|b + (ax)mod N ⟩. If |c⟩ = |0⟩, then
aIndeed, for the order-finding algorithm to work, we need to find the period of (ax)mod N but the period of the garbage bits can be something else.
6
 
c ccc
x xxx
       =b -1
.x)mod N ( b+a
if c=1
b if c=0
    Φ
A D D (20a)
mod N
Φ
A D D (21a)
mod N
Φ
A D D
(2n- 1a)
mod N
Figure 6: The CMULT(a)MOD(N) gate.
the input is unchanged and stays |c⟩|x⟩|b⟩. This gate is very straightforward to implement using doubly controlled φADD(a)MOD(N) gates. We use the identity:
(ax)mod N =
(...((20ax0)mod N + 21ax1)mod N + ... + 2n−1axn−1)mod N. (2)
Thus we only need n successive doubly controlled modular adder gates, each of them adding a different value (2ia)mod N with 0 ≤ i &lt; n to get the CMULT(a)MOD(N) gate. We now have a controlled gate that takes |x⟩|b⟩ to |x⟩|b + (ax)mod N⟩. What we would need instead is a controlled gate that takes |x⟩ to |(ax)mod N⟩. This can however be obtained by a clever trick from reversible computing that uses two controlled multiplication gates (fig 7).
We first apply the CMULT(a)MOD(N) gate to |c⟩|x⟩|0⟩. We follow with a SWAP between the two registers if the qubit |c⟩ = |1⟩ (that is ef- fectively a controlled-SWAP on the registers)b. We only need to control- SWAP n qubits, not n+1. Indeed, the most significant qubit of (ax)mod N will always be 0 since we were careful to include one extra qubit to store the overflow in the φADD(a) gate. We then finish with the inverse of a CMULT(a−1)MOD(N) circuit. The value a−1, which is the inverse of a
bWe can do without the SWAP by modifying all later gates accordingly, but the SWAP simplifies the layout of the circuit without affecting the order of the complexity.
7
.
C M U L T (a) mod N
   b QFT QFT
( b+a
x)mod N if c=1
b if c=0
  
cc=cc
    . 00
.
x if c=0
x
x Ua
C M U L T (a) mod N
C M U L
T
(a )
mod N
(a
x)mod N x if c=0
if c=1
(a
x)mod N
if c=1
 S W A P
-1
Figure 7: The controlled-Ua gate.
modulo N, is computable classically in polynomial time using Euclid’s al- gorithm and it always exists since gcd(a,N) = 1. The fact that we apply the inverse of the circuit means that the circuit effectively takes |c⟩|x⟩|b⟩ to |c⟩|x⟩|(b − a−1x)mod N⟩.
The resulting gate will be called C-Ua for controlled-Ua. It does nothing if |c⟩ = |0⟩ but if |c⟩ = |1⟩, then the two registers take the following values:
|x⟩|0⟩ → |x⟩|(ax)mod N⟩ → |(ax)mod N⟩|x⟩ →
|(ax)mod N⟩|(x − a−1ax)mod N⟩ = |(ax)mod N⟩|0⟩. (3)
Since the bottom register returns to |0⟩ after the computation, we can consider this extra register as being part of the C-Ua gate, thus the gate effectively takes |x⟩ to |(ax)mod N⟩. This is exactly the gate we need to run the quantum order-finding circuit (fig 1). Of course, we don’t need to applyC-Uantimestoget(C-Ua)nbecausewecandirectlyrunC-Uan (where anmod N in computed classically) which is the same as (C-Ua)n since:
(anx)mod N = (a...(a(ax)mod N)mod N...)mod N . (4) 􏱆 􏱅􏱄 􏱇
n times 2.4 The one controlling-qubit trick
An advantage of using the C-Ua2j gates for Shor’s algorithm is the fact that we don’t really need the total 2n controlling qubits. In fact, it can be shown that only one controlling qubit is sufficient [7, 8, 9]. This is possi- ble because the controlled-U gates all commute and the inverse QFT can be applied semi-classically. Indeed, we can get all the bits of the answer
8
  
 0
1
H H m0 Xm0 H R0 m1 Xm1 H       R2n−1 m2n−1 Ua22n−1
    Ua20
Ua21
  Figure 8: The one control qubit trick for factoring. The R gates depend on all previous measurement results and implement the inverse QFT, while the X gates are negations conditionned on the result of each measurement.
sequentially as in figure 8. Each measured bit dictates which unitary trans- formation we have to apply after every controlled-U step before the next measurement. This simulates the inverse QFT followed by a measurement on all qubits as in figure 1. We save an important number of qubits this way, and in fact we need only a total of 2n + 3 qubits to factor an n-bit number as we will show in the complexity analysis section.
a H2 n−1n n−1
a n−2
a1 a0
H n−2n−1
φ(a) n−1
φ(a) n−2
H2 φ1(a) H φ0 (a)
             Figure 9: The exact quantum Fourier transform. H is the Hadamard gate.
2.5 The quantum Fourier transform
The implementation of the exact QFT on n qubits requires O(n2) opera- tions [3] (fig. 9). However, in physical implementations, there will always be a threshold for the precision of the gates. Since many phase shifts will be almost negligible, we will in practice ignore the ones with k greater than a certain threshold kmax. This approximate QFT is in fact very close to the exact QFT even with kmax logarithmic in n. In fact, it has been shown [10] that the error introduced by ignoring all gates with k &gt; kmax is proportional to n2−kmax.We can thus choose kmax ∈ O(lg(n)).
9
 ǫ

The implementation of the approximate QFT on n qubits requires O(n lg(n)) gates. There seems to be no obvious way to reduce the depth of either the exact QFT and the approximate QFT on n qubits below O(n) without using extra qubits [11]. The depth of the QFT on n + 1 qubits is thus O(n) with the little parallelization available without extra qubits.
2.6 The controlled-SWAP
=
Figure 10: The controlled-SWAP gate.
The controlled-SWAP on one qubit is very easy to implement (fig. 10). Only two controlled-not and one Toffoli are needed to perform the SWAP on two qubits controlled by a third. Thus, O(n) gates are needed to control- SWAP n qubits, that is, swap n qubits with n others with one control qubit.
3 Complexity Analysis
We now analyze the complexity of the given circuit for performing factor- ization of an n-bit number N. The analysis keeps track of the number of qubits, the order of the number of gates and the order of the depth of the circuit. For the depth of the circuit, we consider that it will be possible to apply simultaneously different quantum gates that act on different qubits of the quantum computer. However, we consider impossible to have one qubit controlling many operations in the same step. The circuit uses only single qubit gates, up to doubly controlled conditionnal phase shifts and up to doubly controlled not gates. These gates can be implemented using a constant number of single qubit gates and controlled-nots [12], so they can all be considered as elementary quantum gates.
The φADD(a) circuit (fig. 3), where a is a classical value, requires n + 1 qubits and O(n) single qubit gates in constant depth. The number of qubits is n + 1 because we need an extra qubit to prevent overflows. When a
10
   S W A P

control qubit is added to the circuit, the depth becomes O(n) since the conditional phase shifts have to be done sequentially. Indeed, the control qubit has to control each phase shift one at a time. The doubly con- trolled φADD(a)MOD(N) circuit (fig. 5) requires n + 4 qubits. It also requires O(nkmax) gates, but has a depth of only O(n) regardless of kmax be- cause the QFTs can be somewhat parallelized. The CMULT(a)MOD(N) circuit is only n doubly controlled φADD(a)M OD(N ) circuits. It thus takes 2n + 3 qubits, O(n2kmax) gates and a depth of O(n2) to implement the CMULT(a)MOD(N) circuit. Two of these circuits along with the controlled-SWAP are needed for the C-Ua circuit. The controlled-SWAP on n qubits requires only O(n) gates and depth, so the C-Ua circuit requires 2n + 3 qubits, O(n2kmax) gates and a depth of O(n2) again.
For the whole order-finding circuit, that is, the whole quantum part of Shor’s algorithm, we need 2n of these C-Ua circuits. The quantum resources needed are thus 2n+3 qubits, O(n3kmax) gates and a depth of O(n3). If we decide to use the exact QF T in the additions, then we would have kmax = n. As we argued earlier, this would not be clever because the implementation is sure to have hardware errors anyway. We thus should use the approximate
QFT with kmax = O(lg(n)), so that the number of gates is in O(n3 lg(n)) 1ǫ
 for any ǫ polynomial in n .
This result of 2n + 3 qubits is slightly better than previous circuits for
 factorization. Vedral, Barenco and Ekert published a circuit of 7n+1 qubits and O(n3) elementary gates for modular exponentiation [5]. It is mentionned that this number can be easily reduced to 5n+2 qubits with basic optimiza- tion and further reduced to 4n + 3 if unbounded Toffoli gates (n-controlled nots) are available. Beckman, Chan, Devabhaktoni and Preskill provided an extended analysis [13] of modular exponentiation, with a circuit of 5n + 1 qubits using elementary gates and 4n + 1 if unbounded Toffoli gates are available. Zalka also described a method for factorization with 3n + O(lg n) qubits using only elementary gates [8].
The availability of unbounded Toffoli gates will of course depend on the physical implementation of the quantum computer, but it is assumed throughout our design and analysis that such gates cannot be considered elementary. For that matter, if we do not restrict the type and size of the quantum gates in any way, order-finding can be achieved with n + 1 qubits by directly using controlled multiplication gates [9].
Of the 2n + 3 qubits used in the circuit provided here, one is used as an ancilla for modular addition, one is used to prevent addition overflows and n are used as an ancillary register to get modular multiplication from successive additions. An order-finding circuit using elementary gates and
11

less than 2n + O(1) qubits is not ruled out yet, but it seems that a different method would have to be used for modular multiplication to get such a circuit.
Fifteen is the smallest number on which Shor’s algorithm can be ap- plied. The circuit for factorization of N = 15 uses eleven qubits as given here. However, the classical computation performed to build it gives a lot of information on the order of the number a. Indeed, for any 1 &lt; a &lt; 15, the order of a is either two or four. Most of the multiplications in the circuit are simply the identity and can be removed, which amounts to many un- used qubits. The number 15 was factored using NMR with seven qubits in an impressive display of quantum control by Vandersypen, Steffen, Breyta, Yannoni, Sherwood and Chuang [14].
The importance of reducing the number of qubits versus reducing the depth of a quantum computation is not clear as quantum computers of useful size are not yet available. We have to keep in mind that error correction will most probably have to be used on quantum computers, which will create an overhead in the number of qubits used [3]. It is however sensible to minimize the number of qubits before applying error correction if qubits are hard to come by.
4 Conclusion
Putting together several tricks, we have developed a circuit for the quantum part of the factorization algorithm, that is, the order-finding algorithm, while focusing on reducing the number of qubits. The number of qubits needed is 2n + 3 and the depth is O(n3). This circuit uses slightly less qubits than those previously known if restricted to elementary gates. It is also completely general and does not rely on any properties of the number to be factored.
Given the values a and N, this circuit gives the order r of a modulo N with good probability. Many runs of this algorithm may be needed to factor a number. Also, the randomly chosen value a is hardwired in the circuit and there is a probability (about one half) that it will be necessary to choose a new value a and run a new order-finding algorithm on it. This is not a problem if the quantum computer is a physical device where the gates are interactions controlled by a classical computer such as laser pulses on trapped ions, NMR and most implementation proposals. Indeed, the circuit can easily be classically computed. A quantum computer consisting of a physical system controlled by a classical computer is the most conceivable
12

option at this point.
Acknowledgements
The author is very grateful to Michel Arsenault for many helpful com- ments and corrections, and would also like to thank Jos ́e Manuel Fernan- dez, Christof Zalka and Anne Broadbent. This work was supported in part by CSE of Canada, and the author acknowledges support from NSERC of Canada.
References
[1] P. Shor (1997), Polynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer, SIAM J. Comp., 26, pp. 1484-1509. Also on quant-ph/9508027.
[2] R. Cleve, A. Ekert, C. Macchiavello, and M. Mosca (1998), Quantum algorithms revisited, Proc. R. Soc. London A, 454, pp. 339-354. Also on quant-ph/9708016.
[3] Michael A. Nielsen and Isaac L. Chuang (2000), Quantum Computa- tion and Quantum Information. Cambridge University Press (Cam- bridge).
[4] R. Cleve and J. Watrous (2000), Fast parallel circuits for the quan- tum Fourier transform, Proceedings 41st Annual Symposium on Foundations of Computer Science (FOCS’00), pp. 526-536. Also on quant-ph/0006004.
[5] V. Vedral, A. Barenco, and A. Ekert (1996), Quantum networks for elementary arithmetic operations, Phys. Rev. A, 54, pp. 147-153. Also on quant-ph/9511018.
[6] T. Draper (2000), Addition on a quantum computer, quant-ph/0008033.
[7] M. Mosca and A. Ekert (1999), The hidden subgroup problem and eigenvalue estimation on a quantum computer, Lecture Notes in Com- puter Science, 1509, pp. 174-188. Also on quant-ph/9903071.
[8] C. Zalka (1998), Fast versions of Shor’s quantum factoring algorithm, quant-ph/9806084.
13

[9] S. Parker and M.B. Plenio (2000), Efficient factorization with a single pure qubit and logN mixed qubits, Phys. Rev. Lett., 85, pp. 3049-3052. Also on quant-ph/0001066.
[10] D. Coppersmith (1996), An approximate Fourier transform useful in quantum factoring, IBM Research Report No. RC19642. Also on quant-ph/0201067.
[11] C. Moore and M. Nilsson (2002), Parallel quantum computation and quantum codes, SIAM J. Comp., 31, pp. 799-815. Also on quant-ph/9808027.
[12] A. Barenco, C. Bennett, R. Cleve, D.P. DiVincenzo, N. Margolus, P. Shor, T. Sleator, J.A. Smolin, and H. Weifurter (1995), Elementary gates for quantum computation, Phys. Rev. A, 52, pp. 3457-3467. Also on quant-ph/9503016.
[13] D. Beckman, A.N. Chari, S. Devabhaktuni, and J. Preskill (1996), Efficient networks for quantum factoring, Phys. Rev. A, 54, pp. 1034- 1063. Also on quant-ph/9602016.
[14] L.M.K. Vandersypen, M. Steffen, G. Breyta, C.S. Yannoni, M.H. Sher- wood, and I.L. Chuang (2001), Experimental realization of Shor’s quantum factoring algorithm using magnetic resonance, Nature, 414, pp. 883-887.
14
</Text>
        </Document>
    </Documents>
</SearchIndexes>